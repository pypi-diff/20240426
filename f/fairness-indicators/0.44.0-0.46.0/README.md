# Comparing `tmp/fairness_indicators-0.44.0-py3-none-any.whl.zip` & `tmp/fairness_indicators-0.46.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,18 +1,18 @@
-Zip file size: 24797 bytes, number of entries: 16
--rw-rw-r--  2.0 unx      717 b- defN 23-May-03 22:58 fairness_indicators/__init__.py
--rw-rw-r--  2.0 unx     5062 b- defN 23-May-03 22:58 fairness_indicators/example_model.py
--rw-rw-r--  2.0 unx     4656 b- defN 23-May-03 22:58 fairness_indicators/example_model_test.py
--rw-rw-r--  2.0 unx      718 b- defN 23-May-03 22:58 fairness_indicators/version.py
--rw-rw-r--  2.0 unx      596 b- defN 23-May-03 22:58 fairness_indicators/remediation/__init__.py
--rw-rw-r--  2.0 unx     3613 b- defN 23-May-03 22:58 fairness_indicators/remediation/weight_utils.py
--rw-rw-r--  2.0 unx     7739 b- defN 23-May-03 22:58 fairness_indicators/remediation/weight_utils_test.py
--rw-rw-r--  2.0 unx      795 b- defN 23-May-03 22:58 fairness_indicators/tutorial_utils/__init__.py
--rw-rw-r--  2.0 unx     7181 b- defN 23-May-03 22:58 fairness_indicators/tutorial_utils/util.py
--rw-rw-r--  2.0 unx    10697 b- defN 23-May-03 22:58 fairness_indicators/tutorial_utils/util_test.py
--rw-rw-r--  2.0 unx      596 b- defN 23-May-03 22:58 g3doc/__init__.py
--rw-rw-r--  2.0 unx    14103 b- defN 23-May-03 22:58 fairness_indicators-0.44.0.dist-info/LICENSE
--rw-rw-r--  2.0 unx    12321 b- defN 23-May-03 22:58 fairness_indicators-0.44.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-May-03 22:58 fairness_indicators-0.44.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       26 b- defN 23-May-03 22:58 fairness_indicators-0.44.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1508 b- defN 23-May-03 22:58 fairness_indicators-0.44.0.dist-info/RECORD
-16 files, 70420 bytes uncompressed, 22247 bytes compressed:  68.4%
+Zip file size: 24514 bytes, number of entries: 16
+-rw-r--r--  2.0 unx      717 b- defN 24-Apr-26 21:20 fairness_indicators/__init__.py
+-rw-r--r--  2.0 unx     3515 b- defN 24-Apr-26 21:20 fairness_indicators/example_model.py
+-rw-r--r--  2.0 unx     5595 b- defN 24-Apr-26 21:20 fairness_indicators/example_model_test.py
+-rw-r--r--  2.0 unx      718 b- defN 24-Apr-26 21:20 fairness_indicators/version.py
+-rw-r--r--  2.0 unx      596 b- defN 24-Apr-26 21:20 fairness_indicators/remediation/__init__.py
+-rw-r--r--  2.0 unx     3613 b- defN 24-Apr-26 21:20 fairness_indicators/remediation/weight_utils.py
+-rw-r--r--  2.0 unx     7739 b- defN 24-Apr-26 21:20 fairness_indicators/remediation/weight_utils_test.py
+-rw-r--r--  2.0 unx      795 b- defN 24-Apr-26 21:20 fairness_indicators/tutorial_utils/__init__.py
+-rw-r--r--  2.0 unx     7181 b- defN 24-Apr-26 21:20 fairness_indicators/tutorial_utils/util.py
+-rw-r--r--  2.0 unx    10741 b- defN 24-Apr-26 21:20 fairness_indicators/tutorial_utils/util_test.py
+-rw-r--r--  2.0 unx      596 b- defN 24-Apr-26 21:20 g3doc/__init__.py
+-rw-r--r--  2.0 unx    14103 b- defN 24-Apr-26 21:20 fairness_indicators-0.46.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    12426 b- defN 24-Apr-26 21:20 fairness_indicators-0.46.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-26 21:20 fairness_indicators-0.46.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       26 b- defN 24-Apr-26 21:20 fairness_indicators-0.46.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1508 b- defN 24-Apr-26 21:20 fairness_indicators-0.46.0.dist-info/RECORD
+16 files, 69961 bytes uncompressed, 21964 bytes compressed:  68.6%
```

## zipnote {}

```diff
@@ -27,23 +27,23 @@
 
 Filename: fairness_indicators/tutorial_utils/util_test.py
 Comment: 
 
 Filename: g3doc/__init__.py
 Comment: 
 
-Filename: fairness_indicators-0.44.0.dist-info/LICENSE
+Filename: fairness_indicators-0.46.0.dist-info/LICENSE
 Comment: 
 
-Filename: fairness_indicators-0.44.0.dist-info/METADATA
+Filename: fairness_indicators-0.46.0.dist-info/METADATA
 Comment: 
 
-Filename: fairness_indicators-0.44.0.dist-info/WHEEL
+Filename: fairness_indicators-0.46.0.dist-info/WHEEL
 Comment: 
 
-Filename: fairness_indicators-0.44.0.dist-info/top_level.txt
+Filename: fairness_indicators-0.46.0.dist-info/top_level.txt
 Comment: 
 
-Filename: fairness_indicators-0.44.0.dist-info/RECORD
+Filename: fairness_indicators-0.46.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## fairness_indicators/example_model.py

```diff
@@ -10,136 +10,96 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
 """Demo script to train and evaluate a model.
 
-This scripts contains boilerplate code to train a DNNClassifier
+This scripts contains boilerplate code to train a Keras Text Classifier
 and evaluate it using Tensorflow Model Analysis. Evaluation
 results can be visualized using tools like TensorBoard.
-
-Usage:
-
-1. Train model:
-  demo_script.train_model(...)
-
-2. Evaluate:
-  demo_script.evaluate_model(...)
 """
 
-import os
-import tempfile
+from tensorflow import keras
 import tensorflow.compat.v1 as tf
-from tensorflow.compat.v1 import estimator as tf_estimator
-import tensorflow_hub as hub
 import tensorflow_model_analysis as tfma
 from tensorflow_model_analysis.addons.fairness.post_export_metrics import fairness_indicators  # pylint: disable=unused-import
 
 
-def train_model(model_dir,
-                train_tf_file,
-                label,
-                text_feature,
-                feature_map,
-                module_spec='https://tfhub.dev/google/nnlm-en-dim128/1'):
-  """Train model using DNN Classifier.
-
-  Args:
-    model_dir: Directory path to save trained model.
-    train_tf_file: File containing training TFRecordDataset.
-    label: Groundtruth label.
-    text_feature: Text feature to be evaluated.
-    feature_map: Dict of feature names to their data type.
-    module_spec: A module spec defining the module to instantiate or a path
-      where to load a module spec.
-
-  Returns:
-    Trained DNNClassifier.
-  """
-
-  def train_input_fn():
-    """Train Input function."""
+TEXT_FEATURE = 'comment_text'
+LABEL = 'toxicity'
+SLICE = 'slice'
+FEATURE_MAP = {
+    LABEL: tf.io.FixedLenFeature([], tf.float32),
+    TEXT_FEATURE: tf.io.FixedLenFeature([], tf.string),
+    SLICE: tf.io.VarLenFeature(tf.string),
+}
+
+
+class ExampleParser(keras.layers.Layer):
+  """A Keras layer that parses the tf.Example."""
+
+  def __init__(self, input_feature_key):
+    self._input_feature_key = input_feature_key
+    super().__init__()
 
-    def parse_function(serialized):
+  def call(self, serialized_examples):
+    def get_feature(serialized_example):
       parsed_example = tf.io.parse_single_example(
-          serialized=serialized, features=feature_map)
-      # Adds a weight column to deal with unbalanced classes.
-      parsed_example['weight'] = tf.add(parsed_example[label], 0.1)
-      return (parsed_example, parsed_example[label])
-
-    train_dataset = tf.data.TFRecordDataset(
-        filenames=[train_tf_file]).map(parse_function).batch(512)
-    return train_dataset
-
-  text_embedding_column = hub.text_embedding_column(
-      key=text_feature, module_spec=module_spec)
-
-  classifier = tf_estimator.DNNClassifier(
-      hidden_units=[500, 100],
-      weight_column='weight',
-      feature_columns=[text_embedding_column],
-      n_classes=2,
-      optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),
-      model_dir=model_dir)
-
-  classifier.train(input_fn=train_input_fn, steps=1000)
-  return classifier
-
-
-def evaluate_model(classifier, validate_tf_file, tfma_eval_result_path,
-                   selected_slice, label, feature_map):
+          serialized_example, features=FEATURE_MAP
+      )
+      return parsed_example[self._input_feature_key]
+
+    return tf.map_fn(get_feature, serialized_examples)
+
+
+class ExampleModel(keras.Model):
+  """A Example Keras NLP model."""
+
+  def __init__(self, input_feature_key):
+    super().__init__()
+    self.parser = ExampleParser(input_feature_key)
+    self.text_vectorization = keras.layers.TextVectorization(
+        max_tokens=32,
+        output_mode='int',
+        output_sequence_length=32,
+    )
+    self.text_vectorization.adapt(
+        ['nontoxic', 'toxic comment', 'test comment', 'abc', 'abcdef', 'random']
+    )
+    self.dense1 = keras.layers.Dense(32, activation='relu')
+    self.dense2 = keras.layers.Dense(1)
+
+  def call(self, inputs, training=True, mask=None):
+    parsed_example = self.parser(inputs)
+    text_vector = self.text_vectorization(parsed_example)
+    output1 = self.dense1(tf.cast(text_vector, tf.float32))
+    output2 = self.dense2(output1)
+    return output2
+
+
+def evaluate_model(
+    classifier_model_path,
+    validate_tf_file_path,
+    tfma_eval_result_path,
+    eval_config,
+):
   """Evaluate Model using Tensorflow Model Analysis.
 
   Args:
-    classifier: Trained classifier model to be evaluted.
-    validate_tf_file: File containing validation TFRecordDataset.
-    tfma_eval_result_path: Directory path where eval results will be written.
-    selected_slice: Feature for slicing the data.
-    label: Groundtruth label.
-    feature_map: Dict of feature names to their data type.
+    classifier_model_path: Trained classifier model to be evaluted.
+    validate_tf_file_path: File containing validation TFRecordDataset.
+    tfma_eval_result_path: Path to export tfma-related eval path.
+    eval_config: tfma eval_config.
   """
 
-  def eval_input_receiver_fn():
-    """Eval Input Receiver function."""
-    serialized_tf_example = tf.compat.v1.placeholder(
-        dtype=tf.string, shape=[None], name='input_example_placeholder')
-
-    receiver_tensors = {'examples': serialized_tf_example}
-
-    features = tf.io.parse_example(serialized_tf_example, feature_map)
-    features['weight'] = tf.ones_like(features[label])
-
-    return tfma.export.EvalInputReceiver(
-        features=features,
-        receiver_tensors=receiver_tensors,
-        labels=features[label])
-
-  tfma_export_dir = tfma.export.export_eval_savedmodel(
-      estimator=classifier,
-      export_dir_base=os.path.join(tempfile.gettempdir(), 'tfma_eval_model'),
-      eval_input_receiver_fn=eval_input_receiver_fn)
-
-  # Define slices that you want the evaluation to run on.
-  slice_spec = [
-      tfma.slicer.SingleSliceSpec(),  # Overall slice
-      tfma.slicer.SingleSliceSpec(columns=[selected_slice]),
-  ]
-
-  # Add the fairness metrics.
-  # pytype: disable=module-attr
-  add_metrics_callbacks = [
-      tfma.post_export_metrics.fairness_indicators(
-          thresholds=[0.1, 0.3, 0.5, 0.7, 0.9], labels_key=label)
-  ]
-  # pytype: enable=module-attr
-
   eval_shared_model = tfma.default_eval_shared_model(
-      eval_saved_model_path=tfma_export_dir,
-      add_metrics_callbacks=add_metrics_callbacks)
+      eval_saved_model_path=classifier_model_path, eval_config=eval_config
+  )
 
   # Run the fairness evaluation.
   tfma.run_model_analysis(
       eval_shared_model=eval_shared_model,
-      data_location=validate_tf_file,
+      data_location=validate_tf_file_path,
       output_path=tfma_eval_result_path,
-      slice_spec=slice_spec)
+      eval_config=eval_config,
+  )
```

## fairness_indicators/example_model_test.py

```diff
@@ -17,51 +17,46 @@
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
 import datetime
 import os
 import tempfile
+
 from fairness_indicators import example_model
+import numpy as np
 import six
+from tensorflow import keras
 import tensorflow.compat.v1 as tf
 import tensorflow_model_analysis as tfma
-from tensorflow_model_analysis.slicer import slicer_lib as slicer
 
-tf.compat.v1.enable_eager_execution()
+from google.protobuf import text_format
 
-TEXT_FEATURE = 'comment_text'
-LABEL = 'toxicity'
-SLICE = 'slice'
-FEATURE_MAP = {
-    LABEL: tf.io.FixedLenFeature([], tf.float32),
-    TEXT_FEATURE: tf.io.FixedLenFeature([], tf.string),
-    SLICE: tf.io.VarLenFeature(tf.string),
-}
+tf.compat.v1.enable_eager_execution()
 
 
 class ExampleModelTest(tf.test.TestCase):
 
   def setUp(self):
     super(ExampleModelTest, self).setUp()
     self._base_dir = tempfile.gettempdir()
 
     self._model_dir = os.path.join(
         self._base_dir, 'train',
         datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))
 
   def _create_example(self, comment_text, label, slice_value):
     example = tf.train.Example()
-    example.features.feature[TEXT_FEATURE].bytes_list.value[:] = [
+    example.features.feature[example_model.TEXT_FEATURE].bytes_list.value[:] = [
         six.ensure_binary(comment_text, 'utf8')
     ]
-    example.features.feature[SLICE].bytes_list.value[:] = [
+    example.features.feature[example_model.SLICE].bytes_list.value[:] = [
         six.ensure_binary(slice_value, 'utf8')
     ]
-    example.features.feature[LABEL].float_list.value[:] = [label]
+    example.features.feature[example_model.LABEL].float_list.value[:] = [label]
     return example
 
   def _create_data(self):
     examples = []
     examples.append(self._create_example('test comment', 0.0, 'slice1'))
     examples.append(self._create_example('toxic comment', 1.0, 'slice1'))
     examples.append(self._create_example('non-toxic comment', 0.0, 'slice1'))
@@ -81,39 +76,89 @@
     data_location = os.path.join(self._base_dir, 'input_data.rio')
     with tf.io.TFRecordWriter(data_location) as writer:
       for example in examples:
         writer.write(example.SerializeToString())
     return data_location
 
   def test_example_model(self):
-    train_tf_file = self._write_tf_records(self._create_data())
-    classifier = example_model.train_model(self._model_dir, train_tf_file,
-                                           LABEL, TEXT_FEATURE, FEATURE_MAP)
+    data = self._create_data()
+    classifier = example_model.ExampleModel(example_model.TEXT_FEATURE)
+    classifier.compile(optimizer=keras.optimizers.Adam(), loss='mse')
+    classifier.fit(
+        tf.constant([e.SerializeToString() for e in data]),
+        np.array([
+            e.features.feature[example_model.LABEL].float_list.value[:][0]
+            for e in data
+        ]),
+    )
+    classifier.save(self._model_dir, save_format='tf')
+
+    eval_config = text_format.Parse(
+        """
+        model_specs {
+          signature_name: "serving_default"
+          prediction_key: "predictions" # placeholder
+          label_key: "toxicity" # placeholder
+        }
+        slicing_specs {}
+        slicing_specs {
+          feature_keys: ["slice"]
+        }
+        metrics_specs {
+          metrics {
+            class_name: "ExampleCount"
+          }
+          metrics {
+            class_name: "FairnessIndicators"
+          }
+        }
+  """,
+        tfma.EvalConfig(),
+    )
 
-    validate_tf_file = self._write_tf_records(self._create_data())
+    validate_tf_file_path = self._write_tf_records(data)
     tfma_eval_result_path = os.path.join(self._model_dir, 'tfma_eval_result')
-    example_model.evaluate_model(classifier, validate_tf_file,
-                                 tfma_eval_result_path, SLICE, LABEL,
-                                 FEATURE_MAP)
+    example_model.evaluate_model(
+        self._model_dir,
+        validate_tf_file_path,
+        tfma_eval_result_path,
+        eval_config,
+    )
 
-    expected_slice_keys = [
-        'Overall', 'slice:slice3', 'slice:slice1', 'slice:slice2'
-    ]
     evaluation_results = tfma.load_eval_result(tfma_eval_result_path)
 
-    self.assertLen(evaluation_results.slicing_metrics, 4)
-
-    # Verify if false_positive_rate metrics are computed for all values of
-    # slice.
-    for (slice_key, metric_value) in evaluation_results.slicing_metrics:
-      slice_key = slicer.stringify_slice_key(slice_key)
-      self.assertIn(slice_key, expected_slice_keys)
-      self.assertGreaterEqual(
-          1.0, metric_value['']['']
-          ['post_export_metrics/false_positive_rate@0.50']['doubleValue'])
-      self.assertLessEqual(
-          0.0, metric_value['']['']
-          ['post_export_metrics/false_positive_rate@0.50']['doubleValue'])
+    expected_slice_keys = [
+        (),
+        (('slice', 'slice1'),),
+        (('slice', 'slice2'),),
+        (('slice', 'slice3'),),
+    ]
+    slice_keys = [
+        slice_key for slice_key, _ in evaluation_results.slicing_metrics
+    ]
+    self.assertEqual(set(expected_slice_keys), set(slice_keys))
+    # Verify part of the metrics of fairness indicators
+    metric_values = dict(evaluation_results.slicing_metrics)[(
+        ('slice', 'slice1'),
+    )]['']['']
+    self.assertEqual(metric_values['example_count'], {'doubleValue': 5.0})
+
+    self.assertEqual(
+        metric_values['fairness_indicators_metrics/false_positive_rate@0.1'],
+        {'doubleValue': 0.0},
+    )
+    self.assertEqual(
+        metric_values['fairness_indicators_metrics/false_negative_rate@0.1'],
+        {'doubleValue': 1.0},
+    )
+    self.assertEqual(
+        metric_values['fairness_indicators_metrics/true_positive_rate@0.1'],
+        {'doubleValue': 0.0},
+    )
+    self.assertEqual(
+        metric_values['fairness_indicators_metrics/true_negative_rate@0.1'],
+        {'doubleValue': 1.0},
+    )
 
 
 if __name__ == '__main__':
   tf.test.main()
```

## fairness_indicators/version.py

```diff
@@ -10,8 +10,8 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 """Contains the version string of Fairness Indicators."""
 
 # Note that setup.py uses this version.
-__version__ = '0.44.0'
+__version__ = '0.46.0'
```

## fairness_indicators/tutorial_utils/util_test.py

```diff
@@ -250,29 +250,29 @@
     input_file = self._write_csv(self._create_example_csv())
     output_file = util.convert_comments_data(input_file)
 
     # Remove the quotes around identity terms list that read_csv injects.
     df = pd.read_csv(output_file).replace("'", '', regex=True)
 
     expected_df = pd.DataFrame()
-    expected_df = expected_df.append(
+    expected_df = pd.concat([expected_df, pd.DataFrame.from_dict(
         {
             'comment_text':
-                'comment 1',
+                ['comment 1'],
             'toxicity':
-                0.0,
-            'gender': [],
-            'sexual_orientation': ['bisexual'],
-            'race': ['other_race_or_ethnicity'],
-            'religion': ['atheist', 'other_religion'],
-            'disability': [
+                [0.0],
+            'gender': [[]],
+            'sexual_orientation': [['bisexual']],
+            'race': [['other_race_or_ethnicity']],
+            'religion': [['atheist', 'other_religion']],
+            'disability': [[
                 'physical_disability', 'intellectual_or_learning_disability',
                 'psychiatric_or_mental_illness', 'other_disability'
-            ]
-        },
+            ]]
+        })],
         ignore_index=True)
 
     self.assertEqual(
         df.reset_index(drop=True, inplace=True),
         expected_df.reset_index(drop=True, inplace=True))
 
   # TODO(b/172260507): we should also look into testing the e2e call with tfma.
```

## Comparing `fairness_indicators-0.44.0.dist-info/LICENSE` & `fairness_indicators-0.46.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `fairness_indicators-0.44.0.dist-info/METADATA` & `fairness_indicators-0.46.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,42 +1,41 @@
 Metadata-Version: 2.1
-Name: fairness-indicators
-Version: 0.44.0
+Name: fairness_indicators
+Version: 0.46.0
 Summary: Fairness Indicators
 Home-page: https://github.com/tensorflow/fairness-indicators
 Author: Google LLC
 Author-email: packages@tensorflow.org
 License: Apache 2.0
 Keywords: tensorflow model analysis fairness indicators tensorboard machine learning
 Platform: UNKNOWN
 Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Education
 Classifier: Intended Audience :: Science/Research
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Topic :: Scientific/Engineering
 Classifier: Topic :: Scientific/Engineering :: Mathematics
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Topic :: Software Development
 Classifier: Topic :: Software Development :: Libraries
 Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Requires-Python: >=3.8,<3.10
+Requires-Python: >=3.9,<4
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: tensorflow (<2.13,>=2.12.0)
-Requires-Dist: tensorflow-hub (<1.0.0,>=0.8.0)
-Requires-Dist: tensorflow-data-validation (<1.14.0,>=1.13.0)
-Requires-Dist: tensorflow-model-analysis (<0.45,>=0.44)
-Requires-Dist: witwidget (<2,>=1.4.4)
-Requires-Dist: protobuf (<5,>=3.20.3)
+Requires-Dist: tensorflow <2.16,>=2.15
+Requires-Dist: tensorflow-hub <1.0.0,>=0.16.1
+Requires-Dist: tensorflow-data-validation <2.0.0,>=1.15.1
+Requires-Dist: tensorflow-model-analysis <0.47,>=0.46
+Requires-Dist: witwidget <2,>=1.4.4
+Requires-Dist: protobuf <5,>=3.20.3
 
 # Fairness Indicators
 
 ![Fairness_Indicators](https://raw.githubusercontent.com/tensorflow/fairness-indicators/master/fairness_indicators/images/fairnessIndicators.png)
 
 Fairness Indicators is designed to support teams in evaluating, improving, and comparing models for fairness concerns in partnership with the broader Tensorflow toolkit.
 
@@ -117,15 +116,16 @@
 
 The following table shows the  package versions that are
 compatible with each other. This is determined by our testing framework, but
 other *untested* combinations may also work.
 
 |fairness-indicators                                                                        | tensorflow         | tensorflow-data-validation | tensorflow-model-analysis |
 |-------------------------------------------------------------------------------------------|--------------------|----------------------------|---------------------------|
-|[GitHub master](https://github.com/tensorflow/fairness-indicators/blob/master/RELEASE.md)  | nightly (1.x/2.x)  | 1.13.0                     | 0.44.0                    |
+|[GitHub master](https://github.com/tensorflow/fairness-indicators/blob/master/RELEASE.md)  | nightly (1.x/2.x)  | 1.15.1                     | 0.46.0                    |
+|[v0.46.0](https://github.com/tensorflow/fairness-indicators/blob/v0.44.0/RELEASE.md)       | 2.15               | 1.15.1                     | 0.46.0                    |
 |[v0.44.0](https://github.com/tensorflow/fairness-indicators/blob/v0.44.0/RELEASE.md)       | 2.12               | 1.13.0                     | 0.44.0                    |
 |[v0.43.0](https://github.com/tensorflow/fairness-indicators/blob/v0.43.0/RELEASE.md)       | 2.11               | 1.12.0                     | 0.43.0                    |
 |[v0.42.0](https://github.com/tensorflow/fairness-indicators/blob/v0.42.0/RELEASE.md)       | 1.15.5 / 2.10      | 1.11.0                     | 0.42.0                    |
 |[v0.41.0](https://github.com/tensorflow/fairness-indicators/blob/v0.41.0/RELEASE.md)       | 1.15.5 / 2.9       | 1.10.0                     | 0.41.0                    |
 |[v0.40.0](https://github.com/tensorflow/fairness-indicators/blob/v0.40.0/RELEASE.md)       | 1.15.5 / 2.9       | 1.9.0                      | 0.40.0                    |
 |[v0.39.0](https://github.com/tensorflow/fairness-indicators/blob/v0.39.0/RELEASE.md)       | 1.15.5 / 2.8       | 1.8.0                      | 0.39.0                    |
 |[v0.38.0](https://github.com/tensorflow/fairness-indicators/blob/v0.38.0/RELEASE.md)       | 1.15.5 / 2.8       | 1.7.0                      | 0.38.0                    |
```

## Comparing `fairness_indicators-0.44.0.dist-info/RECORD` & `fairness_indicators-0.46.0.dist-info/RECORD`

 * *Files 23% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 fairness_indicators/__init__.py,sha256=x-AYfJKWB8NO-DBRGxytHudHiz_lXgB7nDn0D1ewSbQ,717
-fairness_indicators/example_model.py,sha256=yz2DHaz09u8GvqqbgvSi6WBjodzp5KIw6jp-COJJ-qU,5062
-fairness_indicators/example_model_test.py,sha256=-kfMDiENivu2yr1ZNlXBPYaD4bO0_IzGfPONSZrCgU0,4656
-fairness_indicators/version.py,sha256=DwKQEUdxg-5xsjiFMAdBQgyBDjGH44VIGP1tSfKwMjk,718
+fairness_indicators/example_model.py,sha256=J8WkveVhF_Gh4fqPp3Fs-COmTNZwCIsOdhChYEdq89o,3515
+fairness_indicators/example_model_test.py,sha256=4SdxLcoO-cB4BFFW_7QOrEsFQLV-Jrbxw8jF9sPdf90,5595
+fairness_indicators/version.py,sha256=gSPtKRCa_p9C2s111DxhHpdlvR3MRM7q59Sv-zcsXTo,718
 fairness_indicators/remediation/__init__.py,sha256=ioT-KhgUpHbj9JBI--m171htICEninPDlylL72rOfuA,596
 fairness_indicators/remediation/weight_utils.py,sha256=zF7mtTtUh90rj67Lr0896jLMiPT935rW5ygk2D_EZB4,3613
 fairness_indicators/remediation/weight_utils_test.py,sha256=FGiaVYUt8S2lKB6QyE7rTu20Ep7GO2EVAhQzqjZYYSY,7739
 fairness_indicators/tutorial_utils/__init__.py,sha256=mrbnZSRFO5HziZAoAQaRm2MBRkBdUwX2H5XlDmynsEM,795
 fairness_indicators/tutorial_utils/util.py,sha256=XnpI834ZwAkJK4wBYgzWe-SexEAvSZE-upZfVDNAF0E,7181
-fairness_indicators/tutorial_utils/util_test.py,sha256=t5keach4ULdCTGIZAZGaAU0Cn_2FsckMqa1gPgh9GRQ,10697
+fairness_indicators/tutorial_utils/util_test.py,sha256=eyxMVfFxbOwXv1TAXFjh2dMgMkRmJOL_6B9eqTyixj4,10741
 g3doc/__init__.py,sha256=ioT-KhgUpHbj9JBI--m171htICEninPDlylL72rOfuA,596
-fairness_indicators-0.44.0.dist-info/LICENSE,sha256=l83YTEaxsmCmCOOCgb3Z6ACe0S8QLidC2LNnvZZkfEA,14103
-fairness_indicators-0.44.0.dist-info/METADATA,sha256=3HRzkuJ0tqHItYPDATvJx8vVjWmpBIPZwC9wBpfYvoE,12321
-fairness_indicators-0.44.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-fairness_indicators-0.44.0.dist-info/top_level.txt,sha256=kveXua1yj-xRx_ryo6MFPfRLAOT7ow6QfuRpmJrgcXM,26
-fairness_indicators-0.44.0.dist-info/RECORD,,
+fairness_indicators-0.46.0.dist-info/LICENSE,sha256=l83YTEaxsmCmCOOCgb3Z6ACe0S8QLidC2LNnvZZkfEA,14103
+fairness_indicators-0.46.0.dist-info/METADATA,sha256=Jg01Fs1eYZGuNuKAh4lFdBHUO4tUkLOlW546qL6Gsag,12426
+fairness_indicators-0.46.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+fairness_indicators-0.46.0.dist-info/top_level.txt,sha256=kveXua1yj-xRx_ryo6MFPfRLAOT7ow6QfuRpmJrgcXM,26
+fairness_indicators-0.46.0.dist-info/RECORD,,
```

