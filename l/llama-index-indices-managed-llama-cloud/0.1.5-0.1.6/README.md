# Comparing `tmp/llama_index_indices_managed_llama_cloud-0.1.5.tar.gz` & `tmp/llama_index_indices_managed_llama_cloud-0.1.6.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "llama_index_indices_managed_llama_cloud-0.1.5.tar", max compression
+gzip compressed data, was "llama_index_indices_managed_llama_cloud-0.1.6.tar", max compression
```

## Comparing `llama_index_indices_managed_llama_cloud-0.1.5.tar` & `llama_index_indices_managed_llama_cloud-0.1.6.tar`

### file list

```diff
@@ -1,9 +1,9 @@
--rw-r--r--   0        0        0     3188 2024-03-23 16:57:25.539338 llama_index_indices_managed_llama_cloud-0.1.5/README.md
--rw-r--r--   0        0        0      220 2024-03-23 16:57:25.539338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__init__.py
--rw-r--r--   0        0        0      527 2024-03-23 16:57:25.539338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/__init__.cpython-311.pyc
--rw-r--r--   0        0        0    11326 2024-03-23 16:57:25.539338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/base.cpython-311.pyc
--rw-r--r--   0        0        0     6348 2024-03-23 16:57:25.539338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/retriever.cpython-311.pyc
--rw-r--r--   0        0        0     8459 2024-03-23 16:57:25.543338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/base.py
--rw-r--r--   0        0        0     5311 2024-03-23 16:57:25.543338 llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/retriever.py
--rw-r--r--   0        0        0     1590 2024-03-23 16:57:25.543338 llama_index_indices_managed_llama_cloud-0.1.5/pyproject.toml
--rw-r--r--   0        0        0     3823 1970-01-01 00:00:00.000000 llama_index_indices_managed_llama_cloud-0.1.5/PKG-INFO
+-rw-r--r--   0        0        0     3188 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/README.md
+-rw-r--r--   0        0        0      220 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__init__.py
+-rw-r--r--   0        0        0      527 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/__init__.cpython-311.pyc
+-rw-r--r--   0        0        0    11326 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/base.cpython-311.pyc
+-rw-r--r--   0        0        0     6348 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/retriever.cpython-311.pyc
+-rw-r--r--   0        0        0     8459 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/base.py
+-rw-r--r--   0        0        0     5330 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/retriever.py
+-rw-r--r--   0        0        0     1590 2024-04-26 16:43:55.499899 llama_index_indices_managed_llama_cloud-0.1.6/pyproject.toml
+-rw-r--r--   0        0        0     3823 1970-01-01 00:00:00.000000 llama_index_indices_managed_llama_cloud-0.1.6/PKG-INFO
```

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/README.md` & `llama_index_indices_managed_llama_cloud-0.1.6/README.md`

 * *Files identical despite different names*

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/__init__.cpython-311.pyc` & `llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/__init__.cpython-311.pyc`

 * *Files identical despite different names*

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/base.cpython-311.pyc` & `llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/base.cpython-311.pyc`

 * *Files identical despite different names*

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/__pycache__/retriever.cpython-311.pyc` & `llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/__pycache__/retriever.cpython-311.pyc`

 * *Files identical despite different names*

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/base.py` & `llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/base.py`

 * *Files identical despite different names*

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/llama_index/indices/managed/llama_cloud/retriever.py` & `llama_index_indices_managed_llama_cloud-0.1.6/llama_index/indices/managed/llama_cloud/retriever.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,30 @@
-from typing import Any, Dict, List, Optional
+from typing import Any, List, Optional
 
 from llama_index_client import TextNodeWithScore
 from llama_index_client.resources.pipeline.client import OMIT, PipelineType
 
 from llama_index.core.base.base_retriever import BaseRetriever
 from llama_index.core.constants import DEFAULT_PROJECT_NAME
 from llama_index.core.ingestion.api_utils import get_aclient, get_client
 from llama_index.core.schema import NodeWithScore, QueryBundle, TextNode
+from llama_index.core.vector_stores.types import MetadataFilters
 
 
 class LlamaCloudRetriever(BaseRetriever):
     def __init__(
         self,
         name: str,
         project_name: str = DEFAULT_PROJECT_NAME,
         dense_similarity_top_k: Optional[int] = None,
         sparse_similarity_top_k: Optional[int] = None,
         enable_reranking: Optional[bool] = None,
         rerank_top_n: Optional[int] = None,
         alpha: Optional[float] = None,
-        search_filters: Optional[Dict[str, List[Any]]] = None,
+        filters: Optional[MetadataFilters] = None,
         api_key: Optional[str] = None,
         base_url: Optional[str] = None,
         app_url: Optional[str] = None,
         timeout: int = 60,
         **kwargs: Any,
     ) -> None:
         """Initialize the Platform Retriever."""
@@ -37,15 +38,15 @@
             raise ValueError(f"No project found with name {project_name}")
 
         self._dense_similarity_top_k = dense_similarity_top_k or OMIT
         self._sparse_similarity_top_k = sparse_similarity_top_k or OMIT
         self._enable_reranking = enable_reranking or OMIT
         self._rerank_top_n = rerank_top_n or OMIT
         self._alpha = alpha or OMIT
-        self._search_filters = search_filters or OMIT
+        self._filters = filters or OMIT
 
         super().__init__(
             callback_manager=kwargs.get("callback_manager", None),
             verbose=kwargs.get("verbose", False),
         )
 
     def _result_nodes_to_node_with_score(
@@ -85,15 +86,15 @@
             query=query_bundle.query_str,
             pipeline_id=pipeline.id,
             dense_similarity_top_k=self._dense_similarity_top_k,
             sparse_similarity_top_k=self._sparse_similarity_top_k,
             enable_reranking=self._enable_reranking,
             rerank_top_n=self._rerank_top_n,
             alpha=self._alpha,
-            search_filters=self._search_filters,
+            search_filters=self._filters,
         )
 
         result_nodes = results.retrieval_nodes
 
         return self._result_nodes_to_node_with_score(result_nodes)
 
     async def _aretrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
@@ -123,13 +124,13 @@
             query=query_bundle.query_str,
             pipeline_id=pipeline.id,
             dense_similarity_top_k=self._dense_similarity_top_k,
             sparse_similarity_top_k=self._sparse_similarity_top_k,
             enable_reranking=self._enable_reranking,
             rerank_top_n=self._rerank_top_n,
             alpha=self._alpha,
-            search_filters=self._search_filters,
+            search_filters=self._filters,
         )
 
         result_nodes = results.retrieval_nodes
 
         return self._result_nodes_to_node_with_score(result_nodes)
```

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/pyproject.toml` & `llama_index_indices_managed_llama_cloud-0.1.6/pyproject.toml`

 * *Files 1% similar despite different names*

```diff
@@ -26,20 +26,20 @@
 [tool.poetry]
 authors = ["Logan Markewich <logan@llamaindex.ai>"]
 description = "llama-index indices llama-cloud integration"
 exclude = ["**/BUILD"]
 license = "MIT"
 name = "llama-index-indices-managed-llama-cloud"
 readme = "README.md"
-version = "0.1.5"
+version = "0.1.6"
 
 [tool.poetry.dependencies]
 python = ">=3.8.1,<4.0"
 llama-index-core = "^0.10.0"
-llamaindex-py-client = "^0.1.13"
+llamaindex-py-client = "^0.1.19"
 
 [tool.poetry.group.dev.dependencies]
 ipython = "8.10.0"
 jupyter = "^1.0.0"
 mypy = "0.991"
 pre-commit = "3.2.0"
 pylint = "2.15.10"
```

### Comparing `llama_index_indices_managed_llama_cloud-0.1.5/PKG-INFO` & `llama_index_indices_managed_llama_cloud-0.1.6/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 Metadata-Version: 2.1
 Name: llama-index-indices-managed-llama-cloud
-Version: 0.1.5
+Version: 0.1.6
 Summary: llama-index indices llama-cloud integration
 License: MIT
 Author: Logan Markewich
 Author-email: logan@llamaindex.ai
 Requires-Python: >=3.8.1,<4.0
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Requires-Dist: llama-index-core (>=0.10.0,<0.11.0)
-Requires-Dist: llamaindex-py-client (>=0.1.13,<0.2.0)
+Requires-Dist: llamaindex-py-client (>=0.1.19,<0.2.0)
 Description-Content-Type: text/markdown
 
 # LlamaCloud Index + Retriever
 
 LlamaCloud is a new generation of managed parsing, ingestion, and retrieval services, designed to bring production-grade context-augmentation to your LLM and RAG applications.
 
 Currently, LlamaCloud supports
```

