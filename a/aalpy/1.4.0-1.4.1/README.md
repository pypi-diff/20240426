# Comparing `tmp/aalpy-1.4.0-py3-none-any.whl.zip` & `tmp/aalpy-1.4.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,80 +1,80 @@
-Zip file size: 126395 bytes, number of entries: 78
--rw-rw-rw-  2.0 fat     2109 b- defN 23-Dec-20 18:18 aalpy/__init__.py
--rw-rw-rw-  2.0 fat      460 b- defN 21-Sep-14 17:40 aalpy/paths.py
--rw-rw-rw-  2.0 fat      505 b- defN 23-Dec-18 14:49 aalpy/SULs/AutomataSUL.py
--rw-rw-rw-  2.0 fat     1745 b- defN 22-Apr-26 12:31 aalpy/SULs/PyMethodSUL.py
--rw-rw-rw-  2.0 fat      943 b- defN 21-Oct-18 11:17 aalpy/SULs/RegexSUL.py
--rw-rw-rw-  2.0 fat     1546 b- defN 21-Sep-14 17:40 aalpy/SULs/TomitaSUL.py
--rw-rw-rw-  2.0 fat      150 b- defN 23-Dec-18 14:49 aalpy/SULs/__init__.py
--rw-rw-rw-  2.0 fat     3742 b- defN 23-Dec-18 14:49 aalpy/automata/Dfa.py
--rw-rw-rw-  2.0 fat     2089 b- defN 23-Dec-18 14:49 aalpy/automata/MarkovChain.py
--rw-rw-rw-  2.0 fat     3203 b- defN 23-Dec-18 14:49 aalpy/automata/Mdp.py
--rw-rw-rw-  2.0 fat     3287 b- defN 23-Dec-18 14:49 aalpy/automata/MealyMachine.py
--rw-rw-rw-  2.0 fat     3677 b- defN 23-Dec-18 14:49 aalpy/automata/MooreMachine.py
--rw-rw-rw-  2.0 fat     3037 b- defN 23-Dec-18 14:49 aalpy/automata/Onfsm.py
--rw-rw-rw-  2.0 fat    24177 b- defN 23-Dec-18 14:49 aalpy/automata/Sevpa.py
--rw-rw-rw-  2.0 fat     5044 b- defN 23-Dec-18 14:49 aalpy/automata/StochasticMealyMachine.py
--rw-rw-rw-  2.0 fat      405 b- defN 23-Dec-18 14:49 aalpy/automata/__init__.py
--rw-rw-rw-  2.0 fat    17238 b- defN 23-Dec-20 18:18 aalpy/base/Automaton.py
--rw-rw-rw-  2.0 fat     5736 b- defN 22-Nov-26 15:50 aalpy/base/CacheTree.py
--rw-rw-rw-  2.0 fat     1229 b- defN 21-Sep-14 17:40 aalpy/base/Oracle.py
--rw-rw-rw-  2.0 fat     4120 b- defN 22-Nov-26 15:50 aalpy/base/SUL.py
--rw-rw-rw-  2.0 fat      124 b- defN 22-Jan-09 13:33 aalpy/base/__init__.py
--rw-rw-rw-  2.0 fat      587 b- defN 23-Dec-18 14:49 aalpy/learning_algs/__init__.py
--rw-rw-rw-  2.0 fat    21155 b- defN 23-Dec-18 14:49 aalpy/learning_algs/deterministic/ClassificationTree.py
--rw-rw-rw-  2.0 fat     7034 b- defN 23-Dec-18 14:49 aalpy/learning_algs/deterministic/CounterExampleProcessing.py
--rw-rw-rw-  2.0 fat     6767 b- defN 23-Dec-20 18:18 aalpy/learning_algs/deterministic/KV.py
--rw-rw-rw-  2.0 fat     8335 b- defN 23-Dec-20 18:18 aalpy/learning_algs/deterministic/LStar.py
--rw-rw-rw-  2.0 fat     8318 b- defN 23-Sep-27 14:46 aalpy/learning_algs/deterministic/ObservationTable.py
--rw-rw-rw-  2.0 fat        0 b- defN 21-Sep-14 17:40 aalpy/learning_algs/deterministic/__init__.py
--rw-rw-rw-  2.0 fat     4060 b- defN 23-Aug-30 20:09 aalpy/learning_algs/deterministic_passive/GeneralizedStateMerging.py
--rw-rw-rw-  2.0 fat     7807 b- defN 23-Aug-30 20:09 aalpy/learning_algs/deterministic_passive/RPNI.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 19:51 aalpy/learning_algs/deterministic_passive/__init__.py
--rw-rw-rw-  2.0 fat     1880 b- defN 23-Jul-28 16:15 aalpy/learning_algs/deterministic_passive/active_RPNI.py
--rw-rw-rw-  2.0 fat     9298 b- defN 23-Aug-30 20:09 aalpy/learning_algs/deterministic_passive/rpni_helper_functions.py
--rw-rw-rw-  2.0 fat     6426 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/AbstractedOnfsmLstar.py
--rw-rw-rw-  2.0 fat    15947 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/AbstractedOnfsmObservationTable.py
--rw-rw-rw-  2.0 fat      659 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/NonDeterministicSULWrapper.py
--rw-rw-rw-  2.0 fat     5020 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/OnfsmLstar.py
--rw-rw-rw-  2.0 fat     7032 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/OnfsmObservationTable.py
--rw-rw-rw-  2.0 fat     6011 b- defN 22-Oct-28 12:49 aalpy/learning_algs/non_deterministic/TraceTree.py
--rw-rw-rw-  2.0 fat        0 b- defN 21-Sep-14 17:40 aalpy/learning_algs/non_deterministic/__init__.py
--rw-rw-rw-  2.0 fat     7764 b- defN 22-Nov-14 20:28 aalpy/learning_algs/stochastic/DifferenceChecker.py
--rw-rw-rw-  2.0 fat    25536 b- defN 23-Jul-28 16:15 aalpy/learning_algs/stochastic/SamplingBasedObservationTable.py
--rw-rw-rw-  2.0 fat     3426 b- defN 22-Sep-14 14:23 aalpy/learning_algs/stochastic/StochasticCexProcessing.py
--rw-rw-rw-  2.0 fat    10173 b- defN 23-Aug-30 20:09 aalpy/learning_algs/stochastic/StochasticLStar.py
--rw-rw-rw-  2.0 fat    13239 b- defN 23-Jul-28 16:15 aalpy/learning_algs/stochastic/StochasticTeacher.py
--rw-rw-rw-  2.0 fat        0 b- defN 21-Sep-14 17:40 aalpy/learning_algs/stochastic/__init__.py
--rw-rw-rw-  2.0 fat     2892 b- defN 23-Sep-29 17:54 aalpy/learning_algs/stochastic_passive/ActiveAleriga.py
--rw-rw-rw-  2.0 fat    10137 b- defN 23-Sep-29 18:00 aalpy/learning_algs/stochastic_passive/Alergia.py
--rw-rw-rw-  2.0 fat     1757 b- defN 23-Sep-29 18:00 aalpy/learning_algs/stochastic_passive/CompatibilityChecker.py
--rw-rw-rw-  2.0 fat     3153 b- defN 23-Oct-13 14:01 aalpy/learning_algs/stochastic_passive/FPTA.py
--rw-rw-rw-  2.0 fat        0 b- defN 21-Sep-14 17:40 aalpy/learning_algs/stochastic_passive/__init__.py
--rw-rw-rw-  2.0 fat     1433 b- defN 22-Feb-15 18:15 aalpy/oracles/BreadthFirstExplorationEqOracle.py
--rw-rw-rw-  2.0 fat     3135 b- defN 21-Sep-14 17:40 aalpy/oracles/CacheBasedEqOracle.py
--rw-rw-rw-  2.0 fat     1670 b- defN 22-Jan-09 13:33 aalpy/oracles/PacOracle.py
--rw-rw-rw-  2.0 fat      622 b- defN 23-Sep-29 19:10 aalpy/oracles/PerfectKnowledgeEqOracle.py
--rw-rw-rw-  2.0 fat     1670 b- defN 23-Sep-27 13:41 aalpy/oracles/ProvidedSequencesOracleWrapper.py
--rw-rw-rw-  2.0 fat     2986 b- defN 22-May-13 10:37 aalpy/oracles/RandomWalkEqOracle.py
--rw-rw-rw-  2.0 fat     3438 b- defN 22-Nov-26 15:50 aalpy/oracles/RandomWordEqOracle.py
--rw-rw-rw-  2.0 fat     2816 b- defN 22-Nov-26 15:50 aalpy/oracles/StatePrefixEqOracle.py
--rw-rw-rw-  2.0 fat     2023 b- defN 22-Nov-26 15:50 aalpy/oracles/TransitionFocusOracle.py
--rw-rw-rw-  2.0 fat     2636 b- defN 22-Jan-31 13:33 aalpy/oracles/UserInputEqOracle.py
--rw-rw-rw-  2.0 fat     4522 b- defN 23-Sep-27 13:41 aalpy/oracles/WMethodEqOracle.py
--rw-rw-rw-  2.0 fat      781 b- defN 23-Sep-29 19:10 aalpy/oracles/__init__.py
--rw-rw-rw-  2.0 fat     2676 b- defN 22-Nov-26 15:50 aalpy/oracles/kWayStateCoverageEqOracle.py
--rw-rw-rw-  2.0 fat     6429 b- defN 22-Nov-26 15:50 aalpy/oracles/kWayTransitionCoverageEqOracle.py
--rw-rw-rw-  2.0 fat    22736 b- defN 23-Dec-18 14:49 aalpy/utils/AutomatonGenerators.py
--rw-rw-rw-  2.0 fat    13340 b- defN 23-Dec-18 14:49 aalpy/utils/BenchmarkSULs.py
--rw-rw-rw-  2.0 fat    11066 b- defN 23-Dec-18 14:49 aalpy/utils/BenchmarkSevpaModels.py
--rw-rw-rw-  2.0 fat     2226 b- defN 21-Sep-14 17:40 aalpy/utils/DataHandler.py
--rw-rw-rw-  2.0 fat    15209 b- defN 23-Dec-18 14:49 aalpy/utils/FileHandler.py
--rw-rw-rw-  2.0 fat    11482 b- defN 23-Dec-20 18:18 aalpy/utils/HelperFunctions.py
--rw-rw-rw-  2.0 fat    16196 b- defN 23-Dec-20 18:18 aalpy/utils/ModelChecking.py
--rw-rw-rw-  2.0 fat      850 b- defN 23-Dec-18 14:49 aalpy/utils/__init__.py
--rw-rw-rw-  2.0 fat     1202 b- defN 23-Dec-21 17:23 aalpy-1.4.0.dist-info/LICENCE.txt
--rw-rw-rw-  2.0 fat    10329 b- defN 23-Dec-21 17:23 aalpy-1.4.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 23-Dec-21 17:23 aalpy-1.4.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        6 b- defN 23-Dec-21 17:23 aalpy-1.4.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     7381 b- defN 23-Dec-21 17:23 aalpy-1.4.0.dist-info/RECORD
-78 files, 427931 bytes uncompressed, 114435 bytes compressed:  73.3%
+Zip file size: 125807 bytes, number of entries: 78
+-rw-rw-rw-  2.0 fat     2015 b- defN 24-Feb-01 14:42 aalpy/__init__.py
+-rw-rw-rw-  2.0 fat      448 b- defN 21-Oct-28 09:31 aalpy/paths.py
+-rw-rw-rw-  2.0 fat      485 b- defN 24-Feb-01 14:42 aalpy/SULs/AutomataSUL.py
+-rw-rw-rw-  2.0 fat     1677 b- defN 23-Jun-12 10:49 aalpy/SULs/PyMethodSUL.py
+-rw-rw-rw-  2.0 fat      906 b- defN 21-Nov-02 09:32 aalpy/SULs/RegexSUL.py
+-rw-rw-rw-  2.0 fat     1478 b- defN 21-Nov-02 09:32 aalpy/SULs/TomitaSUL.py
+-rw-rw-rw-  2.0 fat      146 b- defN 24-Feb-01 14:42 aalpy/SULs/__init__.py
+-rw-rw-rw-  2.0 fat     3639 b- defN 24-Feb-01 14:42 aalpy/automata/Dfa.py
+-rw-rw-rw-  2.0 fat     2019 b- defN 24-Feb-01 14:42 aalpy/automata/MarkovChain.py
+-rw-rw-rw-  2.0 fat     3109 b- defN 24-Feb-01 14:42 aalpy/automata/Mdp.py
+-rw-rw-rw-  2.0 fat     3193 b- defN 24-Feb-01 14:42 aalpy/automata/MealyMachine.py
+-rw-rw-rw-  2.0 fat     3575 b- defN 24-Feb-01 14:42 aalpy/automata/MooreMachine.py
+-rw-rw-rw-  2.0 fat     2929 b- defN 24-Feb-01 14:42 aalpy/automata/Onfsm.py
+-rw-rw-rw-  2.0 fat    23609 b- defN 24-Feb-01 14:42 aalpy/automata/Sevpa.py
+-rw-rw-rw-  2.0 fat     4899 b- defN 24-Feb-01 14:42 aalpy/automata/StochasticMealyMachine.py
+-rw-rw-rw-  2.0 fat      397 b- defN 24-Feb-01 14:42 aalpy/automata/__init__.py
+-rw-rw-rw-  2.0 fat    16904 b- defN 24-Mar-14 09:09 aalpy/base/Automaton.py
+-rw-rw-rw-  2.0 fat     5567 b- defN 24-Feb-01 14:42 aalpy/base/CacheTree.py
+-rw-rw-rw-  2.0 fat     1178 b- defN 22-Nov-03 09:46 aalpy/base/Oracle.py
+-rw-rw-rw-  2.0 fat     4066 b- defN 24-Mar-19 06:54 aalpy/base/SUL.py
+-rw-rw-rw-  2.0 fat      121 b- defN 21-Dec-13 13:25 aalpy/base/__init__.py
+-rw-rw-rw-  2.0 fat      577 b- defN 24-Feb-01 14:42 aalpy/learning_algs/__init__.py
+-rw-rw-rw-  2.0 fat    20713 b- defN 24-Mar-14 10:28 aalpy/learning_algs/deterministic/ClassificationTree.py
+-rw-rw-rw-  2.0 fat     6815 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic/CounterExampleProcessing.py
+-rw-rw-rw-  2.0 fat     6597 b- defN 24-Mar-14 10:28 aalpy/learning_algs/deterministic/KV.py
+-rw-rw-rw-  2.0 fat     8145 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic/LStar.py
+-rw-rw-rw-  2.0 fat     8099 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic/ObservationTable.py
+-rw-rw-rw-  2.0 fat        0 b- defN 21-Mar-19 08:28 aalpy/learning_algs/deterministic/__init__.py
+-rw-rw-rw-  2.0 fat     3954 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic_passive/GeneralizedStateMerging.py
+-rw-rw-rw-  2.0 fat     7619 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic_passive/RPNI.py
+-rw-rw-rw-  2.0 fat        0 b- defN 22-Aug-17 08:52 aalpy/learning_algs/deterministic_passive/__init__.py
+-rw-rw-rw-  2.0 fat     1818 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic_passive/active_RPNI.py
+-rw-rw-rw-  2.0 fat     9033 b- defN 24-Feb-01 14:42 aalpy/learning_algs/deterministic_passive/rpni_helper_functions.py
+-rw-rw-rw-  2.0 fat     6280 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/AbstractedOnfsmLstar.py
+-rw-rw-rw-  2.0 fat    15505 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/AbstractedOnfsmObservationTable.py
+-rw-rw-rw-  2.0 fat      634 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/NonDeterministicSULWrapper.py
+-rw-rw-rw-  2.0 fat     4870 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/OnfsmLstar.py
+-rw-rw-rw-  2.0 fat     6828 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/OnfsmObservationTable.py
+-rw-rw-rw-  2.0 fat     5808 b- defN 24-Feb-01 14:42 aalpy/learning_algs/non_deterministic/TraceTree.py
+-rw-rw-rw-  2.0 fat        0 b- defN 21-Mar-19 08:28 aalpy/learning_algs/non_deterministic/__init__.py
+-rw-rw-rw-  2.0 fat     7587 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic/DifferenceChecker.py
+-rw-rw-rw-  2.0 fat    24894 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic/SamplingBasedObservationTable.py
+-rw-rw-rw-  2.0 fat     3296 b- defN 23-Nov-23 09:07 aalpy/learning_algs/stochastic/StochasticCexProcessing.py
+-rw-rw-rw-  2.0 fat     9953 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic/StochasticLStar.py
+-rw-rw-rw-  2.0 fat    12846 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic/StochasticTeacher.py
+-rw-rw-rw-  2.0 fat        0 b- defN 21-Apr-05 18:15 aalpy/learning_algs/stochastic/__init__.py
+-rw-rw-rw-  2.0 fat     2804 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic_passive/ActiveAleriga.py
+-rw-rw-rw-  2.0 fat     9869 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic_passive/Alergia.py
+-rw-rw-rw-  2.0 fat     1707 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic_passive/CompatibilityChecker.py
+-rw-rw-rw-  2.0 fat     3065 b- defN 24-Feb-01 14:42 aalpy/learning_algs/stochastic_passive/FPTA.py
+-rw-rw-rw-  2.0 fat        0 b- defN 21-Oct-28 09:31 aalpy/learning_algs/stochastic_passive/__init__.py
+-rw-rw-rw-  2.0 fat     1382 b- defN 22-Nov-15 10:54 aalpy/oracles/BreadthFirstExplorationEqOracle.py
+-rw-rw-rw-  2.0 fat     3038 b- defN 22-Nov-15 10:54 aalpy/oracles/CacheBasedEqOracle.py
+-rw-rw-rw-  2.0 fat     1670 b- defN 21-Dec-23 10:55 aalpy/oracles/PacOracle.py
+-rw-rw-rw-  2.0 fat      607 b- defN 24-Feb-01 14:42 aalpy/oracles/PerfectKnowledgeEqOracle.py
+-rw-rw-rw-  2.0 fat     1624 b- defN 24-Feb-01 14:42 aalpy/oracles/ProvidedSequencesOracleWrapper.py
+-rw-rw-rw-  2.0 fat     2898 b- defN 23-Nov-23 09:07 aalpy/oracles/RandomWalkEqOracle.py
+-rw-rw-rw-  2.0 fat     3343 b- defN 24-Feb-01 14:42 aalpy/oracles/RandomWordEqOracle.py
+-rw-rw-rw-  2.0 fat     2738 b- defN 24-Feb-01 14:42 aalpy/oracles/StatePrefixEqOracle.py
+-rw-rw-rw-  2.0 fat     1970 b- defN 24-Feb-01 14:42 aalpy/oracles/TransitionFocusOracle.py
+-rw-rw-rw-  2.0 fat     2567 b- defN 22-Jan-31 15:32 aalpy/oracles/UserInputEqOracle.py
+-rw-rw-rw-  2.0 fat     4399 b- defN 24-Feb-01 14:42 aalpy/oracles/WMethodEqOracle.py
+-rw-rw-rw-  2.0 fat      768 b- defN 24-Feb-01 14:42 aalpy/oracles/__init__.py
+-rw-rw-rw-  2.0 fat     2595 b- defN 24-Feb-01 14:42 aalpy/oracles/kWayStateCoverageEqOracle.py
+-rw-rw-rw-  2.0 fat     6264 b- defN 24-Feb-01 14:42 aalpy/oracles/kWayTransitionCoverageEqOracle.py
+-rw-rw-rw-  2.0 fat    21736 b- defN 24-Apr-24 11:20 aalpy/utils/AutomatonGenerators.py
+-rw-rw-rw-  2.0 fat    12908 b- defN 24-Feb-01 14:42 aalpy/utils/BenchmarkSULs.py
+-rw-rw-rw-  2.0 fat    10773 b- defN 24-Feb-01 14:42 aalpy/utils/BenchmarkSevpaModels.py
+-rw-rw-rw-  2.0 fat     2153 b- defN 21-Nov-02 09:32 aalpy/utils/DataHandler.py
+-rw-rw-rw-  2.0 fat    18958 b- defN 24-Mar-19 11:42 aalpy/utils/FileHandler.py
+-rw-rw-rw-  2.0 fat    11157 b- defN 24-Feb-01 14:42 aalpy/utils/HelperFunctions.py
+-rw-rw-rw-  2.0 fat    15774 b- defN 24-Feb-01 14:42 aalpy/utils/ModelChecking.py
+-rw-rw-rw-  2.0 fat      841 b- defN 24-Feb-01 14:42 aalpy/utils/__init__.py
+-rw-rw-rw-  2.0 fat     1181 b- defN 24-Apr-26 09:14 aalpy-1.4.1.dist-info/LICENCE.txt
+-rw-rw-rw-  2.0 fat    10325 b- defN 24-Apr-26 09:14 aalpy-1.4.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 24-Apr-26 09:14 aalpy-1.4.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        6 b- defN 24-Apr-26 09:14 aalpy-1.4.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     7379 b- defN 24-Apr-26 09:14 aalpy-1.4.1.dist-info/RECORD
+78 files, 420827 bytes uncompressed, 113847 bytes compressed:  72.9%
```

## zipnote {}

```diff
@@ -213,23 +213,23 @@
 
 Filename: aalpy/utils/ModelChecking.py
 Comment: 
 
 Filename: aalpy/utils/__init__.py
 Comment: 
 
-Filename: aalpy-1.4.0.dist-info/LICENCE.txt
+Filename: aalpy-1.4.1.dist-info/LICENCE.txt
 Comment: 
 
-Filename: aalpy-1.4.0.dist-info/METADATA
+Filename: aalpy-1.4.1.dist-info/METADATA
 Comment: 
 
-Filename: aalpy-1.4.0.dist-info/WHEEL
+Filename: aalpy-1.4.1.dist-info/WHEEL
 Comment: 
 
-Filename: aalpy-1.4.0.dist-info/top_level.txt
+Filename: aalpy-1.4.1.dist-info/top_level.txt
 Comment: 
 
-Filename: aalpy-1.4.0.dist-info/RECORD
+Filename: aalpy-1.4.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## aalpy/__init__.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-from .automata import (
-    Dfa,
-    DfaState,
-    MarkovChain,
-    McState,
-    Mdp,
-    MdpState,
-    MealyMachine,
-    MealyState,
-    MooreMachine,
-    MooreState,
-    Onfsm,
-    OnfsmState,
-    Sevpa,
-    SevpaAlphabet,
-    SevpaState,
-    SevpaTransition,
-    StochasticMealyMachine,
-    StochasticMealyState,
-)
-from .base import (
-    SUL,
-    Automaton,
-    AutomatonState,
-    CacheTree,
-    DeterministicAutomaton,
-    Oracle,
-)
-from .learning_algs import (
-    run_abstracted_ONFSM_Lstar,
-    run_active_Alergia,
-    run_active_RPNI,
-    run_Alergia,
-    run_JAlergia,
-    run_KV,
-    run_Lstar,
-    run_non_det_Lstar,
-    run_RPNI,
-    run_stochastic_Lstar,
-)
-from .oracles import (
-    BreadthFirstExplorationEqOracle,
-    CacheBasedEqOracle,
-    KWayStateCoverageEqOracle,
-    KWayTransitionCoverageEqOracle,
-    PacOracle,
-    PerfectKnowledgeEqOracle,
-    ProvidedSequencesOracleWrapper,
-    RandomWalkEqOracle,
-    RandomWMethodEqOracle,
-    RandomWordEqOracle,
-    StatePrefixEqOracle,
-    TransitionFocusOracle,
-    UserInputEqOracle,
-    WMethodEqOracle,
-    kWayStateCoverageEqOracle,
-    kWayTransitionCoverageEqOracle,
-)
-from .SULs import (
-    AutomatonSUL, 
-    FunctionDecorator, 
-    PyClassSUL, 
-    RegexSUL, 
-    TomitaSUL
-)
-from .utils import (
-    CharacterTokenizer,
-    DataHandler,
-    DelimiterTokenizer,
-    IODelimiterTokenizer,
-    bisimilar,
-    compare_automata,
-    convert_i_o_traces_for_RPNI,
-    generate_random_deterministic_automata,
-    generate_random_dfa,
-    generate_random_markov_chain,
-    generate_random_mdp,
-    generate_random_mealy_machine,
-    generate_random_moore_machine,
-    generate_random_ONFSM,
-    generate_random_sevpa,
-    generate_random_smm,
-    generate_test_cases,
-    get_correct_prop_values,
-    get_properties_file,
-    load_automaton_from_file,
-    make_input_complete,
-    mdp_2_prism_format,
-    model_check_experiment,
-    model_check_properties,
-    save_automaton_to_file,
-    statistical_model_checking,
-    visualize_automaton,
-)
+from .automata import (
+    Dfa,
+    DfaState,
+    MarkovChain,
+    McState,
+    Mdp,
+    MdpState,
+    MealyMachine,
+    MealyState,
+    MooreMachine,
+    MooreState,
+    Onfsm,
+    OnfsmState,
+    Sevpa,
+    SevpaAlphabet,
+    SevpaState,
+    SevpaTransition,
+    StochasticMealyMachine,
+    StochasticMealyState,
+)
+from .base import (
+    SUL,
+    Automaton,
+    AutomatonState,
+    CacheTree,
+    DeterministicAutomaton,
+    Oracle,
+)
+from .learning_algs import (
+    run_abstracted_ONFSM_Lstar,
+    run_active_Alergia,
+    run_active_RPNI,
+    run_Alergia,
+    run_JAlergia,
+    run_KV,
+    run_Lstar,
+    run_non_det_Lstar,
+    run_RPNI,
+    run_stochastic_Lstar,
+)
+from .oracles import (
+    BreadthFirstExplorationEqOracle,
+    CacheBasedEqOracle,
+    KWayStateCoverageEqOracle,
+    KWayTransitionCoverageEqOracle,
+    PacOracle,
+    PerfectKnowledgeEqOracle,
+    ProvidedSequencesOracleWrapper,
+    RandomWalkEqOracle,
+    RandomWMethodEqOracle,
+    RandomWordEqOracle,
+    StatePrefixEqOracle,
+    TransitionFocusOracle,
+    UserInputEqOracle,
+    WMethodEqOracle,
+    kWayStateCoverageEqOracle,
+    kWayTransitionCoverageEqOracle,
+)
+from .SULs import (
+    AutomatonSUL, 
+    FunctionDecorator, 
+    PyClassSUL, 
+    RegexSUL, 
+    TomitaSUL
+)
+from .utils import (
+    CharacterTokenizer,
+    DataHandler,
+    DelimiterTokenizer,
+    IODelimiterTokenizer,
+    bisimilar,
+    compare_automata,
+    convert_i_o_traces_for_RPNI,
+    generate_random_deterministic_automata,
+    generate_random_dfa,
+    generate_random_markov_chain,
+    generate_random_mdp,
+    generate_random_mealy_machine,
+    generate_random_moore_machine,
+    generate_random_ONFSM,
+    generate_random_sevpa,
+    generate_random_smm,
+    generate_test_cases,
+    get_correct_prop_values,
+    get_properties_file,
+    load_automaton_from_file,
+    make_input_complete,
+    mdp_2_prism_format,
+    model_check_experiment,
+    model_check_properties,
+    save_automaton_to_file,
+    statistical_model_checking,
+    visualize_automaton,
+)
```

## aalpy/paths.py

 * *Ordering differences only*

```diff
@@ -1,12 +1,12 @@
-"""
-File in which necessary paths for model checking are defined.
-
-path_to_prism is the absolute or relative path to the prism executable. Note that it has to include the executable file,
-not just the folder. Eg. /usr/edi/prism/prism.bat and NOT /usr/edi/prism/
-
-If you learn one of the provided examples path to properties should be relative or
-absolute path to 'Benchmarking\prism_eval_props'.
-"""
-
-path_to_prism = None
-path_to_properties = None
+"""
+File in which necessary paths for model checking are defined.
+
+path_to_prism is the absolute or relative path to the prism executable. Note that it has to include the executable file,
+not just the folder. Eg. /usr/edi/prism/prism.bat and NOT /usr/edi/prism/
+
+If you learn one of the provided examples path to properties should be relative or
+absolute path to 'Benchmarking\prism_eval_props'.
+"""
+
+path_to_prism = None
+path_to_properties = None
```

## aalpy/SULs/AutomataSUL.py

 * *Ordering differences only*

```diff
@@ -1,20 +1,20 @@
-from aalpy.base import Automaton
-from aalpy.base import SUL
-
-
-class AutomatonSUL(SUL):
-    def __init__(self, automaton: Automaton):
-        super().__init__()
-        self.automaton: Automaton = automaton
-
-    def pre(self):
-        self.automaton.reset_to_initial()
-
-    def step(self, letter=None):
-        return self.automaton.step(letter)
-
-    def post(self):
-        pass
-
-
-MealySUL = OnfsmSUL = StochasticMealySUL = DfaSUL = MooreSUL = MdpSUL = McSUL = SevpaSUL = AutomatonSUL
+from aalpy.base import Automaton
+from aalpy.base import SUL
+
+
+class AutomatonSUL(SUL):
+    def __init__(self, automaton: Automaton):
+        super().__init__()
+        self.automaton: Automaton = automaton
+
+    def pre(self):
+        self.automaton.reset_to_initial()
+
+    def step(self, letter=None):
+        return self.automaton.step(letter)
+
+    def post(self):
+        pass
+
+
+MealySUL = OnfsmSUL = StochasticMealySUL = DfaSUL = MooreSUL = MdpSUL = McSUL = SevpaSUL = AutomatonSUL
```

## aalpy/SULs/PyMethodSUL.py

 * *Ordering differences only*

```diff
@@ -1,68 +1,68 @@
-from aalpy.base import SUL
-
-
-class FunctionDecorator:
-    """
-    Decorator of methods found in the SUL class.
-    """
-
-    def __init__(self, function, args=None):
-        """
-        Args:
-
-            function: function of the class to be learned
-
-            args: arguments to be passed to the function. Either a single argument, or a list of arguments if
-                function has more than one parameter.
-        """
-
-        self.function = function
-        self.args = None
-        if args:
-            self.args = [args] if not isinstance(args, (list, tuple)) else args
-
-    def __repr__(self):
-        if self.args:
-            return f'{self.function.__name__}{self.args}'
-        return self.function.__name__
-
-
-class PyClassSUL(SUL):
-    """
-    System under learning for inferring python classes.
-    """
-    def __init__(self, python_class):
-        """
-        Args:
-
-            python_class: class to be learned
-        """
-        super().__init__()
-        self._class = python_class
-        self.sul: object = None
-
-    def pre(self):
-        """
-        Do the reset by initializing the class again or call reset method of the class
-        """
-        self.sul = self._class()
-
-    def post(self):
-        pass
-
-    def step(self, letter):
-        """
-        Executes the function(with arguments) found in letter against the SUL
-
-        Args:
-
-            letter: single input of type FunctionDecorator
-
-        Returns:
-
-            output of the function
-
-        """
-        if letter.args:
-            return getattr(self.sul, letter.function.__name__, letter)(*letter.args)
-        return getattr(self.sul, letter.function.__name__, letter)()
+from aalpy.base import SUL
+
+
+class FunctionDecorator:
+    """
+    Decorator of methods found in the SUL class.
+    """
+
+    def __init__(self, function, args=None):
+        """
+        Args:
+
+            function: function of the class to be learned
+
+            args: arguments to be passed to the function. Either a single argument, or a list of arguments if
+                function has more than one parameter.
+        """
+
+        self.function = function
+        self.args = None
+        if args:
+            self.args = [args] if not isinstance(args, (list, tuple)) else args
+
+    def __repr__(self):
+        if self.args:
+            return f'{self.function.__name__}{self.args}'
+        return self.function.__name__
+
+
+class PyClassSUL(SUL):
+    """
+    System under learning for inferring python classes.
+    """
+    def __init__(self, python_class):
+        """
+        Args:
+
+            python_class: class to be learned
+        """
+        super().__init__()
+        self._class = python_class
+        self.sul: object = None
+
+    def pre(self):
+        """
+        Do the reset by initializing the class again or call reset method of the class
+        """
+        self.sul = self._class()
+
+    def post(self):
+        pass
+
+    def step(self, letter):
+        """
+        Executes the function(with arguments) found in letter against the SUL
+
+        Args:
+
+            letter: single input of type FunctionDecorator
+
+        Returns:
+
+            output of the function
+
+        """
+        if letter.args:
+            return getattr(self.sul, letter.function.__name__, letter)(*letter.args)
+        return getattr(self.sul, letter.function.__name__, letter)()
```

## aalpy/SULs/RegexSUL.py

 * *Ordering differences only*

```diff
@@ -1,37 +1,37 @@
-from aalpy.base import SUL
-import re
-
-
-class RegexSUL(SUL):
-    """
-    An example implementation of a system under learning that can be used to learn any regex expression.
-    Note that the $ is added to the expression as in this SUL only exact matches are learned.
-    """
-    def __init__(self, regex: str):
-        super().__init__()
-        self.regex = regex if regex[-1] == '$' else regex + '$'
-        self.string = ""
-
-    def pre(self):
-        self.string = ""
-        pass
-
-    def post(self):
-        self.string = ""
-        pass
-
-    def step(self, letter):
-        """
-
-        Args:
-
-            letter: single element of the input alphabet
-
-        Returns:
-
-            Whether the current string (previous string + letter) is accepted
-
-        """
-        if letter is not None:
-            self.string += str(letter)
-        return True if re.match(self.regex, self.string) else False
+from aalpy.base import SUL
+import re
+
+
+class RegexSUL(SUL):
+    """
+    An example implementation of a system under learning that can be used to learn any regex expression.
+    Note that the $ is added to the expression as in this SUL only exact matches are learned.
+    """
+    def __init__(self, regex: str):
+        super().__init__()
+        self.regex = regex if regex[-1] == '$' else regex + '$'
+        self.string = ""
+
+    def pre(self):
+        self.string = ""
+        pass
+
+    def post(self):
+        self.string = ""
+        pass
+
+    def step(self, letter):
+        """
+
+        Args:
+
+            letter: single element of the input alphabet
+
+        Returns:
+
+            Whether the current string (previous string + letter) is accepted
+
+        """
+        if letter is not None:
+            self.string += str(letter)
+        return True if re.match(self.regex, self.string) else False
```

## aalpy/SULs/TomitaSUL.py

 * *Ordering differences only*

```diff
@@ -1,68 +1,68 @@
-import re
-
-from aalpy.base import SUL
-
-
-class TomitaSUL(SUL):
-    """
-    Tomita grammars are often used as a benchmark for automata-related challenges. Simple SUL that implements all 7
-    Tomita grammars and enables their learning.
-    """
-
-    def __init__(self, tomita_level_fun):
-        super().__init__()
-        num_fun_map = {1: tomita_1, 2: tomita_2, 3: tomita_3, 4: tomita_4, 5: tomita_5, 6: tomita_6, 7: tomita_7,
-                       -3: not_tomita_3}
-        assert tomita_level_fun in num_fun_map.keys()
-        self.string = ""
-        self.tomita_level = num_fun_map[tomita_level_fun]
-
-    def pre(self):
-        self.string = ""
-        pass
-
-    def post(self):
-        self.string = ""
-        pass
-
-    def step(self, letter):
-        if input:
-            self.string += str(letter)
-        return self.tomita_level(self.string)
-
-
-_not_tomita_3 = re.compile("((0|1)*0)*1(11)*(0(0|1)*1)*0(00)*(1(0|1)*)*$")
-
-
-def tomita_1(word):
-    return "0" not in word
-
-
-def tomita_2(word):
-    return word == "10" * (int(len(word) / 2))
-
-
-def tomita_3(word):
-    if not _not_tomita_3.match(word):
-        return True
-    return False
-
-
-def not_tomita_3(word):
-    return not tomita_3(word)
-
-
-def tomita_4(word):
-    return "000" not in word
-
-
-def tomita_5(word):
-    return (word.count("0") % 2 == 0) and (word.count("1") % 2 == 0)
-
-
-def tomita_6(word):
-    return ((word.count("0") - word.count("1")) % 3) == 0
-
-
-def tomita_7(word):
-    return word.count("10") <= 1
+import re
+
+from aalpy.base import SUL
+
+
+class TomitaSUL(SUL):
+    """
+    Tomita grammars are often used as a benchmark for automata-related challenges. Simple SUL that implements all 7
+    Tomita grammars and enables their learning.
+    """
+
+    def __init__(self, tomita_level_fun):
+        super().__init__()
+        num_fun_map = {1: tomita_1, 2: tomita_2, 3: tomita_3, 4: tomita_4, 5: tomita_5, 6: tomita_6, 7: tomita_7,
+                       -3: not_tomita_3}
+        assert tomita_level_fun in num_fun_map.keys()
+        self.string = ""
+        self.tomita_level = num_fun_map[tomita_level_fun]
+
+    def pre(self):
+        self.string = ""
+        pass
+
+    def post(self):
+        self.string = ""
+        pass
+
+    def step(self, letter):
+        if input:
+            self.string += str(letter)
+        return self.tomita_level(self.string)
+
+
+_not_tomita_3 = re.compile("((0|1)*0)*1(11)*(0(0|1)*1)*0(00)*(1(0|1)*)*$")
+
+
+def tomita_1(word):
+    return "0" not in word
+
+
+def tomita_2(word):
+    return word == "10" * (int(len(word) / 2))
+
+
+def tomita_3(word):
+    if not _not_tomita_3.match(word):
+        return True
+    return False
+
+
+def not_tomita_3(word):
+    return not tomita_3(word)
+
+
+def tomita_4(word):
+    return "000" not in word
+
+
+def tomita_5(word):
+    return (word.count("0") % 2 == 0) and (word.count("1") % 2 == 0)
+
+
+def tomita_6(word):
+    return ((word.count("0") - word.count("1")) % 3) == 0
+
+
+def tomita_7(word):
+    return word.count("10") <= 1
```

## aalpy/SULs/__init__.py

 * *Ordering differences only*

```diff
@@ -1,4 +1,4 @@
-from .AutomataSUL import *
-from .PyMethodSUL import FunctionDecorator, PyClassSUL
-from .RegexSUL import RegexSUL
-from .TomitaSUL import TomitaSUL
+from .AutomataSUL import *
+from .PyMethodSUL import FunctionDecorator, PyClassSUL
+from .RegexSUL import RegexSUL
+from .TomitaSUL import TomitaSUL
```

## aalpy/automata/Dfa.py

 * *Ordering differences only*

```diff
@@ -1,104 +1,104 @@
-from typing import Generic, Dict
-
-from aalpy.base import AutomatonState, DeterministicAutomaton
-from aalpy.base.Automaton import InputType
-
-
-class DfaState(AutomatonState, Generic[InputType]):
-    """
-    Single state of a deterministic finite automaton.
-    """
-
-    def __init__(self, state_id, is_accepting=False):
-        super().__init__(state_id)
-        self.transitions : Dict[InputType, DfaState] = dict()
-        self.is_accepting = is_accepting
-
-
-class Dfa(DeterministicAutomaton[DfaState[InputType]]):
-    """
-    Deterministic finite automaton.
-    """
-
-    def __init__(self, initial_state: DfaState, states):
-        super().__init__(initial_state, states)
-
-    def step(self, letter):
-        """
-        Args:
-
-            letter: single input that is looked up in the transition table of the DfaState
-
-        Returns:
-
-            True if the reached state is an accepting state, False otherwise
-        """
-        if letter is not None:
-            self.current_state = self.current_state.transitions[letter]
-        return self.current_state.is_accepting
-
-    def compute_characterization_set(self, char_set_init=None, online_suffix_closure=True, split_all_blocks=True,
-                                     return_same_states=False, raise_warning=True):
-        return super(Dfa, self).compute_characterization_set(char_set_init if char_set_init else [()],
-                                                             online_suffix_closure, split_all_blocks,
-                                                             return_same_states, raise_warning)
-
-    def compute_output_seq(self, state, sequence):
-        if not sequence:
-            return [state.is_accepting]
-        return super(Dfa, self).compute_output_seq(state, sequence)
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        # ensure prefixes are computed
-        self.compute_prefixes()
-
-        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
-        for s in sorted_states:
-            state_setup_dict[s.state_id] = (s.is_accepting, {k: v.state_id for k, v in s.transitions.items()})
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup : dict, **kwargs):
-        """
-            First state in the state setup is the initial state.
-            Example state setup:
-            state_setup = {
-                    "a": (True, {"x": "b1", "y": "a"}),
-                    "b1": (False, {"x": "b2", "y": "a"}),
-                    "b2": (True, {"x": "b3", "y": "a"}),
-                    "b3": (False, {"x": "b4", "y": "a"}),
-                    "b4": (False, {"x": "c", "y": "a"}),
-                    "c": (True, {"x": "a", "y": "a"}),
-                }
-
-            Args:
-
-                state_setup: map from state_id to tuple(output and transitions_dict)
-
-            Returns:
-
-                DFA
-            """
-        # state_setup should map from state_id to tuple(is_accepting and transitions_dict)
-
-        # build states with state_id and output
-        states = {key: DfaState(key, val[0]) for key, val in state_setup.items()}
-
-        # add transitions to states
-        for state_id, state in states.items():
-            for _input, target_state_id in state_setup[state_id][1].items():
-                state.transitions[_input] = states[target_state_id]
-
-        # states to list
-        states = [state for state in states.values()]
-
-        # build moore machine with first state as starting state
-        dfa = Dfa(states[0], states)
-
-        for state in states:
-            state.prefix = dfa.get_shortest_path(dfa.initial_state, state)
-
+from typing import Generic, Dict
+
+from aalpy.base import AutomatonState, DeterministicAutomaton
+from aalpy.base.Automaton import InputType
+
+
+class DfaState(AutomatonState, Generic[InputType]):
+    """
+    Single state of a deterministic finite automaton.
+    """
+
+    def __init__(self, state_id, is_accepting=False):
+        super().__init__(state_id)
+        self.transitions : Dict[InputType, DfaState] = dict()
+        self.is_accepting = is_accepting
+
+
+class Dfa(DeterministicAutomaton[DfaState[InputType]]):
+    """
+    Deterministic finite automaton.
+    """
+
+    def __init__(self, initial_state: DfaState, states):
+        super().__init__(initial_state, states)
+
+    def step(self, letter):
+        """
+        Args:
+
+            letter: single input that is looked up in the transition table of the DfaState
+
+        Returns:
+
+            True if the reached state is an accepting state, False otherwise
+        """
+        if letter is not None:
+            self.current_state = self.current_state.transitions[letter]
+        return self.current_state.is_accepting
+
+    def compute_characterization_set(self, char_set_init=None, online_suffix_closure=True, split_all_blocks=True,
+                                     return_same_states=False, raise_warning=True):
+        return super(Dfa, self).compute_characterization_set(char_set_init if char_set_init else [()],
+                                                             online_suffix_closure, split_all_blocks,
+                                                             return_same_states, raise_warning)
+
+    def compute_output_seq(self, state, sequence):
+        if not sequence:
+            return [state.is_accepting]
+        return super(Dfa, self).compute_output_seq(state, sequence)
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        # ensure prefixes are computed
+        self.compute_prefixes()
+
+        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
+        for s in sorted_states:
+            state_setup_dict[s.state_id] = (s.is_accepting, {k: v.state_id for k, v in s.transitions.items()})
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup : dict, **kwargs):
+        """
+            First state in the state setup is the initial state.
+            Example state setup:
+            state_setup = {
+                    "a": (True, {"x": "b1", "y": "a"}),
+                    "b1": (False, {"x": "b2", "y": "a"}),
+                    "b2": (True, {"x": "b3", "y": "a"}),
+                    "b3": (False, {"x": "b4", "y": "a"}),
+                    "b4": (False, {"x": "c", "y": "a"}),
+                    "c": (True, {"x": "a", "y": "a"}),
+                }
+
+            Args:
+
+                state_setup: map from state_id to tuple(output and transitions_dict)
+
+            Returns:
+
+                DFA
+            """
+        # state_setup should map from state_id to tuple(is_accepting and transitions_dict)
+
+        # build states with state_id and output
+        states = {key: DfaState(key, val[0]) for key, val in state_setup.items()}
+
+        # add transitions to states
+        for state_id, state in states.items():
+            for _input, target_state_id in state_setup[state_id][1].items():
+                state.transitions[_input] = states[target_state_id]
+
+        # states to list
+        states = [state for state in states.values()]
+
+        # build moore machine with first state as starting state
+        dfa = Dfa(states[0], states)
+
+        for state in states:
+            state.prefix = dfa.get_shortest_path(dfa.initial_state, state)
+
         return dfa
```

## aalpy/automata/MarkovChain.py

 * *Ordering differences only*

```diff
@@ -1,70 +1,70 @@
-import random
-from typing import Generic, Tuple, List
-
-from aalpy.base import Automaton, AutomatonState
-from aalpy.base.Automaton import OutputType
-
-
-class McState(AutomatonState, Generic[OutputType]):
-    def __init__(self, state_id, output):
-        super().__init__(state_id)
-        self.output: OutputType = output
-        # transitions is a list of tuples (Node(output), probability)
-        self.transitions: List[Tuple[McState, float]] = list()
-
-
-class MarkovChain(Automaton[McState[OutputType]]):
-    """Markov Decision Process."""
-
-    def __init__(self, initial_state, states: list):
-        super().__init__(initial_state, states)
-
-    def reset_to_initial(self):
-        self.current_state = self.initial_state
-
-    def step(self, letter=None):
-        """Next step is determined based on transition probabilities of the current state.
-
-        Args:
-
-            letter: input
-
-        Returns:
-
-            output of the current state
-        """
-
-        if not self.current_state.transitions:
-            return self.current_state.output
-
-        probability_distributions = [i[1] for i in self.current_state.transitions]
-        states = [i[0] for i in self.current_state.transitions]
-
-        new_state = random.choices(states, probability_distributions, k=1)[0]
-
-        self.current_state = new_state
-        return self.current_state.output
-
-    def step_to(self, input):
-        """Performs a step on the automaton based on the input `inp` and output `out`.
-
-        Args:
-
-            input: input
-
-        Returns:
-
-            output of the reached state, None otherwise
-        """
-        for s in self.current_state.transitions:
-            if s[0].output == input:
-                self.current_state = s[0]
-                return self.current_state.output
-        return None
-
-    @staticmethod
-    def from_state_setup(state_setup: dict, **kwargs):
-        raise NotImplementedError()  # TODO implement
-
-    def to_state_setup(self):
-        raise NotImplementedError()  # TODO implement
+import random
+from typing import Generic, Tuple, List
+
+from aalpy.base import Automaton, AutomatonState
+from aalpy.base.Automaton import OutputType
+
+
+class McState(AutomatonState, Generic[OutputType]):
+    def __init__(self, state_id, output):
+        super().__init__(state_id)
+        self.output: OutputType = output
+        # transitions is a list of tuples (Node(output), probability)
+        self.transitions: List[Tuple[McState, float]] = list()
+
+
+class MarkovChain(Automaton[McState[OutputType]]):
+    """Markov Decision Process."""
+
+    def __init__(self, initial_state, states: list):
+        super().__init__(initial_state, states)
+
+    def reset_to_initial(self):
+        self.current_state = self.initial_state
+
+    def step(self, letter=None):
+        """Next step is determined based on transition probabilities of the current state.
+
+        Args:
+
+            letter: input
+
+        Returns:
+
+            output of the current state
+        """
+
+        if not self.current_state.transitions:
+            return self.current_state.output
+
+        probability_distributions = [i[1] for i in self.current_state.transitions]
+        states = [i[0] for i in self.current_state.transitions]
+
+        new_state = random.choices(states, probability_distributions, k=1)[0]
+
+        self.current_state = new_state
+        return self.current_state.output
+
+    def step_to(self, input):
+        """Performs a step on the automaton based on the input `inp` and output `out`.
+
+        Args:
+
+            input: input
+
+        Returns:
+
+            output of the reached state, None otherwise
+        """
+        for s in self.current_state.transitions:
+            if s[0].output == input:
+                self.current_state = s[0]
+                return self.current_state.output
+        return None
+
+    @staticmethod
+    def from_state_setup(state_setup: dict, **kwargs):
+        raise NotImplementedError()  # TODO implement
+
+    def to_state_setup(self):
+        raise NotImplementedError()  # TODO implement
```

## aalpy/automata/Mdp.py

 * *Ordering differences only*

```diff
@@ -1,94 +1,94 @@
-import random
-from collections import defaultdict
-from typing import Dict, Generic, List, Tuple
-
-from aalpy.base import Automaton, AutomatonState
-from aalpy.base.Automaton import OutputType, InputType
-
-
-class MdpState(AutomatonState, Generic[InputType, OutputType]):
-    """
-    For transitions, each transition is a tuple (Node(output), probability)
-    """
-    def __init__(self, state_id, output=None):
-        super().__init__(state_id)
-        self.output: OutputType = output
-        # each transition is a tuple (Node(output), probability)
-        self.transitions: Dict[InputType, List[Tuple[MdpState, float]]] = defaultdict(list)
-
-
-class Mdp(Automaton[MdpState[InputType, OutputType]]):
-    """Markov Decision Process."""
-
-    def __init__(self, initial_state: MdpState, states: list):
-        super().__init__(initial_state, states)
-
-    def reset_to_initial(self):
-        self.current_state = self.initial_state
-
-    def step(self, letter):
-        """Next step is determined based on transition probabilities of the current state.
-
-        Args:
-
-            letter: input
-
-        Returns:
-
-            output of the current state
-        """
-        if letter is None:
-            return self.current_state.output
-
-        probability_distributions = [i[1] for i in self.current_state.transitions[letter]]
-        states = [i[0] for i in self.current_state.transitions[letter]]
-
-        new_state = random.choices(states, probability_distributions, k=1)[0]
-
-        self.current_state = new_state
-        return self.current_state.output
-
-    def step_to(self, inp, out):
-        """Performs a step on the automaton based on the input `inp` and output `out`.
-
-        Args:
-
-            inp: input
-            out: output
-
-        Returns:
-
-            output of the reached state, None otherwise
-        """
-        for new_state in self.current_state.transitions[inp]:
-            if new_state[0].output == out:
-                self.current_state = new_state[0]
-                return out
-        return None
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        # ensure initial state is first in the list
-        if self.states[0] != self.initial_state:
-            self.states.remove(self.initial_state)
-            self.states.insert(0, self.initial_state)
-
-        for s in self.states:
-            state_setup_dict[s.state_id] = (s.output, {k: [(node.state_id, prob) for node, prob in v]
-                                                       for k, v in s.transitions.items()})
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup: dict, **kwargs):
-        states_map = {key: MdpState(key, output=value[0]) for key, value in state_setup.items()}
-
-        for key, values in state_setup.items():
-            source = states_map[key]
-            for i, transitions in values[1].items():
-                for node, prob in transitions:
-                    source.transitions[i].append((states_map[node], prob))
-
-        initial_state = states_map[list(state_setup.keys())[0]]
-        return Mdp(initial_state, list(states_map.values()))
+import random
+from collections import defaultdict
+from typing import Dict, Generic, List, Tuple
+
+from aalpy.base import Automaton, AutomatonState
+from aalpy.base.Automaton import OutputType, InputType
+
+
+class MdpState(AutomatonState, Generic[InputType, OutputType]):
+    """
+    For transitions, each transition is a tuple (Node(output), probability)
+    """
+    def __init__(self, state_id, output=None):
+        super().__init__(state_id)
+        self.output: OutputType = output
+        # each transition is a tuple (Node(output), probability)
+        self.transitions: Dict[InputType, List[Tuple[MdpState, float]]] = defaultdict(list)
+
+
+class Mdp(Automaton[MdpState[InputType, OutputType]]):
+    """Markov Decision Process."""
+
+    def __init__(self, initial_state: MdpState, states: list):
+        super().__init__(initial_state, states)
+
+    def reset_to_initial(self):
+        self.current_state = self.initial_state
+
+    def step(self, letter):
+        """Next step is determined based on transition probabilities of the current state.
+
+        Args:
+
+            letter: input
+
+        Returns:
+
+            output of the current state
+        """
+        if letter is None:
+            return self.current_state.output
+
+        probability_distributions = [i[1] for i in self.current_state.transitions[letter]]
+        states = [i[0] for i in self.current_state.transitions[letter]]
+
+        new_state = random.choices(states, probability_distributions, k=1)[0]
+
+        self.current_state = new_state
+        return self.current_state.output
+
+    def step_to(self, inp, out):
+        """Performs a step on the automaton based on the input `inp` and output `out`.
+
+        Args:
+
+            inp: input
+            out: output
+
+        Returns:
+
+            output of the reached state, None otherwise
+        """
+        for new_state in self.current_state.transitions[inp]:
+            if new_state[0].output == out:
+                self.current_state = new_state[0]
+                return out
+        return None
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        # ensure initial state is first in the list
+        if self.states[0] != self.initial_state:
+            self.states.remove(self.initial_state)
+            self.states.insert(0, self.initial_state)
+
+        for s in self.states:
+            state_setup_dict[s.state_id] = (s.output, {k: [(node.state_id, prob) for node, prob in v]
+                                                       for k, v in s.transitions.items()})
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup: dict, **kwargs):
+        states_map = {key: MdpState(key, output=value[0]) for key, value in state_setup.items()}
+
+        for key, values in state_setup.items():
+            source = states_map[key]
+            for i, transitions in values[1].items():
+                for node, prob in transitions:
+                    source.transitions[i].append((states_map[node], prob))
+
+        initial_state = states_map[list(state_setup.keys())[0]]
+        return Mdp(initial_state, list(states_map.values()))
```

## aalpy/automata/MealyMachine.py

 * *Ordering differences only*

```diff
@@ -1,95 +1,95 @@
-from typing import Generic, Dict
-
-from aalpy.base import AutomatonState, DeterministicAutomaton
-from aalpy.base.Automaton import OutputType, InputType
-
-
-class MealyState(AutomatonState, Generic[InputType, OutputType]):
-    """
-    Single state of a Mealy machine. Each state has an output_fun dictionary that maps inputs to outputs.
-    """
-
-    def __init__(self, state_id):
-        super().__init__(state_id)
-        self.transitions : Dict[InputType, MealyState] = dict()
-        self.output_fun : Dict[InputType, OutputType] = dict()
-
-
-class MealyMachine(DeterministicAutomaton[MealyState[InputType, OutputType]]):
-
-    def __init__(self, initial_state: MealyState, states):
-        super().__init__(initial_state, states)
-
-    def step(self, letter):
-        """
-        In Mealy machines, outputs depend on the input and the current state.
-
-            Args:
-
-                letter: single input that is looked up in the transition and output functions
-
-            Returns:
-
-                output corresponding to the input from the current state
-        """
-        output = self.current_state.output_fun[letter]
-        self.current_state = self.current_state.transitions[letter]
-        return output
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        # ensure prefixes are computed
-        self.compute_prefixes()
-
-        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
-        for s in sorted_states:
-            state_setup_dict[s.state_id] = {k: (s.output_fun[k], v.state_id) for k, v in s.transitions.items()}
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup : dict, **kwargs):
-        """
-            First state in the state setup is the initial state.
-            state_setup = {
-                "a": {"x": ("o1", "b1"), "y": ("o2", "a")},
-                "b1": {"x": ("o3", "b2"), "y": ("o1", "a")},
-                "b2": {"x": ("o1", "b3"), "y": ("o2", "a")},
-                "b3": {"x": ("o3", "b4"), "y": ("o1", "a")},
-                "b4": {"x": ("o1", "c"), "y": ("o4", "a")},
-                "c": {"x": ("o3", "a"), "y": ("o5", "a")},
-            }
-
-
-        Args:
-
-            state_setup:
-                state_setup should map from state_id to tuple(transitions_dict).
-
-        Returns:
-
-            Mealy Machine
-        """
-        # state_setup should map from state_id to tuple(transitions_dict).
-        # Each entry in transition dict is <input> : <output, new_state_id>
-
-        # build states with state_id and output
-        states = {key: MealyState(key) for key, _ in state_setup.items()}
-
-        # add transitions to states
-        for state_id, state in states.items():
-            for _input, (output, new_state) in state_setup[state_id].items():
-                state.transitions[_input] = states[new_state]
-                state.output_fun[_input] = output
-
-        # states to list
-        states = [state for state in states.values()]
-
-        # build moore machine with first state as starting state
-        mm = MealyMachine(states[0], states)
-
-        for state in states:
-            state.prefix = mm.get_shortest_path(mm.initial_state, state)
-
+from typing import Generic, Dict
+
+from aalpy.base import AutomatonState, DeterministicAutomaton
+from aalpy.base.Automaton import OutputType, InputType
+
+
+class MealyState(AutomatonState, Generic[InputType, OutputType]):
+    """
+    Single state of a Mealy machine. Each state has an output_fun dictionary that maps inputs to outputs.
+    """
+
+    def __init__(self, state_id):
+        super().__init__(state_id)
+        self.transitions : Dict[InputType, MealyState] = dict()
+        self.output_fun : Dict[InputType, OutputType] = dict()
+
+
+class MealyMachine(DeterministicAutomaton[MealyState[InputType, OutputType]]):
+
+    def __init__(self, initial_state: MealyState, states):
+        super().__init__(initial_state, states)
+
+    def step(self, letter):
+        """
+        In Mealy machines, outputs depend on the input and the current state.
+
+            Args:
+
+                letter: single input that is looked up in the transition and output functions
+
+            Returns:
+
+                output corresponding to the input from the current state
+        """
+        output = self.current_state.output_fun[letter]
+        self.current_state = self.current_state.transitions[letter]
+        return output
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        # ensure prefixes are computed
+        self.compute_prefixes()
+
+        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
+        for s in sorted_states:
+            state_setup_dict[s.state_id] = {k: (s.output_fun[k], v.state_id) for k, v in s.transitions.items()}
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup : dict, **kwargs):
+        """
+            First state in the state setup is the initial state.
+            state_setup = {
+                "a": {"x": ("o1", "b1"), "y": ("o2", "a")},
+                "b1": {"x": ("o3", "b2"), "y": ("o1", "a")},
+                "b2": {"x": ("o1", "b3"), "y": ("o2", "a")},
+                "b3": {"x": ("o3", "b4"), "y": ("o1", "a")},
+                "b4": {"x": ("o1", "c"), "y": ("o4", "a")},
+                "c": {"x": ("o3", "a"), "y": ("o5", "a")},
+            }
+
+
+        Args:
+
+            state_setup:
+                state_setup should map from state_id to tuple(transitions_dict).
+
+        Returns:
+
+            Mealy Machine
+        """
+        # state_setup should map from state_id to tuple(transitions_dict).
+        # Each entry in transition dict is <input> : <output, new_state_id>
+
+        # build states with state_id and output
+        states = {key: MealyState(key) for key, _ in state_setup.items()}
+
+        # add transitions to states
+        for state_id, state in states.items():
+            for _input, (output, new_state) in state_setup[state_id].items():
+                state.transitions[_input] = states[new_state]
+                state.output_fun[_input] = output
+
+        # states to list
+        states = [state for state in states.values()]
+
+        # build moore machine with first state as starting state
+        mm = MealyMachine(states[0], states)
+
+        for state in states:
+            state.prefix = mm.get_shortest_path(mm.initial_state, state)
+
         return mm
```

## aalpy/automata/MooreMachine.py

 * *Ordering differences only*

```diff
@@ -1,103 +1,103 @@
-from typing import Generic, Dict
-
-from aalpy.base import AutomatonState, DeterministicAutomaton
-from aalpy.base.Automaton import InputType, OutputType
-
-
-class MooreState(AutomatonState, Generic[InputType,OutputType]):
-    """
-    Single state of a Moore machine. Each state has an output value.
-    """
-
-    def __init__(self, state_id, output=None):
-        super().__init__(state_id)
-        self.output : OutputType = output
-        self.transitions : Dict[InputType, MooreState] = dict()
-
-
-class MooreMachine(DeterministicAutomaton[MooreState[InputType, OutputType]]):
-
-    def __init__(self, initial_state: AutomatonState, states: list):
-        super().__init__(initial_state, states)
-
-    def step(self, letter):
-        """
-        In Moore machines outputs depend on the current state.
-
-        Args:
-
-            letter: single input that is looked up in the transition function leading to a new state
-
-        Returns:
-
-            the output of the reached state
-
-        """
-        if letter is not None:
-            self.current_state = self.current_state.transitions[letter]
-        return self.current_state.output
-
-    def compute_characterization_set(self, char_set_init=None, online_suffix_closure=True, split_all_blocks=True,
-                                     return_same_states=False, raise_warning=True):
-        return super(MooreMachine, self).compute_characterization_set(char_set_init if char_set_init else [()],
-                                                                      online_suffix_closure, split_all_blocks,
-                                                                      return_same_states, raise_warning)
-
-    def compute_output_seq(self, state, sequence):
-        if not sequence:
-            return [state.output]
-        return super(MooreMachine, self).compute_output_seq(state, sequence)
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        # ensure prefixes are computed
-        self.compute_prefixes()
-
-        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
-        for s in sorted_states:
-            state_setup_dict[s.state_id] = (s.output, {k: v.state_id for k, v in s.transitions.items()})
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup : dict, **kwargs):
-        """
-        First state in the state setup is the initial state.
-        Example state setup:
-        state_setup = {
-                "a": ("a", {"x": "b1", "y": "a"}),
-                "b1": ("b", {"x": "b2", "y": "a"}),
-                "b2": ("b", {"x": "b3", "y": "a"}),
-                "b3": ("b", {"x": "b4", "y": "a"}),
-                "b4": ("b", {"x": "c", "y": "a"}),
-                "c": ("c", {"x": "a", "y": "a"}),
-            }
-
-        Args:
-
-            state_setup: map from state_id to tuple(output and transitions_dict)
-
-        Returns:
-
-            Moore machine
-        """
-
-        # build states with state_id and output
-        states = {key: MooreState(key, val[0]) for key, val in state_setup.items()}
-
-        # add transitions to states
-        for state_id, state in states.items():
-            for _input, target_state_id in state_setup[state_id][1].items():
-                state.transitions[_input] = states[target_state_id]
-
-        # states to list
-        states = [state for state in states.values()]
-
-        # build moore machine with first state as starting state
-        mm = MooreMachine(states[0], states)
-
-        for state in states:
-            state.prefix = mm.get_shortest_path(mm.initial_state, state)
-
+from typing import Generic, Dict
+
+from aalpy.base import AutomatonState, DeterministicAutomaton
+from aalpy.base.Automaton import InputType, OutputType
+
+
+class MooreState(AutomatonState, Generic[InputType,OutputType]):
+    """
+    Single state of a Moore machine. Each state has an output value.
+    """
+
+    def __init__(self, state_id, output=None):
+        super().__init__(state_id)
+        self.output : OutputType = output
+        self.transitions : Dict[InputType, MooreState] = dict()
+
+
+class MooreMachine(DeterministicAutomaton[MooreState[InputType, OutputType]]):
+
+    def __init__(self, initial_state: AutomatonState, states: list):
+        super().__init__(initial_state, states)
+
+    def step(self, letter):
+        """
+        In Moore machines outputs depend on the current state.
+
+        Args:
+
+            letter: single input that is looked up in the transition function leading to a new state
+
+        Returns:
+
+            the output of the reached state
+
+        """
+        if letter is not None:
+            self.current_state = self.current_state.transitions[letter]
+        return self.current_state.output
+
+    def compute_characterization_set(self, char_set_init=None, online_suffix_closure=True, split_all_blocks=True,
+                                     return_same_states=False, raise_warning=True):
+        return super(MooreMachine, self).compute_characterization_set(char_set_init if char_set_init else [()],
+                                                                      online_suffix_closure, split_all_blocks,
+                                                                      return_same_states, raise_warning)
+
+    def compute_output_seq(self, state, sequence):
+        if not sequence:
+            return [state.output]
+        return super(MooreMachine, self).compute_output_seq(state, sequence)
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        # ensure prefixes are computed
+        self.compute_prefixes()
+
+        sorted_states = sorted(self.states, key=lambda x: len(x.prefix))
+        for s in sorted_states:
+            state_setup_dict[s.state_id] = (s.output, {k: v.state_id for k, v in s.transitions.items()})
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup : dict, **kwargs):
+        """
+        First state in the state setup is the initial state.
+        Example state setup:
+        state_setup = {
+                "a": ("a", {"x": "b1", "y": "a"}),
+                "b1": ("b", {"x": "b2", "y": "a"}),
+                "b2": ("b", {"x": "b3", "y": "a"}),
+                "b3": ("b", {"x": "b4", "y": "a"}),
+                "b4": ("b", {"x": "c", "y": "a"}),
+                "c": ("c", {"x": "a", "y": "a"}),
+            }
+
+        Args:
+
+            state_setup: map from state_id to tuple(output and transitions_dict)
+
+        Returns:
+
+            Moore machine
+        """
+
+        # build states with state_id and output
+        states = {key: MooreState(key, val[0]) for key, val in state_setup.items()}
+
+        # add transitions to states
+        for state_id, state in states.items():
+            for _input, target_state_id in state_setup[state_id][1].items():
+                state.transitions[_input] = states[target_state_id]
+
+        # states to list
+        states = [state for state in states.values()]
+
+        # build moore machine with first state as starting state
+        mm = MooreMachine(states[0], states)
+
+        for state in states:
+            state.prefix = mm.get_shortest_path(mm.initial_state, state)
+
         return mm
```

## aalpy/automata/Onfsm.py

 * *Ordering differences only*

```diff
@@ -1,109 +1,109 @@
-from collections import defaultdict
-from random import choice
-from typing import Generic, Tuple, Dict, List
-
-from aalpy.base import Automaton, AutomatonState
-from aalpy.base.Automaton import OutputType, InputType
-
-
-class OnfsmState(AutomatonState, Generic[InputType, OutputType]):
-    """ """
-    def __init__(self, state_id):
-        super().__init__(state_id)
-        # TODO this order is inconsistent with probabilistic models
-        # key/input maps to the list of tuples of possible output/new state [(output1, state1), (output2, state2)]
-        self.transitions : Dict[InputType, List[Tuple[OutputType, OnfsmState]]] = defaultdict(list)
-
-    def add_transition(self, inp, out, new_state) :
-        """
-
-        Args:
-          inp: 
-          out: 
-          new_state: 
-
-        Returns:
-
-        """
-        self.transitions[inp].append((out, new_state))
-
-    def get_transition(self, input, output=None):
-        """
-
-        Args:
-          input: 
-          output:  (Default value = None)
-
-        Returns:
-
-        """
-        possible_transitions = self.transitions[input]
-        if output:
-            return next((t for t in possible_transitions if t[0] == output), None)
-        else:
-            return possible_transitions
-
-
-class Onfsm(Automaton[OnfsmState[InputType, OutputType]]):
-    """
-    Observable non-deterministic finite state automaton.
-    """
-    def __init__(self, initial_state: OnfsmState, states: list):
-        super().__init__(initial_state, states)
-
-    def step(self, letter):
-        """Next step is determined based on a uniform distribution over all transitions with the input 'letter'.
-
-        Args:
-
-            letter: input
-
-        Returns:
-
-            output of the probabilistically chosen transition
-
-        """
-        transition = choice(self.current_state.transitions[letter])
-        output = transition[0]
-        self.current_state = transition[1]
-        return output
-
-    def outputs_on_input(self, letter):
-        """All possible observable outputs after executing the current input 'letter'.
-
-        Args:
-
-            letter: input
-
-        Returns:
-
-            list of observable outputs
-
-        """
-        return [trans[0] for trans in self.current_state.transitions[letter]]
-
-    def step_to(self, inp, out):
-        """Performs a step on the automaton based on the input `inp` and output `out`.
-
-        Args:
-
-            inp: input
-            out: output
-
-        Returns:
-
-            output of the reached state, None otherwise
-
-        """
-        for new_state in self.current_state.transitions[inp]:
-            if new_state[0] == out:
-                self.current_state = new_state[1]
-                return out
-        return None
-
-    @staticmethod
-    def from_state_setup(state_setup : dict, **kwargs):
-        raise NotImplementedError() # TODO implement
-
-    def to_state_setup(self):
+from collections import defaultdict
+from random import choice
+from typing import Generic, Tuple, Dict, List
+
+from aalpy.base import Automaton, AutomatonState
+from aalpy.base.Automaton import OutputType, InputType
+
+
+class OnfsmState(AutomatonState, Generic[InputType, OutputType]):
+    """ """
+    def __init__(self, state_id):
+        super().__init__(state_id)
+        # TODO this order is inconsistent with probabilistic models
+        # key/input maps to the list of tuples of possible output/new state [(output1, state1), (output2, state2)]
+        self.transitions : Dict[InputType, List[Tuple[OutputType, OnfsmState]]] = defaultdict(list)
+
+    def add_transition(self, inp, out, new_state) :
+        """
+
+        Args:
+          inp: 
+          out: 
+          new_state: 
+
+        Returns:
+
+        """
+        self.transitions[inp].append((out, new_state))
+
+    def get_transition(self, input, output=None):
+        """
+
+        Args:
+          input: 
+          output:  (Default value = None)
+
+        Returns:
+
+        """
+        possible_transitions = self.transitions[input]
+        if output:
+            return next((t for t in possible_transitions if t[0] == output), None)
+        else:
+            return possible_transitions
+
+
+class Onfsm(Automaton[OnfsmState[InputType, OutputType]]):
+    """
+    Observable non-deterministic finite state automaton.
+    """
+    def __init__(self, initial_state: OnfsmState, states: list):
+        super().__init__(initial_state, states)
+
+    def step(self, letter):
+        """Next step is determined based on a uniform distribution over all transitions with the input 'letter'.
+
+        Args:
+
+            letter: input
+
+        Returns:
+
+            output of the probabilistically chosen transition
+
+        """
+        transition = choice(self.current_state.transitions[letter])
+        output = transition[0]
+        self.current_state = transition[1]
+        return output
+
+    def outputs_on_input(self, letter):
+        """All possible observable outputs after executing the current input 'letter'.
+
+        Args:
+
+            letter: input
+
+        Returns:
+
+            list of observable outputs
+
+        """
+        return [trans[0] for trans in self.current_state.transitions[letter]]
+
+    def step_to(self, inp, out):
+        """Performs a step on the automaton based on the input `inp` and output `out`.
+
+        Args:
+
+            inp: input
+            out: output
+
+        Returns:
+
+            output of the reached state, None otherwise
+
+        """
+        for new_state in self.current_state.transitions[inp]:
+            if new_state[0] == out:
+                self.current_state = new_state[1]
+                return out
+        return None
+
+    @staticmethod
+    def from_state_setup(state_setup : dict, **kwargs):
+        raise NotImplementedError() # TODO implement
+
+    def to_state_setup(self):
         raise NotImplementedError # TODO implement
```

## aalpy/automata/Sevpa.py

 * *Ordering differences only*

```diff
@@ -1,568 +1,568 @@
-import random
-from collections import defaultdict, deque
-from typing import Union
-
-from aalpy.base import Automaton, AutomatonState
-
-from typing import List, Dict
-
-
-class SevpaAlphabet:
-    """
-    The Alphabet of a 1-SEVPA.
-
-    Attributes:
-        internal_alphabet (List[str]): Letters for internal transitions.
-        call_alphabet (List[str]): Letters for push transitions.
-        return_alphabet (List[str]): Letters for pop transitions.
-        exclusive_call_return_pairs (Dict[str, str]): A dictionary representing exclusive pairs
-            of call and return symbols.
-    """
-
-    def __init__(self, internal_alphabet: List[str], call_alphabet: List[str], return_alphabet: List[str],
-                 exclusive_call_return_pairs: Dict[str, str] = None):
-        self.internal_alphabet = internal_alphabet
-        self.call_alphabet = call_alphabet
-        self.return_alphabet = return_alphabet
-        self.exclusive_call_return_pairs = exclusive_call_return_pairs
-
-    def get_merged_alphabet(self) -> List[str]:
-        """
-        Get the merged alphabet, including internal, call, and return symbols.
-
-        Returns:
-            List[str]: A list of all symbols in the alphabet.
-        """
-        alphabet = list()
-        alphabet.extend(self.internal_alphabet)
-        alphabet.extend(self.call_alphabet)
-        alphabet.extend(self.return_alphabet)
-        return alphabet
-
-    def __str__(self) -> str:
-        """
-        Returns:
-            str: A string representation of the alphabet.
-        """
-        return f'Internal: {self.internal_alphabet} Call: {self.call_alphabet} Return: {self.return_alphabet}'
-
-
-class SevpaState(AutomatonState):
-    """
-    Single state of a 1-SEVPA.
-    """
-
-    def __init__(self, state_id, is_accepting=False):
-        super().__init__(state_id)
-        self.transitions = defaultdict(list[SevpaTransition])
-        self.is_accepting = is_accepting
-
-
-class SevpaTransition:
-    """
-    Represents a transition in a 1-SEVPA.
-
-    Attributes:
-        target (SevpaState): The target state of the transition.
-        letter: The symbol associated with the transition.
-        action: The action performed during the transition (pop | None).
-        stack_guard: Pair of (automaton_state_id, call_letter)
-    """
-
-    def __init__(self, target: SevpaState, letter, action, stack_guard=None):
-        self.target_state = target
-        self.letter = letter
-        self.action = action
-        self.stack_guard = stack_guard
-
-    def __str__(self):
-        """
-        Returns:
-            str: A string representation of the transition.
-        """
-        return f'{self.letter} --> {self.target_state.state_id}' + \
-               f' | {self.action}: {self.stack_guard}' if self.stack_guard else ''
-
-
-class Sevpa(Automaton):
-    """
-    1-Module Single Entry Visibly Pushdown Automaton.
-    """
-    empty = "_"
-
-    def __init__(self, initial_state: SevpaState, states: list[SevpaState]):
-        super().__init__(initial_state, states)
-        self.initial_state = initial_state
-        self.states = states
-        self.input_alphabet = self.get_input_alphabet()
-        self.current_state = None
-        self.stack = []
-        self.error_state_reached = False
-
-        # alphabet sets for faster inclusion checks (as in SevpaAlphabet we have lists, for reproducibility)
-        self.internal_set = set(self.input_alphabet.internal_alphabet)
-        self.call_set = set(self.input_alphabet.call_alphabet)
-        self.return_set = set(self.input_alphabet.return_alphabet)
-
-    def reset_to_initial(self):
-        super().reset_to_initial()
-        self.current_state = self.initial_state
-        self.stack = [self.empty]
-        self.error_state_reached = False
-        return self.current_state.is_accepting and self.stack[-1] == self.empty
-
-    def step(self, letter):
-        """
-        Perform a single step on the 1-SEVPA by transitioning with the given input letter.
-
-        Args:
-            letter: A single input that is looked up in the transition table of the SevpaState.
-
-        Returns:
-            bool: True if the reached state is an accepting state and the stack is empty, False otherwise.
-        """
-        if self.error_state_reached:
-            return False
-
-        if letter is None:
-            return self.current_state.is_accepting and self.stack[-1] == self.empty
-
-        if letter in self.call_set:
-            self.stack.append((self.current_state.state_id, letter))
-            self.current_state = self.initial_state
-            return self.current_state.is_accepting and self.stack[-1] == self.empty
-
-        # get possible transitions
-        transitions = self.current_state.transitions[letter]
-        taken_transition = None
-        for t in transitions:
-            if t.letter in self.return_set:
-                if t.stack_guard == self.stack[-1]:
-                    taken_transition = t
-                    break
-            elif t.letter in self.internal_set:
-                taken_transition = t
-                break
-            else:
-                assert False
-
-        # No transition is possible
-        if not taken_transition:
-            self.error_state_reached = True
-            return False
-
-        self.current_state = taken_transition.target_state
-
-        if taken_transition.action == 'pop':
-            # empty stack elem should always be on the stack
-            if len(self.stack) <= 1:
-                self.error_state_reached = True
-                return False
-            self.stack.pop()
-
-        return self.current_state.is_accepting and self.stack[-1] == self.empty
-
-    def get_state_by_id(self, state_id) -> Union[SevpaState, None]:
-        for state in self.states:
-            if state.state_id == state_id:
-                return state
-        return None
-
-    def is_input_complete(self) -> bool:
-        pass
-
-    def execute_sequence(self, origin_state, seq):
-        if origin_state.prefix != self.initial_state.prefix:
-            assert False, 'execute_sequence for Sevpa only is only supported from the initial state.'
-        self.reset_to_initial()
-        self.current_state = origin_state
-        return [self.step(s) for s in seq]
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        sorted_states = sorted(self.states, key=lambda x: x.state_id)
-        for state in sorted_states:
-            transitions_for_symbol = {}
-            for symbol, transition_list in state.transitions.items():
-                trans_list_for_setup = []
-                for transition in transition_list:
-                    trans_list_for_setup.append(
-                        (transition.target_state.state_id, transition.action, transition.stack_guard))
-                if trans_list_for_setup:
-                    transitions_for_symbol[symbol] = trans_list_for_setup
-            state_setup_dict[state.state_id] = (state.is_accepting, transitions_for_symbol)
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup: dict, **kwargs):
-
-        init_state_id = kwargs['init_state_id']
-
-        # build states with state_id and output
-        states = {key: SevpaState(key, val[0]) for key, val in state_setup.items()}
-        # states[Sevpa.error_state.state_id] = Sevpa.error_state  # PdaState(Pda.error_state,False)
-
-        # add transitions to states
-        for state_id, state in states.items():
-            for _input, trans_spec in state_setup[state_id][1].items():
-                for (target_state_id, action, stack_guard) in trans_spec:
-                    if action == 'pop':
-                        stack_guard = (stack_guard[0], stack_guard[1])
-                        trans = SevpaTransition(target=states[target_state_id], letter=_input,
-                                                action=action, stack_guard=stack_guard)
-                    elif action is None:
-                        trans = SevpaTransition(target=states[target_state_id], letter=_input,
-                                                action=None, stack_guard=None)
-                    else:
-                        assert False, 'Action must either be "pop" or None, note that there are no push actions ' \
-                                      'definitions in SEVPA'
-
-                    state.transitions[_input].append(trans)
-
-        init_state = states[init_state_id]
-        return Sevpa(init_state, [state for state in states.values()])
-
-    def transform_access_string(self, state=None, stack_content=None) -> List[str]:
-        """
-        Transform the access string by omitting redundant call and return letters, as well as internal letters.
-
-        This function creates the following word:
-            For every element in the stack (except the first element '_'):
-                - Append the state prefix from where the stack element was pushed
-                - Append the call letter
-            Append the state prefix from the state where you are calling this function from.
-
-        Args:
-            state: The state from which the transformation is initiated (default: initial state).
-            stack_content: The content of the stack for transformation (default: Current Stack content).
-
-        Returns:
-            List[str]: The transformed access string.
-        """
-        word = []
-        calling_state = self.initial_state if not state else state
-        stack = self.stack if not stack_content else stack_content
-
-        for index, stack_elem in enumerate(stack):
-            # Skip the first element because it's the start of the stack '_'
-            if index == 0:
-                continue
-            from_state_id = stack_elem[0]  # The corresponding state where the stack element was pushed from
-            call_letter = stack_elem[1]  # The call letter that was pushed on the stack
-            from_state = self.get_state_by_id(from_state_id)
-            if from_state.prefix != ():
-                word.extend(from_state.prefix)
-            word.append(call_letter)
-        word.extend(calling_state.prefix)
-        return word
-
-    @staticmethod
-    def create_daisy_hypothesis(initial_state, alphabet):
-        """
-        Create a Daisy Hypothesis 1-SEVPA using the given initial state and alphabet.
-
-        This function creates self-loop transitions for the internal state on every internal letter.
-        Additionally, it creates self-loop transitions with a pop action for every call letter.
-
-        Args:
-            initial_state (SevpaState): The initial state of the 1-SEVPA.
-            alphabet (SevpaAlphabet): The alphabet for the 1-SEVPA.
-
-        Returns:
-            Sevpa: The created 1-SEVPA with the specified initial state and alphabet.
-        """
-        for i in alphabet.internal_alphabet:
-            trans = SevpaTransition(target=initial_state, letter=i, action=None)
-            initial_state.transitions[i].append(trans)
-
-        for c in alphabet.call_alphabet:
-            for r in alphabet.return_alphabet:
-                trans = SevpaTransition(target=initial_state, letter=r, action='pop',
-                                        stack_guard=(initial_state.state_id, c))
-                initial_state.transitions[r].append(trans)
-
-        return Sevpa(initial_state, [initial_state])
-
-    def get_input_alphabet(self):
-
-        int_alphabet, ret_alphabet, call_alphabet = [], [], []
-        for state in self.states:
-            for transition_list in state.transitions.values():
-                for transition in transition_list:
-                    if transition.action == 'pop':
-                        if transition.letter not in ret_alphabet:
-                            ret_alphabet.append(transition.letter)
-                        if transition.stack_guard[1] not in call_alphabet:
-                            call_alphabet.append(transition.stack_guard[1])
-                    else:
-                        if transition.letter not in int_alphabet:
-                            int_alphabet.append(transition.letter)
-
-        return SevpaAlphabet(int_alphabet, call_alphabet, ret_alphabet)
-
-    def get_error_state(self):
-        """
-        A state is an error state iff:
-            - if all transitions self loop to itself
-            - if the pop transitions from the corresponding stack symbol lead to the same state
-            - for example:
-                - all q2 transitions lead to q2
-                - the pop transitions from the initial state which pop the q2+call-symbol from the stack lead to q2 as well
-
-            - Not an error state if it is the initial state or an accepting state
-        """
-
-        for state in self.states:
-
-            is_error_state = True
-            if state.is_accepting or state == self.initial_state:
-                continue
-
-            state_target = None
-            # check internal and return transitions
-            ret_int_al = []
-            ret_int_al.extend(self.input_alphabet.internal_alphabet)
-            ret_int_al.extend(self.input_alphabet.return_alphabet)
-            for letter in ret_int_al:
-                for transition in state.transitions[letter]:
-                    if state_target is None:
-                        state_target = transition.target_state
-                    else:
-                        if state_target != transition.target_state:
-                            is_error_state = False
-                            break
-                if not is_error_state:
-                    break
-
-            # check return transitions from the initial state
-            if is_error_state:
-                for return_letter in self.input_alphabet.return_alphabet:
-                    for transition in self.initial_state.transitions[return_letter]:
-                        if transition.stack_guard[0] == state_target.state_id:
-                            if transition.target_state != state_target:
-                                is_error_state = False
-                                break
-                    if not is_error_state:
-                        break
-            else:
-                continue
-
-            if is_error_state:
-                return state
-
-        return None
-
-    def delete_state(self, state_to_remove):
-
-        if state_to_remove is not None:
-            self.states.remove(state_to_remove)
-        else:
-            return
-
-        for state in self.states:
-            ret_int_al = []
-            ret_int_al.extend(self.input_alphabet.internal_alphabet)
-            ret_int_al.extend(self.input_alphabet.return_alphabet)
-            for letter in ret_int_al:
-                cleaned_transitions = []
-                for transition in state.transitions[letter]:
-                    if transition.stack_guard is not None:
-                        if transition.stack_guard[0] == state_to_remove.state_id:
-                            continue
-                    if transition.target_state.state_id == state_to_remove.state_id:
-                        continue
-
-                    cleaned_transitions.append(transition)
-                del state.transitions[letter]
-                state.transitions[letter] = cleaned_transitions
-
-    def get_allowed_call_transitions(self):
-        """
-        Returns a dict of states that are allowed to push a call letters on the stack.
-
-        For all states that are connected via internal transitions from the initial state on, the state_id and
-        call_letter of the stack_guard from every return transition is used.
-
-        States are not allowed to push something somthing on the stack if there is no possibility to pop the
-        stack guard, where their state_id is used, from the stack, which would lead into a dead-end otherwise.
-
-        Returns:
-        - dict: A dictionary where keys are the call_letters and values are sets of the allowed states.
-        """
-
-        # get all states that are connected via internal transitions by using BFS
-        connected_states = set()
-        queue = deque([self.initial_state])
-        while queue:
-            current_state = queue.popleft()
-            connected_states.add(current_state)
-
-            for internal_letter in self.input_alphabet.internal_alphabet:
-                for internal_trans in current_state.transitions[internal_letter]:
-                    target_state = internal_trans.target_state
-                    if target_state not in connected_states:
-                        queue.append(target_state)
-
-        allowed_call_transitions = defaultdict(set)
-        for state in connected_states:
-            for return_letter in self.input_alphabet.return_alphabet:
-                for trans in state.transitions[return_letter]:
-                    allowed_call_transitions[trans.stack_guard[1]].add(trans.stack_guard[0])
-
-        return allowed_call_transitions
-
-    def get_accepting_words_bfs(self, min_word_length: int = 0, num_words: int = 1) -> list:
-        """
-        Generate a list of random words that are accepted by the automaton using the breadth-first search approach.
-
-        Args:
-        - min_word_length (int): Minimum length of the generated words.
-        - amount_words (int): Number of words to generate.
-
-        Returns:
-        - set: A set of randomly generated words that are accepted by the automaton.
-        """
-        allowed_call_trans = self.get_allowed_call_transitions()
-        self.reset_to_initial()
-        queue = deque()
-        shuffled_alphabet = self.input_alphabet.get_merged_alphabet()
-        random.shuffle(shuffled_alphabet)
-        for letter in shuffled_alphabet:
-            queue.append([letter])
-
-        found_words = set()
-        while queue:
-            word = queue.popleft()
-            self.reset_to_initial()
-            self.execute_sequence(self.initial_state, word)
-            # skipping words that lead into the error state will also shorten growth of the queue
-            if self.error_state_reached:
-                continue
-            if self.current_state.is_accepting and self.stack[-1] == self.empty and len(word) >= min_word_length:
-                found_words.add(tuple(word))
-            if len(found_words) >= num_words:
-                found_words = list(found_words)
-                found_words.sort(key=len)
-                return found_words
-            shuffled_alphabet = self.input_alphabet.get_merged_alphabet()
-            for letter in shuffled_alphabet:
-                if letter in allowed_call_trans:
-                    # skip words where it's not possible to pop the stack_guard
-                    if self.current_state.state_id not in allowed_call_trans[letter]:
-                        continue
-                new_word = word + [letter]
-                queue.append(new_word)
-
-    def get_random_accepting_word(self, return_letter_prob: float = 0.5, min_len: int = 2) -> list:
-        """
-        Generate a random word that is accepted by the automaton.
-
-        Only internal letters and return letters will be chosen. If a return letter is randomly chosen a random
-        stack guard will be selected. Then the stack needed stack configuration will be searched by using BFS
-
-        Args:
-        - return_letter_prob (float): Probability for selecting a letter from the return alphabet.
-        - min_len (int): Minimum length of the generated word.
-
-        Returns:
-        - list: A randomly generated word that gets accepted by the automaton.
-        """
-        assert return_letter_prob <= 1.0
-        word = []
-
-        internal_letter_prob = 0.0
-        if len(self.input_alphabet.internal_alphabet) != 0:
-            internal_letter_prob = 1.0 - return_letter_prob
-        else:
-            return_letter_prob = 1.0
-
-        assert (return_letter_prob + internal_letter_prob) == 1.0
-
-        return_letter_boarder = return_letter_prob
-        internal_letter_boarder = return_letter_boarder + internal_letter_prob
-
-        allowed_call_trans = self.get_allowed_call_transitions()
-
-        self.reset_to_initial()
-
-        while True:
-            letter_type = random.uniform(0.0, 1.0)
-            is_return_letter = False
-            if letter_type <= return_letter_boarder:
-                possible_letters = self.input_alphabet.return_alphabet
-                is_return_letter = True
-            elif return_letter_boarder < letter_type <= internal_letter_boarder:
-                possible_letters = self.input_alphabet.internal_alphabet
-            else:
-                assert False
-
-            assert len(possible_letters) > 0
-
-            random_trans_letter_index = random.randint(0, len(possible_letters) - 1)
-            letter_for_word = possible_letters[random_trans_letter_index]
-
-            # find the sub-word for the needed stack guard beginning from the initial state
-            # the new word will be: letter_prefix + word + letter
-            if is_return_letter:
-                # randomly select one of the return transitions with the respective return symbol
-                if len(self.current_state.transitions[letter_for_word]) == 0:
-                    continue
-                elif len(self.current_state.transitions[letter_for_word]) == 1:
-                    random_stack_guard = self.current_state.transitions[letter_for_word][0].stack_guard
-                else:
-                    random_stack_guard_index = random.randint(0,
-                                                              len(self.current_state.transitions[letter_for_word]) - 1)
-                    random_stack_guard = self.current_state.transitions[letter_for_word][
-                        random_stack_guard_index].stack_guard
-
-                # start from the initial state
-                self.reset_to_initial()
-
-                letter_prefix = []
-                needed_stack = self.stack.copy()
-                needed_stack.append(random_stack_guard)
-                queue = deque()
-                for letter in self.input_alphabet.get_merged_alphabet():
-                    queue.append([letter])
-
-                while queue:
-                    letter_prefix = queue.popleft()
-                    self.reset_to_initial()
-                    self.execute_sequence(self.initial_state, letter_prefix)
-                    if self.error_state_reached:
-                        continue
-                    if self.stack == needed_stack:
-                        break
-
-                    for letter in self.input_alphabet.get_merged_alphabet():
-                        if letter in allowed_call_trans:
-                            # skip words where it's not possible to pop the stack_guard
-                            if self.current_state.state_id not in allowed_call_trans[letter]:
-                                continue
-                        new_word = letter_prefix + [letter]
-                        queue.append(new_word)
-
-                for letter in word:
-                    self.step(letter)
-                self.step(letter_for_word)
-                if not self.error_state_reached:
-                    word = letter_prefix + word
-                    word.append(letter_for_word)
-                else:
-                    self.execute_sequence(self.initial_state, word)
-
-            else:
-                self.step(letter_for_word)
-                if not self.error_state_reached:
-                    word.append(letter_for_word)
-                else:
-                    self.execute_sequence(self.initial_state, word)
-
-            if self.current_state.is_accepting and self.stack[-1] == self.empty and len(word) >= min_len \
-                    and random.random() < 0.2:
-                break
-
-        self.reset_to_initial()
-        return word
+import random
+from collections import defaultdict, deque
+from typing import Union
+
+from aalpy.base import Automaton, AutomatonState
+
+from typing import List, Dict
+
+
+class SevpaAlphabet:
+    """
+    The Alphabet of a 1-SEVPA.
+
+    Attributes:
+        internal_alphabet (List[str]): Letters for internal transitions.
+        call_alphabet (List[str]): Letters for push transitions.
+        return_alphabet (List[str]): Letters for pop transitions.
+        exclusive_call_return_pairs (Dict[str, str]): A dictionary representing exclusive pairs
+            of call and return symbols.
+    """
+
+    def __init__(self, internal_alphabet: List[str], call_alphabet: List[str], return_alphabet: List[str],
+                 exclusive_call_return_pairs: Dict[str, str] = None):
+        self.internal_alphabet = internal_alphabet
+        self.call_alphabet = call_alphabet
+        self.return_alphabet = return_alphabet
+        self.exclusive_call_return_pairs = exclusive_call_return_pairs
+
+    def get_merged_alphabet(self) -> List[str]:
+        """
+        Get the merged alphabet, including internal, call, and return symbols.
+
+        Returns:
+            List[str]: A list of all symbols in the alphabet.
+        """
+        alphabet = list()
+        alphabet.extend(self.internal_alphabet)
+        alphabet.extend(self.call_alphabet)
+        alphabet.extend(self.return_alphabet)
+        return alphabet
+
+    def __str__(self) -> str:
+        """
+        Returns:
+            str: A string representation of the alphabet.
+        """
+        return f'Internal: {self.internal_alphabet} Call: {self.call_alphabet} Return: {self.return_alphabet}'
+
+
+class SevpaState(AutomatonState):
+    """
+    Single state of a 1-SEVPA.
+    """
+
+    def __init__(self, state_id, is_accepting=False):
+        super().__init__(state_id)
+        self.transitions = defaultdict(list[SevpaTransition])
+        self.is_accepting = is_accepting
+
+
+class SevpaTransition:
+    """
+    Represents a transition in a 1-SEVPA.
+
+    Attributes:
+        target (SevpaState): The target state of the transition.
+        letter: The symbol associated with the transition.
+        action: The action performed during the transition (pop | None).
+        stack_guard: Pair of (automaton_state_id, call_letter)
+    """
+
+    def __init__(self, target: SevpaState, letter, action, stack_guard=None):
+        self.target_state = target
+        self.letter = letter
+        self.action = action
+        self.stack_guard = stack_guard
+
+    def __str__(self):
+        """
+        Returns:
+            str: A string representation of the transition.
+        """
+        return f'{self.letter} --> {self.target_state.state_id}' + \
+               f' | {self.action}: {self.stack_guard}' if self.stack_guard else ''
+
+
+class Sevpa(Automaton):
+    """
+    1-Module Single Entry Visibly Pushdown Automaton.
+    """
+    empty = "_"
+
+    def __init__(self, initial_state: SevpaState, states: list[SevpaState]):
+        super().__init__(initial_state, states)
+        self.initial_state = initial_state
+        self.states = states
+        self.input_alphabet = self.get_input_alphabet()
+        self.current_state = None
+        self.stack = []
+        self.error_state_reached = False
+
+        # alphabet sets for faster inclusion checks (as in SevpaAlphabet we have lists, for reproducibility)
+        self.internal_set = set(self.input_alphabet.internal_alphabet)
+        self.call_set = set(self.input_alphabet.call_alphabet)
+        self.return_set = set(self.input_alphabet.return_alphabet)
+
+    def reset_to_initial(self):
+        super().reset_to_initial()
+        self.current_state = self.initial_state
+        self.stack = [self.empty]
+        self.error_state_reached = False
+        return self.current_state.is_accepting and self.stack[-1] == self.empty
+
+    def step(self, letter):
+        """
+        Perform a single step on the 1-SEVPA by transitioning with the given input letter.
+
+        Args:
+            letter: A single input that is looked up in the transition table of the SevpaState.
+
+        Returns:
+            bool: True if the reached state is an accepting state and the stack is empty, False otherwise.
+        """
+        if self.error_state_reached:
+            return False
+
+        if letter is None:
+            return self.current_state.is_accepting and self.stack[-1] == self.empty
+
+        if letter in self.call_set:
+            self.stack.append((self.current_state.state_id, letter))
+            self.current_state = self.initial_state
+            return self.current_state.is_accepting and self.stack[-1] == self.empty
+
+        # get possible transitions
+        transitions = self.current_state.transitions[letter]
+        taken_transition = None
+        for t in transitions:
+            if t.letter in self.return_set:
+                if t.stack_guard == self.stack[-1]:
+                    taken_transition = t
+                    break
+            elif t.letter in self.internal_set:
+                taken_transition = t
+                break
+            else:
+                assert False
+
+        # No transition is possible
+        if not taken_transition:
+            self.error_state_reached = True
+            return False
+
+        self.current_state = taken_transition.target_state
+
+        if taken_transition.action == 'pop':
+            # empty stack elem should always be on the stack
+            if len(self.stack) <= 1:
+                self.error_state_reached = True
+                return False
+            self.stack.pop()
+
+        return self.current_state.is_accepting and self.stack[-1] == self.empty
+
+    def get_state_by_id(self, state_id) -> Union[SevpaState, None]:
+        for state in self.states:
+            if state.state_id == state_id:
+                return state
+        return None
+
+    def is_input_complete(self) -> bool:
+        pass
+
+    def execute_sequence(self, origin_state, seq):
+        if origin_state.prefix != self.initial_state.prefix:
+            assert False, 'execute_sequence for Sevpa only is only supported from the initial state.'
+        self.reset_to_initial()
+        self.current_state = origin_state
+        return [self.step(s) for s in seq]
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        sorted_states = sorted(self.states, key=lambda x: x.state_id)
+        for state in sorted_states:
+            transitions_for_symbol = {}
+            for symbol, transition_list in state.transitions.items():
+                trans_list_for_setup = []
+                for transition in transition_list:
+                    trans_list_for_setup.append(
+                        (transition.target_state.state_id, transition.action, transition.stack_guard))
+                if trans_list_for_setup:
+                    transitions_for_symbol[symbol] = trans_list_for_setup
+            state_setup_dict[state.state_id] = (state.is_accepting, transitions_for_symbol)
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup: dict, **kwargs):
+
+        init_state_id = kwargs['init_state_id']
+
+        # build states with state_id and output
+        states = {key: SevpaState(key, val[0]) for key, val in state_setup.items()}
+        # states[Sevpa.error_state.state_id] = Sevpa.error_state  # PdaState(Pda.error_state,False)
+
+        # add transitions to states
+        for state_id, state in states.items():
+            for _input, trans_spec in state_setup[state_id][1].items():
+                for (target_state_id, action, stack_guard) in trans_spec:
+                    if action == 'pop':
+                        stack_guard = (stack_guard[0], stack_guard[1])
+                        trans = SevpaTransition(target=states[target_state_id], letter=_input,
+                                                action=action, stack_guard=stack_guard)
+                    elif action is None:
+                        trans = SevpaTransition(target=states[target_state_id], letter=_input,
+                                                action=None, stack_guard=None)
+                    else:
+                        assert False, 'Action must either be "pop" or None, note that there are no push actions ' \
+                                      'definitions in SEVPA'
+
+                    state.transitions[_input].append(trans)
+
+        init_state = states[init_state_id]
+        return Sevpa(init_state, [state for state in states.values()])
+
+    def transform_access_string(self, state=None, stack_content=None) -> List[str]:
+        """
+        Transform the access string by omitting redundant call and return letters, as well as internal letters.
+
+        This function creates the following word:
+            For every element in the stack (except the first element '_'):
+                - Append the state prefix from where the stack element was pushed
+                - Append the call letter
+            Append the state prefix from the state where you are calling this function from.
+
+        Args:
+            state: The state from which the transformation is initiated (default: initial state).
+            stack_content: The content of the stack for transformation (default: Current Stack content).
+
+        Returns:
+            List[str]: The transformed access string.
+        """
+        word = []
+        calling_state = self.initial_state if not state else state
+        stack = self.stack if not stack_content else stack_content
+
+        for index, stack_elem in enumerate(stack):
+            # Skip the first element because it's the start of the stack '_'
+            if index == 0:
+                continue
+            from_state_id = stack_elem[0]  # The corresponding state where the stack element was pushed from
+            call_letter = stack_elem[1]  # The call letter that was pushed on the stack
+            from_state = self.get_state_by_id(from_state_id)
+            if from_state.prefix != ():
+                word.extend(from_state.prefix)
+            word.append(call_letter)
+        word.extend(calling_state.prefix)
+        return word
+
+    @staticmethod
+    def create_daisy_hypothesis(initial_state, alphabet):
+        """
+        Create a Daisy Hypothesis 1-SEVPA using the given initial state and alphabet.
+
+        This function creates self-loop transitions for the internal state on every internal letter.
+        Additionally, it creates self-loop transitions with a pop action for every call letter.
+
+        Args:
+            initial_state (SevpaState): The initial state of the 1-SEVPA.
+            alphabet (SevpaAlphabet): The alphabet for the 1-SEVPA.
+
+        Returns:
+            Sevpa: The created 1-SEVPA with the specified initial state and alphabet.
+        """
+        for i in alphabet.internal_alphabet:
+            trans = SevpaTransition(target=initial_state, letter=i, action=None)
+            initial_state.transitions[i].append(trans)
+
+        for c in alphabet.call_alphabet:
+            for r in alphabet.return_alphabet:
+                trans = SevpaTransition(target=initial_state, letter=r, action='pop',
+                                        stack_guard=(initial_state.state_id, c))
+                initial_state.transitions[r].append(trans)
+
+        return Sevpa(initial_state, [initial_state])
+
+    def get_input_alphabet(self):
+
+        int_alphabet, ret_alphabet, call_alphabet = [], [], []
+        for state in self.states:
+            for transition_list in state.transitions.values():
+                for transition in transition_list:
+                    if transition.action == 'pop':
+                        if transition.letter not in ret_alphabet:
+                            ret_alphabet.append(transition.letter)
+                        if transition.stack_guard[1] not in call_alphabet:
+                            call_alphabet.append(transition.stack_guard[1])
+                    else:
+                        if transition.letter not in int_alphabet:
+                            int_alphabet.append(transition.letter)
+
+        return SevpaAlphabet(int_alphabet, call_alphabet, ret_alphabet)
+
+    def get_error_state(self):
+        """
+        A state is an error state iff:
+            - if all transitions self loop to itself
+            - if the pop transitions from the corresponding stack symbol lead to the same state
+            - for example:
+                - all q2 transitions lead to q2
+                - the pop transitions from the initial state which pop the q2+call-symbol from the stack lead to q2 as well
+
+            - Not an error state if it is the initial state or an accepting state
+        """
+
+        for state in self.states:
+
+            is_error_state = True
+            if state.is_accepting or state == self.initial_state:
+                continue
+
+            state_target = None
+            # check internal and return transitions
+            ret_int_al = []
+            ret_int_al.extend(self.input_alphabet.internal_alphabet)
+            ret_int_al.extend(self.input_alphabet.return_alphabet)
+            for letter in ret_int_al:
+                for transition in state.transitions[letter]:
+                    if state_target is None:
+                        state_target = transition.target_state
+                    else:
+                        if state_target != transition.target_state:
+                            is_error_state = False
+                            break
+                if not is_error_state:
+                    break
+
+            # check return transitions from the initial state
+            if is_error_state:
+                for return_letter in self.input_alphabet.return_alphabet:
+                    for transition in self.initial_state.transitions[return_letter]:
+                        if transition.stack_guard[0] == state_target.state_id:
+                            if transition.target_state != state_target:
+                                is_error_state = False
+                                break
+                    if not is_error_state:
+                        break
+            else:
+                continue
+
+            if is_error_state:
+                return state
+
+        return None
+
+    def delete_state(self, state_to_remove):
+
+        if state_to_remove is not None:
+            self.states.remove(state_to_remove)
+        else:
+            return
+
+        for state in self.states:
+            ret_int_al = []
+            ret_int_al.extend(self.input_alphabet.internal_alphabet)
+            ret_int_al.extend(self.input_alphabet.return_alphabet)
+            for letter in ret_int_al:
+                cleaned_transitions = []
+                for transition in state.transitions[letter]:
+                    if transition.stack_guard is not None:
+                        if transition.stack_guard[0] == state_to_remove.state_id:
+                            continue
+                    if transition.target_state.state_id == state_to_remove.state_id:
+                        continue
+
+                    cleaned_transitions.append(transition)
+                del state.transitions[letter]
+                state.transitions[letter] = cleaned_transitions
+
+    def get_allowed_call_transitions(self):
+        """
+        Returns a dict of states that are allowed to push a call letters on the stack.
+
+        For all states that are connected via internal transitions from the initial state on, the state_id and
+        call_letter of the stack_guard from every return transition is used.
+
+        States are not allowed to push something somthing on the stack if there is no possibility to pop the
+        stack guard, where their state_id is used, from the stack, which would lead into a dead-end otherwise.
+
+        Returns:
+        - dict: A dictionary where keys are the call_letters and values are sets of the allowed states.
+        """
+
+        # get all states that are connected via internal transitions by using BFS
+        connected_states = set()
+        queue = deque([self.initial_state])
+        while queue:
+            current_state = queue.popleft()
+            connected_states.add(current_state)
+
+            for internal_letter in self.input_alphabet.internal_alphabet:
+                for internal_trans in current_state.transitions[internal_letter]:
+                    target_state = internal_trans.target_state
+                    if target_state not in connected_states:
+                        queue.append(target_state)
+
+        allowed_call_transitions = defaultdict(set)
+        for state in connected_states:
+            for return_letter in self.input_alphabet.return_alphabet:
+                for trans in state.transitions[return_letter]:
+                    allowed_call_transitions[trans.stack_guard[1]].add(trans.stack_guard[0])
+
+        return allowed_call_transitions
+
+    def get_accepting_words_bfs(self, min_word_length: int = 0, num_words: int = 1) -> list:
+        """
+        Generate a list of random words that are accepted by the automaton using the breadth-first search approach.
+
+        Args:
+        - min_word_length (int): Minimum length of the generated words.
+        - amount_words (int): Number of words to generate.
+
+        Returns:
+        - set: A set of randomly generated words that are accepted by the automaton.
+        """
+        allowed_call_trans = self.get_allowed_call_transitions()
+        self.reset_to_initial()
+        queue = deque()
+        shuffled_alphabet = self.input_alphabet.get_merged_alphabet()
+        random.shuffle(shuffled_alphabet)
+        for letter in shuffled_alphabet:
+            queue.append([letter])
+
+        found_words = set()
+        while queue:
+            word = queue.popleft()
+            self.reset_to_initial()
+            self.execute_sequence(self.initial_state, word)
+            # skipping words that lead into the error state will also shorten growth of the queue
+            if self.error_state_reached:
+                continue
+            if self.current_state.is_accepting and self.stack[-1] == self.empty and len(word) >= min_word_length:
+                found_words.add(tuple(word))
+            if len(found_words) >= num_words:
+                found_words = list(found_words)
+                found_words.sort(key=len)
+                return found_words
+            shuffled_alphabet = self.input_alphabet.get_merged_alphabet()
+            for letter in shuffled_alphabet:
+                if letter in allowed_call_trans:
+                    # skip words where it's not possible to pop the stack_guard
+                    if self.current_state.state_id not in allowed_call_trans[letter]:
+                        continue
+                new_word = word + [letter]
+                queue.append(new_word)
+
+    def get_random_accepting_word(self, return_letter_prob: float = 0.5, min_len: int = 2) -> list:
+        """
+        Generate a random word that is accepted by the automaton.
+
+        Only internal letters and return letters will be chosen. If a return letter is randomly chosen a random
+        stack guard will be selected. Then the stack needed stack configuration will be searched by using BFS
+
+        Args:
+        - return_letter_prob (float): Probability for selecting a letter from the return alphabet.
+        - min_len (int): Minimum length of the generated word.
+
+        Returns:
+        - list: A randomly generated word that gets accepted by the automaton.
+        """
+        assert return_letter_prob <= 1.0
+        word = []
+
+        internal_letter_prob = 0.0
+        if len(self.input_alphabet.internal_alphabet) != 0:
+            internal_letter_prob = 1.0 - return_letter_prob
+        else:
+            return_letter_prob = 1.0
+
+        assert (return_letter_prob + internal_letter_prob) == 1.0
+
+        return_letter_boarder = return_letter_prob
+        internal_letter_boarder = return_letter_boarder + internal_letter_prob
+
+        allowed_call_trans = self.get_allowed_call_transitions()
+
+        self.reset_to_initial()
+
+        while True:
+            letter_type = random.uniform(0.0, 1.0)
+            is_return_letter = False
+            if letter_type <= return_letter_boarder:
+                possible_letters = self.input_alphabet.return_alphabet
+                is_return_letter = True
+            elif return_letter_boarder < letter_type <= internal_letter_boarder:
+                possible_letters = self.input_alphabet.internal_alphabet
+            else:
+                assert False
+
+            assert len(possible_letters) > 0
+
+            random_trans_letter_index = random.randint(0, len(possible_letters) - 1)
+            letter_for_word = possible_letters[random_trans_letter_index]
+
+            # find the sub-word for the needed stack guard beginning from the initial state
+            # the new word will be: letter_prefix + word + letter
+            if is_return_letter:
+                # randomly select one of the return transitions with the respective return symbol
+                if len(self.current_state.transitions[letter_for_word]) == 0:
+                    continue
+                elif len(self.current_state.transitions[letter_for_word]) == 1:
+                    random_stack_guard = self.current_state.transitions[letter_for_word][0].stack_guard
+                else:
+                    random_stack_guard_index = random.randint(0,
+                                                              len(self.current_state.transitions[letter_for_word]) - 1)
+                    random_stack_guard = self.current_state.transitions[letter_for_word][
+                        random_stack_guard_index].stack_guard
+
+                # start from the initial state
+                self.reset_to_initial()
+
+                letter_prefix = []
+                needed_stack = self.stack.copy()
+                needed_stack.append(random_stack_guard)
+                queue = deque()
+                for letter in self.input_alphabet.get_merged_alphabet():
+                    queue.append([letter])
+
+                while queue:
+                    letter_prefix = queue.popleft()
+                    self.reset_to_initial()
+                    self.execute_sequence(self.initial_state, letter_prefix)
+                    if self.error_state_reached:
+                        continue
+                    if self.stack == needed_stack:
+                        break
+
+                    for letter in self.input_alphabet.get_merged_alphabet():
+                        if letter in allowed_call_trans:
+                            # skip words where it's not possible to pop the stack_guard
+                            if self.current_state.state_id not in allowed_call_trans[letter]:
+                                continue
+                        new_word = letter_prefix + [letter]
+                        queue.append(new_word)
+
+                for letter in word:
+                    self.step(letter)
+                self.step(letter_for_word)
+                if not self.error_state_reached:
+                    word = letter_prefix + word
+                    word.append(letter_for_word)
+                else:
+                    self.execute_sequence(self.initial_state, word)
+
+            else:
+                self.step(letter_for_word)
+                if not self.error_state_reached:
+                    word.append(letter_for_word)
+                else:
+                    self.execute_sequence(self.initial_state, word)
+
+            if self.current_state.is_accepting and self.stack[-1] == self.empty and len(word) >= min_len \
+                    and random.random() < 0.2:
+                break
+
+        self.reset_to_initial()
+        return word
```

## aalpy/automata/StochasticMealyMachine.py

 * *Ordering differences only*

```diff
@@ -1,145 +1,145 @@
-import random
-from collections import defaultdict
-from typing import Generic, Tuple, List, Dict
-
-from aalpy.automata import MdpState, Mdp
-from aalpy.base import Automaton, AutomatonState
-from aalpy.base.Automaton import OutputType, InputType
-
-
-class StochasticMealyState(AutomatonState, Generic[InputType, OutputType]):
-
-    def __init__(self, state_id):
-        super().__init__(state_id)
-        # Each transition is a tuple (newNode, output, probability)
-        self.transitions: Dict[InputType, List[Tuple[StochasticMealyState, OutputType, float]]] = defaultdict(list)
-
-
-class StochasticMealyMachine(Automaton[StochasticMealyState[InputType, OutputType]]):
-
-    def __init__(self, initial_state: StochasticMealyState, states: list):
-        super().__init__(initial_state, states)
-
-    def reset_to_initial(self):
-        self.current_state = self.initial_state
-
-    def step(self, letter):
-        """
-        Next step is determined based on transition probabilities of the current state.
-
-        Args:
-
-           letter: input
-
-        Returns:
-
-           output of the current state
-        """
-        prob = random.random()
-        probability_distributions = [i[2] for i in self.current_state.transitions[letter]]
-        index = 0
-        for i, p in enumerate(probability_distributions):
-            prob -= p
-            if prob <= 0:
-                index = i
-                break
-
-        transition = self.current_state.transitions[letter][index]
-        self.current_state = transition[0]
-        return transition[1]
-
-    def step_to(self, inp, out):
-        """Performs a step on the automaton based on the input `inp` and output `out`.
-
-        Args:
-
-            inp: input
-            out: output
-
-        Returns:
-
-            output of the reached state, None otherwise
-
-        """
-        for (new_state, output, prob) in self.current_state.transitions[inp]:
-            if output == out:
-                self.current_state = new_state
-                return out
-        return None
-
-    def to_mdp(self):
-        return smm_to_mdp_conversion(self)
-
-    def to_state_setup(self):
-        state_setup_dict = {}
-
-        # ensure initial state is first in the list
-        if self.states[0] != self.initial_state:
-            self.states.remove(self.initial_state)
-            self.states.insert(0, self.initial_state)
-
-        for s in self.states:
-            state_setup_dict[s.state_id] = {k: [(node.state_id, output, prob) for node, output, prob in v]
-                                            for k, v in s.transitions.items()}
-
-        return state_setup_dict
-
-    @staticmethod
-    def from_state_setup(state_setup : dict, **kwargs):
-        states_map = {key: StochasticMealyState(key) for key in state_setup.keys()}
-
-        for key, values in state_setup.items():
-            source = states_map[key]
-            for i, transitions in values.items():
-                for node, output, prob in transitions:
-                    source.transitions[i].append((states_map[node], output, prob))
-
-        initial_state = states_map[list(state_setup.keys())[0]]
-        return StochasticMealyMachine(initial_state, list(states_map.values()))
-
-
-def smm_to_mdp_conversion(smm: StochasticMealyMachine):
-    """
-    Convert SMM to MDP.
-
-    Args:
-      smm: StochasticMealyMachine: SMM to convert
-
-    Returns:
-
-        equivalent MDP
-
-    """
-    inputs = smm.get_input_alphabet()
-    mdp_states = []
-    smm_state_to_mdp_state = dict()
-    init_state = MdpState("0", "___start___")
-    mdp_states.append(init_state)
-    for s in smm.states:
-        incoming_edges = defaultdict(list)
-        incoming_outputs = set()
-        for pre_s in smm.states:
-            for i in inputs:
-                incoming_edges[i] += filter(lambda t: t[0] == s, pre_s.transitions[i])
-                incoming_outputs.update(map(lambda t: t[1], incoming_edges[i]))
-        state_id = 0
-        for o in incoming_outputs:
-            new_state_id = s.state_id + str(state_id)
-            state_id += 1
-            new_state = MdpState(new_state_id, o)
-            mdp_states.append(new_state)
-            smm_state_to_mdp_state[(s.state_id, o)] = new_state
-
-    for s in smm.states:
-        mdp_states_for_s = {mdp_state for (s_id, o), mdp_state in smm_state_to_mdp_state.items() if s_id == s.state_id}
-        for i in inputs:
-            for outgoing_t in s.transitions[i]:
-                target_smm_state = outgoing_t[0]
-                output = outgoing_t[1]
-                prob = outgoing_t[2]
-                target_mdp_state = smm_state_to_mdp_state[(target_smm_state.state_id, output)]
-                for mdp_state in mdp_states_for_s:
-                    mdp_state.transitions[i].append((target_mdp_state, prob))
-                if s == smm.initial_state:
-                    init_state.transitions[i].append((target_mdp_state, prob))
-    return Mdp(init_state, mdp_states)
+import random
+from collections import defaultdict
+from typing import Generic, Tuple, List, Dict
+
+from aalpy.automata import MdpState, Mdp
+from aalpy.base import Automaton, AutomatonState
+from aalpy.base.Automaton import OutputType, InputType
+
+
+class StochasticMealyState(AutomatonState, Generic[InputType, OutputType]):
+
+    def __init__(self, state_id):
+        super().__init__(state_id)
+        # Each transition is a tuple (newNode, output, probability)
+        self.transitions: Dict[InputType, List[Tuple[StochasticMealyState, OutputType, float]]] = defaultdict(list)
+
+
+class StochasticMealyMachine(Automaton[StochasticMealyState[InputType, OutputType]]):
+
+    def __init__(self, initial_state: StochasticMealyState, states: list):
+        super().__init__(initial_state, states)
+
+    def reset_to_initial(self):
+        self.current_state = self.initial_state
+
+    def step(self, letter):
+        """
+        Next step is determined based on transition probabilities of the current state.
+
+        Args:
+
+           letter: input
+
+        Returns:
+
+           output of the current state
+        """
+        prob = random.random()
+        probability_distributions = [i[2] for i in self.current_state.transitions[letter]]
+        index = 0
+        for i, p in enumerate(probability_distributions):
+            prob -= p
+            if prob <= 0:
+                index = i
+                break
+
+        transition = self.current_state.transitions[letter][index]
+        self.current_state = transition[0]
+        return transition[1]
+
+    def step_to(self, inp, out):
+        """Performs a step on the automaton based on the input `inp` and output `out`.
+
+        Args:
+
+            inp: input
+            out: output
+
+        Returns:
+
+            output of the reached state, None otherwise
+
+        """
+        for (new_state, output, prob) in self.current_state.transitions[inp]:
+            if output == out:
+                self.current_state = new_state
+                return out
+        return None
+
+    def to_mdp(self):
+        return smm_to_mdp_conversion(self)
+
+    def to_state_setup(self):
+        state_setup_dict = {}
+
+        # ensure initial state is first in the list
+        if self.states[0] != self.initial_state:
+            self.states.remove(self.initial_state)
+            self.states.insert(0, self.initial_state)
+
+        for s in self.states:
+            state_setup_dict[s.state_id] = {k: [(node.state_id, output, prob) for node, output, prob in v]
+                                            for k, v in s.transitions.items()}
+
+        return state_setup_dict
+
+    @staticmethod
+    def from_state_setup(state_setup : dict, **kwargs):
+        states_map = {key: StochasticMealyState(key) for key in state_setup.keys()}
+
+        for key, values in state_setup.items():
+            source = states_map[key]
+            for i, transitions in values.items():
+                for node, output, prob in transitions:
+                    source.transitions[i].append((states_map[node], output, prob))
+
+        initial_state = states_map[list(state_setup.keys())[0]]
+        return StochasticMealyMachine(initial_state, list(states_map.values()))
+
+
+def smm_to_mdp_conversion(smm: StochasticMealyMachine):
+    """
+    Convert SMM to MDP.
+
+    Args:
+      smm: StochasticMealyMachine: SMM to convert
+
+    Returns:
+
+        equivalent MDP
+
+    """
+    inputs = smm.get_input_alphabet()
+    mdp_states = []
+    smm_state_to_mdp_state = dict()
+    init_state = MdpState("0", "___start___")
+    mdp_states.append(init_state)
+    for s in smm.states:
+        incoming_edges = defaultdict(list)
+        incoming_outputs = set()
+        for pre_s in smm.states:
+            for i in inputs:
+                incoming_edges[i] += filter(lambda t: t[0] == s, pre_s.transitions[i])
+                incoming_outputs.update(map(lambda t: t[1], incoming_edges[i]))
+        state_id = 0
+        for o in incoming_outputs:
+            new_state_id = s.state_id + str(state_id)
+            state_id += 1
+            new_state = MdpState(new_state_id, o)
+            mdp_states.append(new_state)
+            smm_state_to_mdp_state[(s.state_id, o)] = new_state
+
+    for s in smm.states:
+        mdp_states_for_s = {mdp_state for (s_id, o), mdp_state in smm_state_to_mdp_state.items() if s_id == s.state_id}
+        for i in inputs:
+            for outgoing_t in s.transitions[i]:
+                target_smm_state = outgoing_t[0]
+                output = outgoing_t[1]
+                prob = outgoing_t[2]
+                target_mdp_state = smm_state_to_mdp_state[(target_smm_state.state_id, output)]
+                for mdp_state in mdp_states_for_s:
+                    mdp_state.transitions[i].append((target_mdp_state, prob))
+                if s == smm.initial_state:
+                    init_state.transitions[i].append((target_mdp_state, prob))
+    return Mdp(init_state, mdp_states)
```

## aalpy/automata/__init__.py

 * *Ordering differences only*

```diff
@@ -1,8 +1,8 @@
-from .Dfa import Dfa, DfaState
-from .Mdp import Mdp, MdpState
-from .MealyMachine import MealyMachine, MealyState
-from .MooreMachine import MooreMachine, MooreState
-from .Onfsm import Onfsm, OnfsmState
-from .StochasticMealyMachine import StochasticMealyMachine, StochasticMealyState
-from .MarkovChain import MarkovChain, McState
-from .Sevpa import Sevpa, SevpaState, SevpaAlphabet, SevpaTransition
+from .Dfa import Dfa, DfaState
+from .Mdp import Mdp, MdpState
+from .MealyMachine import MealyMachine, MealyState
+from .MooreMachine import MooreMachine, MooreState
+from .Onfsm import Onfsm, OnfsmState
+from .StochasticMealyMachine import StochasticMealyMachine, StochasticMealyState
+from .MarkovChain import MarkovChain, McState
+from .Sevpa import Sevpa, SevpaState, SevpaAlphabet, SevpaTransition
```

## aalpy/base/Automaton.py

```diff
@@ -1,447 +1,448 @@
-import copy
-import warnings
-from abc import ABC, abstractmethod
-from collections import defaultdict
-from typing import Union, TypeVar, Generic, List
-
-
-class AutomatonState(ABC):
-
-    def __init__(self, state_id):
-        """
-        Single state of an automaton. Each state consists of a state id, a dictionary of transitions, where the keys are
-        inputs and the values are the corresponding target states, and a prefix that leads to the state from the initial
-        state.
-
-        Args:
-
-            state_id(Any): used for graphical representation of the state. A good practice is to keep it unique.
-
-        """
-        self.state_id = state_id
-        self.transitions = None
-        self.prefix = None
-
-    def get_diff_state_transitions(self) -> list:
-        """
-        Returns a list of transitions that lead to new states, not same-state transitions.
-        """
-        transitions = []
-        for trans, state in self.transitions.items():
-            if state != self:
-                transitions.append(trans)
-        return transitions
-
-    def get_same_state_transitions(self) -> list:
-        """
-        Get all transitions that lead to the same state (self loops).
-        """
-        dst = self.get_diff_state_transitions()
-        all_trans = set(self.transitions.keys())
-        return [t for t in all_trans if t not in dst]
-
-
-AutomatonStateType = TypeVar("AutomatonStateType", bound=AutomatonState)
-
-OutputType = TypeVar("OutputType")
-InputType = TypeVar("InputType")
-
-
-class Automaton(ABC, Generic[AutomatonStateType]):
-    """
-    Abstract class representing an automaton.
-    """
-
-    def __init__(self, initial_state: AutomatonStateType, states: List[AutomatonStateType]):
-        """
-        Args:
-
-            initial_state (AutomatonState): initial state of the automaton
-            states (list) : list containing all states of the automaton
-
-        """
-        self.initial_state: AutomatonStateType = initial_state
-        self.states: List[AutomatonStateType] = states
-        self.characterization_set: list = []
-        self.current_state: AutomatonStateType = initial_state
-
-    @property
-    def size(self):
-        return len(self.states)
-
-    def reset_to_initial(self):
-        """
-        Resets the current state of the automaton to the initial state
-        """
-        self.current_state = self.initial_state
-
-    @abstractmethod
-    def step(self, letter):
-        """
-        Performs a single step on the automaton changing its current state.
-
-        Args:
-
-            letter: element of the input alphabet to be executed on the system under learning
-
-        Returns:
-
-            Output produced when executing the input letter from the current state
-
-        """
-        pass
-
-    def is_input_complete(self) -> bool:
-        """
-        Check whether all states have defined transition for all inputs
-        :return: true if automaton is input complete
-
-        Returns:
-
-            True if input complete, False otherwise
-
-        """
-        alphabet = set(self.get_input_alphabet())
-        for state in self.states:
-            if set(state.transitions.keys()) != alphabet:
-                return False
-        return True
-
-    # returns a list which is input alphabet, or a sevpa alphabet in case of VPAs
-    def get_input_alphabet(self):
-        """
-        Returns the input alphabet
-        """
-        alphabet = list()
-        for s in self.states:
-            for i in s.transitions.keys():
-                if i not in alphabet:
-                    alphabet.append(i)
-        return list(alphabet)
-
-    def get_state_by_id(self, state_id) -> Union[AutomatonStateType, None]:
-        for state in self.states:
-            if state.state_id == state_id:
-                return state
-
-        return None
-
-    def __str__(self):
-        """
-        :return: A string representation of the automaton
-        """
-        from aalpy.utils import save_automaton_to_file
-        return save_automaton_to_file(self, path='learnedModel', file_type='string', round_floats=2)
-
-    def make_input_complete(self, missing_transition_go_to='self_loop'):
-        """
-        For more details check the implementation of this method in utils.HelperFunctions
-
-        missing_transition_go_to: either 'self_loop' or 'sink_state'.
-        """
-        from aalpy.utils.HelperFunctions import make_input_complete
-        make_input_complete(self, missing_transition_go_to)
-
-    def execute_sequence(self, origin_state, seq):
-        self.current_state = origin_state
-        return [self.step(s) for s in seq]
-
-    def save(self, file_path='LearnedModel'):
-        from aalpy.utils import save_automaton_to_file
-        save_automaton_to_file(self, path=file_path)
-
-    def visualize(self, path='LearnedModel', file_type='pdf', display_same_state_transitions=True):
-        from aalpy.utils import visualize_automaton
-        visualize_automaton(self, path, file_type, display_same_state_transitions)
-
-    @staticmethod
-    @abstractmethod
-    def from_state_setup(state_setup: dict, **kwargs) -> 'Automaton':
-        pass
-
-    @abstractmethod
-    def to_state_setup(self):
-        pass
-
-    def copy(self) -> 'Automaton':
-        return self.from_state_setup(self.to_state_setup())
-
-    def __reduce__(self):
-        return self.from_state_setup, (self.to_state_setup(),)
-
-
-class DeterministicAutomaton(Automaton[AutomatonStateType]):
-
-    @abstractmethod
-    def step(self, letter):
-        pass
-
-    def get_shortest_path(self, origin_state: AutomatonStateType, target_state: AutomatonStateType) -> Union[
-        tuple, None]:
-        """
-        Breath First Search over the automaton to find the shortest path
-
-        Args:
-
-            origin_state (AutomatonState): state from which the BFS will start
-            target_state (AutomatonState): state that will be reached with the return value
-
-        Returns:
-
-            sequence of inputs that lead from origin_state to target state, or None if target state is not reachable
-            from origin state
-
-        """
-        if origin_state not in self.states or target_state not in self.states:
-            warnings.warn('Origin or target state not in automaton. Returning None.')
-            return None
-
-        explored = []
-        queue = [[origin_state]]
-
-        if origin_state == target_state:
-            return ()
-
-        while queue:
-            path = queue.pop(0)
-            node = path[-1]
-            if node not in explored:
-                neighbours = node.transitions.values()
-                for neighbour in neighbours:
-                    new_path = list(path)
-                    new_path.append(neighbour)
-                    queue.append(new_path)
-                    # return path if neighbour is goal
-                    if neighbour == target_state:
-                        acc_seq = new_path[:-1]
-                        inputs = []
-                        for ind, state in enumerate(acc_seq):
-                            inputs.append(next(key for key, value in state.transitions.items()
-                                               if value == new_path[ind + 1]))
-                        return tuple(inputs)
-
-                # mark node as explored
-                explored.append(node)
-
-        return None
-
-    def is_strongly_connected(self) -> bool:
-        """
-        Check whether the automaton is strongly connected,
-        meaning that every state can be reached from every other state.
-
-        Returns:
-
-            True if strongly connected, False otherwise
-
-        """
-        import itertools
-
-        state_comb_list = itertools.permutations(self.states, 2)
-        for state_comb in state_comb_list:
-            if self.get_shortest_path(state_comb[0], state_comb[1]) is None:
-                return False
-        return True
-
-    def output_step(self, state, letter):
-        """
-            Given an input letter, compute the output response from a given state.
-            Args:
-                state: state from which the output response shall be computed
-                letter: an input letter from the alphabet
-
-            Returns: the single-step output response
-
-        """
-        state_save = self.current_state
-        self.current_state = state
-        output = self.step(letter)
-        self.current_state = state_save
-        return output
-
-    def find_distinguishing_seq(self, state1, state2):
-        """
-        A BFS to determine an input sequence that distinguishes two states in the automaton, i.e., a sequence such that
-        the output response from the given states is different. In a minimal automaton, this function always returns a
-        sequence different from None
-        Args:
-            state1: first state
-            state2: second state to distinguish
-
-        Returns: an input sequence distinguishing two states, or None if the states are equivalent
-
-        """
-        visited = set()
-        to_explore = [(state1, state2, [])]
-        alphabet = self.get_input_alphabet()
-        while to_explore:
-            (curr_s1, curr_s2, prefix) = to_explore.pop(0)
-            visited.add((curr_s1, curr_s2))
-            for i in alphabet:
-                o1 = self.output_step(curr_s1, i)
-                o2 = self.output_step(curr_s2, i)
-                new_prefix = prefix + [i]
-                if o1 != o2:
-                    return new_prefix
-                else:
-                    next_s1 = curr_s1.transitions[i]
-                    next_s2 = curr_s2.transitions[i]
-                    if (next_s1, next_s2) not in visited:
-                        to_explore.append((next_s1, next_s2, new_prefix))
-
-        return None
-
-    def compute_output_seq(self, state, sequence):
-        """
-        Given an input sequence, compute the output response from a given state.
-        Args:
-            state: state from which the output response shall be computed
-            sequence: an input sequence over the alphabet
-
-        Returns: the output response
-
-        """
-        state_save = self.current_state
-        output = self.execute_sequence(state, sequence)
-        self.current_state = state_save
-        return output
-
-    def is_minimal(self):
-        if not self.is_input_complete():
-            warnings.warn('Minimization of non input complete automata is not yet supported. Returning False.')
-            return False
-        return self.compute_characterization_set(raise_warning=False) is not None
-
-    def compute_characterization_set(self, char_set_init=None,
-                                     online_suffix_closure=True,
-                                     split_all_blocks=True,
-                                     return_same_states=False,
-                                     raise_warning=True):
-        """
-        Computation of a characterization set, that is, a set of sequences that can distinguish all states in the
-        automation. The implementation follows the approach for finding multiple preset diagnosing experiments described
-        by Arthur Gill in "Introduction to the Theory of Finite State Machines".
-        Some optional parameterized adaptations, e.g., for computing suffix-closed sets target the application in
-        L*-based learning and conformance testing.
-        The function only works for minimal automata.
-        Args:
-            char_set_init: a list of sequence that will be included in the characterization set, e.g., the input
-                        alphabet. A empty sequance is added to this list when using automata with state labels
-                        (DFA and Moore)
-            online_suffix_closure: if true, ensures suffix closedness of the characterization set at every computation
-                                step
-            split_all_blocks: if false, the computation follows the original tree-based strategy, where newly computed
-                        sequences are only checked on a subset of the states to be distinguished
-                        if true, sequences are used to distinguish all states, yielding a potentially smaller set, which
-                        is useful for conformance testing and learning
-            return_same_states: if True, a single distinguishable pair of states will be returned, or None None if there
-                        are no non-distinguishable states
-            raise_warning: prints warning message if characterization set cannot be computed
-
-        Returns: a characterization set or None if a non-minimal automaton is passed to the function
-
-        """
-        blocks = list()
-        blocks.append(copy.copy(self.states))
-        char_set = [] if not char_set_init else char_set_init
-        if char_set_init:
-            for seq in char_set_init:
-                blocks = self._split_blocks(blocks, seq)
-
-        while True:
-            # Given a partition (of states), this function returns a block with at least two elements.
-            try:
-                block_to_split = next(filter(lambda b: len(b) > 1, blocks))
-            except StopIteration:
-                block_to_split = None
-
-            if not block_to_split:
-                break
-            split_state1 = block_to_split[0]
-            split_state2 = block_to_split[1]
-            dist_seq = self.find_distinguishing_seq(split_state1, split_state2)
-            if dist_seq is None:
-                if return_same_states:
-                    return split_state1, split_state2
-
-                if raise_warning:
-                    warnings.warn("Automaton is non-canonical: could not compute characterization set."
-                                  "Returning None.")
-                return None
-
-            # in L*-based learning, we use suffix-closed column labels, so it makes sense to use a suffix-closed
-            # char set in this context
-            if online_suffix_closure:
-                dist_seq_closure = [tuple(dist_seq[len(dist_seq) - i - 1:]) for i in range(len(dist_seq))]
-            else:
-                dist_seq_closure = [tuple(dist_seq)]
-
-            # the standard approach described by Gill, computes a sequence that splits one block and really only splits
-            # one block, that is, it is only applied to the states in said block
-            # in L*-based learning we combine every prefix with every, therefore it makes sense to apply the sequence
-            # on all blocks and split all
-            if split_all_blocks:
-                for seq in dist_seq_closure:
-                    # seq may be in char_set if we do the closure on the fly
-                    if seq in char_set:
-                        continue
-                    char_set.append(seq)
-                    blocks = self._split_blocks(blocks, seq)
-            else:
-                blocks.remove(block_to_split)
-                new_blocks = [block_to_split]
-                for seq in dist_seq_closure:
-                    char_set.append(seq)
-                    new_blocks = self._split_blocks(new_blocks, seq)
-                for new_block in new_blocks:
-                    blocks.append(new_block)
-
-        char_set = list(set(char_set))
-        if return_same_states:
-            return None, None
-        return char_set
-
-    def _split_blocks(self, blocks, seq):
-        """
-        Refines a partition of states (blocks) using the output response to a given input sequence seq.
-        Args:
-            blocks: a partition of states
-            seq: an input sequence
-
-        Returns: a refined partition of states
-
-        """
-        new_blocks = []
-        for block in blocks:
-            block_after_split = defaultdict(list)
-            for state in block:
-                output_seq = tuple(self.compute_output_seq(state, seq))
-                block_after_split[output_seq].append(state)
-            for new_block in block_after_split.values():
-                new_blocks.append(new_block)
-        return new_blocks
-
-    def compute_prefixes(self):
-        for s in self.states:
-            if not s.prefix:
-                s.prefix = self.get_shortest_path(self.initial_state, s)
-
-    def minimize(self):
-        if not self.is_input_complete():
-            warnings.warn('Minimization of non input complete automata is not yet supported.\n Model not minimized.')
-            return
-
-        s1, s2 = self.compute_characterization_set(return_same_states=True)
-        while s1 and s2:
-            for s in self.states:
-                for i, new_state in s.transitions.items():
-                    if new_state == s2:
-                        s.transitions[i] = s1
-            self.states.remove(s2)
-            s1, s2 = self.compute_characterization_set(return_same_states=True)
-
-        self.compute_prefixes()
-
-    def __eq__(self, other):
-        from aalpy.utils import bisimilar
+import copy
+import warnings
+from abc import ABC, abstractmethod
+from collections import defaultdict
+from typing import Union, TypeVar, Generic, List
+
+
+class AutomatonState(ABC):
+
+    def __init__(self, state_id):
+        """
+        Single state of an automaton. Each state consists of a state id, a dictionary of transitions, where the keys are
+        inputs and the values are the corresponding target states, and a prefix that leads to the state from the initial
+        state.
+
+        Args:
+
+            state_id(Any): used for graphical representation of the state. A good practice is to keep it unique.
+
+        """
+        self.state_id = state_id
+        self.transitions = None
+        self.prefix = None
+
+    def get_diff_state_transitions(self) -> list:
+        """
+        Returns a list of transitions that lead to new states, not same-state transitions.
+        """
+        transitions = []
+        for trans, state in self.transitions.items():
+            if state != self:
+                transitions.append(trans)
+        return transitions
+
+    def get_same_state_transitions(self) -> list:
+        """
+        Get all transitions that lead to the same state (self loops).
+        """
+        dst = self.get_diff_state_transitions()
+        all_trans = set(self.transitions.keys())
+        return [t for t in all_trans if t not in dst]
+
+
+AutomatonStateType = TypeVar("AutomatonStateType", bound=AutomatonState)
+
+OutputType = TypeVar("OutputType")
+InputType = TypeVar("InputType")
+
+
+class Automaton(ABC, Generic[AutomatonStateType]):
+    """
+    Abstract class representing an automaton.
+    """
+
+    def __init__(self, initial_state: AutomatonStateType, states: List[AutomatonStateType]):
+        """
+        Args:
+
+            initial_state (AutomatonState): initial state of the automaton
+            states (list) : list containing all states of the automaton
+
+        """
+        self.initial_state: AutomatonStateType = initial_state
+        self.states: List[AutomatonStateType] = states
+        self.characterization_set: list = []
+        self.current_state: AutomatonStateType = initial_state
+
+    @property
+    def size(self):
+        return len(self.states)
+
+    def reset_to_initial(self):
+        """
+        Resets the current state of the automaton to the initial state
+        """
+        self.current_state = self.initial_state
+
+    @abstractmethod
+    def step(self, letter):
+        """
+        Performs a single step on the automaton changing its current state.
+
+        Args:
+
+            letter: element of the input alphabet to be executed on the system under learning
+
+        Returns:
+
+            Output produced when executing the input letter from the current state
+
+        """
+        pass
+
+    def is_input_complete(self) -> bool:
+        """
+        Check whether all states have defined transition for all inputs
+        :return: true if automaton is input complete
+
+        Returns:
+
+            True if input complete, False otherwise
+
+        """
+        alphabet = set(self.get_input_alphabet())
+        for state in self.states:
+            if set(state.transitions.keys()) != alphabet:
+                return False
+        return True
+
+    # returns a list which is input alphabet, or a sevpa alphabet in case of VPAs
+    def get_input_alphabet(self):
+        """
+        Returns the input alphabet
+        """
+        alphabet = list()
+        for s in self.states:
+            for i in s.transitions.keys():
+                if i not in alphabet:
+                    alphabet.append(i)
+        return list(alphabet)
+
+    def get_state_by_id(self, state_id) -> Union[AutomatonStateType, None]:
+        for state in self.states:
+            if state.state_id == state_id:
+                return state
+
+        return None
+
+    def __str__(self):
+        """
+        :return: A string representation of the automaton
+        """
+        from aalpy.utils import save_automaton_to_file
+        return save_automaton_to_file(self, path='learnedModel', file_type='string', round_floats=2)
+
+    def make_input_complete(self, missing_transition_go_to='self_loop'):
+        """
+        For more details check the implementation of this method in utils.HelperFunctions
+
+        missing_transition_go_to: either 'self_loop' or 'sink_state'.
+        """
+        from aalpy.utils.HelperFunctions import make_input_complete
+        make_input_complete(self, missing_transition_go_to)
+
+    def execute_sequence(self, origin_state, seq):
+        self.current_state = origin_state
+        return [self.step(s) for s in seq]
+
+    def save(self, file_path='LearnedModel', file_type='dot'):
+        from aalpy.utils import save_automaton_to_file
+        save_automaton_to_file(self, path=file_path, file_type=file_type)
+
+    def visualize(self, path='LearnedModel', file_type='pdf', display_same_state_transitions=True):
+        from aalpy.utils import visualize_automaton
+        visualize_automaton(self, path, file_type, display_same_state_transitions)
+
+    @staticmethod
+    @abstractmethod
+    def from_state_setup(state_setup: dict, **kwargs) -> 'Automaton':
+        pass
+
+    @abstractmethod
+    def to_state_setup(self):
+        pass
+
+    def copy(self) -> 'Automaton':
+        return self.from_state_setup(self.to_state_setup())
+
+    def __reduce__(self):
+        return self.from_state_setup, (self.to_state_setup(),)
+
+
+class DeterministicAutomaton(Automaton[AutomatonStateType]):
+
+    @abstractmethod
+    def step(self, letter):
+        pass
+
+    def get_shortest_path(self, origin_state: AutomatonStateType, target_state: AutomatonStateType) -> Union[
+        tuple, None]:
+        """
+        Breath First Search over the automaton to find the shortest path
+
+        Args:
+
+            origin_state (AutomatonState): state from which the BFS will start
+            target_state (AutomatonState): state that will be reached with the return value
+
+        Returns:
+
+            sequence of inputs that lead from origin_state to target state, or None if target state is not reachable
+            from origin state
+
+        """
+        if origin_state not in self.states or target_state not in self.states:
+            warnings.warn('Origin or target state not in automaton. Returning None.')
+            return None
+
+        explored = []
+        queue = [[origin_state]]
+
+        if origin_state == target_state:
+            return ()
+
+        while queue:
+            path = queue.pop(0)
+            node = path[-1]
+            if node not in explored:
+                neighbours = node.transitions.values()
+                for neighbour in neighbours:
+                    new_path = list(path)
+                    new_path.append(neighbour)
+                    queue.append(new_path)
+                    # return path if neighbour is goal
+                    if neighbour == target_state:
+                        acc_seq = new_path[:-1]
+                        inputs = []
+                        for ind, state in enumerate(acc_seq):
+                            inputs.append(next(key for key, value in state.transitions.items()
+                                               if value == new_path[ind + 1]))
+                        return tuple(inputs)
+
+                # mark node as explored
+                explored.append(node)
+
+        return None
+
+    def is_strongly_connected(self) -> bool:
+        """
+        Check whether the automaton is strongly connected,
+        meaning that every state can be reached from every other state.
+
+        Returns:
+
+            True if strongly connected, False otherwise
+
+        """
+        import itertools
+
+        state_comb_list = itertools.permutations(self.states, 2)
+        for state_comb in state_comb_list:
+            if self.get_shortest_path(state_comb[0], state_comb[1]) is None:
+                return False
+        return True
+
+    def output_step(self, state, letter):
+        """
+            Given an input letter, compute the output response from a given state.
+            Args:
+                state: state from which the output response shall be computed
+                letter: an input letter from the alphabet
+
+            Returns: the single-step output response
+
+        """
+        state_save = self.current_state
+        self.current_state = state
+        output = self.step(letter)
+        self.current_state = state_save
+        return output
+
+    def find_distinguishing_seq(self, state1, state2, alphabet):
+        """
+        A BFS to determine an input sequence that distinguishes two states in the automaton, i.e., a sequence such that
+        the output response from the given states is different. In a minimal automaton, this function always returns a
+        sequence different from None
+        Args:
+            state1: first state
+            state2: second state to distinguish
+            alphabet: input alphabet of the automaton
+
+        Returns: an input sequence distinguishing two states, or None if the states are equivalent
+
+        """
+        visited = set()
+        to_explore = [(state1, state2, [])]
+        while to_explore:
+            (curr_s1, curr_s2, prefix) = to_explore.pop(0)
+            visited.add((curr_s1, curr_s2))
+            for i in alphabet:
+                o1 = self.output_step(curr_s1, i)
+                o2 = self.output_step(curr_s2, i)
+                new_prefix = prefix + [i]
+                if o1 != o2:
+                    return new_prefix
+                else:
+                    next_s1 = curr_s1.transitions[i]
+                    next_s2 = curr_s2.transitions[i]
+                    if (next_s1, next_s2) not in visited:
+                        to_explore.append((next_s1, next_s2, new_prefix))
+
+        return None
+
+    def compute_output_seq(self, state, sequence):
+        """
+        Given an input sequence, compute the output response from a given state.
+        Args:
+            state: state from which the output response shall be computed
+            sequence: an input sequence over the alphabet
+
+        Returns: the output response
+
+        """
+        state_save = self.current_state
+        output = self.execute_sequence(state, sequence)
+        self.current_state = state_save
+        return output
+
+    def is_minimal(self):
+        if not self.is_input_complete():
+            warnings.warn('Minimization of non input complete automata is not yet supported. Returning False.')
+            return False
+        return self.compute_characterization_set(raise_warning=False) is not None
+
+    def compute_characterization_set(self, char_set_init=None,
+                                     online_suffix_closure=True,
+                                     split_all_blocks=True,
+                                     return_same_states=False,
+                                     raise_warning=True):
+        """
+        Computation of a characterization set, that is, a set of sequences that can distinguish all states in the
+        automation. The implementation follows the approach for finding multiple preset diagnosing experiments described
+        by Arthur Gill in "Introduction to the Theory of Finite State Machines".
+        Some optional parameterized adaptations, e.g., for computing suffix-closed sets target the application in
+        L*-based learning and conformance testing.
+        The function only works for minimal automata.
+        Args:
+            char_set_init: a list of sequence that will be included in the characterization set, e.g., the input
+                        alphabet. A empty sequance is added to this list when using automata with state labels
+                        (DFA and Moore)
+            online_suffix_closure: if true, ensures suffix closedness of the characterization set at every computation
+                                step
+            split_all_blocks: if false, the computation follows the original tree-based strategy, where newly computed
+                        sequences are only checked on a subset of the states to be distinguished
+                        if true, sequences are used to distinguish all states, yielding a potentially smaller set, which
+                        is useful for conformance testing and learning
+            return_same_states: if True, a single distinguishable pair of states will be returned, or None None if there
+                        are no non-distinguishable states
+            raise_warning: prints warning message if characterization set cannot be computed
+
+        Returns: a characterization set or None if a non-minimal automaton is passed to the function
+
+        """
+        blocks = list()
+        blocks.append(copy.copy(self.states))
+        char_set = [] if not char_set_init else char_set_init
+        if char_set_init:
+            for seq in char_set_init:
+                blocks = self._split_blocks(blocks, seq)
+
+        alphabet = self.get_input_alphabet()
+        while True:
+            # Given a partition (of states), this function returns a block with at least two elements.
+            try:
+                block_to_split = next(filter(lambda b: len(b) > 1, blocks))
+            except StopIteration:
+                block_to_split = None
+
+            if not block_to_split:
+                break
+            split_state1 = block_to_split[0]
+            split_state2 = block_to_split[1]
+            dist_seq = self.find_distinguishing_seq(split_state1, split_state2, alphabet)
+            if dist_seq is None:
+                if return_same_states:
+                    return split_state1, split_state2
+
+                if raise_warning:
+                    warnings.warn("Automaton is non-canonical: could not compute characterization set."
+                                  "Returning None.")
+                return None
+
+            # in L*-based learning, we use suffix-closed column labels, so it makes sense to use a suffix-closed
+            # char set in this context
+            if online_suffix_closure:
+                dist_seq_closure = [tuple(dist_seq[len(dist_seq) - i - 1:]) for i in range(len(dist_seq))]
+            else:
+                dist_seq_closure = [tuple(dist_seq)]
+
+            # the standard approach described by Gill, computes a sequence that splits one block and really only splits
+            # one block, that is, it is only applied to the states in said block
+            # in L*-based learning we combine every prefix with every, therefore it makes sense to apply the sequence
+            # on all blocks and split all
+            if split_all_blocks:
+                for seq in dist_seq_closure:
+                    # seq may be in char_set if we do the closure on the fly
+                    if seq in char_set:
+                        continue
+                    char_set.append(seq)
+                    blocks = self._split_blocks(blocks, seq)
+            else:
+                blocks.remove(block_to_split)
+                new_blocks = [block_to_split]
+                for seq in dist_seq_closure:
+                    char_set.append(seq)
+                    new_blocks = self._split_blocks(new_blocks, seq)
+                for new_block in new_blocks:
+                    blocks.append(new_block)
+
+        char_set = list(set(char_set))
+        if return_same_states:
+            return None, None
+        return char_set
+
+    def _split_blocks(self, blocks, seq):
+        """
+        Refines a partition of states (blocks) using the output response to a given input sequence seq.
+        Args:
+            blocks: a partition of states
+            seq: an input sequence
+
+        Returns: a refined partition of states
+
+        """
+        new_blocks = []
+        for block in blocks:
+            block_after_split = defaultdict(list)
+            for state in block:
+                output_seq = tuple(self.compute_output_seq(state, seq))
+                block_after_split[output_seq].append(state)
+            for new_block in block_after_split.values():
+                new_blocks.append(new_block)
+        return new_blocks
+
+    def compute_prefixes(self):
+        for s in self.states:
+            if not s.prefix:
+                s.prefix = self.get_shortest_path(self.initial_state, s)
+
+    def minimize(self):
+        if not self.is_input_complete():
+            warnings.warn('Minimization of non input complete automata is not yet supported.\n Model not minimized.')
+            return
+
+        s1, s2 = self.compute_characterization_set(return_same_states=True)
+        while s1 and s2:
+            for s in self.states:
+                for i, new_state in s.transitions.items():
+                    if new_state == s2:
+                        s.transitions[i] = s1
+            self.states.remove(s2)
+            s1, s2 = self.compute_characterization_set(return_same_states=True)
+
+        self.compute_prefixes()
+
+    def __eq__(self, other):
+        from aalpy.utils import bisimilar
         return bisimilar(self, other)
```

## aalpy/base/CacheTree.py

 * *Ordering differences only*

```diff
@@ -1,169 +1,169 @@
-class Node(object):
-    __slots__ = ['value', 'children']
-
-    def __init__(self, value=None):
-        self.value = value
-        self.children = {}
-
-
-class CacheTree:
-    """
-    Tree in which all membership queries and corresponding outputs/values are stored. Membership queries update the tree
-    and while updating, check if determinism is maintained.
-    Root node corresponds to the initial state, and from that point on, for every new input/output pair, a new child is
-    created where the output is the value of the child, and the input is the transition leading from the parent to the
-    child.
-    """
-
-    def __init__(self):
-        self.root_node = Node()
-        self.curr_node = None
-        self.inputs = ()
-        self.outputs = ()
-
-    def reset(self):
-        self.curr_node = self.root_node
-        self.inputs = ()
-        self.outputs = ()
-
-    def step_in_cache(self, inp, out):
-        """
-        Preform a step in the cache. If output exist for the current state, and is not the same as `out`, throw
-        the non-determinism violation error and abort learning.
-        Args:
-
-            inp: input
-            out: output
-
-        """
-        self.inputs += (inp,)
-        self.outputs += (out,)
-        if inp is None:
-            self.root_node.value = out
-            return
-
-        if inp not in self.curr_node.children.keys():
-            node = Node(out)
-            self.curr_node.children[inp] = node
-        else:
-            node = self.curr_node.children[inp]
-            if node.value != out:
-                expected_seq = self.outputs[:-1]
-                expected_seq += (node.value,)
-                msg = f'Non-determinism detected.\n' \
-                      f'Error inserting: {self.inputs}\n' \
-                      f'Conflict detected: {node.value} vs {out}\n' \
-                      f'Expected Output: {expected_seq}\n' \
-                      f'Received output: {self.outputs}'
-                raise SystemExit(msg)
-        self.curr_node = node
-
-    def in_cache(self, input_seq: tuple):
-        """
-        Check if the result of the membership query for input_seq is cached is in the tree. If it is, return the
-        corresponding output sequence.
-
-        Args:
-
-            input_seq: corresponds to the membership query
-
-        Returns:
-
-            outputs associated with inputs if it is in the query, None otherwise
-
-        """
-        curr_node = self.root_node
-
-        output_seq = ()
-        for letter in input_seq:
-            if letter in curr_node.children.keys():
-                curr_node = curr_node.children[letter]
-                output_seq += (curr_node.value,)
-            else:
-                return None
-
-        return output_seq
-
-    def add_to_cache(self, input_sequence, output_sequence):
-        """
-        Add input-output sequence to cache
-        """
-        self.reset()
-        for i, o in zip(input_sequence, output_sequence):
-            self.step_in_cache(i, o)
-
-
-class CacheDict:
-    """
-    Dictionary in which all membership queries and corresponding outputs/values are stored. Membership queries update
-    the tree and while updating, check if determinism is maintained.
-    Root node corresponds to the initial state, and from that point on, for every new input/output pair, a new child is
-    created where the output is the value of the child, and the input is the transition leading from the parent to the
-    child.
-    """
-
-    def __init__(self):
-        self.cache_dict = dict()
-        self.inputs = ()
-
-    def reset(self):
-        self.inputs = ()
-        pass
-
-    def step_in_cache(self, inp, out):
-        """
-        Preform a step in the cache. If output exist for the current state, and is not the same as `out`, throw
-        the non-determinism violation error and abort learning.
-        Args:
-
-            inp: input
-            out: output
-
-        """
-
-        if inp is None:
-            return self.cache_dict[()]
-
-        self.inputs += (inp,)
-
-        if self.inputs not in self.cache_dict.keys():
-            self.cache_dict[self.inputs] = out
-        else:
-            cache_output = self.cache_dict[self.inputs]
-            if cache_output != out:
-                expected_seq = self.get_output_sequence(self.inputs)
-                received_seq = expected_seq[:-1] + (out,)
-                msg = f'Non-determinism detected.\n' \
-                      f'Error inserting: {self.inputs}\n' \
-                      f'Conflict detected: {cache_output} vs {out}\n' \
-                      f'Expected Output: {expected_seq}\n' \
-                      f'Received output: {received_seq}'
-                raise SystemExit(msg)
-
-    def in_cache(self, input_seq: tuple):
-        """
-        Check if the result of the membership query for input_seq is cached is in the tree. If it is, return the
-        corresponding output sequence.
-
-        Args:
-
-            input_seq: corresponds to the membership query
-
-        Returns:
-
-            outputs associated with inputs if it is in the query, None otherwise
-
-        """
-        if input_seq in self.cache_dict.keys():
-            return self.get_output_sequence(input_seq)
-        return None
-
-    def add_to_cache(self, input_sequence, output_sequence):
-        """
-        Add input-output sequence to cache
-        """
-        for i in range(1, len(input_sequence) + 1):
-            self.cache_dict[input_sequence[:i]] = output_sequence[i-1]
-
-    def get_output_sequence(self, input_seq):
-        return tuple(self.cache_dict[input_seq[:i]] for i in range(1, len(input_seq) + 1))
+class Node(object):
+    __slots__ = ['value', 'children']
+
+    def __init__(self, value=None):
+        self.value = value
+        self.children = {}
+
+
+class CacheTree:
+    """
+    Tree in which all membership queries and corresponding outputs/values are stored. Membership queries update the tree
+    and while updating, check if determinism is maintained.
+    Root node corresponds to the initial state, and from that point on, for every new input/output pair, a new child is
+    created where the output is the value of the child, and the input is the transition leading from the parent to the
+    child.
+    """
+
+    def __init__(self):
+        self.root_node = Node()
+        self.curr_node = None
+        self.inputs = ()
+        self.outputs = ()
+
+    def reset(self):
+        self.curr_node = self.root_node
+        self.inputs = ()
+        self.outputs = ()
+
+    def step_in_cache(self, inp, out):
+        """
+        Preform a step in the cache. If output exist for the current state, and is not the same as `out`, throw
+        the non-determinism violation error and abort learning.
+        Args:
+
+            inp: input
+            out: output
+
+        """
+        self.inputs += (inp,)
+        self.outputs += (out,)
+        if inp is None:
+            self.root_node.value = out
+            return
+
+        if inp not in self.curr_node.children.keys():
+            node = Node(out)
+            self.curr_node.children[inp] = node
+        else:
+            node = self.curr_node.children[inp]
+            if node.value != out:
+                expected_seq = self.outputs[:-1]
+                expected_seq += (node.value,)
+                msg = f'Non-determinism detected.\n' \
+                      f'Error inserting: {self.inputs}\n' \
+                      f'Conflict detected: {node.value} vs {out}\n' \
+                      f'Expected Output: {expected_seq}\n' \
+                      f'Received output: {self.outputs}'
+                raise SystemExit(msg)
+        self.curr_node = node
+
+    def in_cache(self, input_seq: tuple):
+        """
+        Check if the result of the membership query for input_seq is cached is in the tree. If it is, return the
+        corresponding output sequence.
+
+        Args:
+
+            input_seq: corresponds to the membership query
+
+        Returns:
+
+            outputs associated with inputs if it is in the query, None otherwise
+
+        """
+        curr_node = self.root_node
+
+        output_seq = ()
+        for letter in input_seq:
+            if letter in curr_node.children.keys():
+                curr_node = curr_node.children[letter]
+                output_seq += (curr_node.value,)
+            else:
+                return None
+
+        return output_seq
+
+    def add_to_cache(self, input_sequence, output_sequence):
+        """
+        Add input-output sequence to cache
+        """
+        self.reset()
+        for i, o in zip(input_sequence, output_sequence):
+            self.step_in_cache(i, o)
+
+
+class CacheDict:
+    """
+    Dictionary in which all membership queries and corresponding outputs/values are stored. Membership queries update
+    the tree and while updating, check if determinism is maintained.
+    Root node corresponds to the initial state, and from that point on, for every new input/output pair, a new child is
+    created where the output is the value of the child, and the input is the transition leading from the parent to the
+    child.
+    """
+
+    def __init__(self):
+        self.cache_dict = dict()
+        self.inputs = ()
+
+    def reset(self):
+        self.inputs = ()
+        pass
+
+    def step_in_cache(self, inp, out):
+        """
+        Preform a step in the cache. If output exist for the current state, and is not the same as `out`, throw
+        the non-determinism violation error and abort learning.
+        Args:
+
+            inp: input
+            out: output
+
+        """
+
+        if inp is None:
+            return self.cache_dict[()]
+
+        self.inputs += (inp,)
+
+        if self.inputs not in self.cache_dict.keys():
+            self.cache_dict[self.inputs] = out
+        else:
+            cache_output = self.cache_dict[self.inputs]
+            if cache_output != out:
+                expected_seq = self.get_output_sequence(self.inputs)
+                received_seq = expected_seq[:-1] + (out,)
+                msg = f'Non-determinism detected.\n' \
+                      f'Error inserting: {self.inputs}\n' \
+                      f'Conflict detected: {cache_output} vs {out}\n' \
+                      f'Expected Output: {expected_seq}\n' \
+                      f'Received output: {received_seq}'
+                raise SystemExit(msg)
+
+    def in_cache(self, input_seq: tuple):
+        """
+        Check if the result of the membership query for input_seq is cached is in the tree. If it is, return the
+        corresponding output sequence.
+
+        Args:
+
+            input_seq: corresponds to the membership query
+
+        Returns:
+
+            outputs associated with inputs if it is in the query, None otherwise
+
+        """
+        if input_seq in self.cache_dict.keys():
+            return self.get_output_sequence(input_seq)
+        return None
+
+    def add_to_cache(self, input_sequence, output_sequence):
+        """
+        Add input-output sequence to cache
+        """
+        for i in range(1, len(input_sequence) + 1):
+            self.cache_dict[input_sequence[:i]] = output_sequence[i-1]
+
+    def get_output_sequence(self, input_seq):
+        return tuple(self.cache_dict[input_seq[:i]] for i in range(1, len(input_seq) + 1))
```

## aalpy/base/Oracle.py

 * *Ordering differences only*

```diff
@@ -1,52 +1,52 @@
-from abc import ABC, abstractmethod
-
-from aalpy.base import SUL
-
-
-class Oracle(ABC):
-    """Abstract class implemented by all equivalence oracles."""
-
-    def __init__(self, alphabet: list, sul: SUL):
-        """
-        Default constructor for all equivalence oracles.
-
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-        """
-
-        self.alphabet = alphabet
-        self.sul = sul
-        self.num_queries = 0
-        self.num_steps = 0
-
-    @abstractmethod
-    def find_cex(self, hypothesis):
-        """
-        Return a counterexample (inputs) that displays different behavior on system under learning and
-        current hypothesis.
-
-        Args:
-
-          hypothesis: current hypothesis
-
-        Returns:
-
-            tuple or list containing counterexample inputs, None if no counterexample is found
-        """
-        pass
-
-    def reset_hyp_and_sul(self, hypothesis):
-        """
-        Reset SUL and hypothesis to initial state.
-
-        Args:
-
-            hypothesis: current hypothesis
-
-        """
-        hypothesis.reset_to_initial()
-        self.sul.post()
-        self.sul.pre()
+from abc import ABC, abstractmethod
+
+from aalpy.base import SUL
+
+
+class Oracle(ABC):
+    """Abstract class implemented by all equivalence oracles."""
+
+    def __init__(self, alphabet: list, sul: SUL):
+        """
+        Default constructor for all equivalence oracles.
+
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+        """
+
+        self.alphabet = alphabet
+        self.sul = sul
+        self.num_queries = 0
+        self.num_steps = 0
+
+    @abstractmethod
+    def find_cex(self, hypothesis):
+        """
+        Return a counterexample (inputs) that displays different behavior on system under learning and
+        current hypothesis.
+
+        Args:
+
+          hypothesis: current hypothesis
+
+        Returns:
+
+            tuple or list containing counterexample inputs, None if no counterexample is found
+        """
+        pass
+
+    def reset_hyp_and_sul(self, hypothesis):
+        """
+        Reset SUL and hypothesis to initial state.
+
+        Args:
+
+            hypothesis: current hypothesis
+
+        """
+        hypothesis.reset_to_initial()
+        self.sul.post()
+        self.sul.pre()
         self.num_queries += 1
```

## aalpy/base/SUL.py

```diff
@@ -1,142 +1,145 @@
-from abc import ABC, abstractmethod
-
-from aalpy.base.CacheTree import CacheTree, CacheDict
-
-
-class SUL(ABC):
-    """
-    System Under Learning (SUL) abstract class. Defines the interaction between the learning algorithm and the system
-    under learning. All systems under learning have to implement this class, as it is
-    passed to the learning algorithm and the equivalence oracle.
-    """
-
-    def __init__(self):
-        self.num_queries = 0
-        self.num_steps = 0
-        self.num_cached_queries = 0
-
-    def query(self, word: tuple) -> list:
-        """
-        Performs a membership query on the SUL. Before the query, pre() method is called and after the query post()
-        method is called. Each letter in the word (input in the input sequence) is executed using the step method.
-
-        Args:
-
-            word: membership query (word consisting of letters/inputs)
-
-        Returns:
-
-            list of outputs, where the i-th output corresponds to the output of the system after the i-th input
-
-        """
-        self.pre()
-        # Empty string for DFA
-        if len(word) == 0:
-            out = [self.step(None)]
-        else:
-            out = [self.step(letter) for letter in word]
-        self.post()
-        self.num_queries += 1
-        self.num_steps += len(word)
-        return out
-
-    @abstractmethod
-    def pre(self):
-        """
-        Resets the system. Called after post method in the equivalence query.
-        """
-        pass
-
-    @abstractmethod
-    def post(self):
-        """
-        Performs additional cleanup on the system in necessary. Called before pre method in the equivalence query.
-        """
-        pass
-
-    @abstractmethod
-    def step(self, letter):
-        """
-        Executes an action on the system under learning and returns its result.
-
-        Args:
-
-            letter: Single input that is executed on the SUL.
-
-        Returns:
-
-            Output received after executing the input.
-
-        """
-        pass
-
-
-class CacheSUL(SUL):
-    """
-    System under learning that keeps a multiset of all queries in memory.
-    This multiset/cache is encoded as a tree.
-    """
-
-    def __init__(self, sul: SUL, cache_type='tree'):
-        super().__init__()
-        self.sul = sul
-        self.cache = CacheTree() if cache_type == 'tree' else CacheDict()
-
-    def query(self, word):
-        """
-        Performs a membership query on the SUL if and only if `word` is not a prefix of any trace in the cache.
-        Before the query, pre() method is called and after the query post()
-        method is called. Each letter in the word (input in the input sequence) is executed using the step method.
-
-        Args:
-
-            word: membership query (word consisting of letters/inputs)
-
-        Returns:
-
-            list of outputs, where the i-th output corresponds to the output of the system after the i-th input
-
-        """
-        cached_query = self.cache.in_cache(word)
-        if cached_query:
-            self.num_cached_queries += 1
-            return cached_query
-
-        # get outputs using default query method
-        out = self.sul.query(word)
-
-        # add input/outputs to tree
-        self.cache.reset()
-        for i, o in zip(word, out):
-            self.cache.step_in_cache(i, o)
-
-        self.num_queries += 1
-        self.num_steps += len(word)
-        return out
-
-    def pre(self):
-        """
-        Reset the system under learning and current node in the cache tree.
-        """
-        self.cache.reset()
-        self.sul.pre()
-
-    def post(self):
-        self.sul.post()
-
-    def step(self, letter):
-        """
-        Executes an action on the system under learning, adds it to the cache and returns its result.
-
-        Args:
-
-           letter: Single input that is executed on the SUL.
-
-        Returns:
-
-           Output received after executing the input.
-
-        """
-        out = self.sul.step(letter)
-        self.cache.step_in_cache(letter, out)
-        return out
+from abc import ABC, abstractmethod
+
+from aalpy.base.CacheTree import CacheTree, CacheDict
+
+
+class SUL(ABC):
+    """
+    System Under Learning (SUL) abstract class. Defines the interaction between the learning algorithm and the system
+    under learning. All systems under learning have to implement this class, as it is
+    passed to the learning algorithm and the equivalence oracle.
+    """
+
+    def __init__(self):
+        self.num_queries = 0
+        self.num_steps = 0
+        self.num_cached_queries = 0
+
+    def query(self, word: tuple) -> list:
+        """
+        Performs a membership query on the SUL. Before the query, pre() method is called and after the query post()
+        method is called. Each letter in the word (input in the input sequence) is executed using the step method.
+
+        Args:
+
+            word: membership query (word consisting of letters/inputs)
+
+        Returns:
+
+            list of outputs, where the i-th output corresponds to the output of the system after the i-th input
+
+        """
+        self.pre()
+        # Empty string for DFA
+        if len(word) == 0:
+            out = [self.step(None)]
+        else:
+            out = [self.step(letter) for letter in word]
+        self.post()
+        self.num_queries += 1
+        self.num_steps += len(word)
+        return out
+
+    def io_query(self, word : tuple):
+        return list(zip(word, self.query(word)))
+
+    @abstractmethod
+    def pre(self):
+        """
+        Resets the system. Called after post method in the equivalence query.
+        """
+        pass
+
+    @abstractmethod
+    def post(self):
+        """
+        Performs additional cleanup on the system in necessary. Called before pre method in the equivalence query.
+        """
+        pass
+
+    @abstractmethod
+    def step(self, letter):
+        """
+        Executes an action on the system under learning and returns its result.
+
+        Args:
+
+            letter: Single input that is executed on the SUL.
+
+        Returns:
+
+            Output received after executing the input.
+
+        """
+        pass
+
+
+class CacheSUL(SUL):
+    """
+    System under learning that keeps a multiset of all queries in memory.
+    This multiset/cache is encoded as a tree.
+    """
+
+    def __init__(self, sul: SUL, cache_type='tree'):
+        super().__init__()
+        self.sul = sul
+        self.cache = CacheTree() if cache_type == 'tree' else CacheDict()
+
+    def query(self, word):
+        """
+        Performs a membership query on the SUL if and only if `word` is not a prefix of any trace in the cache.
+        Before the query, pre() method is called and after the query post()
+        method is called. Each letter in the word (input in the input sequence) is executed using the step method.
+
+        Args:
+
+            word: membership query (word consisting of letters/inputs)
+
+        Returns:
+
+            list of outputs, where the i-th output corresponds to the output of the system after the i-th input
+
+        """
+        cached_query = self.cache.in_cache(word)
+        if cached_query:
+            self.num_cached_queries += 1
+            return cached_query
+
+        # get outputs using default query method
+        out = self.sul.query(word)
+
+        # add input/outputs to tree
+        self.cache.reset()
+        for i, o in zip(word, out):
+            self.cache.step_in_cache(i, o)
+
+        self.num_queries += 1
+        self.num_steps += len(word)
+        return out
+
+    def pre(self):
+        """
+        Reset the system under learning and current node in the cache tree.
+        """
+        self.cache.reset()
+        self.sul.pre()
+
+    def post(self):
+        self.sul.post()
+
+    def step(self, letter):
+        """
+        Executes an action on the system under learning, adds it to the cache and returns its result.
+
+        Args:
+
+           letter: Single input that is executed on the SUL.
+
+        Returns:
+
+           Output received after executing the input.
+
+        """
+        out = self.sul.step(letter)
+        self.cache.step_in_cache(letter, out)
+        return out
```

## aalpy/base/__init__.py

 * *Ordering differences only*

```diff
@@ -1,3 +1,3 @@
-from .Automaton import Automaton, AutomatonState, DeterministicAutomaton
-from .Oracle import Oracle
-from .SUL import SUL
+from .Automaton import Automaton, AutomatonState, DeterministicAutomaton
+from .Oracle import Oracle
+from .SUL import SUL
```

## aalpy/learning_algs/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-# public API for running automata learning algorithms
-from .deterministic.LStar import run_Lstar
-from .deterministic.KV import run_KV
-from .non_deterministic.OnfsmLstar import run_non_det_Lstar
-from .non_deterministic.AbstractedOnfsmLstar import run_abstracted_ONFSM_Lstar
-from .stochastic.StochasticLStar import run_stochastic_Lstar
-from .stochastic_passive.Alergia import run_Alergia, run_JAlergia
-from .stochastic_passive.ActiveAleriga import run_active_Alergia
-from .deterministic_passive.RPNI import run_RPNI
-from .deterministic_passive.active_RPNI import run_active_RPNI
+# public API for running automata learning algorithms
+from .deterministic.LStar import run_Lstar
+from .deterministic.KV import run_KV
+from .non_deterministic.OnfsmLstar import run_non_det_Lstar
+from .non_deterministic.AbstractedOnfsmLstar import run_abstracted_ONFSM_Lstar
+from .stochastic.StochasticLStar import run_stochastic_Lstar
+from .stochastic_passive.Alergia import run_Alergia, run_JAlergia
+from .stochastic_passive.ActiveAleriga import run_active_Alergia
+from .deterministic_passive.RPNI import run_RPNI
+from .deterministic_passive.active_RPNI import run_active_RPNI
```

## aalpy/learning_algs/deterministic/ClassificationTree.py

```diff
@@ -1,470 +1,464 @@
-from collections import defaultdict
-from typing import Union
-
-from aalpy.automata import DfaState, Dfa, MealyState, MealyMachine, MooreState, MooreMachine, \
-    SevpaAlphabet, SevpaState, SevpaTransition, Sevpa
-from aalpy.base import SUL
-from aalpy.learning_algs.deterministic.CounterExampleProcessing import rs_cex_processing, linear_cex_processing, \
-    exponential_cex_processing
-
-automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
-
-
-class CTNode:
-    __slots__ = ['parent', 'path_to_node']
-
-    def __init__(self, parent, path_to_node):
-        self.parent = parent
-        self.path_to_node = path_to_node
-
-    def is_leaf(self):
-        pass
-
-
-class CTInternalNode(CTNode):
-    __slots__ = ['distinguishing_string', 'children']
-
-    def __init__(self, distinguishing_string: tuple, parent, path_to_node):
-        super().__init__(parent, path_to_node)
-        self.distinguishing_string = distinguishing_string
-        self.children = defaultdict(None)  # {True: None, False: None}
-
-    def is_leaf(self):
-        return False
-
-
-class CTLeafNode(CTNode):
-    __slots__ = ['access_string']
-
-    def __init__(self, access_string: tuple, parent, path_to_node):
-        super().__init__(parent, path_to_node)
-        self.access_string = access_string
-
-    def __repr__(self):
-        return f"{self.__class__.__name__} '{self.access_string}'"
-
-    @property
-    def output(self):
-        c, p = self, self.parent
-        while p.parent:
-            c = p
-            p = p.parent
-        for output, child in p.children.items():
-            if child == c:
-                return output
-        assert False
-
-    def is_leaf(self):
-        return True
-
-
-class ClassificationTree:
-    def __init__(self, alphabet: Union[list, SevpaAlphabet], sul: SUL, automaton_type: str, cex: tuple):
-        self.sul = sul
-        self.alphabet = alphabet
-        self.automaton_type = automaton_type
-
-        self.leaf_nodes = {}
-        self.query_cache = dict()
-
-        self.sifting_cache = {}
-
-        # prefix of identified error state in VPDA learning
-        self.error_state_prefix = None
-
-        if self.automaton_type != 'mealy':
-            initial_output = sul.query(())[-1]
-            cex_output = sul.query(cex)[-1]
-
-            self.query_cache[()] = initial_output
-
-            root_distinguishing_string = () if automaton_type != 'vpa' else ([(), ()])
-
-            self.root = CTInternalNode(distinguishing_string=root_distinguishing_string, parent=None, path_to_node=None)
-
-            initial_output_node = CTLeafNode(access_string=tuple(), parent=self.root, path_to_node=initial_output)
-            cex_output_node = CTLeafNode(access_string=cex, parent=self.root, path_to_node=cex_output)
-
-            self.root.children[initial_output] = initial_output_node
-            self.root.children[cex_output] = cex_output_node
-
-            self.leaf_nodes[tuple()] = initial_output_node
-            self.leaf_nodes[cex] = cex_output_node
-
-        else:
-            self.root = CTInternalNode(distinguishing_string=(cex[-1],), parent=None, path_to_node=None)
-
-            hypothesis_output = sul.query((cex[-1],))[-1]
-            cex_output = sul.query(cex)[-1]
-
-            hypothesis_output_node = CTLeafNode(access_string=tuple(), parent=self.root, path_to_node=hypothesis_output)
-            cex_output_node = CTLeafNode(access_string=cex[:-1], parent=self.root, path_to_node=cex_output)
-
-            self.root.children[hypothesis_output] = hypothesis_output_node
-            self.root.children[cex_output] = cex_output_node
-
-            self.leaf_nodes[tuple()] = self.root.children[hypothesis_output]
-            self.leaf_nodes[cex[:-1]] = self.root.children[cex_output]
-
-    def _sift(self, word):
-        """
-        Sifting a word into the classification tree.
-        Starting at the root, at every inner node (a CTInternalNode),
-        we branch into the child, depending on the result of the
-        membership query (word * node.distinguishing_string). Repeated until a leaf
-        (a CTLeafNode) is reached, which is the result of the sifting.
-
-        Args:
-
-            word: the word to sift into the discrimination tree (a tuple of all letters)
-
-        Returns:
-
-            the CTLeafNode that is reached by the sifting operation.
-        """
-
-        if word in self.sifting_cache:
-            return self.sifting_cache[word]
-
-        node = self.root
-        while not node.is_leaf():
-
-            if self.automaton_type != 'vpa':
-                query = word + node.distinguishing_string
-            else:
-                query = node.distinguishing_string[0] + word + node.distinguishing_string[1]
-
-            if query not in self.query_cache.keys():
-                mq_result = self.sul.query(query)
-                # keep track of transitions (this might miss some due to other caching, but rest can be obtained from
-                # cache in gen hyp)
-                if self.automaton_type == 'mealy' and word not in self.query_cache.keys():
-                    self.query_cache[word] = mq_result[len(word) - 1]
-
-                mq_result = mq_result[-1]
-                self.query_cache[query] = mq_result
-            else:
-                mq_result = self.query_cache[query]
-
-            if mq_result not in node.children.keys():
-                new_leaf = CTLeafNode(access_string=word, parent=node, path_to_node=mq_result)
-                self.leaf_nodes[word] = new_leaf
-                node.children[mq_result] = new_leaf
-
-            node = node.children[mq_result]
-
-        self.sifting_cache[word] = node
-        assert node.is_leaf()
-        return node
-
-    def gen_hypothesis(self):
-        # for each CTLeafNode of this CT,
-        # create a state in the hypothesis that is labeled by that
-        # node's access string. The start state is the empty word
-        states = {}
-        initial_state = None
-        state_counter = 0
-        for node in self.leaf_nodes.values():
-
-            if self.automaton_type == 'dfa':
-                new_state = DfaState(state_id=f's{state_counter}', is_accepting=node.output)
-            elif self.automaton_type == 'moore':
-                new_state = MooreState(state_id=f's{state_counter}', output=node.output)
-            elif self.automaton_type == 'vpa':
-                new_state = SevpaState(state_id=f'q{state_counter}', is_accepting=node.output)
-            else:
-                new_state = MealyState(state_id=f's{state_counter}')
-
-            new_state.prefix = node.access_string
-            if new_state.prefix == ():
-                initial_state = new_state
-            states[new_state.prefix] = new_state
-            state_counter += 1
-        assert initial_state is not None
-
-        # For each access state s of the hypothesis and each letter b in the
-        # alphabet, compute the b-transition out of state s by sifting s.state_id*b
-        states_for_transitions = list(states.values())
-        for state in states_for_transitions:
-            if self.automaton_type != 'vpa':
-                for letter in self.alphabet:
-                    transition_target_node = self._sift(state.prefix + (letter,))
-                    transition_target_access_string = transition_target_node.access_string
-
-                    if self.automaton_type != "dfa" and transition_target_access_string not in states:
-                        if self.automaton_type == 'mealy':
-                            new_state = MealyState(state_id=f's{state_counter}')
-                        else:
-                            output = self._query_and_update_cache(transition_target_access_string)
-                            new_state = MooreState(state_id=f's{state_counter}', output=output)
-
-                        new_state.prefix = transition_target_access_string
-                        states_for_transitions.append(new_state)
-                        states[new_state.prefix] = new_state
-                        state_counter += 1
-
-                    state.transitions[letter] = states[transition_target_access_string]
-
-                    if self.automaton_type == "mealy":
-                        state.output_fun[letter] = self._query_and_update_cache(state.prefix + (letter,))
-            else:
-                # internal transitions
-                for internal_letter in self.alphabet.internal_alphabet:
-                    transition_target_node = self._sift(state.prefix + (internal_letter,))
-                    transition_target_access_string = transition_target_node.access_string
-
-                    assert transition_target_access_string in states
-                    trans = SevpaTransition(target=states[transition_target_access_string],
-                                            letter=internal_letter, action=None)
-                    state.transitions[internal_letter].append(trans)
-
-                # Add call transitions
-                for call_letter in self.alphabet.call_alphabet:
-                    # Add return transitions
-                    for return_letter in self.alphabet.return_alphabet:
-                        # check if exclusive pairs of call and return letters are defined in an alphabets
-                        if self.alphabet.exclusive_call_return_pairs and \
-                                self.alphabet.exclusive_call_return_pairs[call_letter] != return_letter:
-                            continue
-
-                        for other_state in states_for_transitions:
-                            # ignore other state if other state is error state
-                            if other_state.prefix == self.error_state_prefix:
-                                continue
-                            transition_target_node = self._sift(
-                                other_state.prefix + (call_letter,) + state.prefix + (return_letter,))
-                            transition_target_access_string = transition_target_node.access_string
-
-                            trans = SevpaTransition(target=states[transition_target_access_string],
-                                                    letter=return_letter,
-                                                    action='pop', stack_guard=(other_state.state_id, call_letter))
-                            state.transitions[return_letter].append(trans)
-
-        if self.automaton_type == 'vpa':
-            hypothesis = Sevpa(initial_state=initial_state, states=list(states.values()))
-            if not self.error_state_prefix:
-                error_state = hypothesis.get_error_state()
-                if error_state:
-                    self.error_state_prefix = error_state.prefix
-            return hypothesis
-
-        return automaton_class[self.automaton_type](initial_state=initial_state, states=list(states.values()))
-
-    def _least_common_ancestor(self, node_1_id, node_2_id):
-        """
-        Find the distinguishing string of the least common ancestor
-        of the leaf nodes node_1 and node_2. Both nodes have to exist.
-        Adapted from https://www.geeksforgeeks.org/lowest-common-ancestor-binary-tree-set-1/
-
-        Args:
-
-            node_1_id: first leaf node's id
-            node_2_id: second leaf node's id
-
-        Returns:
-
-            the distinguishing string of the lca
-
-        """
-
-        def ancestor(parent, node):
-            for child in parent.children.values():
-                if child.is_leaf():
-                    if child.access_string == node:
-                        return True
-                else:
-                    next_ancestor = ancestor(child, node)
-                    if next_ancestor:
-                        return True
-            return False
-
-        def findLCA(n1_id, n2_id):
-            node = self.leaf_nodes[n1_id]
-            parent = node.parent
-            while parent:
-                if ancestor(parent, n2_id):
-                    return parent
-                if parent.parent:
-                    parent = parent.parent
-                else:
-                    return parent
-            return None
-
-        return findLCA(node_1_id, node_2_id).distinguishing_string
-
-    def update(self, cex: tuple, hypothesis):
-        """
-        Updates the classification tree based on a counterexample.
-        - For each prefix cex[:i] of the counterexample, get
-              s_i      = self.sift(cex[:i])    and
-              s_star_i = id of the state with the access sequence cex[:i]
-                         in the hypothesis
-          and let j be the least i such that s_i != s_star_i.
-        - Replace the CTLeafNode labeled with the access string of the state
-          that is reached by the sequence cex[:j-1] in the hypothesis
-          with an CTInternalNode with two CTLeafNodes: one keeps the old
-          access string, and one gets the new access string cex[:j-1].
-          The internal node is labeled with the distinguishing string (cex[j-1],*d),
-          where d is the distinguishing string of the LCA of s_i and s_star_i.
-
-        Args:
-            cex: the counterexample used to update the tree
-            hypothesis: the former (wrong) hypothesis
-
-        """
-        j = d = None
-        for i in range(1, len(cex) + 1):
-            s_i = self._sift(cex[:i]).access_string
-            hypothesis.execute_sequence(hypothesis.initial_state, cex[:i])
-            s_star_i = hypothesis.current_state.prefix
-
-            if s_i != s_star_i:
-                j = i
-                d = self._least_common_ancestor(s_i, s_star_i)
-                break
-        if j is None and d is None:
-            j = len(cex)
-            d = []
-        assert j is not None and d is not None
-
-        hypothesis.execute_sequence(hypothesis.initial_state, cex[:j - 1] or tuple())
-
-        self._insert_new_leaf(discriminator=(cex[j - 1], *d),
-                              old_leaf_access_string=hypothesis.current_state.prefix,
-                              new_leaf_access_string=tuple(cex[:j - 1]) or tuple(),
-                              new_leaf_position=self.sul.query((*cex[:j - 1], *(cex[j - 1], *d)))[-1])
-
-    def process_counterexample(self, cex: tuple, hypothesis, cex_processing_fun):
-        """
-        Updates the classification tree based on a counterexample,
-        using Rivest & Schapire's counterexample processing
-        - Replace the CTLeafNode labeled with the access string of the state
-          that is reached by the sequence cex[:j-1] in the hypothesis
-          with an CTInternalNode with two CTLeafNodes: one keeps the old
-          access string, and one gets the new access string cex[:j-1].
-          The internal node is labeled with the distinguishing string (cex[j-1],*d),
-          where d is the distinguishing string of the LCA of s_i and s_star_i.
-
-        Args:
-            cex: the counterexample used to update the tree
-            hypothesis: the former (wrong) hypothesis
-            cex_processing_fun: string choosing which cex_processing to use
-
-        """
-        v = None
-        if 'linear' in cex_processing_fun:
-            direction = cex_processing_fun[-3:]
-            v = linear_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
-                                      direction=direction, suffix_closedness=False)[0]
-        elif 'exponential' in cex_processing_fun:
-            direction = cex_processing_fun[-3:]
-            v = exponential_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
-                                           direction=direction, suffix_closedness=False)[0]
-        elif cex_processing_fun == 'rs':
-            v = rs_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
-                                  suffix_closedness=False)[0]
-
-        assert v
-        a = cex[len(cex) - len(v) - 1]
-        u = cex[:len(cex) - len(v) - 1]
-        assert (*u, a, *v) == cex
-
-        hypothesis.execute_sequence(hypothesis.initial_state, u)
-        u_state = hypothesis.current_state
-
-        top_of_stack = hypothesis.stack[-1] if self.automaton_type == 'vpa' else None
-
-        # get state reached after executing last action => old leaf
-        hypothesis.step(a)
-        ua_state = hypothesis.current_state
-
-        # get discriminator and new_leaf_access_string
-        if self.automaton_type == 'vpa':
-            discriminator = (tuple(hypothesis.transform_access_string()), tuple(v))
-
-            if a in self.alphabet.internal_alphabet:
-                new_leaf_access_string = (*u_state.prefix, a)
-            else:
-                assert a in self.alphabet.return_alphabet
-                l_prime, call = hypothesis.get_state_by_id(top_of_stack[0]), top_of_stack[1]
-                new_leaf_access_string = l_prime.prefix + (call,) + u_state.prefix + (a,)
-        else:
-            discriminator = v
-            new_leaf_access_string = (*u_state.prefix, a)
-
-        if self.automaton_type == 'dfa' or self.automaton_type == 'vpa':
-            new_leaf_position = not hypothesis.execute_sequence(hypothesis.initial_state, cex)[-1]
-        else:
-            new_leaf_position = self.sul.query(cex)[-1]
-
-        self._insert_new_leaf(discriminator=discriminator,
-                              old_leaf_access_string=ua_state.prefix,
-                              new_leaf_access_string=new_leaf_access_string,
-                              new_leaf_position=new_leaf_position)
-
-    def _insert_new_leaf(self, discriminator, old_leaf_access_string, new_leaf_access_string, new_leaf_position):
-        """
-        Inserts a new leaf in the classification tree by:
-        - moving the leaf node specified by <old_leaf_access_string> down one level
-        - inserting an internal node  at the former position of the old node (i.e. as the parent of the old node)
-        - adding a new leaf node with <new_leaf_access_string> as child of the new internal node/sibling of the old node
-        Could also be thought of as 'splitting' the old node into two (one of which keeps the old access string and one
-        of which gets the new one) with <discriminator> as the distinguishing string between the two.
-
-        where one of the resulting nodes keeps the old
-        node's access string and the other gets new_leaf_access_string.
-        Args:
-            discriminator: The distinguishing string of the new internal node
-            old_leaf_access_string: The access string specifying the leaf node to be 'split' (or rather moved down)
-            new_leaf_access_string: The access string of the leaf node that will be created
-            new_leaf_position: The path from the new internal node to the new leaf node
-
-        Returns:
-
-        """
-        if self.automaton_type == "dfa" or self.automaton_type == 'vpa':
-            other_leaf_position = not new_leaf_position
-        else:
-            # check if this query is in the node cache
-            other_leaf_position = self.sul.query((*old_leaf_access_string, *discriminator))[-1]
-
-        old_leaf = self.leaf_nodes[old_leaf_access_string]
-
-        # create an internal node at the same position as the old leaf node
-        discriminator_node = CTInternalNode(distinguishing_string=discriminator,
-                                            parent=old_leaf.parent, path_to_node=old_leaf.path_to_node)
-
-        # create the new leaf node and add it as child of the internal node
-        new_leaf = CTLeafNode(access_string=new_leaf_access_string,
-                              parent=discriminator_node,
-                              path_to_node=new_leaf_position)
-        self.leaf_nodes[new_leaf_access_string] = new_leaf
-
-        # redirect the old nodes former parent to the internal node
-        old_leaf.parent.children[old_leaf.path_to_node] = discriminator_node
-
-        # add the internal node as parent of the old leaf
-        old_leaf.parent = discriminator_node
-        old_leaf.path_to_node = other_leaf_position
-
-        # set the two nodes as children of the internal node
-        discriminator_node.children[new_leaf_position] = new_leaf
-        discriminator_node.children[other_leaf_position] = old_leaf
-
-        # sifting cache update
-        sifting_cache_outdated = []
-        if old_leaf in self.sifting_cache.values():
-            for prefix, node in self.sifting_cache.items():
-                if old_leaf == node:
-                    sifting_cache_outdated.append(prefix)
-
-        for to_delete in sifting_cache_outdated:
-            del self.sifting_cache[to_delete]
-
-    def _query_and_update_cache(self, word):
-        if word in self.query_cache.keys():
-            output = self.query_cache[word]
-        else:
-            output = self.sul.query(word)[-1]
-            self.query_cache[word] = output
-        return output
+from collections import defaultdict
+from itertools import product
+from typing import Union
+
+from aalpy.automata import DfaState, Dfa, MealyState, MealyMachine, MooreState, MooreMachine, \
+    SevpaAlphabet, SevpaState, SevpaTransition, Sevpa
+from aalpy.base import SUL
+from aalpy.learning_algs.deterministic.CounterExampleProcessing import rs_cex_processing, linear_cex_processing, \
+    exponential_cex_processing
+
+automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
+
+
+class CTNode:
+    __slots__ = ['parent', 'path_to_node']
+
+    def __init__(self, parent, path_to_node):
+        self.parent = parent
+        self.path_to_node = path_to_node
+
+    def is_leaf(self):
+        pass
+
+
+class CTInternalNode(CTNode):
+    __slots__ = ['distinguishing_string', 'children']
+
+    def __init__(self, distinguishing_string: tuple, parent, path_to_node):
+        super().__init__(parent, path_to_node)
+        self.distinguishing_string = distinguishing_string
+        self.children = defaultdict(None)  # {True: None, False: None}
+
+    def is_leaf(self):
+        return False
+
+
+class CTLeafNode(CTNode):
+    __slots__ = ['access_string']
+
+    def __init__(self, access_string: tuple, parent, path_to_node):
+        super().__init__(parent, path_to_node)
+        self.access_string = access_string
+
+    def __repr__(self):
+        return f"{self.__class__.__name__} '{self.access_string}'"
+
+    @property
+    def output(self):
+        c, p = self, self.parent
+        while p.parent:
+            c = p
+            p = p.parent
+        for output, child in p.children.items():
+            if child == c:
+                return output
+        assert False
+
+    def is_leaf(self):
+        return True
+
+
+class ClassificationTree:
+    def __init__(self, alphabet: Union[list, SevpaAlphabet], sul: SUL, automaton_type: str, cex: tuple):
+        self.sul = sul
+        self.alphabet = alphabet
+        self.automaton_type = automaton_type
+
+        self.leaf_nodes = {}
+
+        self.initial_state = None
+        self.hypothesis_states = {}
+
+        # prefix of identified error state in VPDA learning
+        self.error_state_prefix = None
+
+        if self.automaton_type != 'mealy':
+            initial_output = sul.query(())[-1]
+            cex_output = sul.query(cex)[-1]
+
+            root_distinguishing_string = () if automaton_type != 'vpa' else ([(), ()])
+
+            self.root = CTInternalNode(distinguishing_string=root_distinguishing_string, parent=None, path_to_node=None)
+
+            initial_output_node = CTLeafNode(access_string=tuple(), parent=self.root, path_to_node=initial_output)
+            cex_output_node = CTLeafNode(access_string=cex, parent=self.root, path_to_node=cex_output)
+
+            self.root.children[initial_output] = initial_output_node
+            self.root.children[cex_output] = cex_output_node
+
+            self.leaf_nodes[tuple()] = initial_output_node
+            self.leaf_nodes[cex] = cex_output_node
+
+        else:
+            self.root = CTInternalNode(distinguishing_string=(cex[-1],), parent=None, path_to_node=None)
+
+            hypothesis_output = sul.query((cex[-1],))[-1]
+            cex_output = sul.query(cex)[-1]
+
+            hypothesis_output_node = CTLeafNode(access_string=tuple(), parent=self.root, path_to_node=hypothesis_output)
+            cex_output_node = CTLeafNode(access_string=cex[:-1], parent=self.root, path_to_node=cex_output)
+
+            self.root.children[hypothesis_output] = hypothesis_output_node
+            self.root.children[cex_output] = cex_output_node
+
+            self.leaf_nodes[tuple()] = self.root.children[hypothesis_output]
+            self.leaf_nodes[cex[:-1]] = self.root.children[cex_output]
+
+        self.new_states = list(self.leaf_nodes.values())
+        self.transitions_to_update = []
+
+    def _sift(self, word):
+        """
+        Sifting a word into the classification tree.
+        Starting at the root, at every inner node (a CTInternalNode),
+        we branch into the child, depending on the result of the
+        membership query (word * node.distinguishing_string). Repeated until a leaf
+        (a CTLeafNode) is reached, which is the result of the sifting.
+
+        Args:
+
+            word: the word to sift into the discrimination tree (a tuple of all letters)
+
+        Returns:
+
+            the CTLeafNode that is reached by the sifting operation.
+        """
+
+        node = self.root
+        while not node.is_leaf():
+
+            if self.automaton_type != 'vpa':
+                query = word + node.distinguishing_string
+            else:
+                query = node.distinguishing_string[0] + word + node.distinguishing_string[1]
+
+            mq_result = self.sul.query(query)[-1]
+
+            if mq_result not in node.children.keys():
+                new_leaf = CTLeafNode(access_string=word, parent=node, path_to_node=mq_result)
+                self.leaf_nodes[word] = new_leaf
+                node.children[mq_result] = new_leaf
+
+            node = node.children[mq_result]
+
+        assert node.is_leaf()
+        return node
+
+    def update_hypothesis(self):
+        # for each CTLeafNode of this CT,
+        # create a state in the hypothesis that is labeled by that
+        # node's access string. The start state is the empty word
+        state_counter = len(self.hypothesis_states.values())
+        while self.new_states:
+            node = self.new_states.pop(0)
+
+            if self.automaton_type == 'dfa':
+                new_state = DfaState(state_id=f's{state_counter}', is_accepting=node.output)
+            elif self.automaton_type == 'moore':
+                new_state = MooreState(state_id=f's{state_counter}', output=node.output)
+            elif self.automaton_type == 'vpa':
+                new_state = SevpaState(state_id=f'q{state_counter}', is_accepting=node.output)
+            else:
+                new_state = MealyState(state_id=f's{state_counter}')
+
+            new_state.prefix = node.access_string
+            if new_state.prefix == ():
+                self.initial_state = new_state
+
+            self.hypothesis_states[new_state.prefix] = new_state
+
+            if self.automaton_type != 'vpa':
+                self.transitions_to_update.extend(product([new_state], self.alphabet))
+            else:
+                self.transitions_to_update.extend(product([new_state], self.alphabet.internal_alphabet))
+                self.transitions_to_update.extend(product([new_state], self.alphabet.call_alphabet))
+
+            state_counter += 1
+
+        assert self.initial_state is not None
+
+        # For each access state s of the hypothesis and each letter b in the
+        # alphabet, compute the b-transition out of state s by sifting s.state_id*b
+        while self.transitions_to_update:
+            state, input_element = self.transitions_to_update.pop(0)
+
+            if self.automaton_type != 'vpa':
+
+                transition_target_node = self._sift(state.prefix + (input_element,))
+                transition_target_access_string = transition_target_node.access_string
+
+                if self.automaton_type != "dfa" and transition_target_access_string not in self.hypothesis_states:
+                    if self.automaton_type == 'mealy':
+                        new_state = MealyState(state_id=f's{state_counter}')
+                    else:
+                        output = self.sul.query(transition_target_access_string)[-1]
+                        new_state = MooreState(state_id=f's{state_counter}', output=output)
+
+                    new_state.prefix = transition_target_access_string
+                    self.hypothesis_states[new_state.prefix] = new_state
+                    self.transitions_to_update.extend(product([new_state], self.alphabet))
+                    state_counter += 1
+
+                state.transitions[input_element] = self.hypothesis_states[transition_target_access_string]
+
+                if self.automaton_type == "mealy":
+                    state.output_fun[input_element] = self.sul.query(state.prefix + (input_element,))[-1]
+            else:
+                # internal transitions
+                if input_element in self.alphabet.internal_alphabet:
+                    transition_target_node = self._sift(state.prefix + (input_element,))
+                    transition_target_access_string = transition_target_node.access_string
+
+                    assert transition_target_access_string in self.hypothesis_states
+                    trans = SevpaTransition(target=self.hypothesis_states[transition_target_access_string],
+                                            letter=input_element, action=None)
+                    state.transitions[input_element].append(trans)
+
+                #  call transitions
+                elif input_element in self.alphabet.call_alphabet:
+                    # Add return transitions
+                    for return_letter in self.alphabet.return_alphabet:
+                        # check if exclusive pairs of call and return letters are defined in an alphabets
+                        if self.alphabet.exclusive_call_return_pairs and \
+                                self.alphabet.exclusive_call_return_pairs[input_element] != return_letter:
+                            continue
+
+                        for other_state in self.hypothesis_states.values():
+                            # ignore other state if other state is error state
+                            if other_state.prefix == self.error_state_prefix:
+                                continue
+                            transition_target_node = self._sift(
+                                other_state.prefix + (input_element,) + state.prefix + (return_letter,))
+                            transition_target_access_string = transition_target_node.access_string
+
+                            trans = SevpaTransition(target=self.hypothesis_states[transition_target_access_string],
+                                                    letter=return_letter,
+                                                    action='pop', stack_guard=(other_state.state_id, input_element))
+                            state.transitions[return_letter].append(trans)
+
+        if self.automaton_type == 'vpa':
+            hypothesis = Sevpa(initial_state=self.initial_state, states=list(self.hypothesis_states.values()))
+            if not self.error_state_prefix:
+                error_state = hypothesis.get_error_state()
+                if error_state:
+                    self.error_state_prefix = error_state.prefix
+            return hypothesis
+
+        return automaton_class[self.automaton_type](initial_state=self.initial_state,
+                                                    states=list(self.hypothesis_states.values()))
+
+    def _least_common_ancestor(self, node_1_id, node_2_id):
+        """
+        Find the distinguishing string of the least common ancestor
+        of the leaf nodes node_1 and node_2. Both nodes have to exist.
+        Adapted from https://www.geeksforgeeks.org/lowest-common-ancestor-binary-tree-set-1/
+
+        Args:
+
+            node_1_id: first leaf node's id
+            node_2_id: second leaf node's id
+
+        Returns:
+
+            the distinguishing string of the lca
+
+        """
+
+        def ancestor(parent, node):
+            for child in parent.children.values():
+                if child.is_leaf():
+                    if child.access_string == node:
+                        return True
+                else:
+                    next_ancestor = ancestor(child, node)
+                    if next_ancestor:
+                        return True
+            return False
+
+        def findLCA(n1_id, n2_id):
+            node = self.leaf_nodes[n1_id]
+            parent = node.parent
+            while parent:
+                if ancestor(parent, n2_id):
+                    return parent
+                if parent.parent:
+                    parent = parent.parent
+                else:
+                    return parent
+            return None
+
+        return findLCA(node_1_id, node_2_id).distinguishing_string
+
+    def update(self, cex: tuple, hypothesis):
+        """
+        Updates the classification tree based on a counterexample.
+        - For each prefix cex[:i] of the counterexample, get
+              s_i      = self.sift(cex[:i])    and
+              s_star_i = id of the state with the access sequence cex[:i]
+                         in the hypothesis
+          and let j be the least i such that s_i != s_star_i.
+        - Replace the CTLeafNode labeled with the access string of the state
+          that is reached by the sequence cex[:j-1] in the hypothesis
+          with an CTInternalNode with two CTLeafNodes: one keeps the old
+          access string, and one gets the new access string cex[:j-1].
+          The internal node is labeled with the distinguishing string (cex[j-1],*d),
+          where d is the distinguishing string of the LCA of s_i and s_star_i.
+
+        Args:
+            cex: the counterexample used to update the tree
+            hypothesis: the former (wrong) hypothesis
+
+        """
+        j = d = None
+        for i in range(1, len(cex) + 1):
+            s_i = self._sift(cex[:i]).access_string
+            hypothesis.execute_sequence(hypothesis.initial_state, cex[:i])
+            s_star_i = hypothesis.current_state.prefix
+
+            if s_i != s_star_i:
+                j = i
+                d = self._least_common_ancestor(s_i, s_star_i)
+                break
+        if j is None and d is None:
+            j = len(cex)
+            d = []
+        assert j is not None and d is not None
+
+        hypothesis.execute_sequence(hypothesis.initial_state, cex[:j - 1] or tuple())
+
+        self._insert_new_leaf(discriminator=(cex[j - 1], *d),
+                              old_leaf_access_string=hypothesis.current_state.prefix,
+                              new_leaf_access_string=tuple(cex[:j - 1]) or tuple(),
+                              new_leaf_position=self.sul.query((*cex[:j - 1], *(cex[j - 1], *d)))[-1])
+
+    def process_counterexample(self, cex: tuple, hypothesis, cex_processing_fun):
+        """
+        Updates the classification tree based on a counterexample,
+        using Rivest & Schapire counterexample processing
+        - Replace the CTLeafNode labeled with the access string of the state
+          that is reached by the sequence cex[:j-1] in the hypothesis
+          with an CTInternalNode with two CTLeafNodes: one keeps the old
+          access string, and one gets the new access string cex[:j-1].
+          The internal node is labeled with the distinguishing string (cex[j-1],*d),
+          where d is the distinguishing string of the LCA of s_i and s_star_i.
+
+        Args:
+            cex: the counterexample used to update the tree
+            hypothesis: the former (wrong) hypothesis
+            cex_processing_fun: string choosing which cex_processing to use
+
+        """
+        v = None
+        if 'linear' in cex_processing_fun:
+            direction = cex_processing_fun[-3:]
+            v = linear_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
+                                      direction=direction, suffix_closedness=False)[0]
+        elif 'exponential' in cex_processing_fun:
+            direction = cex_processing_fun[-3:]
+            v = exponential_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
+                                           direction=direction, suffix_closedness=False)[0]
+        elif cex_processing_fun == 'rs':
+            v = rs_cex_processing(self.sul, cex, hypothesis, is_vpa=self.automaton_type == 'vpa',
+                                  suffix_closedness=False)[0]
+
+        assert v
+        a = cex[len(cex) - len(v) - 1]
+        u = cex[:len(cex) - len(v) - 1]
+        assert (*u, a, *v) == cex
+
+        hypothesis.execute_sequence(hypothesis.initial_state, u)
+        u_state = hypothesis.current_state
+
+        top_of_stack = hypothesis.stack[-1] if self.automaton_type == 'vpa' else None
+
+        # get state reached after executing last action => old leaf
+        hypothesis.step(a)
+        ua_state = hypothesis.current_state
+
+        # get discriminator and new_leaf_access_string
+        if self.automaton_type == 'vpa':
+            discriminator = (tuple(hypothesis.transform_access_string()), tuple(v))
+
+            if a in self.alphabet.internal_alphabet:
+                new_leaf_access_string = (*u_state.prefix, a)
+            else:
+                assert a in self.alphabet.return_alphabet
+                l_prime, call = hypothesis.get_state_by_id(top_of_stack[0]), top_of_stack[1]
+                new_leaf_access_string = l_prime.prefix + (call,) + u_state.prefix + (a,)
+        else:
+            discriminator = v
+            new_leaf_access_string = (*u_state.prefix, a)
+
+        if self.automaton_type == 'dfa' or self.automaton_type == 'vpa':
+            new_leaf_position = not hypothesis.execute_sequence(hypothesis.initial_state, cex)[-1]
+        else:
+            new_leaf_position = self.sul.query(cex)[-1]
+
+        self._insert_new_leaf(discriminator=discriminator,
+                              old_leaf_access_string=ua_state.prefix,
+                              new_leaf_access_string=new_leaf_access_string,
+                              new_leaf_position=new_leaf_position)
+
+    def _insert_new_leaf(self, discriminator, old_leaf_access_string, new_leaf_access_string, new_leaf_position):
+        """
+        Inserts a new leaf in the classification tree by:
+        - moving the leaf node specified by <old_leaf_access_string> down one level
+        - inserting an internal node  at the former position of the old node (i.e. as the parent of the old node)
+        - adding a new leaf node with <new_leaf_access_string> as child of the new internal node/sibling of the old node
+        Could also be thought of as 'splitting' the old node into two (one of which keeps the old access string and one
+        of which gets the new one) with <discriminator> as the distinguishing string between the two.
+
+        where one of the resulting nodes keeps the old
+        node's access string and the other gets new_leaf_access_string.
+        Args:
+            discriminator: The distinguishing string of the new internal node
+            old_leaf_access_string: The access string specifying the leaf node to be 'split' (or rather moved down)
+            new_leaf_access_string: The access string of the leaf node that will be created
+            new_leaf_position: The path from the new internal node to the new leaf node
+
+        Returns:
+
+        """
+        if self.automaton_type == "dfa" or self.automaton_type == 'vpa':
+            other_leaf_position = not new_leaf_position
+        else:
+            # check if this query is in the node cache
+            other_leaf_position = self.sul.query((*old_leaf_access_string, *discriminator))[-1]
+
+        old_leaf = self.leaf_nodes[old_leaf_access_string]
+
+        # create an internal node at the same position as the old leaf node
+        discriminator_node = CTInternalNode(distinguishing_string=discriminator,
+                                            parent=old_leaf.parent, path_to_node=old_leaf.path_to_node)
+
+        # create the new leaf node and add it as child of the internal node
+        new_leaf = CTLeafNode(access_string=new_leaf_access_string,
+                              parent=discriminator_node,
+                              path_to_node=new_leaf_position)
+        self.leaf_nodes[new_leaf_access_string] = new_leaf
+
+        # redirect the old nodes former parent to the internal node
+        old_leaf.parent.children[old_leaf.path_to_node] = discriminator_node
+
+        # add the internal node as parent of the old leaf
+        old_leaf.parent = discriminator_node
+        old_leaf.path_to_node = other_leaf_position
+
+        # set the two nodes as children of the internal node
+        discriminator_node.children[new_leaf_position] = new_leaf
+        discriminator_node.children[other_leaf_position] = old_leaf
+
+        # sifting cache update
+        self.new_states.append(new_leaf)
+
+        if self.automaton_type != 'vpa':
+            for state in self.hypothesis_states.values():
+                for inp, destination in state.transitions.items():
+                    if old_leaf_access_string == destination.prefix:
+                        self.transitions_to_update.append((state, inp))
+        else:
+            for state in self.hypothesis_states.values():
+                state.transitions.clear()
+                self.transitions_to_update.extend(product([state], self.alphabet.internal_alphabet))
+                self.transitions_to_update.extend(product([state], self.alphabet.call_alphabet))
```

## aalpy/learning_algs/deterministic/CounterExampleProcessing.py

 * *Ordering differences only*

```diff
@@ -1,219 +1,219 @@
-from aalpy.base import SUL
-from aalpy.utils.HelperFunctions import all_suffixes, all_prefixes
-
-
-def counterexample_successfully_processed(sul, cex, hypothesis):
-    cex_outputs = sul.query(cex)
-    hyp_outputs = hypothesis.execute_sequence(hypothesis.initial_state, cex)
-    return cex_outputs[-1] == hyp_outputs[-1]
-
-
-def longest_prefix_cex_processing(s_union_s_dot_a: list, cex: tuple, closedness='suffix'):
-    """
-    Suffix processing strategy found in Shahbaz-Groz paper 'Inferring Mealy Machines'.
-    It splits the counterexample into prefix and suffix. The prefix is the longest element of the S union S.A that
-    matches the beginning of the counterexample. By removing such prefixes from counterexample, no consistency check
-    is needed.
-
-    Args:
-
-        s_union_s_dot_a: list of all prefixes found in observation table sorted from shortest to longest
-        cex: counterexample
-        closedness: either 'suffix' or 'prefix'. (Default value = 'suffix')
-        s_union_s_dot_a: list:
-        cex: tuple: counterexample
-
-    Returns:
-
-        suffixes to add to the E set
-
-    """
-    prefixes = s_union_s_dot_a
-    prefixes.reverse()
-    trimmed_suffix = None
-
-    for p in prefixes:
-        if p == cex[:len(p)]:
-            trimmed_suffix = cex[len(p):]
-            break
-
-    trimmed_suffix = trimmed_suffix if trimmed_suffix else cex
-    suffixes = all_suffixes(trimmed_suffix) if closedness == 'suffix' else all_prefixes(trimmed_suffix)
-    suffixes.reverse()
-    return suffixes
-
-
-def rs_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
-                      is_vpa=False, lower=None, upper=None):
-    """
-    Riverst-Schapire counter example processing.
-
-    Args:
-
-        sul: system under learning
-        cex: found counterexample
-        hypothesis: hypothesis on which counterexample was found
-        suffix_closedness: If true all suffixes will be added, else just one (Default value = True)
-        closedness: either 'suffix' or 'prefix'. (Default value = 'suffix')
-        sul: SUL: system under learning
-        cex: tuple: counterexample
-        is_vpa: system under learning behaves as a context free language
-        upper: upper boarder for cex (from preprocessing), None will set it to 1
-        lower: lower boarder for cex (from preprocessing), None will set it to  len(cex_input) - 2
-
-    Returns:
-
-        suffixes to be added to the E set
-
-    """
-    cex_out = sul.query(cex)
-    cex_input = list(cex)
-
-    lower = 1 if lower is None else lower
-    upper = len(cex_input) - 2 if upper is None else upper
-
-    while True:
-        hypothesis.reset_to_initial()
-        mid = (lower + upper) // 2
-
-        # arr[:n] -> first n values
-        # arr[n:] -> last n values
-
-        for s_p in cex_input[:mid]:
-            hypothesis.step(s_p)
-
-        if not is_vpa:
-            s_bracket = hypothesis.current_state.prefix
-        else:
-            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
-
-        d = tuple(cex_input[mid:])
-        mq = sul.query(s_bracket + d)
-
-        if mq[-1] == cex_out[-1]:  # only check if the last element is the same as the cex
-            lower = mid + 1
-            if upper < lower:
-                suffix = d[1:]
-                break
-        else:
-            upper = mid - 1
-            if upper < lower:
-                suffix = d
-                break
-
-    if suffix_closedness:
-        suffixes = all_suffixes(suffix) if closedness == 'suffix' else all_prefixes(suffix)
-        suffixes.reverse()
-        suffix_to_query = suffixes
-    else:
-        suffix_to_query = [suffix]
-    return suffix_to_query
-
-
-def linear_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
-                          direction='fwd', is_vpa=False):
-    assert direction in {'fwd', 'bwd'}
-
-    direction = 'fwd'
-
-    distinguishing_suffix = None
-    previous_output = None
-
-    for i in range(0, len(cex)):
-        bp = i if direction == 'fwd' else -i - 1
-        prefix = cex[:bp]
-        suffix = cex[bp:]
-        assert cex == prefix + suffix
-
-        hypothesis.reset_to_initial()
-        hypothesis.execute_sequence(hypothesis.initial_state, prefix)
-
-        if not is_vpa:
-            s_bracket = hypothesis.current_state.prefix
-        else:
-            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
-
-        sul_out = sul.query(s_bracket + suffix)[-1]
-
-        if previous_output is None:
-            previous_output = sul_out
-            continue
-
-        if sul_out != previous_output:
-            distinguishing_suffix = suffix if direction == 'fwd' else cex[bp + 1:]
-            break
-
-        previous_output = sul_out
-
-    assert distinguishing_suffix
-    if suffix_closedness:
-        suffixes = all_suffixes(distinguishing_suffix) if closedness == 'suffix' else all_prefixes(
-            distinguishing_suffix)
-        suffixes.reverse()
-        suffix_to_query = suffixes
-    else:
-        suffix_to_query = [distinguishing_suffix]
-
-    return suffix_to_query
-
-
-def exponential_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
-                               direction='fwd', is_vpa=False):
-    assert direction in {'fwd', 'bwd'}
-
-    cex_out = sul.query(cex)
-
-    bwd_subtrahend = 1
-    if direction == 'fwd':
-        bp_recent = 0
-        bp = 1
-    else:
-        bp_recent = len(cex)
-        bp = len(cex)-1
-
-    suffix = None
-    while True:
-        if direction == 'fwd':
-            if bp >= len(cex):
-                bp = len(cex)
-                break
-        else:
-            if bp <= 1:
-                bp = 1
-                break
-
-        prefix = cex[:bp]
-        suffix = cex[bp:]
-        assert cex == prefix + suffix
-
-        hypothesis.reset_to_initial()
-        hypothesis.execute_sequence(hypothesis.initial_state, prefix)
-
-        if not is_vpa:
-            s_bracket = hypothesis.current_state.prefix
-        else:
-            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
-
-        sul_out = sul.query(s_bracket + suffix)
-
-        if sul_out[-1] != cex_out[-1] and direction == 'fwd':
-            break
-        elif sul_out[-1] == cex_out[-1] and direction == 'bwd':
-            break
-
-        bp_recent = bp
-        if direction == 'fwd':
-            bp *= 2
-        else:
-            bp -= bwd_subtrahend
-            bwd_subtrahend *= 2
-
-    if (bp - bp_recent) == 1:
-        return [suffix]
-    else:
-        if direction == 'fwd':
-            return rs_cex_processing(sul, cex, hypothesis, suffix_closedness, closedness, is_vpa, lower=bp_recent)
-        else:
-            return rs_cex_processing(sul, cex, hypothesis, suffix_closedness, closedness, is_vpa, upper=bp_recent)
-
-
+from aalpy.base import SUL
+from aalpy.utils.HelperFunctions import all_suffixes, all_prefixes
+
+
+def counterexample_successfully_processed(sul, cex, hypothesis):
+    cex_outputs = sul.query(cex)
+    hyp_outputs = hypothesis.execute_sequence(hypothesis.initial_state, cex)
+    return cex_outputs[-1] == hyp_outputs[-1]
+
+
+def longest_prefix_cex_processing(s_union_s_dot_a: list, cex: tuple, closedness='suffix'):
+    """
+    Suffix processing strategy found in Shahbaz-Groz paper 'Inferring Mealy Machines'.
+    It splits the counterexample into prefix and suffix. The prefix is the longest element of the S union S.A that
+    matches the beginning of the counterexample. By removing such prefixes from counterexample, no consistency check
+    is needed.
+
+    Args:
+
+        s_union_s_dot_a: list of all prefixes found in observation table sorted from shortest to longest
+        cex: counterexample
+        closedness: either 'suffix' or 'prefix'. (Default value = 'suffix')
+        s_union_s_dot_a: list:
+        cex: tuple: counterexample
+
+    Returns:
+
+        suffixes to add to the E set
+
+    """
+    prefixes = s_union_s_dot_a
+    prefixes.reverse()
+    trimmed_suffix = None
+
+    for p in prefixes:
+        if p == cex[:len(p)]:
+            trimmed_suffix = cex[len(p):]
+            break
+
+    trimmed_suffix = trimmed_suffix if trimmed_suffix else cex
+    suffixes = all_suffixes(trimmed_suffix) if closedness == 'suffix' else all_prefixes(trimmed_suffix)
+    suffixes.reverse()
+    return suffixes
+
+
+def rs_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
+                      is_vpa=False, lower=None, upper=None):
+    """
+    Riverst-Schapire counter example processing.
+
+    Args:
+
+        sul: system under learning
+        cex: found counterexample
+        hypothesis: hypothesis on which counterexample was found
+        suffix_closedness: If true all suffixes will be added, else just one (Default value = True)
+        closedness: either 'suffix' or 'prefix'. (Default value = 'suffix')
+        sul: SUL: system under learning
+        cex: tuple: counterexample
+        is_vpa: system under learning behaves as a context free language
+        upper: upper boarder for cex (from preprocessing), None will set it to 1
+        lower: lower boarder for cex (from preprocessing), None will set it to  len(cex_input) - 2
+
+    Returns:
+
+        suffixes to be added to the E set
+
+    """
+    cex_out = sul.query(cex)
+    cex_input = list(cex)
+
+    lower = 1 if lower is None else lower
+    upper = len(cex_input) - 2 if upper is None else upper
+
+    while True:
+        hypothesis.reset_to_initial()
+        mid = (lower + upper) // 2
+
+        # arr[:n] -> first n values
+        # arr[n:] -> last n values
+
+        for s_p in cex_input[:mid]:
+            hypothesis.step(s_p)
+
+        if not is_vpa:
+            s_bracket = hypothesis.current_state.prefix
+        else:
+            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
+
+        d = tuple(cex_input[mid:])
+        mq = sul.query(s_bracket + d)
+
+        if mq[-1] == cex_out[-1]:  # only check if the last element is the same as the cex
+            lower = mid + 1
+            if upper < lower:
+                suffix = d[1:]
+                break
+        else:
+            upper = mid - 1
+            if upper < lower:
+                suffix = d
+                break
+
+    if suffix_closedness:
+        suffixes = all_suffixes(suffix) if closedness == 'suffix' else all_prefixes(suffix)
+        suffixes.reverse()
+        suffix_to_query = suffixes
+    else:
+        suffix_to_query = [suffix]
+    return suffix_to_query
+
+
+def linear_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
+                          direction='fwd', is_vpa=False):
+    assert direction in {'fwd', 'bwd'}
+
+    direction = 'fwd'
+
+    distinguishing_suffix = None
+    previous_output = None
+
+    for i in range(0, len(cex)):
+        bp = i if direction == 'fwd' else -i - 1
+        prefix = cex[:bp]
+        suffix = cex[bp:]
+        assert cex == prefix + suffix
+
+        hypothesis.reset_to_initial()
+        hypothesis.execute_sequence(hypothesis.initial_state, prefix)
+
+        if not is_vpa:
+            s_bracket = hypothesis.current_state.prefix
+        else:
+            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
+
+        sul_out = sul.query(s_bracket + suffix)[-1]
+
+        if previous_output is None:
+            previous_output = sul_out
+            continue
+
+        if sul_out != previous_output:
+            distinguishing_suffix = suffix if direction == 'fwd' else cex[bp + 1:]
+            break
+
+        previous_output = sul_out
+
+    assert distinguishing_suffix
+    if suffix_closedness:
+        suffixes = all_suffixes(distinguishing_suffix) if closedness == 'suffix' else all_prefixes(
+            distinguishing_suffix)
+        suffixes.reverse()
+        suffix_to_query = suffixes
+    else:
+        suffix_to_query = [distinguishing_suffix]
+
+    return suffix_to_query
+
+
+def exponential_cex_processing(sul: SUL, cex: tuple, hypothesis, suffix_closedness=True, closedness='suffix',
+                               direction='fwd', is_vpa=False):
+    assert direction in {'fwd', 'bwd'}
+
+    cex_out = sul.query(cex)
+
+    bwd_subtrahend = 1
+    if direction == 'fwd':
+        bp_recent = 0
+        bp = 1
+    else:
+        bp_recent = len(cex)
+        bp = len(cex)-1
+
+    suffix = None
+    while True:
+        if direction == 'fwd':
+            if bp >= len(cex):
+                bp = len(cex)
+                break
+        else:
+            if bp <= 1:
+                bp = 1
+                break
+
+        prefix = cex[:bp]
+        suffix = cex[bp:]
+        assert cex == prefix + suffix
+
+        hypothesis.reset_to_initial()
+        hypothesis.execute_sequence(hypothesis.initial_state, prefix)
+
+        if not is_vpa:
+            s_bracket = hypothesis.current_state.prefix
+        else:
+            s_bracket = tuple(hypothesis.transform_access_string(hypothesis.current_state))
+
+        sul_out = sul.query(s_bracket + suffix)
+
+        if sul_out[-1] != cex_out[-1] and direction == 'fwd':
+            break
+        elif sul_out[-1] == cex_out[-1] and direction == 'bwd':
+            break
+
+        bp_recent = bp
+        if direction == 'fwd':
+            bp *= 2
+        else:
+            bp -= bwd_subtrahend
+            bwd_subtrahend *= 2
+
+    if (bp - bp_recent) == 1:
+        return [suffix]
+    else:
+        if direction == 'fwd':
+            return rs_cex_processing(sul, cex, hypothesis, suffix_closedness, closedness, is_vpa, lower=bp_recent)
+        else:
+            return rs_cex_processing(sul, cex, hypothesis, suffix_closedness, closedness, is_vpa, upper=bp_recent)
+
+
```

## aalpy/learning_algs/deterministic/KV.py

```diff
@@ -1,173 +1,173 @@
-import time
-from typing import Union
-
-from aalpy.automata import Dfa, DfaState, MealyState, MealyMachine, MooreState, MooreMachine, \
-    Sevpa, SevpaState, SevpaAlphabet
-from aalpy.base import Oracle, SUL
-from aalpy.utils.HelperFunctions import print_learning_info, visualize_classification_tree
-from .ClassificationTree import ClassificationTree
-from .CounterExampleProcessing import counterexample_successfully_processed
-from ...base.SUL import CacheSUL
-
-print_options = [0, 1, 2, 3]
-counterexample_processing_strategy = ['rs', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd']
-automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine, 'vpa': Sevpa}
-
-
-def run_KV(alphabet: Union[list, SevpaAlphabet], sul: SUL, eq_oracle: Oracle, automaton_type, cex_processing='rs',
-           max_learning_rounds=None, cache_and_non_det_check=True, return_data=False, print_level=2):
-    """
-    Executes the KV algorithm.
-
-    Args:
-
-        alphabet: input alphabet
-
-        sul: system under learning
-
-        eq_oracle: equivalence oracle
-
-        automaton_type: type of automaton to be learned. One of 'dfa', 'mealy', 'moore', 'vpa'
-
-        cex_processing: Counterexample processing strategy. Either 'rs' (Riverst-Schapire), 'longest_prefix'.
-            (Default value = 'rs'), 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd'
-
-        max_learning_rounds: number of learning rounds after which learning will terminate (Default value = None)
-
-        cache_and_non_det_check: Use caching and non-determinism checks (Default value = True)
-
-        return_data: if True, a map containing all information(runtime/#queries/#steps) will be returned
-            (Default value = False)
-
-        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
-            (Default value = 2)
-
-
-    Returns:
-
-        automaton of type automaton_type (dict containing all information about learning if 'return_data' is True)
-
-    """
-
-    assert print_level in print_options
-    assert cex_processing in counterexample_processing_strategy
-    assert automaton_type in [*automaton_class]
-    assert automaton_type != 'vpa' and isinstance(alphabet, list) or isinstance(alphabet, SevpaAlphabet)
-
-    start_time = time.time()
-    eq_query_time = 0
-    learning_rounds = 0
-
-    if cache_and_non_det_check:
-        # Wrap the sul in the CacheSUL, so that all steps/queries are cached
-        sul = CacheSUL(sul)
-        eq_oracle.sul = sul
-
-    if automaton_type != 'mealy':
-        # Do a membership query on the empty string to determine whether
-        # the start state of the SUL is accepting or rejecting
-        empty_string_mq = sul.query(tuple())[-1]
-
-        # Construct a hypothesis automaton that consists simply of this
-        # single (accepting or rejecting) state with self-loops for
-        # all transitions.
-        if automaton_type == 'dfa':
-            initial_state = DfaState(state_id='q0', is_accepting=empty_string_mq)
-        elif automaton_type == 'moore':
-            initial_state = MooreState(state_id='q0', output=empty_string_mq)
-        else:
-            initial_state = SevpaState(state_id='q0', is_accepting=empty_string_mq)
-    else:
-        initial_state = MealyState(state_id='q0')
-
-    initial_state.prefix = tuple()
-
-    if automaton_type != 'vpa':
-        for a in alphabet:
-            initial_state.transitions[a] = initial_state
-            if automaton_type == 'mealy':
-                initial_state.output_fun[a] = sul.query((a,))[-1]
-
-    if automaton_type != 'vpa':
-        hypothesis = automaton_class[automaton_type](initial_state, [initial_state])
-    else:
-        hypothesis = Sevpa.create_daisy_hypothesis(initial_state, alphabet)
-
-    # Perform an equivalence query on this automaton
-    eq_query_start = time.time()
-    cex = eq_oracle.find_cex(hypothesis)
-
-    eq_query_time += time.time() - eq_query_start
-
-    classification_tree = None
-    if cex is not None:
-        cex = tuple(cex)
-
-        # initialise the classification tree to have a root
-        # labeled with the empty word as the distinguishing string
-        # and two leaves labeled with access strings cex and empty word
-        classification_tree = ClassificationTree(alphabet=alphabet, sul=sul, automaton_type=automaton_type, cex=cex)
-
-        while True:
-            learning_rounds += 1
-            if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
-                break
-
-            hypothesis = classification_tree.gen_hypothesis()
-
-            if print_level == 2:
-                print(f'\rHypothesis {learning_rounds}: {hypothesis.size} states.', end="")
-
-            if print_level == 3:
-                # would be nice to have an option to print classification tree
-                print(f'Hypothesis {learning_rounds}: {hypothesis.size} states.')
-
-            if counterexample_successfully_processed(sul, cex, hypothesis):
-                # Perform an equivalence query on this automaton
-                eq_query_start = time.time()
-                cex = eq_oracle.find_cex(hypothesis)
-                eq_query_time += time.time() - eq_query_start
-
-                if cex is None:
-                    break
-                else:
-                    cex = tuple(cex)
-
-                if print_level == 3:
-                    print('Counterexample', cex)
-
-            classification_tree.process_counterexample(cex, hypothesis, cex_processing)
-
-    if automaton_type == 'vpa':
-        hypothesis.delete_state(hypothesis.get_error_state())
-
-    total_time = round(time.time() - start_time, 2)
-    eq_query_time = round(eq_query_time, 2)
-    learning_time = round(total_time - eq_query_time, 2)
-
-    info = {
-        'learning_rounds': learning_rounds,
-        'automaton_size': hypothesis.size,
-        'queries_learning': sul.num_queries,
-        'steps_learning': sul.num_steps,
-        'queries_eq_oracle': eq_oracle.num_queries,
-        'steps_eq_oracle': eq_oracle.num_steps,
-        'learning_time': learning_time,
-        'eq_oracle_time': eq_query_time,
-        'total_time': total_time,
-        'cache_saved': sul.num_cached_queries,
-    }
-
-    if print_level > 0:
-        if print_level == 2:
-            print("")
-        print_learning_info(info)
-
-        if print_level == 3 and classification_tree:
-            print('Visualization of classification tree saved to classification_tree.pdf')
-            visualize_classification_tree(classification_tree.root)
-
-    if return_data:
-        return hypothesis, info
-
-    return hypothesis
+import time
+from typing import Union
+
+from aalpy.automata import Dfa, DfaState, MealyState, MealyMachine, MooreState, MooreMachine, \
+    Sevpa, SevpaState, SevpaAlphabet
+from aalpy.base import Oracle, SUL
+from aalpy.utils.HelperFunctions import print_learning_info, visualize_classification_tree
+from .ClassificationTree import ClassificationTree
+from .CounterExampleProcessing import counterexample_successfully_processed
+from ...base.SUL import CacheSUL
+
+print_options = [0, 1, 2, 3]
+counterexample_processing_strategy = ['rs', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd']
+automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine, 'vpa': Sevpa}
+
+
+def run_KV(alphabet: Union[list, SevpaAlphabet], sul: SUL, eq_oracle: Oracle, automaton_type, cex_processing='rs',
+           max_learning_rounds=None, cache_and_non_det_check=True, return_data=False, print_level=2):
+    """
+    Executes the KV algorithm.
+
+    Args:
+
+        alphabet: input alphabet
+
+        sul: system under learning
+
+        eq_oracle: equivalence oracle
+
+        automaton_type: type of automaton to be learned. One of 'dfa', 'mealy', 'moore', 'vpa'
+
+        cex_processing: Counterexample processing strategy. Either 'rs' (Riverst-Schapire), 'longest_prefix'.
+            (Default value = 'rs'), 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd'
+
+        max_learning_rounds: number of learning rounds after which learning will terminate (Default value = None)
+
+        cache_and_non_det_check: Use caching and non-determinism checks (Default value = True)
+
+        return_data: if True, a map containing all information(runtime/#queries/#steps) will be returned
+            (Default value = False)
+
+        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
+            (Default value = 2)
+
+
+    Returns:
+
+        automaton of type automaton_type (dict containing all information about learning if 'return_data' is True)
+
+    """
+
+    assert print_level in print_options
+    assert cex_processing in counterexample_processing_strategy
+    assert automaton_type in [*automaton_class]
+    assert automaton_type != 'vpa' and isinstance(alphabet, list) or isinstance(alphabet, SevpaAlphabet)
+
+    start_time = time.time()
+    eq_query_time = 0
+    learning_rounds = 0
+
+    if cache_and_non_det_check:
+        # Wrap the sul in the CacheSUL, so that all steps/queries are cached
+        sul = CacheSUL(sul)
+        eq_oracle.sul = sul
+
+    if automaton_type != 'mealy':
+        # Do a membership query on the empty string to determine whether
+        # the start state of the SUL is accepting or rejecting
+        empty_string_mq = sul.query(tuple())[-1]
+
+        # Construct a hypothesis automaton that consists simply of this
+        # single (accepting or rejecting) state with self-loops for
+        # all transitions.
+        if automaton_type == 'dfa':
+            initial_state = DfaState(state_id='q0', is_accepting=empty_string_mq)
+        elif automaton_type == 'moore':
+            initial_state = MooreState(state_id='q0', output=empty_string_mq)
+        else:
+            initial_state = SevpaState(state_id='q0', is_accepting=empty_string_mq)
+    else:
+        initial_state = MealyState(state_id='q0')
+
+    initial_state.prefix = tuple()
+
+    if automaton_type != 'vpa':
+        for a in alphabet:
+            initial_state.transitions[a] = initial_state
+            if automaton_type == 'mealy':
+                initial_state.output_fun[a] = sul.query((a,))[-1]
+
+    if automaton_type != 'vpa':
+        hypothesis = automaton_class[automaton_type](initial_state, [initial_state])
+    else:
+        hypothesis = Sevpa.create_daisy_hypothesis(initial_state, alphabet)
+
+    # Perform an equivalence query on this automaton
+    eq_query_start = time.time()
+    cex = eq_oracle.find_cex(hypothesis)
+
+    eq_query_time += time.time() - eq_query_start
+
+    classification_tree = None
+    if cex is not None:
+        cex = tuple(cex)
+
+        # initialise the classification tree to have a root
+        # labeled with the empty word as the distinguishing string
+        # and two leaves labeled with access strings cex and empty word
+        classification_tree = ClassificationTree(alphabet=alphabet, sul=sul, automaton_type=automaton_type, cex=cex)
+
+        while True:
+            learning_rounds += 1
+            if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
+                break
+
+            hypothesis = classification_tree.update_hypothesis()
+
+            if print_level == 2:
+                print(f'\rHypothesis {learning_rounds}: {hypothesis.size} states.', end="")
+
+            if print_level == 3:
+                # would be nice to have an option to print classification tree
+                print(f'Hypothesis {learning_rounds}: {hypothesis.size} states.')
+
+            if counterexample_successfully_processed(sul, cex, hypothesis):
+                # Perform an equivalence query on this automaton
+                eq_query_start = time.time()
+                cex = eq_oracle.find_cex(hypothesis)
+                eq_query_time += time.time() - eq_query_start
+
+                if cex is None:
+                    break
+                else:
+                    cex = tuple(cex)
+
+                if print_level == 3:
+                    print('Counterexample', cex)
+
+            classification_tree.process_counterexample(cex, hypothesis, cex_processing)
+
+    if automaton_type == 'vpa':
+        hypothesis.delete_state(hypothesis.get_error_state())
+
+    total_time = round(time.time() - start_time, 2)
+    eq_query_time = round(eq_query_time, 2)
+    learning_time = round(total_time - eq_query_time, 2)
+
+    info = {
+        'learning_rounds': learning_rounds,
+        'automaton_size': hypothesis.size,
+        'queries_learning': sul.num_queries,
+        'steps_learning': sul.num_steps,
+        'queries_eq_oracle': eq_oracle.num_queries,
+        'steps_eq_oracle': eq_oracle.num_steps,
+        'learning_time': learning_time,
+        'eq_oracle_time': eq_query_time,
+        'total_time': total_time,
+        'cache_saved': sul.num_cached_queries,
+    }
+
+    if print_level > 0:
+        if print_level == 2:
+            print("")
+        print_learning_info(info)
+
+        if print_level == 3 and classification_tree:
+            print('Visualization of classification tree saved to classification_tree.pdf')
+            visualize_classification_tree(classification_tree.root)
+
+    if return_data:
+        return hypothesis, info
+
+    return hypothesis
```

## aalpy/learning_algs/deterministic/LStar.py

 * *Ordering differences only*

```diff
@@ -1,190 +1,190 @@
-import time
-
-from aalpy.base import Oracle, SUL
-from aalpy.utils.HelperFunctions import extend_set, print_learning_info, print_observation_table, all_prefixes
-from .CounterExampleProcessing import longest_prefix_cex_processing, rs_cex_processing, \
-    counterexample_successfully_processed, linear_cex_processing, exponential_cex_processing
-from .ObservationTable import ObservationTable
-from ...base.SUL import CacheSUL
-
-counterexample_processing_strategy = [None, 'rs', 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd',
-                                      'exponential_bwd']
-closedness_options = ['suffix_all', 'suffix_single']
-print_options = [0, 1, 2, 3]
-
-
-def run_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, automaton_type, samples=None,
-              closing_strategy='shortest_first', cex_processing='rs',
-              e_set_suffix_closed=False, all_prefixes_in_obs_table=True,
-              max_learning_rounds=None, cache_and_non_det_check=True, return_data=False, print_level=2):
-    """
-    Executes L* algorithm.
-
-    Args:
-
-        alphabet: input alphabet
-
-        sul: system under learning
-
-        eq_oracle: equivalence oracle
-
-        automaton_type: type of automaton to be learned. Either 'dfa', 'mealy' or 'moore'.
-
-        samples: input output traces provided to the learning algorithm. They are added to cache and could reduce
-        total interaction with the system. Syntax: list of [(input_sequence, output_sequence)] or None
-
-        closing_strategy: closing strategy used in the close method. Either 'longest_first', 'shortest_first' or
-            'single' (Default value = 'shortest_first')
-
-        cex_processing: Counterexample processing strategy. Either None, 'rs' (Riverst-Schapire), 'longest_prefix'.
-            (Default value = 'rs'), 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd'
-
-        e_set_suffix_closed: True option ensures that E set is suffix closed,
-            False adds just a single suffix per counterexample.
-
-        all_prefixes_in_obs_table: if True, entries of observation table will contain the whole output of the whole
-            suffix, otherwise just the last output meaning that all prefixes of the suffix will be added.
-            If False, just a single suffix will be added.
-
-        max_learning_rounds: number of learning rounds after which learning will terminate (Default value = None)
-
-        cache_and_non_det_check: Use caching and non-determinism checks (Default value = True)
-
-        return_data: if True, a map containing all information(runtime/#queries/#steps) will be returned
-            (Default value = False)
-
-        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
-            (Default value = 2)
-
-    Returns:
-
-        automaton of type automaton_type (dict containing all information about learning if 'return_data' is True)
-
-    """
-
-    assert cex_processing in counterexample_processing_strategy
-    assert print_level in print_options
-
-    if cache_and_non_det_check or samples is not None:
-        # Wrap the sul in the CacheSUL, so that all steps/queries are cached
-        sul = CacheSUL(sul)
-        eq_oracle.sul = sul
-
-        if samples:
-            for input_seq, output_seq in samples:
-                sul.cache.add_to_cache(input_seq, output_seq)
-
-    start_time = time.time()
-    eq_query_time = 0
-    learning_rounds = 0
-    hypothesis = None
-
-    observation_table = ObservationTable(alphabet, sul, automaton_type, all_prefixes_in_obs_table)
-
-    # Initial update of observation table, for empty row
-    observation_table.update_obs_table()
-    cex = None
-
-    while True:
-        if max_learning_rounds and learning_rounds == max_learning_rounds:
-            break
-
-        # Make observation table consistent (iff there is no counterexample processing)
-        if not cex_processing:
-            inconsistent_rows = observation_table.get_causes_of_inconsistency()
-            while inconsistent_rows is not None:
-                added_suffix = extend_set(observation_table.E, inconsistent_rows)
-                observation_table.update_obs_table(e_set=added_suffix)
-                inconsistent_rows = observation_table.get_causes_of_inconsistency()
-
-        # Close observation table
-        rows_to_close = observation_table.get_rows_to_close(closing_strategy)
-        while rows_to_close is not None:
-            rows_to_query = []
-            for row in rows_to_close:
-                observation_table.S.append(row)
-                rows_to_query.extend([row + (a,) for a in alphabet])
-            observation_table.update_obs_table(s_set=rows_to_query)
-            rows_to_close = observation_table.get_rows_to_close(closing_strategy)
-
-        # Generate hypothesis
-        hypothesis = observation_table.gen_hypothesis(no_cex_processing_used=cex_processing is None)
-        # Find counterexample if none has previously been found (first round) and cex is successfully processed
-        # (not a counterexample in the current hypothesis)
-        if cex is None or counterexample_successfully_processed(sul, cex, hypothesis):
-            learning_rounds += 1
-
-            if print_level > 1:
-                print(f'Hypothesis {learning_rounds}: {len(hypothesis.states)} states.')
-
-            if print_level == 3:
-                print_observation_table(observation_table, 'det')
-
-            eq_query_start = time.time()
-            cex = eq_oracle.find_cex(hypothesis)
-            eq_query_time += time.time() - eq_query_start
-
-        # If no counterexample is found, return the hypothesis
-        if cex is None:
-            break
-
-        # make sure counterexample is a tuple in case oracle returns a list
-        cex = tuple(cex)
-
-        if print_level == 3:
-            print('Counterexample', cex)
-
-        # Process counterexample and ask membership queries
-        if not cex_processing:
-            s_to_update = []
-            added_rows = extend_set(observation_table.S, all_prefixes(cex))
-            s_to_update.extend(added_rows)
-            for p in added_rows:
-                s_to_update.extend([p + (a,) for a in alphabet])
-
-            observation_table.update_obs_table(s_set=s_to_update)
-            continue
-
-        elif cex_processing == 'longest_prefix':
-            cex_suffixes = longest_prefix_cex_processing(observation_table.S + list(observation_table.s_dot_a()),
-                                                         cex, closedness='suffix')
-        elif cex_processing == 'rs':
-            cex_suffixes = rs_cex_processing(sul, cex, hypothesis, e_set_suffix_closed, closedness='suffix')
-        else:
-            direction = cex_processing[-3:]
-            if 'linear' in cex_processing:
-                cex_suffixes = linear_cex_processing(sul, cex, hypothesis, e_set_suffix_closed,
-                                                     direction=direction, closedness='suffix')
-            else:
-                cex_suffixes = exponential_cex_processing(sul, cex, hypothesis, e_set_suffix_closed,
-                                                          direction=direction, closedness='suffix')
-
-        added_suffixes = extend_set(observation_table.E, cex_suffixes)
-        observation_table.update_obs_table(e_set=added_suffixes)
-
-    total_time = round(time.time() - start_time, 2)
-    eq_query_time = round(eq_query_time, 2)
-    learning_time = round(total_time - eq_query_time, 2)
-
-    info = {
-        'learning_rounds': learning_rounds,
-        'automaton_size': hypothesis.size,
-        'queries_learning': sul.num_queries,
-        'steps_learning': sul.num_steps,
-        'queries_eq_oracle': eq_oracle.num_queries,
-        'steps_eq_oracle': eq_oracle.num_steps,
-        'learning_time': learning_time,
-        'eq_oracle_time': eq_query_time,
-        'total_time': total_time,
-        'characterization_set': observation_table.E
-    }
-    if cache_and_non_det_check:
-        info['cache_saved'] = sul.num_cached_queries
-
-    if print_level > 0:
-        print_learning_info(info)
-
-    if return_data:
-        return hypothesis, info
-
-    return hypothesis
+import time
+
+from aalpy.base import Oracle, SUL
+from aalpy.utils.HelperFunctions import extend_set, print_learning_info, print_observation_table, all_prefixes
+from .CounterExampleProcessing import longest_prefix_cex_processing, rs_cex_processing, \
+    counterexample_successfully_processed, linear_cex_processing, exponential_cex_processing
+from .ObservationTable import ObservationTable
+from ...base.SUL import CacheSUL
+
+counterexample_processing_strategy = [None, 'rs', 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd',
+                                      'exponential_bwd']
+closedness_options = ['suffix_all', 'suffix_single']
+print_options = [0, 1, 2, 3]
+
+
+def run_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, automaton_type, samples=None,
+              closing_strategy='shortest_first', cex_processing='rs',
+              e_set_suffix_closed=False, all_prefixes_in_obs_table=True,
+              max_learning_rounds=None, cache_and_non_det_check=True, return_data=False, print_level=2):
+    """
+    Executes L* algorithm.
+
+    Args:
+
+        alphabet: input alphabet
+
+        sul: system under learning
+
+        eq_oracle: equivalence oracle
+
+        automaton_type: type of automaton to be learned. Either 'dfa', 'mealy' or 'moore'.
+
+        samples: input output traces provided to the learning algorithm. They are added to cache and could reduce
+        total interaction with the system. Syntax: list of [(input_sequence, output_sequence)] or None
+
+        closing_strategy: closing strategy used in the close method. Either 'longest_first', 'shortest_first' or
+            'single' (Default value = 'shortest_first')
+
+        cex_processing: Counterexample processing strategy. Either None, 'rs' (Riverst-Schapire), 'longest_prefix'.
+            (Default value = 'rs'), 'longest_prefix', 'linear_fwd', 'linear_bwd', 'exponential_fwd', 'exponential_bwd'
+
+        e_set_suffix_closed: True option ensures that E set is suffix closed,
+            False adds just a single suffix per counterexample.
+
+        all_prefixes_in_obs_table: if True, entries of observation table will contain the whole output of the whole
+            suffix, otherwise just the last output meaning that all prefixes of the suffix will be added.
+            If False, just a single suffix will be added.
+
+        max_learning_rounds: number of learning rounds after which learning will terminate (Default value = None)
+
+        cache_and_non_det_check: Use caching and non-determinism checks (Default value = True)
+
+        return_data: if True, a map containing all information(runtime/#queries/#steps) will be returned
+            (Default value = False)
+
+        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
+            (Default value = 2)
+
+    Returns:
+
+        automaton of type automaton_type (dict containing all information about learning if 'return_data' is True)
+
+    """
+
+    assert cex_processing in counterexample_processing_strategy
+    assert print_level in print_options
+
+    if cache_and_non_det_check or samples is not None:
+        # Wrap the sul in the CacheSUL, so that all steps/queries are cached
+        sul = CacheSUL(sul)
+        eq_oracle.sul = sul
+
+        if samples:
+            for input_seq, output_seq in samples:
+                sul.cache.add_to_cache(input_seq, output_seq)
+
+    start_time = time.time()
+    eq_query_time = 0
+    learning_rounds = 0
+    hypothesis = None
+
+    observation_table = ObservationTable(alphabet, sul, automaton_type, all_prefixes_in_obs_table)
+
+    # Initial update of observation table, for empty row
+    observation_table.update_obs_table()
+    cex = None
+
+    while True:
+        if max_learning_rounds and learning_rounds == max_learning_rounds:
+            break
+
+        # Make observation table consistent (iff there is no counterexample processing)
+        if not cex_processing:
+            inconsistent_rows = observation_table.get_causes_of_inconsistency()
+            while inconsistent_rows is not None:
+                added_suffix = extend_set(observation_table.E, inconsistent_rows)
+                observation_table.update_obs_table(e_set=added_suffix)
+                inconsistent_rows = observation_table.get_causes_of_inconsistency()
+
+        # Close observation table
+        rows_to_close = observation_table.get_rows_to_close(closing_strategy)
+        while rows_to_close is not None:
+            rows_to_query = []
+            for row in rows_to_close:
+                observation_table.S.append(row)
+                rows_to_query.extend([row + (a,) for a in alphabet])
+            observation_table.update_obs_table(s_set=rows_to_query)
+            rows_to_close = observation_table.get_rows_to_close(closing_strategy)
+
+        # Generate hypothesis
+        hypothesis = observation_table.gen_hypothesis(no_cex_processing_used=cex_processing is None)
+        # Find counterexample if none has previously been found (first round) and cex is successfully processed
+        # (not a counterexample in the current hypothesis)
+        if cex is None or counterexample_successfully_processed(sul, cex, hypothesis):
+            learning_rounds += 1
+
+            if print_level > 1:
+                print(f'Hypothesis {learning_rounds}: {len(hypothesis.states)} states.')
+
+            if print_level == 3:
+                print_observation_table(observation_table, 'det')
+
+            eq_query_start = time.time()
+            cex = eq_oracle.find_cex(hypothesis)
+            eq_query_time += time.time() - eq_query_start
+
+        # If no counterexample is found, return the hypothesis
+        if cex is None:
+            break
+
+        # make sure counterexample is a tuple in case oracle returns a list
+        cex = tuple(cex)
+
+        if print_level == 3:
+            print('Counterexample', cex)
+
+        # Process counterexample and ask membership queries
+        if not cex_processing:
+            s_to_update = []
+            added_rows = extend_set(observation_table.S, all_prefixes(cex))
+            s_to_update.extend(added_rows)
+            for p in added_rows:
+                s_to_update.extend([p + (a,) for a in alphabet])
+
+            observation_table.update_obs_table(s_set=s_to_update)
+            continue
+
+        elif cex_processing == 'longest_prefix':
+            cex_suffixes = longest_prefix_cex_processing(observation_table.S + list(observation_table.s_dot_a()),
+                                                         cex, closedness='suffix')
+        elif cex_processing == 'rs':
+            cex_suffixes = rs_cex_processing(sul, cex, hypothesis, e_set_suffix_closed, closedness='suffix')
+        else:
+            direction = cex_processing[-3:]
+            if 'linear' in cex_processing:
+                cex_suffixes = linear_cex_processing(sul, cex, hypothesis, e_set_suffix_closed,
+                                                     direction=direction, closedness='suffix')
+            else:
+                cex_suffixes = exponential_cex_processing(sul, cex, hypothesis, e_set_suffix_closed,
+                                                          direction=direction, closedness='suffix')
+
+        added_suffixes = extend_set(observation_table.E, cex_suffixes)
+        observation_table.update_obs_table(e_set=added_suffixes)
+
+    total_time = round(time.time() - start_time, 2)
+    eq_query_time = round(eq_query_time, 2)
+    learning_time = round(total_time - eq_query_time, 2)
+
+    info = {
+        'learning_rounds': learning_rounds,
+        'automaton_size': hypothesis.size,
+        'queries_learning': sul.num_queries,
+        'steps_learning': sul.num_steps,
+        'queries_eq_oracle': eq_oracle.num_queries,
+        'steps_eq_oracle': eq_oracle.num_steps,
+        'learning_time': learning_time,
+        'eq_oracle_time': eq_query_time,
+        'total_time': total_time,
+        'characterization_set': observation_table.E
+    }
+    if cache_and_non_det_check:
+        info['cache_saved'] = sul.num_cached_queries
+
+    if print_level > 0:
+        print_learning_info(info)
+
+    if return_data:
+        return hypothesis, info
+
+    return hypothesis
```

## aalpy/learning_algs/deterministic/ObservationTable.py

 * *Ordering differences only*

```diff
@@ -1,219 +1,219 @@
-from collections import defaultdict
-
-from aalpy.base import Automaton, SUL
-from aalpy.automata import Dfa, DfaState, MealyState, MealyMachine, MooreMachine, MooreState
-
-aut_type = ['dfa', 'mealy', 'moore']
-closing_options = ['shortest_first', 'longest_first', 'single', 'single_longest']
-
-
-class ObservationTable:
-    def __init__(self, alphabet: list, sul: SUL, automaton_type, prefixes_in_cell=False):
-        """
-        Constructor of the observation table. Initial queries are asked in the constructor.
-
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-            automaton_type: automaton type, one of ['dfa', 'mealy', 'moore']
-
-        Returns:
-
-        """
-        assert automaton_type in aut_type
-        assert alphabet is not None and sul is not None
-        self.automaton_type = automaton_type
-
-        # If True add prefixes of each element of E set to a cell, else only add the output
-        self.prefixes_in_cell = prefixes_in_cell
-
-        self.A = [tuple([a]) for a in alphabet]
-        self.S = list()  # prefixes of S
-        # DFA's can also take whole alphabet in E, this convention follows Angluin's paper
-        self.E = [] if self.automaton_type != 'mealy' else [tuple([a]) for a in alphabet]
-        # For performance reasons, the T function maps S to a tuple where element at index i is the element of the E
-        # set of index i. Therefore it is important to keep E set ordered and ask membership queries only when needed
-        # and in correct order. It would make more sense to implement it as a defaultdict(dict) where you can access
-        # elements via self.T[s][e], but it causes significant performance hit.
-        self.T = defaultdict(tuple)
-
-        self.sul = sul
-        empty_word = tuple()
-        self.S.append(empty_word)
-
-        # DFAs and Moore machines use empty word for identification of accepting states/state outputs
-        if self.automaton_type == 'dfa' or self.automaton_type == 'moore':
-            self.E.insert(0, empty_word)
-
-    def get_rows_to_close(self, closing_strategy='longest_first'):
-        """
-        Get rows for that need to be closed. Row selection is done according to closing_strategy.
-        The length of the row is defined by the length of the prefix corresponding to the row in the S set.
-        longest_first -> get all rows that need to be closed and ask membership queries for the longest row first
-        shortest_first -> get all rows that need to be closed and ask membership queries for the shortest row first
-        single -> find and ask membership query for the single row
-        single_longest -> returns single longest row to close
-
-        Args:
-
-            closing_strategy: one of ['shortest_first', 'longest_first', 'single'] (Default value = 'longest_first')
-
-        Returns:
-
-            list if non-closed exist, None otherwise: rows that will be moved to S set and closed
-
-        """
-        assert closing_strategy in closing_options
-        rows_to_close = []
-        row_values = set()
-
-        s_rows = {self.T[s] for s in self.S}
-
-        for t in self.s_dot_a():
-            row_t = self.T[t]
-            if row_t not in s_rows and row_t not in row_values:
-                rows_to_close.append(t)
-                row_values.add(row_t)
-
-                if closing_strategy == 'single':
-                    return rows_to_close
-
-        if not rows_to_close:
-            return None
-
-        if 'longest' in closing_strategy:
-            rows_to_close.sort(key=len, reverse=True)
-            if closing_strategy == 'longest_first':
-                return rows_to_close
-            if closing_strategy == 'single_longest':
-                return [rows_to_close[0]]
-
-        return rows_to_close
-
-    def get_causes_of_inconsistency(self):
-        """
-        If the two rows in the S set are the same, but their one letter extensions are not, this method founds
-        the cause of inconsistency and returns it.
-        :return:
-
-        Returns:
-
-            a+e values that are the causes of inconsistency
-
-        """
-        for i, s1 in enumerate(self.S):
-            for s2 in self.S[i + 1:]:
-                if self.T[s1] == self.T[s2]:
-                    for a in self.A:
-                        if self.T[s1 + a] != self.T[s2 + a]:
-                            for index, e in enumerate(self.E):
-                                if self.T[s1 + a][index] != self.T[s2 + a][index]:
-                                    return [(a + e)]
-
-        return None
-
-    def s_dot_a(self):
-        """
-        Helper generator function that returns extended S, or S.A set.
-        """
-        s_set = set(self.S)
-        for s in self.S:
-            for a in self.A:
-                if s + a not in s_set:
-                    yield s + a
-
-    def update_obs_table(self, s_set: list = None, e_set: list = None):
-        """
-        Perform the membership queries.
-
-        Args:
-
-            s_set: Prefixes of S set on which to preform membership queries. If None, then whole S set will be used.
-
-            e_set: Suffixes of E set on which to perform membership queries. If None, then whole E set will be used.
-
-        Returns:
-
-        """
-
-        update_S = s_set if s_set else list(self.S) + list(self.s_dot_a())
-        update_E = e_set if e_set else self.E
-
-        # This could save few queries
-        update_S.reverse()
-
-        for s in update_S:
-            for e in update_E:
-                if len(self.T[s]) != len(self.E):
-                    output = tuple(self.sul.query(s + e))
-                    if self.prefixes_in_cell and len(e) > 1:
-                        obs_table_entry = tuple([output[-len(e):]],)
-                    else:
-                        obs_table_entry = (output[-1],)
-                    self.T[s] += obs_table_entry
-
-    def gen_hypothesis(self, no_cex_processing_used=False) -> Automaton:
-        """
-        Generate automaton based on the values found in the observation table.
-        :return:
-
-        Args:
-
-            check_for_duplicate_rows:  (Default value = False)
-
-        Returns:
-
-            Automaton of type `automaton_type`
-
-        """
-        state_distinguish = dict()
-        states_dict = dict()
-        initial_state = None
-        automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
-
-        s_set = self.S
-        # Added check for the algorithm without counterexample processing
-        if no_cex_processing_used:
-            s_set = self._get_row_representatives()
-
-        # create states based on S set
-        stateCounter = 0
-        for prefix in s_set:
-            state_id = f's{stateCounter}'
-
-            if self.automaton_type == 'dfa':
-                states_dict[prefix] = DfaState(state_id)
-                states_dict[prefix].is_accepting = self.T[prefix][0]
-            elif self.automaton_type == 'moore':
-                states_dict[prefix] = MooreState(state_id, output=self.T[prefix][0])
-            else:
-                states_dict[prefix] = MealyState(state_id)
-
-            states_dict[prefix].prefix = prefix
-            state_distinguish[tuple(self.T[prefix])] = states_dict[prefix]
-
-            if not prefix:
-                initial_state = states_dict[prefix]
-            stateCounter += 1
-
-        # add transitions based on extended S set
-        for prefix in s_set:
-            for a in self.A:
-                state_in_S = state_distinguish[self.T[prefix + a]]
-                states_dict[prefix].transitions[a[0]] = state_in_S
-                if self.automaton_type == 'mealy':
-                    states_dict[prefix].output_fun[a[0]] = self.T[prefix][self.E.index(a)]
-
-        automaton = automaton_class[self.automaton_type](initial_state, list(states_dict.values()))
-        automaton.characterization_set = self.E
-
-        return automaton
-
-    def _get_row_representatives(self):
-        self.S.sort(key=len)
-        representatives = defaultdict(list)
-        for prefix in self.S:
-            representatives[self.T[prefix]].append(prefix)
-
-        return [r[0] for r in representatives.values()]
+from collections import defaultdict
+
+from aalpy.base import Automaton, SUL
+from aalpy.automata import Dfa, DfaState, MealyState, MealyMachine, MooreMachine, MooreState
+
+aut_type = ['dfa', 'mealy', 'moore']
+closing_options = ['shortest_first', 'longest_first', 'single', 'single_longest']
+
+
+class ObservationTable:
+    def __init__(self, alphabet: list, sul: SUL, automaton_type, prefixes_in_cell=False):
+        """
+        Constructor of the observation table. Initial queries are asked in the constructor.
+
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+            automaton_type: automaton type, one of ['dfa', 'mealy', 'moore']
+
+        Returns:
+
+        """
+        assert automaton_type in aut_type
+        assert alphabet is not None and sul is not None
+        self.automaton_type = automaton_type
+
+        # If True add prefixes of each element of E set to a cell, else only add the output
+        self.prefixes_in_cell = prefixes_in_cell
+
+        self.A = [tuple([a]) for a in alphabet]
+        self.S = list()  # prefixes of S
+        # DFA's can also take whole alphabet in E, this convention follows Angluin's paper
+        self.E = [] if self.automaton_type != 'mealy' else [tuple([a]) for a in alphabet]
+        # For performance reasons, the T function maps S to a tuple where element at index i is the element of the E
+        # set of index i. Therefore it is important to keep E set ordered and ask membership queries only when needed
+        # and in correct order. It would make more sense to implement it as a defaultdict(dict) where you can access
+        # elements via self.T[s][e], but it causes significant performance hit.
+        self.T = defaultdict(tuple)
+
+        self.sul = sul
+        empty_word = tuple()
+        self.S.append(empty_word)
+
+        # DFAs and Moore machines use empty word for identification of accepting states/state outputs
+        if self.automaton_type == 'dfa' or self.automaton_type == 'moore':
+            self.E.insert(0, empty_word)
+
+    def get_rows_to_close(self, closing_strategy='longest_first'):
+        """
+        Get rows for that need to be closed. Row selection is done according to closing_strategy.
+        The length of the row is defined by the length of the prefix corresponding to the row in the S set.
+        longest_first -> get all rows that need to be closed and ask membership queries for the longest row first
+        shortest_first -> get all rows that need to be closed and ask membership queries for the shortest row first
+        single -> find and ask membership query for the single row
+        single_longest -> returns single longest row to close
+
+        Args:
+
+            closing_strategy: one of ['shortest_first', 'longest_first', 'single'] (Default value = 'longest_first')
+
+        Returns:
+
+            list if non-closed exist, None otherwise: rows that will be moved to S set and closed
+
+        """
+        assert closing_strategy in closing_options
+        rows_to_close = []
+        row_values = set()
+
+        s_rows = {self.T[s] for s in self.S}
+
+        for t in self.s_dot_a():
+            row_t = self.T[t]
+            if row_t not in s_rows and row_t not in row_values:
+                rows_to_close.append(t)
+                row_values.add(row_t)
+
+                if closing_strategy == 'single':
+                    return rows_to_close
+
+        if not rows_to_close:
+            return None
+
+        if 'longest' in closing_strategy:
+            rows_to_close.sort(key=len, reverse=True)
+            if closing_strategy == 'longest_first':
+                return rows_to_close
+            if closing_strategy == 'single_longest':
+                return [rows_to_close[0]]
+
+        return rows_to_close
+
+    def get_causes_of_inconsistency(self):
+        """
+        If the two rows in the S set are the same, but their one letter extensions are not, this method founds
+        the cause of inconsistency and returns it.
+        :return:
+
+        Returns:
+
+            a+e values that are the causes of inconsistency
+
+        """
+        for i, s1 in enumerate(self.S):
+            for s2 in self.S[i + 1:]:
+                if self.T[s1] == self.T[s2]:
+                    for a in self.A:
+                        if self.T[s1 + a] != self.T[s2 + a]:
+                            for index, e in enumerate(self.E):
+                                if self.T[s1 + a][index] != self.T[s2 + a][index]:
+                                    return [(a + e)]
+
+        return None
+
+    def s_dot_a(self):
+        """
+        Helper generator function that returns extended S, or S.A set.
+        """
+        s_set = set(self.S)
+        for s in self.S:
+            for a in self.A:
+                if s + a not in s_set:
+                    yield s + a
+
+    def update_obs_table(self, s_set: list = None, e_set: list = None):
+        """
+        Perform the membership queries.
+
+        Args:
+
+            s_set: Prefixes of S set on which to preform membership queries. If None, then whole S set will be used.
+
+            e_set: Suffixes of E set on which to perform membership queries. If None, then whole E set will be used.
+
+        Returns:
+
+        """
+
+        update_S = s_set if s_set else list(self.S) + list(self.s_dot_a())
+        update_E = e_set if e_set else self.E
+
+        # This could save few queries
+        update_S.reverse()
+
+        for s in update_S:
+            for e in update_E:
+                if len(self.T[s]) != len(self.E):
+                    output = tuple(self.sul.query(s + e))
+                    if self.prefixes_in_cell and len(e) > 1:
+                        obs_table_entry = tuple([output[-len(e):]],)
+                    else:
+                        obs_table_entry = (output[-1],)
+                    self.T[s] += obs_table_entry
+
+    def gen_hypothesis(self, no_cex_processing_used=False) -> Automaton:
+        """
+        Generate automaton based on the values found in the observation table.
+        :return:
+
+        Args:
+
+            check_for_duplicate_rows:  (Default value = False)
+
+        Returns:
+
+            Automaton of type `automaton_type`
+
+        """
+        state_distinguish = dict()
+        states_dict = dict()
+        initial_state = None
+        automaton_class = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
+
+        s_set = self.S
+        # Added check for the algorithm without counterexample processing
+        if no_cex_processing_used:
+            s_set = self._get_row_representatives()
+
+        # create states based on S set
+        stateCounter = 0
+        for prefix in s_set:
+            state_id = f's{stateCounter}'
+
+            if self.automaton_type == 'dfa':
+                states_dict[prefix] = DfaState(state_id)
+                states_dict[prefix].is_accepting = self.T[prefix][0]
+            elif self.automaton_type == 'moore':
+                states_dict[prefix] = MooreState(state_id, output=self.T[prefix][0])
+            else:
+                states_dict[prefix] = MealyState(state_id)
+
+            states_dict[prefix].prefix = prefix
+            state_distinguish[tuple(self.T[prefix])] = states_dict[prefix]
+
+            if not prefix:
+                initial_state = states_dict[prefix]
+            stateCounter += 1
+
+        # add transitions based on extended S set
+        for prefix in s_set:
+            for a in self.A:
+                state_in_S = state_distinguish[self.T[prefix + a]]
+                states_dict[prefix].transitions[a[0]] = state_in_S
+                if self.automaton_type == 'mealy':
+                    states_dict[prefix].output_fun[a[0]] = self.T[prefix][self.E.index(a)]
+
+        automaton = automaton_class[self.automaton_type](initial_state, list(states_dict.values()))
+        automaton.characterization_set = self.E
+
+        return automaton
+
+    def _get_row_representatives(self):
+        self.S.sort(key=len)
+        representatives = defaultdict(list)
+        for prefix in self.S:
+            representatives[self.T[prefix]].append(prefix)
+
+        return [r[0] for r in representatives.values()]
```

## aalpy/learning_algs/deterministic_passive/GeneralizedStateMerging.py

 * *Ordering differences only*

```diff
@@ -1,106 +1,106 @@
-import queue
-import time
-
-from aalpy.learning_algs.deterministic_passive.rpni_helper_functions import to_automaton, RpniNode, createPTA
-
-
-class GeneralizedStateMerging:
-    def __init__(self, data, automaton_type, print_info=True):
-        self.data = data
-        self.final_automaton_type = automaton_type
-        self.automaton_type = automaton_type if automaton_type != 'dfa' else 'moore'
-        self.print_info = print_info
-
-        pta_construction_start = time.time()
-        self.root = createPTA(data, self.automaton_type)
-        self.log = []
-
-        if self.print_info:
-            print(f'PTA Construction Time: {round(time.time() - pta_construction_start, 2)}')
-
-    def run_rpni(self):
-        start_time = time.time()
-
-        # sorted list of states already considered
-        red_states = [self.root]
-        # used to get the minimal non-red state
-        blue_states = list(red_states[0].children.values())
-
-        while blue_states:
-            blue_state = min(list(blue_states))
-
-            partition = None
-            for red_state in red_states:
-                partition = self._partition_from_merge(red_state, blue_state)
-                if partition is not None:
-                    break
-
-            if partition is None:
-                self.log.append(["promote", (blue_state.prefix,)])
-                red_states.append(blue_state)
-                if self.print_info:
-                    print(f'\rCurrent automaton size: {len(red_states)}', end="")
-            else:
-                self.log.append(["merge", (red_state.prefix, blue_state.prefix)])
-
-                # use the partition for merging
-                for node in partition.keys():
-                    block = partition[node]
-                    # assert RpniNode.compatible(node, block)
-                    node.output = block.output
-                    node.children = block.children
-
-                node = self.root.get_child_by_prefix(blue_state.prefix[:-1])
-                node.children[blue_state.prefix[-1]] = red_state
-
-            blue_states.clear()
-            for r in red_states:
-                for c in r.children.values():
-                    if c not in red_states:
-                        blue_states.append(c)
-
-        if self.print_info:
-            print(f'\nRPNI-GSM Learning Time: {round(time.time() - start_time, 2)}')
-            print(f'RPNI-GSM Learned {len(red_states)} state automaton.')
-
-        return to_automaton(red_states, self.final_automaton_type)
-
-    def _partition_from_merge(self, red: RpniNode, blue: RpniNode):
-        """
-        Compatibility check based on partitions
-        """
-
-        partitions = dict()
-        q = queue.Queue()
-        q.put((red, blue))
-
-        while not q.empty():
-            red, blue = q.get()
-
-            def get_partition(node: RpniNode):
-                if node not in partitions:
-                    p = node.shallow_copy()
-                    partitions[node] = p
-                else:
-                    p = partitions[node]
-                return p
-
-            partition = get_partition(red)
-
-            if not RpniNode.compatible_outputs(partition, blue):
-                return None
-            if self.automaton_type == 'moore' and partition.output is None:
-                partition.output = blue.output
-            if self.automaton_type == 'mealy':
-                for key in filter(lambda k: k not in partition.output or partition.output[k] is None, blue.output):
-                    partition.output[key] = blue.output[key]
-
-            partitions[blue] = partition
-
-            for symbol, blue_child in blue.children.items():
-                if symbol in partition.children.keys():
-                    q.put((partition.children[symbol], blue_child))
-                else:
-                    # blue_child is blue after merging if there is a red state in the partition
-                    partition.children[symbol] = blue_child
-        return partitions
+import queue
+import time
+
+from aalpy.learning_algs.deterministic_passive.rpni_helper_functions import to_automaton, RpniNode, createPTA
+
+
+class GeneralizedStateMerging:
+    def __init__(self, data, automaton_type, print_info=True):
+        self.data = data
+        self.final_automaton_type = automaton_type
+        self.automaton_type = automaton_type if automaton_type != 'dfa' else 'moore'
+        self.print_info = print_info
+
+        pta_construction_start = time.time()
+        self.root = createPTA(data, self.automaton_type)
+        self.log = []
+
+        if self.print_info:
+            print(f'PTA Construction Time: {round(time.time() - pta_construction_start, 2)}')
+
+    def run_rpni(self):
+        start_time = time.time()
+
+        # sorted list of states already considered
+        red_states = [self.root]
+        # used to get the minimal non-red state
+        blue_states = list(red_states[0].children.values())
+
+        while blue_states:
+            blue_state = min(list(blue_states))
+
+            partition = None
+            for red_state in red_states:
+                partition = self._partition_from_merge(red_state, blue_state)
+                if partition is not None:
+                    break
+
+            if partition is None:
+                self.log.append(["promote", (blue_state.prefix,)])
+                red_states.append(blue_state)
+                if self.print_info:
+                    print(f'\rCurrent automaton size: {len(red_states)}', end="")
+            else:
+                self.log.append(["merge", (red_state.prefix, blue_state.prefix)])
+
+                # use the partition for merging
+                for node in partition.keys():
+                    block = partition[node]
+                    # assert RpniNode.compatible(node, block)
+                    node.output = block.output
+                    node.children = block.children
+
+                node = self.root.get_child_by_prefix(blue_state.prefix[:-1])
+                node.children[blue_state.prefix[-1]] = red_state
+
+            blue_states.clear()
+            for r in red_states:
+                for c in r.children.values():
+                    if c not in red_states:
+                        blue_states.append(c)
+
+        if self.print_info:
+            print(f'\nRPNI-GSM Learning Time: {round(time.time() - start_time, 2)}')
+            print(f'RPNI-GSM Learned {len(red_states)} state automaton.')
+
+        return to_automaton(red_states, self.final_automaton_type)
+
+    def _partition_from_merge(self, red: RpniNode, blue: RpniNode):
+        """
+        Compatibility check based on partitions
+        """
+
+        partitions = dict()
+        q = queue.Queue()
+        q.put((red, blue))
+
+        while not q.empty():
+            red, blue = q.get()
+
+            def get_partition(node: RpniNode):
+                if node not in partitions:
+                    p = node.shallow_copy()
+                    partitions[node] = p
+                else:
+                    p = partitions[node]
+                return p
+
+            partition = get_partition(red)
+
+            if not RpniNode.compatible_outputs(partition, blue):
+                return None
+            if self.automaton_type == 'moore' and partition.output is None:
+                partition.output = blue.output
+            if self.automaton_type == 'mealy':
+                for key in filter(lambda k: k not in partition.output or partition.output[k] is None, blue.output):
+                    partition.output[key] = blue.output[key]
+
+            partitions[blue] = partition
+
+            for symbol, blue_child in blue.children.items():
+                if symbol in partition.children.keys():
+                    q.put((partition.children[symbol], blue_child))
+                else:
+                    # blue_child is blue after merging if there is a red state in the partition
+                    partition.children[symbol] = blue_child
+        return partitions
```

## aalpy/learning_algs/deterministic_passive/RPNI.py

 * *Ordering differences only*

```diff
@@ -1,188 +1,188 @@
-import time
-from bisect import insort
-from typing import Union
-
-from aalpy.base import DeterministicAutomaton
-from aalpy.learning_algs.deterministic_passive.GeneralizedStateMerging import GeneralizedStateMerging
-from aalpy.learning_algs.deterministic_passive.rpni_helper_functions import to_automaton, createPTA, \
-    check_sequence, extract_unique_sequences
-
-
-class RPNI:
-    def __init__(self, data, automaton_type, print_info=True):
-        self.data = data
-        self.automaton_type = automaton_type
-        self.print_info = print_info
-
-        pta_construction_start = time.time()
-        self.root_node = createPTA(data, automaton_type)
-        self.test_data = extract_unique_sequences(self.root_node)
-
-        if self.print_info:
-            print(f'PTA Construction Time: {round(time.time() - pta_construction_start, 2)}')
-
-    def run_rpni(self):
-        start_time = time.time()
-
-        red = [self.root_node]
-        blue = list(red[0].children.values())
-        while blue:
-            lex_min_blue = min(list(blue))
-            merged = False
-
-            for red_state in red:
-                if not self._compatible_states(red_state, lex_min_blue):
-                    continue
-                merge_candidate = self._merge(red_state, lex_min_blue, copy_nodes=True)
-                if self._compatible(merge_candidate):
-                    self._merge(red_state, lex_min_blue)
-                    merged = True
-                    break
-
-            if not merged:
-                insort(red, lex_min_blue)
-                if self.print_info:
-                    print(f'\rCurrent automaton size: {len(red)}', end="")
-
-            blue.clear()
-            for r in red:
-                for c in r.children.values():
-                    if c not in red:
-                        blue.append(c)
-
-        if self.print_info:
-            print(f'\nRPNI Learning Time: {round(time.time() - start_time, 2)}')
-            print(f'RPNI Learned {len(red)} state automaton.')
-
-        assert sorted(red, key=lambda x: len(x.prefix)) == red
-        return to_automaton(red, self.automaton_type)
-
-    def _compatible(self, root_node):
-        """
-        Check if current model is compatible with the data.
-        """
-        for sequence in self.test_data:
-            if not check_sequence(root_node, sequence, automaton_type=self.automaton_type):
-                return False
-        return True
-
-    def _compatible_states(self, red_node, blue_node):
-        """
-        Only allow merging of states that have same output(s).
-        """
-        if self.automaton_type != 'mealy':
-            # None is compatible with everything
-            return red_node.output == blue_node.output or red_node.output is None or blue_node.output is None
-        else:
-            red_io = {i: o for i, o in red_node.children.keys()}
-            blue_io = {i: o for i, o in blue_node.children.keys()}
-            for common_i in set(red_io.keys()).intersection(blue_io.keys()):
-                if red_io[common_i] != blue_io[common_i]:
-                    return False
-        return True
-
-    def _merge(self, red_node, lex_min_blue, copy_nodes=False):
-        """
-        Merge two states and return the root node of resulting model.
-        """
-        root_node = self.root_node.copy() if copy_nodes else self.root_node
-        lex_min_blue = lex_min_blue.copy() if copy_nodes else lex_min_blue
-
-        red_node_in_tree = root_node
-        for p in red_node.prefix:
-            red_node_in_tree = red_node_in_tree.children[p]
-
-        to_update = root_node
-        for p in lex_min_blue.prefix[:-1]:
-            to_update = to_update.children[p]
-
-        to_update.children[lex_min_blue.prefix[-1]] = red_node_in_tree
-
-        if self.automaton_type != 'mealy':
-            self._fold(red_node_in_tree, lex_min_blue)
-        else:
-            self._fold_mealy(red_node_in_tree, lex_min_blue)
-
-        return root_node
-
-    def _fold(self, red_node, blue_node):
-        # Change the output of red only to concrete output, ignore None
-        red_node.output = blue_node.output if blue_node.output is not None else red_node.output
-
-        for i in blue_node.children.keys():
-            if i in red_node.children.keys():
-                self._fold(red_node.children[i], blue_node.children[i])
-            else:
-                red_node.children[i] = blue_node.children[i]
-
-    def _fold_mealy(self, red_node, blue_node):
-        blue_io_map = {i: o for i, o in blue_node.children.keys()}
-
-        updated_keys = {}
-        for io, val in red_node.children.items():
-            o = blue_io_map[io[0]] if io[0] in blue_io_map.keys() else io[1]
-            updated_keys[(io[0], o)] = val
-
-        red_node.children = updated_keys
-
-        for io in blue_node.children.keys():
-            if io in red_node.children.keys():
-                self._fold_mealy(red_node.children[io], blue_node.children[io])
-            else:
-                red_node.children[io] = blue_node.children[io]
-
-
-def run_RPNI(data, automaton_type, algorithm='gsm',
-             input_completeness=None, print_info=True) -> Union[DeterministicAutomaton, None]:
-    """
-    Run RPNI, a deterministic passive model learning algorithm.
-    Resulting model conforms to the provided data.
-    For more information on RPNI, check out AALpy' Wiki:
-    https://github.com/DES-Lab/AALpy/wiki/RPNI---Passive-Deterministic-Automata-Learning
-
-    Args:
-
-        data: sequence of input sequences and corresponding label. Eg. [[(i1,i2,i3, ...), label], ...]
-        automaton_type: either 'dfa', 'mealy', 'moore'. Note that for 'mealy' machine learning, data has to be prefix-closed.
-        algorithm: either 'gsm' (generalized state merging) or 'classic' for base RPNI implementation. GSM is much faster and less resource intensive.
-        input_completeness: either None, 'sink_state', or 'self_loop'. If None, learned model could be input incomplete,
-        sink_state will lead all undefined inputs form some state to the sink state, whereas self_loop will simply create
-        a self loop. In case of Mealy learning output of the added transition will be 'epsilon'.
-        print_info: print learning progress and runtime information
-
-    Returns:
-
-        Model conforming to the data, or None if data is non-deterministic.
-    """
-    assert algorithm in {'gsm', 'classic'}
-    assert automaton_type in {'dfa', 'mealy', 'moore'}
-    assert input_completeness in {None, 'self_loop', 'sink_state'}
-
-    if algorithm == 'classic':
-        rpni = RPNI(data, automaton_type, print_info)
-
-        if rpni.root_node is None:
-            print('Data provided to RPNI is not deterministic. Ensure that the data is deterministic, '
-                  'or consider using Alergia.')
-            return None
-    else:
-        rpni = GeneralizedStateMerging(data, automaton_type, print_info)
-
-        if rpni.root is None:
-            print('Data provided to RPNI is not deterministic. Ensure that the data is deterministic, '
-                  'or consider using Alergia.')
-            return None
-
-    learned_model = rpni.run_rpni()
-
-    if not learned_model.is_input_complete():
-        if not input_completeness:
-            if print_info:
-                print('Warning: Learned Model is not input complete (inputs not defined for all states). '
-                      'Consider calling .make_input_complete()')
-        else:
-            if print_info:
-                print(f'Learned model was not input complete. Adapting it with {input_completeness} transitions.')
-            learned_model.make_input_complete(input_completeness)
-
-    return learned_model
+import time
+from bisect import insort
+from typing import Union
+
+from aalpy.base import DeterministicAutomaton
+from aalpy.learning_algs.deterministic_passive.GeneralizedStateMerging import GeneralizedStateMerging
+from aalpy.learning_algs.deterministic_passive.rpni_helper_functions import to_automaton, createPTA, \
+    check_sequence, extract_unique_sequences
+
+
+class RPNI:
+    def __init__(self, data, automaton_type, print_info=True):
+        self.data = data
+        self.automaton_type = automaton_type
+        self.print_info = print_info
+
+        pta_construction_start = time.time()
+        self.root_node = createPTA(data, automaton_type)
+        self.test_data = extract_unique_sequences(self.root_node)
+
+        if self.print_info:
+            print(f'PTA Construction Time: {round(time.time() - pta_construction_start, 2)}')
+
+    def run_rpni(self):
+        start_time = time.time()
+
+        red = [self.root_node]
+        blue = list(red[0].children.values())
+        while blue:
+            lex_min_blue = min(list(blue))
+            merged = False
+
+            for red_state in red:
+                if not self._compatible_states(red_state, lex_min_blue):
+                    continue
+                merge_candidate = self._merge(red_state, lex_min_blue, copy_nodes=True)
+                if self._compatible(merge_candidate):
+                    self._merge(red_state, lex_min_blue)
+                    merged = True
+                    break
+
+            if not merged:
+                insort(red, lex_min_blue)
+                if self.print_info:
+                    print(f'\rCurrent automaton size: {len(red)}', end="")
+
+            blue.clear()
+            for r in red:
+                for c in r.children.values():
+                    if c not in red:
+                        blue.append(c)
+
+        if self.print_info:
+            print(f'\nRPNI Learning Time: {round(time.time() - start_time, 2)}')
+            print(f'RPNI Learned {len(red)} state automaton.')
+
+        assert sorted(red, key=lambda x: len(x.prefix)) == red
+        return to_automaton(red, self.automaton_type)
+
+    def _compatible(self, root_node):
+        """
+        Check if current model is compatible with the data.
+        """
+        for sequence in self.test_data:
+            if not check_sequence(root_node, sequence, automaton_type=self.automaton_type):
+                return False
+        return True
+
+    def _compatible_states(self, red_node, blue_node):
+        """
+        Only allow merging of states that have same output(s).
+        """
+        if self.automaton_type != 'mealy':
+            # None is compatible with everything
+            return red_node.output == blue_node.output or red_node.output is None or blue_node.output is None
+        else:
+            red_io = {i: o for i, o in red_node.children.keys()}
+            blue_io = {i: o for i, o in blue_node.children.keys()}
+            for common_i in set(red_io.keys()).intersection(blue_io.keys()):
+                if red_io[common_i] != blue_io[common_i]:
+                    return False
+        return True
+
+    def _merge(self, red_node, lex_min_blue, copy_nodes=False):
+        """
+        Merge two states and return the root node of resulting model.
+        """
+        root_node = self.root_node.copy() if copy_nodes else self.root_node
+        lex_min_blue = lex_min_blue.copy() if copy_nodes else lex_min_blue
+
+        red_node_in_tree = root_node
+        for p in red_node.prefix:
+            red_node_in_tree = red_node_in_tree.children[p]
+
+        to_update = root_node
+        for p in lex_min_blue.prefix[:-1]:
+            to_update = to_update.children[p]
+
+        to_update.children[lex_min_blue.prefix[-1]] = red_node_in_tree
+
+        if self.automaton_type != 'mealy':
+            self._fold(red_node_in_tree, lex_min_blue)
+        else:
+            self._fold_mealy(red_node_in_tree, lex_min_blue)
+
+        return root_node
+
+    def _fold(self, red_node, blue_node):
+        # Change the output of red only to concrete output, ignore None
+        red_node.output = blue_node.output if blue_node.output is not None else red_node.output
+
+        for i in blue_node.children.keys():
+            if i in red_node.children.keys():
+                self._fold(red_node.children[i], blue_node.children[i])
+            else:
+                red_node.children[i] = blue_node.children[i]
+
+    def _fold_mealy(self, red_node, blue_node):
+        blue_io_map = {i: o for i, o in blue_node.children.keys()}
+
+        updated_keys = {}
+        for io, val in red_node.children.items():
+            o = blue_io_map[io[0]] if io[0] in blue_io_map.keys() else io[1]
+            updated_keys[(io[0], o)] = val
+
+        red_node.children = updated_keys
+
+        for io in blue_node.children.keys():
+            if io in red_node.children.keys():
+                self._fold_mealy(red_node.children[io], blue_node.children[io])
+            else:
+                red_node.children[io] = blue_node.children[io]
+
+
+def run_RPNI(data, automaton_type, algorithm='gsm',
+             input_completeness=None, print_info=True) -> Union[DeterministicAutomaton, None]:
+    """
+    Run RPNI, a deterministic passive model learning algorithm.
+    Resulting model conforms to the provided data.
+    For more information on RPNI, check out AALpy' Wiki:
+    https://github.com/DES-Lab/AALpy/wiki/RPNI---Passive-Deterministic-Automata-Learning
+
+    Args:
+
+        data: sequence of input sequences and corresponding label. Eg. [[(i1,i2,i3, ...), label], ...]
+        automaton_type: either 'dfa', 'mealy', 'moore'. Note that for 'mealy' machine learning, data has to be prefix-closed.
+        algorithm: either 'gsm' (generalized state merging) or 'classic' for base RPNI implementation. GSM is much faster and less resource intensive.
+        input_completeness: either None, 'sink_state', or 'self_loop'. If None, learned model could be input incomplete,
+        sink_state will lead all undefined inputs form some state to the sink state, whereas self_loop will simply create
+        a self loop. In case of Mealy learning output of the added transition will be 'epsilon'.
+        print_info: print learning progress and runtime information
+
+    Returns:
+
+        Model conforming to the data, or None if data is non-deterministic.
+    """
+    assert algorithm in {'gsm', 'classic'}
+    assert automaton_type in {'dfa', 'mealy', 'moore'}
+    assert input_completeness in {None, 'self_loop', 'sink_state'}
+
+    if algorithm == 'classic':
+        rpni = RPNI(data, automaton_type, print_info)
+
+        if rpni.root_node is None:
+            print('Data provided to RPNI is not deterministic. Ensure that the data is deterministic, '
+                  'or consider using Alergia.')
+            return None
+    else:
+        rpni = GeneralizedStateMerging(data, automaton_type, print_info)
+
+        if rpni.root is None:
+            print('Data provided to RPNI is not deterministic. Ensure that the data is deterministic, '
+                  'or consider using Alergia.')
+            return None
+
+    learned_model = rpni.run_rpni()
+
+    if not learned_model.is_input_complete():
+        if not input_completeness:
+            if print_info:
+                print('Warning: Learned Model is not input complete (inputs not defined for all states). '
+                      'Consider calling .make_input_complete()')
+        else:
+            if print_info:
+                print(f'Learned model was not input complete. Adapting it with {input_completeness} transitions.')
+            learned_model.make_input_complete(input_completeness)
+
+    return learned_model
```

## aalpy/learning_algs/deterministic_passive/active_RPNI.py

 * *Ordering differences only*

```diff
@@ -1,62 +1,62 @@
-from abc import ABC, abstractmethod
-from random import randint, choice
-
-from aalpy.learning_algs import run_RPNI
-from aalpy.utils import convert_i_o_traces_for_RPNI
-
-
-class RpniActiveSampler(ABC):
-    """
-    Abstract class whose implementations are used to provide samples for active passive learning.
-    """
-
-    @abstractmethod
-    def sample(self, sul, model):
-        """
-        Abstract method implementing sampling strategy.
-
-        Args:
-
-            sul: system under learning
-            model: current learned model
-
-        Returns:
-
-            Data to be added to the data set for the passive RPNI learning in its data-format.
-
-        """
-        pass
-
-
-class RandomWordSampler(RpniActiveSampler):
-    def __init__(self, num_walks, min_walk_len, max_walk_len):
-        self.num_walks = num_walks
-        self.min_walk_len = min_walk_len
-        self.max_walk_len = max_walk_len
-
-    def sample(self, sul, model):
-        input_al = list({el for s in model.states for el in s.transitions.keys()})
-        samples = []
-
-        for _ in range(self.num_walks):
-            walk_len = randint(self.min_walk_len, self.max_walk_len)
-            random_walk = tuple(choice(input_al) for _ in range(walk_len))
-
-            outputs = sul.query(random_walk)
-            samples.append(list(zip(random_walk, outputs)))
-
-        samples = convert_i_o_traces_for_RPNI(samples)
-        return samples
-
-
-def run_active_RPNI(data, sul, sampler, n_iter, automaton_type, print_info=True):
-    model = None
-    for i in range(n_iter):
-        if print_info:
-            print(f'-------------Active RPNI Iteration: {i}-------------')
-        model = run_RPNI(data, automaton_type=automaton_type, print_info=print_info)
-
-        new_samples = sampler.sample(sul, model)
-        data.extend(new_samples)
-
-    return model
+from abc import ABC, abstractmethod
+from random import randint, choice
+
+from aalpy.learning_algs import run_RPNI
+from aalpy.utils import convert_i_o_traces_for_RPNI
+
+
+class RpniActiveSampler(ABC):
+    """
+    Abstract class whose implementations are used to provide samples for active passive learning.
+    """
+
+    @abstractmethod
+    def sample(self, sul, model):
+        """
+        Abstract method implementing sampling strategy.
+
+        Args:
+
+            sul: system under learning
+            model: current learned model
+
+        Returns:
+
+            Data to be added to the data set for the passive RPNI learning in its data-format.
+
+        """
+        pass
+
+
+class RandomWordSampler(RpniActiveSampler):
+    def __init__(self, num_walks, min_walk_len, max_walk_len):
+        self.num_walks = num_walks
+        self.min_walk_len = min_walk_len
+        self.max_walk_len = max_walk_len
+
+    def sample(self, sul, model):
+        input_al = list({el for s in model.states for el in s.transitions.keys()})
+        samples = []
+
+        for _ in range(self.num_walks):
+            walk_len = randint(self.min_walk_len, self.max_walk_len)
+            random_walk = tuple(choice(input_al) for _ in range(walk_len))
+
+            outputs = sul.query(random_walk)
+            samples.append(list(zip(random_walk, outputs)))
+
+        samples = convert_i_o_traces_for_RPNI(samples)
+        return samples
+
+
+def run_active_RPNI(data, sul, sampler, n_iter, automaton_type, print_info=True):
+    model = None
+    for i in range(n_iter):
+        if print_info:
+            print(f'-------------Active RPNI Iteration: {i}-------------')
+        model = run_RPNI(data, automaton_type=automaton_type, print_info=print_info)
+
+        new_samples = sampler.sample(sul, model)
+        data.extend(new_samples)
+
+    return model
```

## aalpy/learning_algs/deterministic_passive/rpni_helper_functions.py

 * *Ordering differences only*

```diff
@@ -1,265 +1,265 @@
-import pickle
-import queue
-from functools import total_ordering
-from typing import Set
-
-
-@total_ordering
-class RpniNode:
-    __slots__ = ['output', 'children', 'prefix', "type"]
-
-    def __init__(self, output=None, children=None, automaton_type='moore'):
-        if output is None and automaton_type == 'mealy':
-            output = dict()
-        if children is None:
-            children = dict()
-        self.output = output
-        self.children = children
-        self.prefix = ()
-        self.type = automaton_type
-
-    def shallow_copy(self):
-        output = self.output if self.type != 'mealy' else dict(self.output)
-        return RpniNode(output, dict(self.children), self.type)
-
-    def copy(self):
-        return pickle.loads(pickle.dumps(self, -1))
-
-    def __lt__(self, other):
-        return (len(self.prefix), self.prefix) < (len(other.prefix), other.prefix)
-
-    def __eq__(self, other):
-        return self.prefix == other.prefix
-
-    def __hash__(self):
-        return id(self)  # TODO This is a hack
-
-    def get_all_nodes(self) -> Set['RpniNode']:
-        qu = queue.Queue()
-        qu.put(self)
-        nodes = set()
-        while not qu.empty():
-            state = qu.get()
-            nodes.add(state)
-            for child in state.children.values():
-                if child not in nodes:
-                    qu.put(child)
-        return nodes
-
-    def to_automaton(self):
-        nodes = self.get_all_nodes()
-        nodes.remove(self)  # dunno whether order is preserved?
-        nodes = [self] + list(nodes)
-        return to_automaton(nodes, self.type)
-
-    def compatible_outputs(self, other):
-        so, oo = [self.output, other.output]
-        cmp = lambda x, y: x is None or y is None or x == y
-        if self.type == 'moore':
-            return cmp(so, oo)
-        else:
-            return all(cmp(so[key], oo[key]) for key in filter(lambda k: k in oo, so))
-
-    def get_child_by_prefix(self, prefix):
-        node = self
-        for symbol in prefix:
-            node = node.children[symbol]
-        return node
-
-
-class StateMerging:
-    def __init__(self, data, automaton_type, print_info=True):
-        self.data = data
-        self.automaton_type = automaton_type
-        self.print_info = print_info
-
-        self.root = createPTA(data, automaton_type)
-        self.merges = []
-
-    def merge(self, red_node, lex_min_blue, copy_nodes=False):
-        """
-        Merge two states and return the root node of resulting model.
-        """
-
-        if self.automaton_type == 'mealy':
-            raise NotImplementedError()
-
-        if not copy_nodes:
-            self.merges.append((red_node, lex_min_blue))
-
-        root_node = self.root.copy() if copy_nodes else self.root
-        lex_min_blue = lex_min_blue.copy() if copy_nodes else lex_min_blue
-
-        red_node_in_tree = root_node
-        for p in red_node.prefix:
-            red_node_in_tree = red_node_in_tree.children[p]
-
-        to_update = root_node
-        for p in lex_min_blue.prefix[:-1]:
-            to_update = to_update.children[p]
-
-        to_update.children[lex_min_blue.prefix[-1]] = red_node_in_tree
-
-        if not self._fold(red_node_in_tree, lex_min_blue, not copy_nodes):
-            return None
-
-        return root_node
-
-    def _fold(self, red_node, blue_node, report):
-        # Change the output of red only to concrete output, ignore None
-        if report and not RpniNode.compatible_outputs(red_node, blue_node):
-            print(f"conflict {red_node.prefix} ({red_node.output}) {blue_node.prefix} ({blue_node.output})")
-            return False
-        red_node.output = blue_node.output if blue_node.output is not None else red_node.output
-
-        for i in blue_node.children.keys():
-            if i in red_node.children.keys():
-                self._fold(red_node.children[i], blue_node.children[i], report)
-            else:
-                red_node.children[i] = blue_node.children[i]
-        return True
-
-    def to_automaton(self):
-        return self.root.to_automaton()
-
-    def replay_log(self, commands: list):
-        for command, args in commands:
-            if command == "merge":
-                self.merge(self.root.get_child_by_prefix(args[0]), self.root.get_child_by_prefix(args[1]))
-            elif command == "promote":
-                pass
-
-    @staticmethod
-    def replay_log_on_pta(data, commands: list, automaton_type):
-        sm = StateMerging(data, automaton_type)
-        sm.replay_log(commands)
-        return sm.to_automaton()
-
-
-def check_sequence(root_node, seq, automaton_type):
-    """
-    Checks whether each sequence in the dataset is valid in the current automaton.
-    """
-    curr_node = root_node
-    for i, o in seq:
-        if automaton_type == 'mealy':
-            input_outputs = {i: o for i, o in curr_node.children.keys()}
-            if i[0] not in input_outputs.keys() or o is not None and input_outputs[i[0]] != o:
-                return False
-            curr_node = curr_node.children[(i[0], input_outputs[i[0]])]
-        else:
-            # For dfa and moore, check if outputs are the same, iff output in test data is concrete (not None)
-            curr_node = curr_node.children[i]
-            if o is not None and curr_node.output != o:
-                return False
-    return True
-
-
-def createPTA(data, automaton_type):
-    data.sort(key=lambda x: len(x[0]))
-
-    root_node = RpniNode(automaton_type=automaton_type)
-    for seq, label in data:
-        curr_node = root_node
-        for idx, symbol in enumerate(seq):
-            if symbol not in curr_node.children.keys():
-                node = RpniNode(automaton_type=automaton_type)
-                node.prefix = curr_node.prefix + (symbol,)
-                curr_node.children[symbol] = node
-
-            if automaton_type == 'mealy' and idx == len(seq) - 1:
-                if symbol not in curr_node.output:
-                    curr_node.output[symbol] = label
-                if curr_node.output[symbol] != label:
-                    return None
-            curr_node = curr_node.children[symbol]
-        if automaton_type == 'moore' or automaton_type == 'dfa':
-            if curr_node.output is None:
-                curr_node.output = label
-            if curr_node.output != label:
-                return None
-
-    return root_node
-
-
-def extract_unique_sequences(root_node):
-    def get_leaf_nodes(root):
-        leaves = []
-
-        def _get_leaf_nodes(node):
-            if node is not None:
-                if len(node.children.keys()) == 0:
-                    leaves.append(node)
-                for n in node.children.values():
-                    _get_leaf_nodes(n)
-
-        _get_leaf_nodes(root)
-        return leaves
-
-    leaf_nodes = get_leaf_nodes(root_node)
-    paths = []
-    for node in leaf_nodes:
-        seq = []
-        curr_node = root_node
-        for i in node.prefix:
-            curr_node = curr_node.children[i]
-            seq.append((i, curr_node.output))
-        paths.append(seq)
-
-    return paths
-
-
-def to_automaton(red, automaton_type):
-    from aalpy.automata import DfaState, Dfa, MooreMachine, MooreState, MealyMachine, MealyState
-
-    if automaton_type == 'dfa':
-        state, automaton = DfaState, Dfa
-    elif automaton_type == 'moore':
-        state, automaton = MooreState, MooreMachine
-    else:
-        state, automaton = MealyState, MealyMachine
-
-    initial_state = None
-    prefix_state_map = {}
-    for i, r in enumerate(red):
-        if automaton_type == 'moore' or automaton_type == 'dfa':
-            prefix_state_map[r.prefix] = state(f's{i}', r.output)
-        else:
-            prefix_state_map[r.prefix] = state(f's{i}')
-        if i == 0:
-            initial_state = prefix_state_map[r.prefix]
-
-    for r in red:
-        for i, c in r.children.items():
-            if automaton_type == 'moore' or automaton_type == 'dfa':
-                prefix_state_map[r.prefix].transitions[i] = prefix_state_map[c.prefix]
-            else:
-                prefix_state_map[r.prefix].transitions[i] = prefix_state_map[c.prefix]
-                prefix_state_map[r.prefix].output_fun[i] = r.output[i] if i in r.output else None
-
-    return automaton(initial_state, list(prefix_state_map.values()))
-
-
-def visualize_pta(root_node, path='pta.pdf'):
-    from pydot import Dot, Node, Edge
-    graph = Dot('fpta', graph_type='digraph')
-
-    graph.add_node(Node(str(root_node.prefix), label=f'{root_node.output}'))
-
-    queue = [root_node]
-    visited = set()
-    visited.add(root_node.prefix)
-    while queue:
-        curr = queue.pop(0)
-        for i, c in curr.children.items():
-            if c.prefix not in visited:
-                graph.add_node(Node(str(c.prefix), label=f'{c.output}'))
-            graph.add_edge(Edge(str(curr.prefix), str(c.prefix), label=f'{i}'))
-            if c.prefix not in visited:
-                queue.append(c)
-            visited.add(c.prefix)
-
-    graph.add_node(Node('__start0', shape='none', label=''))
-    graph.add_edge(Edge('__start0', str(root_node.prefix), label=''))
-
-    graph.write(path=path, format='pdf')
+import pickle
+import queue
+from functools import total_ordering
+from typing import Set
+
+
+@total_ordering
+class RpniNode:
+    __slots__ = ['output', 'children', 'prefix', "type"]
+
+    def __init__(self, output=None, children=None, automaton_type='moore'):
+        if output is None and automaton_type == 'mealy':
+            output = dict()
+        if children is None:
+            children = dict()
+        self.output = output
+        self.children = children
+        self.prefix = ()
+        self.type = automaton_type
+
+    def shallow_copy(self):
+        output = self.output if self.type != 'mealy' else dict(self.output)
+        return RpniNode(output, dict(self.children), self.type)
+
+    def copy(self):
+        return pickle.loads(pickle.dumps(self, -1))
+
+    def __lt__(self, other):
+        return (len(self.prefix), self.prefix) < (len(other.prefix), other.prefix)
+
+    def __eq__(self, other):
+        return self.prefix == other.prefix
+
+    def __hash__(self):
+        return id(self)  # TODO This is a hack
+
+    def get_all_nodes(self) -> Set['RpniNode']:
+        qu = queue.Queue()
+        qu.put(self)
+        nodes = set()
+        while not qu.empty():
+            state = qu.get()
+            nodes.add(state)
+            for child in state.children.values():
+                if child not in nodes:
+                    qu.put(child)
+        return nodes
+
+    def to_automaton(self):
+        nodes = self.get_all_nodes()
+        nodes.remove(self)  # dunno whether order is preserved?
+        nodes = [self] + list(nodes)
+        return to_automaton(nodes, self.type)
+
+    def compatible_outputs(self, other):
+        so, oo = [self.output, other.output]
+        cmp = lambda x, y: x is None or y is None or x == y
+        if self.type == 'moore':
+            return cmp(so, oo)
+        else:
+            return all(cmp(so[key], oo[key]) for key in filter(lambda k: k in oo, so))
+
+    def get_child_by_prefix(self, prefix):
+        node = self
+        for symbol in prefix:
+            node = node.children[symbol]
+        return node
+
+
+class StateMerging:
+    def __init__(self, data, automaton_type, print_info=True):
+        self.data = data
+        self.automaton_type = automaton_type
+        self.print_info = print_info
+
+        self.root = createPTA(data, automaton_type)
+        self.merges = []
+
+    def merge(self, red_node, lex_min_blue, copy_nodes=False):
+        """
+        Merge two states and return the root node of resulting model.
+        """
+
+        if self.automaton_type == 'mealy':
+            raise NotImplementedError()
+
+        if not copy_nodes:
+            self.merges.append((red_node, lex_min_blue))
+
+        root_node = self.root.copy() if copy_nodes else self.root
+        lex_min_blue = lex_min_blue.copy() if copy_nodes else lex_min_blue
+
+        red_node_in_tree = root_node
+        for p in red_node.prefix:
+            red_node_in_tree = red_node_in_tree.children[p]
+
+        to_update = root_node
+        for p in lex_min_blue.prefix[:-1]:
+            to_update = to_update.children[p]
+
+        to_update.children[lex_min_blue.prefix[-1]] = red_node_in_tree
+
+        if not self._fold(red_node_in_tree, lex_min_blue, not copy_nodes):
+            return None
+
+        return root_node
+
+    def _fold(self, red_node, blue_node, report):
+        # Change the output of red only to concrete output, ignore None
+        if report and not RpniNode.compatible_outputs(red_node, blue_node):
+            print(f"conflict {red_node.prefix} ({red_node.output}) {blue_node.prefix} ({blue_node.output})")
+            return False
+        red_node.output = blue_node.output if blue_node.output is not None else red_node.output
+
+        for i in blue_node.children.keys():
+            if i in red_node.children.keys():
+                self._fold(red_node.children[i], blue_node.children[i], report)
+            else:
+                red_node.children[i] = blue_node.children[i]
+        return True
+
+    def to_automaton(self):
+        return self.root.to_automaton()
+
+    def replay_log(self, commands: list):
+        for command, args in commands:
+            if command == "merge":
+                self.merge(self.root.get_child_by_prefix(args[0]), self.root.get_child_by_prefix(args[1]))
+            elif command == "promote":
+                pass
+
+    @staticmethod
+    def replay_log_on_pta(data, commands: list, automaton_type):
+        sm = StateMerging(data, automaton_type)
+        sm.replay_log(commands)
+        return sm.to_automaton()
+
+
+def check_sequence(root_node, seq, automaton_type):
+    """
+    Checks whether each sequence in the dataset is valid in the current automaton.
+    """
+    curr_node = root_node
+    for i, o in seq:
+        if automaton_type == 'mealy':
+            input_outputs = {i: o for i, o in curr_node.children.keys()}
+            if i[0] not in input_outputs.keys() or o is not None and input_outputs[i[0]] != o:
+                return False
+            curr_node = curr_node.children[(i[0], input_outputs[i[0]])]
+        else:
+            # For dfa and moore, check if outputs are the same, iff output in test data is concrete (not None)
+            curr_node = curr_node.children[i]
+            if o is not None and curr_node.output != o:
+                return False
+    return True
+
+
+def createPTA(data, automaton_type):
+    data.sort(key=lambda x: len(x[0]))
+
+    root_node = RpniNode(automaton_type=automaton_type)
+    for seq, label in data:
+        curr_node = root_node
+        for idx, symbol in enumerate(seq):
+            if symbol not in curr_node.children.keys():
+                node = RpniNode(automaton_type=automaton_type)
+                node.prefix = curr_node.prefix + (symbol,)
+                curr_node.children[symbol] = node
+
+            if automaton_type == 'mealy' and idx == len(seq) - 1:
+                if symbol not in curr_node.output:
+                    curr_node.output[symbol] = label
+                if curr_node.output[symbol] != label:
+                    return None
+            curr_node = curr_node.children[symbol]
+        if automaton_type == 'moore' or automaton_type == 'dfa':
+            if curr_node.output is None:
+                curr_node.output = label
+            if curr_node.output != label:
+                return None
+
+    return root_node
+
+
+def extract_unique_sequences(root_node):
+    def get_leaf_nodes(root):
+        leaves = []
+
+        def _get_leaf_nodes(node):
+            if node is not None:
+                if len(node.children.keys()) == 0:
+                    leaves.append(node)
+                for n in node.children.values():
+                    _get_leaf_nodes(n)
+
+        _get_leaf_nodes(root)
+        return leaves
+
+    leaf_nodes = get_leaf_nodes(root_node)
+    paths = []
+    for node in leaf_nodes:
+        seq = []
+        curr_node = root_node
+        for i in node.prefix:
+            curr_node = curr_node.children[i]
+            seq.append((i, curr_node.output))
+        paths.append(seq)
+
+    return paths
+
+
+def to_automaton(red, automaton_type):
+    from aalpy.automata import DfaState, Dfa, MooreMachine, MooreState, MealyMachine, MealyState
+
+    if automaton_type == 'dfa':
+        state, automaton = DfaState, Dfa
+    elif automaton_type == 'moore':
+        state, automaton = MooreState, MooreMachine
+    else:
+        state, automaton = MealyState, MealyMachine
+
+    initial_state = None
+    prefix_state_map = {}
+    for i, r in enumerate(red):
+        if automaton_type == 'moore' or automaton_type == 'dfa':
+            prefix_state_map[r.prefix] = state(f's{i}', r.output)
+        else:
+            prefix_state_map[r.prefix] = state(f's{i}')
+        if i == 0:
+            initial_state = prefix_state_map[r.prefix]
+
+    for r in red:
+        for i, c in r.children.items():
+            if automaton_type == 'moore' or automaton_type == 'dfa':
+                prefix_state_map[r.prefix].transitions[i] = prefix_state_map[c.prefix]
+            else:
+                prefix_state_map[r.prefix].transitions[i] = prefix_state_map[c.prefix]
+                prefix_state_map[r.prefix].output_fun[i] = r.output[i] if i in r.output else None
+
+    return automaton(initial_state, list(prefix_state_map.values()))
+
+
+def visualize_pta(root_node, path='pta.pdf'):
+    from pydot import Dot, Node, Edge
+    graph = Dot('fpta', graph_type='digraph')
+
+    graph.add_node(Node(str(root_node.prefix), label=f'{root_node.output}'))
+
+    queue = [root_node]
+    visited = set()
+    visited.add(root_node.prefix)
+    while queue:
+        curr = queue.pop(0)
+        for i, c in curr.children.items():
+            if c.prefix not in visited:
+                graph.add_node(Node(str(c.prefix), label=f'{c.output}'))
+            graph.add_edge(Edge(str(curr.prefix), str(c.prefix), label=f'{i}'))
+            if c.prefix not in visited:
+                queue.append(c)
+            visited.add(c.prefix)
+
+    graph.add_node(Node('__start0', shape='none', label=''))
+    graph.add_edge(Edge('__start0', str(root_node.prefix), label=''))
+
+    graph.write(path=path, format='pdf')
```

## aalpy/learning_algs/non_deterministic/AbstractedOnfsmLstar.py

 * *Ordering differences only*

```diff
@@ -1,146 +1,146 @@
-import time
-
-from aalpy.base import SUL, Oracle
-from aalpy.learning_algs.non_deterministic.AbstractedOnfsmObservationTable import AbstractedNonDetObservationTable
-from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
-from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table
-
-print_options = [0, 1, 2, 3]
-
-
-def run_abstracted_ONFSM_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, abstraction_mapping: dict, n_sampling=100,
-                               max_learning_rounds=None, return_data=False, print_level=2):
-    """
-    Based on ''Learning Abstracted Non-deterministic Finite State Machines'' from Pferscher and Aichernig.
-    The algorithm learns an abstracted onfsm of a non-deterministic system. For the additional abstraction,
-    equivalence classes for outputs are used.
-    Learning ONFSM relies on all-weather assumption. If this assumption is not satisfied by sampling,
-    learning might not converge to the minimal model and runtime could increase substantially.
-    Note that this is the inherent flaw of the all-weather assumption. (All outputs will be seen)
-    AALpy v.2.0 will try to solve that problem with a novel approach.
-
-    Args:
-
-        alphabet: input alphabet
-
-        sul: system under learning
-
-        eq_oracle: equivalence oracle
-
-        abstraction_mapping: dictionary containing mappings from abstracted to concrete values (equivalence classes)
-
-        n_sampling: number of times that membership/input queries will be asked for each cell in the observation
-            (Default value = 100)
-
-        max_learning_rounds: if max_learning_rounds is reached, learning will stop (Default value = None)
-
-        return_data: if True, map containing all information like number of queries... will be returned
-            (Default value = False)
-
-        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
-            (Default value = 2)
-
-    Returns:
-        learned abstracted ONFSM
-
-    """
-    start_time = time.time()
-    eq_query_time = 0
-    learning_rounds = 0
-    hypothesis = None
-
-    sul = NonDeterministicSULWrapper(sul)
-    eq_oracle.sul = sul
-
-    abstracted_observation_table = AbstractedNonDetObservationTable(alphabet, sul, abstraction_mapping, n_sampling)
-
-    # We fist query the initial row. Then based on output in its cells, we generate new rows in S.A,
-    # and then we perform membership/input queries for them.
-    abstracted_observation_table.update_obs_table()
-    new_rows = abstracted_observation_table.update_extended_S()
-    abstracted_observation_table.update_obs_table(s_set=new_rows)
-
-    while True:
-        learning_rounds += 1
-        if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
-            break
-
-        closed_complete_consistent = False
-        while not closed_complete_consistent:
-            closed_complete_consistent = True
-
-            row_to_close = abstracted_observation_table.get_row_to_close()
-            while row_to_close is not None:
-                # First we add new rows to the S.A. They are added based on the values in the cells of the
-                # rows that is to be closed. Once those rows are created, they are populated and closedness is checked
-                # once again.
-                closed_complete_consistent = False
-                extended_rows = abstracted_observation_table.update_extended_S(row_to_close)
-                abstracted_observation_table.update_obs_table(s_set=extended_rows)
-                row_to_close = abstracted_observation_table.get_row_to_close()
-
-            row_to_complete = abstracted_observation_table.get_row_to_complete()
-            while row_to_complete is not None:
-                closed_complete_consistent = False
-                abstracted_observation_table.extend_S_dot_A([row_to_complete])
-                abstracted_observation_table.update_obs_table(s_set=[row_to_complete])
-                row_to_complete = abstracted_observation_table.get_row_to_complete()
-
-            e_column_for_consistency = abstracted_observation_table.get_row_to_make_consistent()
-            while e_column_for_consistency is not None:
-                closed_complete_consistent = False
-                extended_col = abstracted_observation_table.update_E(e_column_for_consistency)
-                abstracted_observation_table.update_obs_table(e_set=extended_col)
-                e_column_for_consistency = abstracted_observation_table.get_row_to_make_consistent()
-
-        abstracted_observation_table.clean_tables()
-        hypothesis = abstracted_observation_table.gen_hypothesis()
-
-        if print_level == 3:
-            print('Observation Table')
-            print_observation_table(abstracted_observation_table.observation_table, 'non-det')
-            print()
-            print('Abstracted Observation Table')
-            # CHANGED, but not important to alg
-            print_observation_table(abstracted_observation_table, 'abstracted-non-det')
-
-        if print_level > 1:
-            print(f'Hypothesis {learning_rounds} has {len(hypothesis.states)} states.')
-
-        # Find counterexample
-        eq_query_start = time.time()
-        cex = eq_oracle.find_cex(hypothesis)
-        eq_query_time += time.time() - eq_query_start
-
-        if cex is None:
-            break
-
-        if print_level >= 2:
-            print('Counterexample', cex)
-
-        # Process counterexample -> add cex to S.A or E
-        abstracted_observation_table.cex_processing(cex, hypothesis)
-
-    total_time = round(time.time() - start_time, 2)
-    eq_query_time = round(eq_query_time, 2)
-    learning_time = round(total_time - eq_query_time, 2)
-
-    info = {
-        'learning_rounds': learning_rounds,
-        'automaton_size': len(hypothesis.states),
-        'queries_learning': sul.num_queries,
-        'steps_learning': sul.num_steps,
-        'queries_eq_oracle': eq_oracle.num_queries,
-        'steps_eq_oracle': eq_oracle.num_steps,
-        'learning_time': learning_time,
-        'eq_oracle_time': eq_query_time,
-        'total_time': total_time
-    }
-
-    if print_level > 0:
-        print_learning_info(info)
-
-    if return_data:
-        return hypothesis, info
-
-    return hypothesis
+import time
+
+from aalpy.base import SUL, Oracle
+from aalpy.learning_algs.non_deterministic.AbstractedOnfsmObservationTable import AbstractedNonDetObservationTable
+from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
+from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table
+
+print_options = [0, 1, 2, 3]
+
+
+def run_abstracted_ONFSM_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, abstraction_mapping: dict, n_sampling=100,
+                               max_learning_rounds=None, return_data=False, print_level=2):
+    """
+    Based on ''Learning Abstracted Non-deterministic Finite State Machines'' from Pferscher and Aichernig.
+    The algorithm learns an abstracted onfsm of a non-deterministic system. For the additional abstraction,
+    equivalence classes for outputs are used.
+    Learning ONFSM relies on all-weather assumption. If this assumption is not satisfied by sampling,
+    learning might not converge to the minimal model and runtime could increase substantially.
+    Note that this is the inherent flaw of the all-weather assumption. (All outputs will be seen)
+    AALpy v.2.0 will try to solve that problem with a novel approach.
+
+    Args:
+
+        alphabet: input alphabet
+
+        sul: system under learning
+
+        eq_oracle: equivalence oracle
+
+        abstraction_mapping: dictionary containing mappings from abstracted to concrete values (equivalence classes)
+
+        n_sampling: number of times that membership/input queries will be asked for each cell in the observation
+            (Default value = 100)
+
+        max_learning_rounds: if max_learning_rounds is reached, learning will stop (Default value = None)
+
+        return_data: if True, map containing all information like number of queries... will be returned
+            (Default value = False)
+
+        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
+            (Default value = 2)
+
+    Returns:
+        learned abstracted ONFSM
+
+    """
+    start_time = time.time()
+    eq_query_time = 0
+    learning_rounds = 0
+    hypothesis = None
+
+    sul = NonDeterministicSULWrapper(sul)
+    eq_oracle.sul = sul
+
+    abstracted_observation_table = AbstractedNonDetObservationTable(alphabet, sul, abstraction_mapping, n_sampling)
+
+    # We fist query the initial row. Then based on output in its cells, we generate new rows in S.A,
+    # and then we perform membership/input queries for them.
+    abstracted_observation_table.update_obs_table()
+    new_rows = abstracted_observation_table.update_extended_S()
+    abstracted_observation_table.update_obs_table(s_set=new_rows)
+
+    while True:
+        learning_rounds += 1
+        if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
+            break
+
+        closed_complete_consistent = False
+        while not closed_complete_consistent:
+            closed_complete_consistent = True
+
+            row_to_close = abstracted_observation_table.get_row_to_close()
+            while row_to_close is not None:
+                # First we add new rows to the S.A. They are added based on the values in the cells of the
+                # rows that is to be closed. Once those rows are created, they are populated and closedness is checked
+                # once again.
+                closed_complete_consistent = False
+                extended_rows = abstracted_observation_table.update_extended_S(row_to_close)
+                abstracted_observation_table.update_obs_table(s_set=extended_rows)
+                row_to_close = abstracted_observation_table.get_row_to_close()
+
+            row_to_complete = abstracted_observation_table.get_row_to_complete()
+            while row_to_complete is not None:
+                closed_complete_consistent = False
+                abstracted_observation_table.extend_S_dot_A([row_to_complete])
+                abstracted_observation_table.update_obs_table(s_set=[row_to_complete])
+                row_to_complete = abstracted_observation_table.get_row_to_complete()
+
+            e_column_for_consistency = abstracted_observation_table.get_row_to_make_consistent()
+            while e_column_for_consistency is not None:
+                closed_complete_consistent = False
+                extended_col = abstracted_observation_table.update_E(e_column_for_consistency)
+                abstracted_observation_table.update_obs_table(e_set=extended_col)
+                e_column_for_consistency = abstracted_observation_table.get_row_to_make_consistent()
+
+        abstracted_observation_table.clean_tables()
+        hypothesis = abstracted_observation_table.gen_hypothesis()
+
+        if print_level == 3:
+            print('Observation Table')
+            print_observation_table(abstracted_observation_table.observation_table, 'non-det')
+            print()
+            print('Abstracted Observation Table')
+            # CHANGED, but not important to alg
+            print_observation_table(abstracted_observation_table, 'abstracted-non-det')
+
+        if print_level > 1:
+            print(f'Hypothesis {learning_rounds} has {len(hypothesis.states)} states.')
+
+        # Find counterexample
+        eq_query_start = time.time()
+        cex = eq_oracle.find_cex(hypothesis)
+        eq_query_time += time.time() - eq_query_start
+
+        if cex is None:
+            break
+
+        if print_level >= 2:
+            print('Counterexample', cex)
+
+        # Process counterexample -> add cex to S.A or E
+        abstracted_observation_table.cex_processing(cex, hypothesis)
+
+    total_time = round(time.time() - start_time, 2)
+    eq_query_time = round(eq_query_time, 2)
+    learning_time = round(total_time - eq_query_time, 2)
+
+    info = {
+        'learning_rounds': learning_rounds,
+        'automaton_size': len(hypothesis.states),
+        'queries_learning': sul.num_queries,
+        'steps_learning': sul.num_steps,
+        'queries_eq_oracle': eq_oracle.num_queries,
+        'steps_eq_oracle': eq_oracle.num_steps,
+        'learning_time': learning_time,
+        'eq_oracle_time': eq_query_time,
+        'total_time': total_time
+    }
+
+    if print_level > 0:
+        print_learning_info(info)
+
+    if return_data:
+        return hypothesis, info
+
+    return hypothesis
```

## aalpy/learning_algs/non_deterministic/AbstractedOnfsmObservationTable.py

 * *Ordering differences only*

```diff
@@ -1,442 +1,442 @@
-from collections import defaultdict
-
-from aalpy.automata import Onfsm, OnfsmState
-from aalpy.learning_algs.non_deterministic.OnfsmObservationTable import NonDetObservationTable
-from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
-from aalpy.utils.HelperFunctions import all_suffixes, extend_set
-
-
-class AbstractedNonDetObservationTable:
-    def __init__(self, alphabet: list, sul: NonDeterministicSULWrapper, abstraction_mapping: dict, n_sampling=100):
-        """
-        Construction of the abstracted non-deterministic observation table.
-
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-            abstraction_mapping: map that translates outputs to abstracted outputs
-            n_sampling: number of samples to be performed for each cell
-        """
-
-        assert alphabet is not None and sul is not None
-
-        self.observation_table = NonDetObservationTable(alphabet, sul, n_sampling)
-
-        self.S = list()
-        self.S_dot_A = []
-        self.E = []
-        self.T = defaultdict(dict)
-        self.A = [tuple([a]) for a in alphabet]
-
-        self.abstraction_mapping = abstraction_mapping
-        self.sul = sul
-
-        empty_word = tuple()
-        self.S.append((empty_word, empty_word))
-
-    def update_obs_table(self, s_set=None, e_set: list = None):
-        """
-        Perform the membership queries and abstraction on observation table
-        With  the  all-weather  assumption,  each  output  query  is  tried  a  number  of  times  on  the  system,
-        and  the  driver  reports  the  set  of  all  possible  outputs.
-
-        Args:
-
-            s_set: Prefixes of S set on which to preform membership queries (Default value = None)
-            e_set: Suffixes of E set on which to perform membership queries
-
-
-        """
-
-        self.observation_table.query_missing_observations(s_set, e_set)
-        self.abstract_obs_table()
-        self.clean_obs_table()
-
-    def abstract_obs_table(self):
-        """
-        Creation of abstracted observation table. The provided abstraction mapping is used to
-        replace outputs by abstracted outputs.
-        """
-
-        self.S = self.observation_table.S
-        self.S_dot_A = list(set(self.observation_table.get_extended_S()).union(set(self.S_dot_A) - set(self.S)))
-        self.E = self.observation_table.E
-
-        update_S = self.S + self.S_dot_A
-        update_E = self.E
-
-        for s in update_S:
-            for e in update_E:
-                for o_tup in self.get_all_outputs(s, e):
-                    abstracted_outputs = []
-                    o_tup = tuple([o_tup])
-                    for outputs in o_tup:
-                        for o in outputs:
-                            abstract_output = self.get_abstraction(o)
-                            abstracted_outputs.append(abstract_output)
-                    self.add_to_T(s, e, tuple(abstracted_outputs))
-
-    def add_to_T(self, s, e, value):
-        """
-        Add values to the cell at T[s][e].
-
-        Args:
-
-            s: prefix
-            e: element of S
-            value: value to be added to the cell
-
-
-        """
-        if e not in self.T[s]:
-            self.T[s][e] = set()
-        self.T[s][e].add(value)
-
-    # CHANGED
-    # helper function
-    def get_all_outputs(self, s, e):
-        cell_outputs = set()
-        cell_outputs.update(self.sul.cache.get_all_traces(s, e))
-        return cell_outputs
-
-    def update_extended_S(self, row_prefix=None):
-        """
-        Helper generator function that returns extended S, or S.A set.
-        For all values in the cell, create a new row where inputs is parent input plus element of alphabet, and
-        output is parent output plus value in cell.
-
-        Returns:
-
-            New rows of extended S set.
-        """
-        return self.observation_table.get_extended_S(row_prefix=row_prefix)
-
-    def get_row_to_close(self):
-        """
-        Get row for that needs to be closed.
-
-        Returns:
-
-            row that will be moved to S set and closed
-        """
-        s_rows = set()
-        for s in self.S:
-            s_rows.add(self.row_to_hashable(s))
-
-        for t in self.S_dot_A:
-            row_t = self.row_to_hashable(t)
-
-            if row_t not in s_rows:
-                self.S.append(t)
-                self.S_dot_A.remove(t)
-                return t
-
-        return None
-
-    def get_row_to_complete(self):
-        """
-        Get row for that needs to be completed.
-
-        Returns:
-
-            row that will be added to S.A
-        """
-
-        s_rows = set()
-        for s in self.S:
-            s_rows.add(tuple((s, self.row_to_hashable(s))))
-
-        for s_row in s_rows:
-            similar_s_dot_a_rows = []
-            for t in self.S_dot_A:
-                row_t = self.row_to_hashable(t)
-                if row_t == s_row[1]:
-                    similar_s_dot_a_rows.append(t)
-            similar_s_dot_a_rows.sort(key=lambda row: len(row[0]))
-            for a in self.A:
-                complete_outputs = self.get_all_outputs(s_row[0], a)
-                for similar_s_dot_a_row in similar_s_dot_a_rows:
-                    t_row_outputs = self.get_all_outputs(similar_s_dot_a_row, a)
-                    output_difference = t_row_outputs.difference(complete_outputs)
-                    if len(output_difference) > 0:
-                        for o in output_difference:
-                            extension = (similar_s_dot_a_row[0] + a, similar_s_dot_a_row[1] + tuple([o[0]]))
-                            if extension not in self.S and extension not in self.S_dot_A:
-                                return extension
-                            else:
-                                complete_outputs = complete_outputs.union(output_difference)
-
-        return None
-
-    def get_row_to_make_consistent(self):
-        """
-        Get row that violates consistency.
-        """
-        unified_S = self.S + self.S_dot_A
-        s_rows = set()
-        for s in self.S:
-            s_rows.add(tuple((s, self.row_to_hashable(s))))
-
-        for s_row in s_rows:
-            similar_s_dot_a_rows = []
-            for t in self.S_dot_A:
-                row_t = self.row_to_hashable(t)
-                if row_t == s_row[1]:
-                    similar_s_dot_a_rows.append(t)
-
-            similar_s_dot_a_rows.sort(key=lambda row: len(row[0]))
-
-            for a in self.A:
-                # CHANGED
-                #                 outputs = self.observation_table.T[s_row[0]][a]
-                outputs = self.get_all_outputs(s_row[0], a)
-                for o in outputs:
-                    extended_s_sequence = (s_row[0][0] + a, s_row[0][1] + tuple([o]))
-                    if extended_s_sequence in unified_S:
-                        extended_s_sequence_row = self.row_to_hashable(extended_s_sequence)
-                        for similar_s_dot_a_row in similar_s_dot_a_rows:
-                            extended_s_dot_a_sequence = (
-                                similar_s_dot_a_row[0] + a, similar_s_dot_a_row[1] + tuple([o]))
-                            if extended_s_dot_a_sequence in unified_S:
-                                extended_s_dot_a_sequence_row = self.row_to_hashable(extended_s_dot_a_sequence)
-                                if extended_s_sequence_row is not extended_s_dot_a_sequence_row:
-                                    return self.get_distinctive_input_sequence(extended_s_sequence,
-                                                                               extended_s_dot_a_sequence, a)
-
-        return None
-
-    def get_distinctive_input_sequence(self, first_row, second_row, inp):
-        """
-        get input sequence that leads to a different output sequence for two given input/output sequences
-
-        Args:
-
-            first_row: row to be compared
-            second_row: row to be compared
-            inp: appended input to first_row and second_row that leads to different state 
-
-        Returns:
-
-            input sequence that leads to different outputs
-
-        """
-        for e in self.E:
-            if len(self.T[first_row][e].difference(self.T[second_row][e])) > 0:
-                return tuple([inp]) + e
-
-        return None
-
-    def update_E(self, seq):
-        if seq not in self.E:
-            self.E.append(seq)
-
-    def clean_obs_table(self):
-        """
-        Moves duplicates from S to S_dot_A. The entries in S_dot_A which are based on the moved row get deleted.
-        The table will be smaller and more efficient.
-
-        """
-        # just for testing without cleaning
-        # return False
-
-        tmp_S = self.S.copy()
-        tmp_both_S = self.S + self.S_dot_A
-        hashed_rows_from_s = set()
-
-        tmp_S.sort(key=lambda t: len(t[0]))
-
-        for s in tmp_S:
-            hashed_s_row = self.row_to_hashable(s)
-            if hashed_s_row in hashed_rows_from_s:
-                if s in self.S:
-                    self.S.remove(s)
-                    self.observation_table.S.remove(s)
-                size = len(s[0])
-                for row_prefix in tmp_both_S:
-                    s_both_row = (row_prefix[0][:size], row_prefix[1][:size])
-                    if s != row_prefix and s == s_both_row:
-                        if row_prefix in self.S:
-                            self.S.remove(row_prefix)
-                            self.observation_table.S.remove(s)
-            else:
-                hashed_rows_from_s.add(hashed_s_row)
-
-    def row_to_hashable(self, row_prefix):
-        """
-        Creates the hashable representation of the row. Frozenset is used as the order of element in each cell does not
-        matter
-
-        Args:
-
-            row_prefix: prefix of the row in the observation table
-
-        Returns:
-
-            hashable representation of the row
-
-        """
-        row_repr = tuple()
-        for e in self.E:
-            # if e in self.T[row_prefix].keys():
-            row_repr += (frozenset(self.T[row_prefix][e]),)
-        return row_repr
-
-    def gen_hypothesis(self) -> Onfsm:
-        """
-        Generate automaton based on the values found in the abstracted observation table.
-
-        Returns:
-
-            Current abstracted hypothesis
-
-        """
-        state_distinguish = dict()
-        states_dict = dict()
-        initial = None
-
-        unified_S = self.S + self.S_dot_A
-
-        stateCounter = 0
-        for prefix in self.S:
-            state_id = f's{stateCounter}'
-            states_dict[prefix] = OnfsmState(state_id)
-
-            states_dict[prefix].prefix = prefix
-            state_distinguish[self.row_to_hashable(prefix)] = states_dict[prefix]
-
-            if prefix == self.S[0]:
-                initial = states_dict[prefix]
-            stateCounter += 1
-
-        for prefix in self.S:
-            similar_rows = []
-            for row in unified_S:
-                if self.row_to_hashable(row) == self.row_to_hashable(prefix):
-                    similar_rows.append(row)
-            for row in similar_rows:
-                for a in self.A:
-                    for t in self.get_all_outputs(row, a):
-                        s_entry = (row[0] + a, row[1] + t)
-                        if s_entry in unified_S:
-                            state_in_S = state_distinguish[self.row_to_hashable(s_entry)]
-
-                            if (t[0], state_in_S) not in states_dict[prefix].transitions[a[0]]:
-                                states_dict[prefix].transitions[a[0]].append((t[0], state_in_S))
-
-        assert initial
-        automaton = Onfsm(initial, [s for s in states_dict.values()])
-        automaton.characterization_set = self.E
-
-        return automaton
-
-    def extend_S_dot_A(self, cex_prefixes: list):
-        """
-        Extends S.A based on counterexample prefixes.
-
-        Args:
-
-        cex_prefixes: input/output sequences that are added to S.A
-
-        Returns:
-
-        input/output sequences that have been added to the S.A
-        """
-        prefixes = self.S + self.S_dot_A
-        prefixes_to_extend = []
-        for cex_prefix in cex_prefixes:
-            if cex_prefix not in prefixes:
-                prefixes_to_extend.append(cex_prefix)
-                self.S_dot_A.append(cex_prefix)
-        return prefixes_to_extend
-
-    def get_abstraction(self, out):
-        """
-        Get an abstraction for a concrete output. If such abstraction is not defined, return output.
-
-        Args:
-
-            out: output to be abstracted if possible
-
-        Returns:
-
-            abstracted output or output itself
-        """
-        return self.abstraction_mapping[out] if out in self.abstraction_mapping.keys() else out
-
-    def cex_processing(self, cex: tuple, hypothesis: Onfsm):
-        """
-        Add counterexample to the observation table. If the counterexample leads to a state where an output of the
-        same equivalence class already exists, the prefixes of the counterexample are added to S.A.
-        Otherwise, the postfixes of counterexample are added to E.
-
-
-        Args:
-
-            cex: counterexample that should be added to the observation table
-            hypothesis: onfsm that implements the counterexample
-        """
-
-        cex_len = len(cex[0])
-        hypothesis.reset_to_initial()
-
-        for step in range(0, cex_len - 1):
-            hypothesis.step_to(cex[0][step], cex[1][step])
-
-        possible_outputs = hypothesis.outputs_on_input(cex[0][cex_len - 1])
-
-        equivalent_output = False
-
-        for out in possible_outputs:
-            abstracted_out = self.get_abstraction(out)
-            abstracted_out_cex = self.get_abstraction(cex[1][cex_len - 1])
-            if abstracted_out_cex == abstracted_out:
-                equivalent_output = True
-                break
-
-        if equivalent_output:
-            # add prefixes of cex to S_dot_A
-            cex_prefixes = [(tuple(cex[0][0:i + 1]), tuple(cex[1][0:i + 1])) for i in range(0, len(cex[0]))]
-            prefixes_to_extend = self.extend_S_dot_A(cex_prefixes)
-
-            # CHANGED: REMOVED
-            # self.observation_table.S_dot_A.extend(prefixes_to_extend)
-            self.update_obs_table(s_set=prefixes_to_extend)
-        else:
-            # add distinguishing suffixes of cex to E
-            # CHANGED CEX PROX
-            # TODO: this will now not work as cex processing was changed
-            # cex_suffixes = non_det_longest_prefix_cex_processing(self.observation_table, cex)
-            cex_suffixes = all_suffixes(cex[0])
-
-            added_suffixes = extend_set(self.observation_table.E, cex_suffixes)
-            self.update_obs_table(e_set=added_suffixes)
-
-    def clean_tables(self):
-
-        self.observation_table.clean_obs_table()
-        self.abstract_obs_table()
-
-        update_S = self.S.copy()
-        whole_S = self.S + self.S_dot_A
-
-        update_S.sort()
-        update_S.sort(key=lambda t: len(t[0]))
-
-        s_rows = set()
-        for s in update_S:
-            hashed_s_row = self.row_to_hashable(s)
-            if hashed_s_row not in s_rows:
-                s_rows.add(hashed_s_row)
-            else:
-                size = len(s[0])
-                for row in whole_S:
-                    cmp_row = (row[0][:size], row[1][:size])
-                    if s == cmp_row:
-                        if row in self.S_dot_A:
-                            self.S_dot_A.remove(row)
-                        elif row in self.S:
-                            self.S.remove(row)
-
-                self.S_dot_A.append(s)
-                self.S.remove(s)
+from collections import defaultdict
+
+from aalpy.automata import Onfsm, OnfsmState
+from aalpy.learning_algs.non_deterministic.OnfsmObservationTable import NonDetObservationTable
+from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
+from aalpy.utils.HelperFunctions import all_suffixes, extend_set
+
+
+class AbstractedNonDetObservationTable:
+    def __init__(self, alphabet: list, sul: NonDeterministicSULWrapper, abstraction_mapping: dict, n_sampling=100):
+        """
+        Construction of the abstracted non-deterministic observation table.
+
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+            abstraction_mapping: map that translates outputs to abstracted outputs
+            n_sampling: number of samples to be performed for each cell
+        """
+
+        assert alphabet is not None and sul is not None
+
+        self.observation_table = NonDetObservationTable(alphabet, sul, n_sampling)
+
+        self.S = list()
+        self.S_dot_A = []
+        self.E = []
+        self.T = defaultdict(dict)
+        self.A = [tuple([a]) for a in alphabet]
+
+        self.abstraction_mapping = abstraction_mapping
+        self.sul = sul
+
+        empty_word = tuple()
+        self.S.append((empty_word, empty_word))
+
+    def update_obs_table(self, s_set=None, e_set: list = None):
+        """
+        Perform the membership queries and abstraction on observation table
+        With  the  all-weather  assumption,  each  output  query  is  tried  a  number  of  times  on  the  system,
+        and  the  driver  reports  the  set  of  all  possible  outputs.
+
+        Args:
+
+            s_set: Prefixes of S set on which to preform membership queries (Default value = None)
+            e_set: Suffixes of E set on which to perform membership queries
+
+
+        """
+
+        self.observation_table.query_missing_observations(s_set, e_set)
+        self.abstract_obs_table()
+        self.clean_obs_table()
+
+    def abstract_obs_table(self):
+        """
+        Creation of abstracted observation table. The provided abstraction mapping is used to
+        replace outputs by abstracted outputs.
+        """
+
+        self.S = self.observation_table.S
+        self.S_dot_A = list(set(self.observation_table.get_extended_S()).union(set(self.S_dot_A) - set(self.S)))
+        self.E = self.observation_table.E
+
+        update_S = self.S + self.S_dot_A
+        update_E = self.E
+
+        for s in update_S:
+            for e in update_E:
+                for o_tup in self.get_all_outputs(s, e):
+                    abstracted_outputs = []
+                    o_tup = tuple([o_tup])
+                    for outputs in o_tup:
+                        for o in outputs:
+                            abstract_output = self.get_abstraction(o)
+                            abstracted_outputs.append(abstract_output)
+                    self.add_to_T(s, e, tuple(abstracted_outputs))
+
+    def add_to_T(self, s, e, value):
+        """
+        Add values to the cell at T[s][e].
+
+        Args:
+
+            s: prefix
+            e: element of S
+            value: value to be added to the cell
+
+
+        """
+        if e not in self.T[s]:
+            self.T[s][e] = set()
+        self.T[s][e].add(value)
+
+    # CHANGED
+    # helper function
+    def get_all_outputs(self, s, e):
+        cell_outputs = set()
+        cell_outputs.update(self.sul.cache.get_all_traces(s, e))
+        return cell_outputs
+
+    def update_extended_S(self, row_prefix=None):
+        """
+        Helper generator function that returns extended S, or S.A set.
+        For all values in the cell, create a new row where inputs is parent input plus element of alphabet, and
+        output is parent output plus value in cell.
+
+        Returns:
+
+            New rows of extended S set.
+        """
+        return self.observation_table.get_extended_S(row_prefix=row_prefix)
+
+    def get_row_to_close(self):
+        """
+        Get row for that needs to be closed.
+
+        Returns:
+
+            row that will be moved to S set and closed
+        """
+        s_rows = set()
+        for s in self.S:
+            s_rows.add(self.row_to_hashable(s))
+
+        for t in self.S_dot_A:
+            row_t = self.row_to_hashable(t)
+
+            if row_t not in s_rows:
+                self.S.append(t)
+                self.S_dot_A.remove(t)
+                return t
+
+        return None
+
+    def get_row_to_complete(self):
+        """
+        Get row for that needs to be completed.
+
+        Returns:
+
+            row that will be added to S.A
+        """
+
+        s_rows = set()
+        for s in self.S:
+            s_rows.add(tuple((s, self.row_to_hashable(s))))
+
+        for s_row in s_rows:
+            similar_s_dot_a_rows = []
+            for t in self.S_dot_A:
+                row_t = self.row_to_hashable(t)
+                if row_t == s_row[1]:
+                    similar_s_dot_a_rows.append(t)
+            similar_s_dot_a_rows.sort(key=lambda row: len(row[0]))
+            for a in self.A:
+                complete_outputs = self.get_all_outputs(s_row[0], a)
+                for similar_s_dot_a_row in similar_s_dot_a_rows:
+                    t_row_outputs = self.get_all_outputs(similar_s_dot_a_row, a)
+                    output_difference = t_row_outputs.difference(complete_outputs)
+                    if len(output_difference) > 0:
+                        for o in output_difference:
+                            extension = (similar_s_dot_a_row[0] + a, similar_s_dot_a_row[1] + tuple([o[0]]))
+                            if extension not in self.S and extension not in self.S_dot_A:
+                                return extension
+                            else:
+                                complete_outputs = complete_outputs.union(output_difference)
+
+        return None
+
+    def get_row_to_make_consistent(self):
+        """
+        Get row that violates consistency.
+        """
+        unified_S = self.S + self.S_dot_A
+        s_rows = set()
+        for s in self.S:
+            s_rows.add(tuple((s, self.row_to_hashable(s))))
+
+        for s_row in s_rows:
+            similar_s_dot_a_rows = []
+            for t in self.S_dot_A:
+                row_t = self.row_to_hashable(t)
+                if row_t == s_row[1]:
+                    similar_s_dot_a_rows.append(t)
+
+            similar_s_dot_a_rows.sort(key=lambda row: len(row[0]))
+
+            for a in self.A:
+                # CHANGED
+                #                 outputs = self.observation_table.T[s_row[0]][a]
+                outputs = self.get_all_outputs(s_row[0], a)
+                for o in outputs:
+                    extended_s_sequence = (s_row[0][0] + a, s_row[0][1] + tuple([o]))
+                    if extended_s_sequence in unified_S:
+                        extended_s_sequence_row = self.row_to_hashable(extended_s_sequence)
+                        for similar_s_dot_a_row in similar_s_dot_a_rows:
+                            extended_s_dot_a_sequence = (
+                                similar_s_dot_a_row[0] + a, similar_s_dot_a_row[1] + tuple([o]))
+                            if extended_s_dot_a_sequence in unified_S:
+                                extended_s_dot_a_sequence_row = self.row_to_hashable(extended_s_dot_a_sequence)
+                                if extended_s_sequence_row is not extended_s_dot_a_sequence_row:
+                                    return self.get_distinctive_input_sequence(extended_s_sequence,
+                                                                               extended_s_dot_a_sequence, a)
+
+        return None
+
+    def get_distinctive_input_sequence(self, first_row, second_row, inp):
+        """
+        get input sequence that leads to a different output sequence for two given input/output sequences
+
+        Args:
+
+            first_row: row to be compared
+            second_row: row to be compared
+            inp: appended input to first_row and second_row that leads to different state 
+
+        Returns:
+
+            input sequence that leads to different outputs
+
+        """
+        for e in self.E:
+            if len(self.T[first_row][e].difference(self.T[second_row][e])) > 0:
+                return tuple([inp]) + e
+
+        return None
+
+    def update_E(self, seq):
+        if seq not in self.E:
+            self.E.append(seq)
+
+    def clean_obs_table(self):
+        """
+        Moves duplicates from S to S_dot_A. The entries in S_dot_A which are based on the moved row get deleted.
+        The table will be smaller and more efficient.
+
+        """
+        # just for testing without cleaning
+        # return False
+
+        tmp_S = self.S.copy()
+        tmp_both_S = self.S + self.S_dot_A
+        hashed_rows_from_s = set()
+
+        tmp_S.sort(key=lambda t: len(t[0]))
+
+        for s in tmp_S:
+            hashed_s_row = self.row_to_hashable(s)
+            if hashed_s_row in hashed_rows_from_s:
+                if s in self.S:
+                    self.S.remove(s)
+                    self.observation_table.S.remove(s)
+                size = len(s[0])
+                for row_prefix in tmp_both_S:
+                    s_both_row = (row_prefix[0][:size], row_prefix[1][:size])
+                    if s != row_prefix and s == s_both_row:
+                        if row_prefix in self.S:
+                            self.S.remove(row_prefix)
+                            self.observation_table.S.remove(s)
+            else:
+                hashed_rows_from_s.add(hashed_s_row)
+
+    def row_to_hashable(self, row_prefix):
+        """
+        Creates the hashable representation of the row. Frozenset is used as the order of element in each cell does not
+        matter
+
+        Args:
+
+            row_prefix: prefix of the row in the observation table
+
+        Returns:
+
+            hashable representation of the row
+
+        """
+        row_repr = tuple()
+        for e in self.E:
+            # if e in self.T[row_prefix].keys():
+            row_repr += (frozenset(self.T[row_prefix][e]),)
+        return row_repr
+
+    def gen_hypothesis(self) -> Onfsm:
+        """
+        Generate automaton based on the values found in the abstracted observation table.
+
+        Returns:
+
+            Current abstracted hypothesis
+
+        """
+        state_distinguish = dict()
+        states_dict = dict()
+        initial = None
+
+        unified_S = self.S + self.S_dot_A
+
+        stateCounter = 0
+        for prefix in self.S:
+            state_id = f's{stateCounter}'
+            states_dict[prefix] = OnfsmState(state_id)
+
+            states_dict[prefix].prefix = prefix
+            state_distinguish[self.row_to_hashable(prefix)] = states_dict[prefix]
+
+            if prefix == self.S[0]:
+                initial = states_dict[prefix]
+            stateCounter += 1
+
+        for prefix in self.S:
+            similar_rows = []
+            for row in unified_S:
+                if self.row_to_hashable(row) == self.row_to_hashable(prefix):
+                    similar_rows.append(row)
+            for row in similar_rows:
+                for a in self.A:
+                    for t in self.get_all_outputs(row, a):
+                        s_entry = (row[0] + a, row[1] + t)
+                        if s_entry in unified_S:
+                            state_in_S = state_distinguish[self.row_to_hashable(s_entry)]
+
+                            if (t[0], state_in_S) not in states_dict[prefix].transitions[a[0]]:
+                                states_dict[prefix].transitions[a[0]].append((t[0], state_in_S))
+
+        assert initial
+        automaton = Onfsm(initial, [s for s in states_dict.values()])
+        automaton.characterization_set = self.E
+
+        return automaton
+
+    def extend_S_dot_A(self, cex_prefixes: list):
+        """
+        Extends S.A based on counterexample prefixes.
+
+        Args:
+
+        cex_prefixes: input/output sequences that are added to S.A
+
+        Returns:
+
+        input/output sequences that have been added to the S.A
+        """
+        prefixes = self.S + self.S_dot_A
+        prefixes_to_extend = []
+        for cex_prefix in cex_prefixes:
+            if cex_prefix not in prefixes:
+                prefixes_to_extend.append(cex_prefix)
+                self.S_dot_A.append(cex_prefix)
+        return prefixes_to_extend
+
+    def get_abstraction(self, out):
+        """
+        Get an abstraction for a concrete output. If such abstraction is not defined, return output.
+
+        Args:
+
+            out: output to be abstracted if possible
+
+        Returns:
+
+            abstracted output or output itself
+        """
+        return self.abstraction_mapping[out] if out in self.abstraction_mapping.keys() else out
+
+    def cex_processing(self, cex: tuple, hypothesis: Onfsm):
+        """
+        Add counterexample to the observation table. If the counterexample leads to a state where an output of the
+        same equivalence class already exists, the prefixes of the counterexample are added to S.A.
+        Otherwise, the postfixes of counterexample are added to E.
+
+
+        Args:
+
+            cex: counterexample that should be added to the observation table
+            hypothesis: onfsm that implements the counterexample
+        """
+
+        cex_len = len(cex[0])
+        hypothesis.reset_to_initial()
+
+        for step in range(0, cex_len - 1):
+            hypothesis.step_to(cex[0][step], cex[1][step])
+
+        possible_outputs = hypothesis.outputs_on_input(cex[0][cex_len - 1])
+
+        equivalent_output = False
+
+        for out in possible_outputs:
+            abstracted_out = self.get_abstraction(out)
+            abstracted_out_cex = self.get_abstraction(cex[1][cex_len - 1])
+            if abstracted_out_cex == abstracted_out:
+                equivalent_output = True
+                break
+
+        if equivalent_output:
+            # add prefixes of cex to S_dot_A
+            cex_prefixes = [(tuple(cex[0][0:i + 1]), tuple(cex[1][0:i + 1])) for i in range(0, len(cex[0]))]
+            prefixes_to_extend = self.extend_S_dot_A(cex_prefixes)
+
+            # CHANGED: REMOVED
+            # self.observation_table.S_dot_A.extend(prefixes_to_extend)
+            self.update_obs_table(s_set=prefixes_to_extend)
+        else:
+            # add distinguishing suffixes of cex to E
+            # CHANGED CEX PROX
+            # TODO: this will now not work as cex processing was changed
+            # cex_suffixes = non_det_longest_prefix_cex_processing(self.observation_table, cex)
+            cex_suffixes = all_suffixes(cex[0])
+
+            added_suffixes = extend_set(self.observation_table.E, cex_suffixes)
+            self.update_obs_table(e_set=added_suffixes)
+
+    def clean_tables(self):
+
+        self.observation_table.clean_obs_table()
+        self.abstract_obs_table()
+
+        update_S = self.S.copy()
+        whole_S = self.S + self.S_dot_A
+
+        update_S.sort()
+        update_S.sort(key=lambda t: len(t[0]))
+
+        s_rows = set()
+        for s in update_S:
+            hashed_s_row = self.row_to_hashable(s)
+            if hashed_s_row not in s_rows:
+                s_rows.add(hashed_s_row)
+            else:
+                size = len(s[0])
+                for row in whole_S:
+                    cmp_row = (row[0][:size], row[1][:size])
+                    if s == cmp_row:
+                        if row in self.S_dot_A:
+                            self.S_dot_A.remove(row)
+                        elif row in self.S:
+                            self.S.remove(row)
+
+                self.S_dot_A.append(s)
+                self.S.remove(s)
```

## aalpy/learning_algs/non_deterministic/NonDeterministicSULWrapper.py

 * *Ordering differences only*

```diff
@@ -1,25 +1,25 @@
-from aalpy.base import SUL
-from aalpy.learning_algs.non_deterministic.TraceTree import TraceTree
-
-
-class NonDeterministicSULWrapper(SUL):
-    """
-    Wrapper for non-deterministic SUL. After every step, input/output pair is added to the tree containing all traces.
-    """
-
-    def __init__(self, sul: SUL):
-        super().__init__()
-        self.sul = sul
-        self.cache = TraceTree()
-
-    def pre(self):
-        self.cache.reset()
-        self.sul.pre()
-
-    def post(self):
-        self.sul.post()
-
-    def step(self, letter):
-        out = self.sul.step(letter)
-        self.cache.add_to_tree(letter, out)
-        return out
+from aalpy.base import SUL
+from aalpy.learning_algs.non_deterministic.TraceTree import TraceTree
+
+
+class NonDeterministicSULWrapper(SUL):
+    """
+    Wrapper for non-deterministic SUL. After every step, input/output pair is added to the tree containing all traces.
+    """
+
+    def __init__(self, sul: SUL):
+        super().__init__()
+        self.sul = sul
+        self.cache = TraceTree()
+
+    def pre(self):
+        self.cache.reset()
+        self.sul.pre()
+
+    def post(self):
+        self.sul.post()
+
+    def step(self, letter):
+        out = self.sul.step(letter)
+        self.cache.add_to_tree(letter, out)
+        return out
```

## aalpy/learning_algs/non_deterministic/OnfsmLstar.py

 * *Ordering differences only*

```diff
@@ -1,150 +1,150 @@
-import time
-
-from aalpy.base import SUL, Oracle
-from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
-from aalpy.learning_algs.non_deterministic.OnfsmObservationTable import NonDetObservationTable
-from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table, \
-    get_available_oracles_and_err_msg, all_suffixes
-
-print_options = [0, 1, 2, 3]
-
-available_oracles, available_oracles_error_msg = get_available_oracles_and_err_msg()
-
-
-def run_non_det_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, n_sampling=5, samples=None, stochastic=False,
-                      max_learning_rounds=None, return_data=False, print_level=2):
-    """
-    A ONFSM learning algorithm that does not rely on all weather assumption (once an input is queried, all possible
-    outputs are observed).
-
-    Args:
-
-        alphabet: input alphabet
-
-        sul: system under learning
-
-        eq_oracle: equivalence oracle
-
-        n_sampling: number of times that each cell has to be updated. If this number is to low, all-weather condition
-            will not hold and learning will not converge to the correct model. (Default value = 50)
-
-        samples: input output sequances provided to learning algorithm. List of ((input sequence), (output sequence)).
-
-        stochastic: if True, non deterministic learning will be performed but probabilities will be added to the
-        returned model, making it a stochastic Mealy machine
-
-        max_learning_rounds: if max_learning_rounds is reached, learning will stop (Default value = None)
-
-        return_data: if True, map containing all information like number of queries... will be returned
-            (Default value = False)
-
-        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
-            (Default value = 2)
-
-    Returns:
-        learned ONFSM
-
-    """
-
-    start_time = time.time()
-    eq_query_time = 0
-    learning_rounds = 0
-
-    sul = NonDeterministicSULWrapper(sul)
-
-    if samples:
-        for inputs, outputs in samples:
-            sul.cache.add_trace(inputs, outputs)
-
-    eq_oracle.sul = sul
-
-    ot = NonDetObservationTable(alphabet, sul, n_sampling)
-
-    # Keep track of last counterexample and last hypothesis size
-    # With this data we can check if the extension of the E set lead to state increase
-    last_cex = None
-
-    hypothesis = None
-
-    while True:
-        if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
-            break
-
-        ot.S = list()
-        ot.S.append((tuple(), tuple()))
-        ot.query_missing_observations()
-
-        row_to_close = ot.get_row_to_close()
-        while row_to_close is not None:
-            ot.query_missing_observations()
-            row_to_close = ot.get_row_to_close()
-            ot.clean_obs_table()
-
-        hypothesis = ot.gen_hypothesis()
-
-        if counterexample_not_valid(hypothesis, last_cex):
-            cex = sul.cache.find_cex_in_cache(hypothesis)
-
-            if cex is None:
-                learning_rounds += 1
-                # Find counterexample
-                if print_level > 1:
-                    print(f'Hypothesis {learning_rounds}: {len(hypothesis.states)} states.')
-
-                if print_level == 3:
-                    print_observation_table(ot, 'non-det')
-
-                eq_query_start = time.time()
-                cex = eq_oracle.find_cex(hypothesis)
-                eq_query_time += time.time() - eq_query_start
-
-            last_cex = cex
-        else:
-            cex = last_cex
-
-        if cex is None:
-            break
-        else:
-            cex_suffixes = all_suffixes(cex[0])
-            for suffix in cex_suffixes:
-                if suffix not in ot.E:
-                    ot.E.append(suffix)
-                    break
-
-    if stochastic:
-        hypothesis = ot.gen_hypothesis(stochastic=True)
-
-    total_time = round(time.time() - start_time, 2)
-    eq_query_time = round(eq_query_time, 2)
-    learning_time = round(total_time - eq_query_time, 2)
-
-    info = {
-        'learning_rounds': learning_rounds,
-        'automaton_size': len(hypothesis.states),
-        'queries_learning': sul.num_queries,
-        'steps_learning': sul.num_steps,
-        'queries_eq_oracle': eq_oracle.num_queries,
-        'steps_eq_oracle': eq_oracle.num_steps,
-        'learning_time': learning_time,
-        'eq_oracle_time': eq_query_time,
-        'total_time': total_time
-    }
-
-    if print_level > 0:
-        print_learning_info(info)
-
-    if return_data:
-        return hypothesis, info
-
-    return hypothesis
-
-
-def counterexample_not_valid(hypothesis, cex):
-    if cex is None:
-        return True
-    hypothesis.reset_to_initial()
-    for i, o in zip(cex[0], cex[1]):
-        out = hypothesis.step_to(i, o)
-        if out is None:
-            return False
-    return True
+import time
+
+from aalpy.base import SUL, Oracle
+from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
+from aalpy.learning_algs.non_deterministic.OnfsmObservationTable import NonDetObservationTable
+from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table, \
+    get_available_oracles_and_err_msg, all_suffixes
+
+print_options = [0, 1, 2, 3]
+
+available_oracles, available_oracles_error_msg = get_available_oracles_and_err_msg()
+
+
+def run_non_det_Lstar(alphabet: list, sul: SUL, eq_oracle: Oracle, n_sampling=5, samples=None, stochastic=False,
+                      max_learning_rounds=None, return_data=False, print_level=2):
+    """
+    A ONFSM learning algorithm that does not rely on all weather assumption (once an input is queried, all possible
+    outputs are observed).
+
+    Args:
+
+        alphabet: input alphabet
+
+        sul: system under learning
+
+        eq_oracle: equivalence oracle
+
+        n_sampling: number of times that each cell has to be updated. If this number is to low, all-weather condition
+            will not hold and learning will not converge to the correct model. (Default value = 50)
+
+        samples: input output sequances provided to learning algorithm. List of ((input sequence), (output sequence)).
+
+        stochastic: if True, non deterministic learning will be performed but probabilities will be added to the
+        returned model, making it a stochastic Mealy machine
+
+        max_learning_rounds: if max_learning_rounds is reached, learning will stop (Default value = None)
+
+        return_data: if True, map containing all information like number of queries... will be returned
+            (Default value = False)
+
+        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
+            (Default value = 2)
+
+    Returns:
+        learned ONFSM
+
+    """
+
+    start_time = time.time()
+    eq_query_time = 0
+    learning_rounds = 0
+
+    sul = NonDeterministicSULWrapper(sul)
+
+    if samples:
+        for inputs, outputs in samples:
+            sul.cache.add_trace(inputs, outputs)
+
+    eq_oracle.sul = sul
+
+    ot = NonDetObservationTable(alphabet, sul, n_sampling)
+
+    # Keep track of last counterexample and last hypothesis size
+    # With this data we can check if the extension of the E set lead to state increase
+    last_cex = None
+
+    hypothesis = None
+
+    while True:
+        if max_learning_rounds and learning_rounds - 1 == max_learning_rounds:
+            break
+
+        ot.S = list()
+        ot.S.append((tuple(), tuple()))
+        ot.query_missing_observations()
+
+        row_to_close = ot.get_row_to_close()
+        while row_to_close is not None:
+            ot.query_missing_observations()
+            row_to_close = ot.get_row_to_close()
+            ot.clean_obs_table()
+
+        hypothesis = ot.gen_hypothesis()
+
+        if counterexample_not_valid(hypothesis, last_cex):
+            cex = sul.cache.find_cex_in_cache(hypothesis)
+
+            if cex is None:
+                learning_rounds += 1
+                # Find counterexample
+                if print_level > 1:
+                    print(f'Hypothesis {learning_rounds}: {len(hypothesis.states)} states.')
+
+                if print_level == 3:
+                    print_observation_table(ot, 'non-det')
+
+                eq_query_start = time.time()
+                cex = eq_oracle.find_cex(hypothesis)
+                eq_query_time += time.time() - eq_query_start
+
+            last_cex = cex
+        else:
+            cex = last_cex
+
+        if cex is None:
+            break
+        else:
+            cex_suffixes = all_suffixes(cex[0])
+            for suffix in cex_suffixes:
+                if suffix not in ot.E:
+                    ot.E.append(suffix)
+                    break
+
+    if stochastic:
+        hypothesis = ot.gen_hypothesis(stochastic=True)
+
+    total_time = round(time.time() - start_time, 2)
+    eq_query_time = round(eq_query_time, 2)
+    learning_time = round(total_time - eq_query_time, 2)
+
+    info = {
+        'learning_rounds': learning_rounds,
+        'automaton_size': len(hypothesis.states),
+        'queries_learning': sul.num_queries,
+        'steps_learning': sul.num_steps,
+        'queries_eq_oracle': eq_oracle.num_queries,
+        'steps_eq_oracle': eq_oracle.num_steps,
+        'learning_time': learning_time,
+        'eq_oracle_time': eq_query_time,
+        'total_time': total_time
+    }
+
+    if print_level > 0:
+        print_learning_info(info)
+
+    if return_data:
+        return hypothesis, info
+
+    return hypothesis
+
+
+def counterexample_not_valid(hypothesis, cex):
+    if cex is None:
+        return True
+    hypothesis.reset_to_initial()
+    for i, o in zip(cex[0], cex[1]):
+        out = hypothesis.step_to(i, o)
+        if out is None:
+            return False
+    return True
```

## aalpy/learning_algs/non_deterministic/OnfsmObservationTable.py

 * *Ordering differences only*

```diff
@@ -1,204 +1,204 @@
-from collections import Counter
-
-from aalpy.automata import Onfsm, OnfsmState, StochasticMealyState, StochasticMealyMachine
-from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
-
-
-class NonDetObservationTable:
-
-    def __init__(self, alphabet: list, sul: NonDeterministicSULWrapper, n_sampling):
-        """
-        Construction of the non-deterministic observation table.
-
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-            n_sampling: number of samples to be performed for each cell
-        """
-        assert alphabet is not None and sul is not None
-
-        self.alphabet = alphabet
-        self.A = [tuple([a]) for a in alphabet]
-        self.S = list()  # prefixes of S
-
-        self.E = [tuple([a]) for a in alphabet]
-
-        self.n_samples = n_sampling
-        self.closing_counter = 0
-
-        self.sul = sul
-
-        self.sampling_counter = Counter()
-
-        empty_word = tuple()
-
-        # Elements of S are in form that is presented in 'Learning Finite State Models of Observable Nondeterministic
-        # Systems in a Testing Context'. Each element of S is a (inputs, outputs) tuple, where first element of the
-        # tuple are inputs and second element of the tuple are outputs associated with inputs.
-        self.S.append((empty_word, empty_word))
-
-        self.pruned_nodes = set()
-
-    def get_row_to_close(self):
-        """
-        Get row for that need to be closed.
-
-        Returns:
-
-            row that will be moved to S set and closed
-        """
-
-        s_rows = set()
-        update_S_dot_A = self.get_extended_S()
-
-        for s in self.S.copy():
-            s_rows.add(self.row_to_hashable(s))
-
-        for t in update_S_dot_A:
-            row_t = self.row_to_hashable(t)
-            if row_t not in s_rows:
-                self.closing_counter += 1
-                self.S.append(t)
-                return t
-
-        self.closing_counter = 0
-        return None
-
-    def get_extended_S(self, row_prefix=None):
-        """
-        Helper generator function that returns extended S, or S.A set.
-        For all values in the cell, create a new row where inputs is parent input plus element of alphabet, and
-        output is parent output plus value in cell.
-
-        Returns:
-
-            extended S set.
-        """
-
-        rows = self.S if row_prefix is None else [row_prefix]
-
-        S_dot_A = []
-        for row in rows:
-            for a in self.A:
-                trace = self.sul.cache.get_all_traces(row, a)
-
-                for t in trace:
-                    new_row = (row[0] + a, row[1] + (t[-1],))
-                    if new_row not in self.S:
-                        S_dot_A.append(new_row)
-        return S_dot_A
-
-    def query_missing_observations(self, s=None, e=None):
-        s_set = s if s is not None else self.S + self.get_extended_S()
-        e_set = e if e is not None else self.E
-
-        for s in s_set:
-            for e in e_set:
-                while self.sul.cache.get_s_e_sampling_frequency(s, e) < self.n_samples:
-                    self.sul.query(s[0] + e)
-
-    def row_to_hashable(self, row_prefix):
-        """
-        Creates the hashable representation of the row. Frozenset is used as the order of element in each cell does not
-        matter
-
-        Args:
-
-            row_prefix: prefix of the row in the observation table
-
-        Returns:
-
-            hashable representation of the row
-
-        """
-        row_repr = tuple()
-
-        for e in self.E:
-            cell = self.sul.cache.get_all_traces(row_prefix, e)
-            while cell is None:
-                self.query_missing_observations([row_prefix], [e])
-                cell = self.sul.cache.get_all_traces(row_prefix, e)
-
-            row_repr += (frozenset(cell),)
-
-        return row_repr
-
-    def clean_obs_table(self):
-        """
-        Moves duplicates from S to S_dot_A. The entries in S_dot_A which are based on the moved row get deleted.
-        The table will be smaller and more efficient.
-
-        """
-
-        tmp_S = self.S.copy()
-        tmp_both_S = self.S + self.get_extended_S()
-        hashed_rows_from_s = set()
-
-        tmp_S.sort(key=lambda t: len(t[0]))
-
-        for s in tmp_S:
-            hashed_s_row = self.row_to_hashable(s)
-            if hashed_s_row in hashed_rows_from_s:
-                if s in self.S:
-                    self.S.remove(s)
-                size = len(s[0])
-                for row_prefix in tmp_both_S:
-                    s_both_row = (row_prefix[0][:size], row_prefix[1][:size])
-                    if s != row_prefix and s == s_both_row:
-                        if row_prefix in self.S:
-                            self.S.remove(row_prefix)
-            else:
-                hashed_rows_from_s.add(hashed_s_row)
-
-    def gen_hypothesis(self, stochastic=False):
-        """
-        Generate automaton based on the values found in the observation table.
-        If stochastic is set to True, returns a Stochastic Mealy Machine.
-
-        Returns:
-
-            Current hypothesis
-        """
-
-        state_distinguish = dict()
-        states_dict = dict()
-        initial = None
-
-        stateCounter = 0
-
-        state_class = OnfsmState if not stochastic else StochasticMealyState
-        model_class = Onfsm if not stochastic else StochasticMealyMachine
-
-        for prefix in self.S:
-            state_id = f's{stateCounter}'
-            states_dict[prefix] = state_class(state_id)
-
-            states_dict[prefix].prefix = prefix
-            state_distinguish[self.row_to_hashable(prefix)] = states_dict[prefix]
-
-            if prefix == self.S[0]:
-                initial = states_dict[prefix]
-            stateCounter += 1
-
-        for prefix in self.S:
-            for a in self.A:
-                observations_in_cell = self.sul.cache.get_all_traces(prefix, a)
-                probability_distribution = None
-                if stochastic:
-                    probability_distribution = self.sul.cache.get_sampling_distributions(prefix, a[0])
-                for obs in observations_in_cell:
-                    reached_row = (prefix[0] + a, prefix[1] + (obs[-1],))
-                    destination = state_distinguish[self.row_to_hashable(reached_row)]
-                    assert destination
-                    if not stochastic:
-                        states_dict[prefix].transitions[a[0]].append((obs[-1], destination))
-                    else:
-                        states_dict[prefix].transitions[a[0]].append((destination, obs[-1],
-                                                                      probability_distribution[obs[-1]]))
-
-        assert initial
-        automaton = model_class(initial, [s for s in states_dict.values()])
-        automaton.characterization_set = self.E
-
-        return automaton
+from collections import Counter
+
+from aalpy.automata import Onfsm, OnfsmState, StochasticMealyState, StochasticMealyMachine
+from aalpy.learning_algs.non_deterministic.NonDeterministicSULWrapper import NonDeterministicSULWrapper
+
+
+class NonDetObservationTable:
+
+    def __init__(self, alphabet: list, sul: NonDeterministicSULWrapper, n_sampling):
+        """
+        Construction of the non-deterministic observation table.
+
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+            n_sampling: number of samples to be performed for each cell
+        """
+        assert alphabet is not None and sul is not None
+
+        self.alphabet = alphabet
+        self.A = [tuple([a]) for a in alphabet]
+        self.S = list()  # prefixes of S
+
+        self.E = [tuple([a]) for a in alphabet]
+
+        self.n_samples = n_sampling
+        self.closing_counter = 0
+
+        self.sul = sul
+
+        self.sampling_counter = Counter()
+
+        empty_word = tuple()
+
+        # Elements of S are in form that is presented in 'Learning Finite State Models of Observable Nondeterministic
+        # Systems in a Testing Context'. Each element of S is a (inputs, outputs) tuple, where first element of the
+        # tuple are inputs and second element of the tuple are outputs associated with inputs.
+        self.S.append((empty_word, empty_word))
+
+        self.pruned_nodes = set()
+
+    def get_row_to_close(self):
+        """
+        Get row for that need to be closed.
+
+        Returns:
+
+            row that will be moved to S set and closed
+        """
+
+        s_rows = set()
+        update_S_dot_A = self.get_extended_S()
+
+        for s in self.S.copy():
+            s_rows.add(self.row_to_hashable(s))
+
+        for t in update_S_dot_A:
+            row_t = self.row_to_hashable(t)
+            if row_t not in s_rows:
+                self.closing_counter += 1
+                self.S.append(t)
+                return t
+
+        self.closing_counter = 0
+        return None
+
+    def get_extended_S(self, row_prefix=None):
+        """
+        Helper generator function that returns extended S, or S.A set.
+        For all values in the cell, create a new row where inputs is parent input plus element of alphabet, and
+        output is parent output plus value in cell.
+
+        Returns:
+
+            extended S set.
+        """
+
+        rows = self.S if row_prefix is None else [row_prefix]
+
+        S_dot_A = []
+        for row in rows:
+            for a in self.A:
+                trace = self.sul.cache.get_all_traces(row, a)
+
+                for t in trace:
+                    new_row = (row[0] + a, row[1] + (t[-1],))
+                    if new_row not in self.S:
+                        S_dot_A.append(new_row)
+        return S_dot_A
+
+    def query_missing_observations(self, s=None, e=None):
+        s_set = s if s is not None else self.S + self.get_extended_S()
+        e_set = e if e is not None else self.E
+
+        for s in s_set:
+            for e in e_set:
+                while self.sul.cache.get_s_e_sampling_frequency(s, e) < self.n_samples:
+                    self.sul.query(s[0] + e)
+
+    def row_to_hashable(self, row_prefix):
+        """
+        Creates the hashable representation of the row. Frozenset is used as the order of element in each cell does not
+        matter
+
+        Args:
+
+            row_prefix: prefix of the row in the observation table
+
+        Returns:
+
+            hashable representation of the row
+
+        """
+        row_repr = tuple()
+
+        for e in self.E:
+            cell = self.sul.cache.get_all_traces(row_prefix, e)
+            while cell is None:
+                self.query_missing_observations([row_prefix], [e])
+                cell = self.sul.cache.get_all_traces(row_prefix, e)
+
+            row_repr += (frozenset(cell),)
+
+        return row_repr
+
+    def clean_obs_table(self):
+        """
+        Moves duplicates from S to S_dot_A. The entries in S_dot_A which are based on the moved row get deleted.
+        The table will be smaller and more efficient.
+
+        """
+
+        tmp_S = self.S.copy()
+        tmp_both_S = self.S + self.get_extended_S()
+        hashed_rows_from_s = set()
+
+        tmp_S.sort(key=lambda t: len(t[0]))
+
+        for s in tmp_S:
+            hashed_s_row = self.row_to_hashable(s)
+            if hashed_s_row in hashed_rows_from_s:
+                if s in self.S:
+                    self.S.remove(s)
+                size = len(s[0])
+                for row_prefix in tmp_both_S:
+                    s_both_row = (row_prefix[0][:size], row_prefix[1][:size])
+                    if s != row_prefix and s == s_both_row:
+                        if row_prefix in self.S:
+                            self.S.remove(row_prefix)
+            else:
+                hashed_rows_from_s.add(hashed_s_row)
+
+    def gen_hypothesis(self, stochastic=False):
+        """
+        Generate automaton based on the values found in the observation table.
+        If stochastic is set to True, returns a Stochastic Mealy Machine.
+
+        Returns:
+
+            Current hypothesis
+        """
+
+        state_distinguish = dict()
+        states_dict = dict()
+        initial = None
+
+        stateCounter = 0
+
+        state_class = OnfsmState if not stochastic else StochasticMealyState
+        model_class = Onfsm if not stochastic else StochasticMealyMachine
+
+        for prefix in self.S:
+            state_id = f's{stateCounter}'
+            states_dict[prefix] = state_class(state_id)
+
+            states_dict[prefix].prefix = prefix
+            state_distinguish[self.row_to_hashable(prefix)] = states_dict[prefix]
+
+            if prefix == self.S[0]:
+                initial = states_dict[prefix]
+            stateCounter += 1
+
+        for prefix in self.S:
+            for a in self.A:
+                observations_in_cell = self.sul.cache.get_all_traces(prefix, a)
+                probability_distribution = None
+                if stochastic:
+                    probability_distribution = self.sul.cache.get_sampling_distributions(prefix, a[0])
+                for obs in observations_in_cell:
+                    reached_row = (prefix[0] + a, prefix[1] + (obs[-1],))
+                    destination = state_distinguish[self.row_to_hashable(reached_row)]
+                    assert destination
+                    if not stochastic:
+                        states_dict[prefix].transitions[a[0]].append((obs[-1], destination))
+                    else:
+                        states_dict[prefix].transitions[a[0]].append((destination, obs[-1],
+                                                                      probability_distribution[obs[-1]]))
+
+        assert initial
+        automaton = model_class(initial, [s for s in states_dict.values()])
+        automaton.characterization_set = self.E
+
+        return automaton
```

## aalpy/learning_algs/non_deterministic/TraceTree.py

 * *Ordering differences only*

```diff
@@ -1,203 +1,203 @@
-from collections import defaultdict
-
-
-class Node:
-    __slots__ = ['output', 'children', 'parent', 'frequency_counter']
-
-    def __init__(self, output):
-        self.output = output
-        self.children = defaultdict(list)
-        self.parent = None
-
-        # frq counter
-        self.frequency_counter = 0
-
-    def get_child(self, inp, out):
-        """
-        Args:
-          inp:
-          out:
-
-        Returns:
-
-        """
-        return next((child for child in self.children[inp] if child.output == out), None)
-
-    def get_prefix(self):
-        prefix = ()
-        curr_node = self
-        while curr_node.parent is not None:
-            prefix = (curr_node.output,) + prefix
-            curr_node = curr_node.parent
-        return prefix
-
-
-class TraceTree:
-    """
-    Tree used for keeping track of seen observations.
-    """
-
-    def __init__(self):
-        self.root_node = Node(None)
-        self.curr_node = None
-
-    def reset(self):
-        self.curr_node = self.root_node
-
-    def add_to_tree(self, inp, out):
-        """
-        Adds new element to tree and makes it the current node
-
-        Args:
-
-          inp: Input
-          out: Output
-
-        """
-        if inp not in self.curr_node.children.keys() or \
-                out not in {child.output for child in self.curr_node.children[inp]}:
-            node = Node(out)
-            self.curr_node.children[inp].append(node)
-            node.parent = self.curr_node
-
-        self.curr_node = self.curr_node.get_child(inp, out)
-        self.curr_node.frequency_counter += 1
-
-    def add_trace(self, inputs, outputs):
-        self.reset()
-        for i, o in zip(inputs, outputs):
-            self.add_to_tree(i, o)
-
-    def get_to_node(self, inputs, outputs):
-        """
-        Follows the path described by inp and out and returns the node which is reached
-
-        Args:
-          inputs: Inputs
-          outputs: Outputs
-
-        Returns:
-
-          Node that is reached when following the given input and output through the tree
-        """
-        curr_node = self.root_node
-        for i, o in zip(inputs, outputs):
-            node = curr_node.get_child(i, o)
-            if node is None:
-                return None
-            curr_node = node
-
-        return curr_node
-
-    def get_all_traces(self, prefix, e=None):
-        """
-
-        Args:
-
-          prefix: prefix
-          e: List of inputs
-
-        Returns:
-
-          Traces of outputs corresponding to the input-sequence given by e
-        """
-
-        if not prefix or not e:
-            return []
-
-        curr_node = self.root_node
-        for i, o in zip(prefix[0], prefix[1]):
-            curr_node = curr_node.get_child(i, o)
-            if curr_node is None:
-                return []
-
-        queue = [(curr_node, 0)]
-        reached_nodes = []
-        while queue:
-            node, depth = queue.pop(0)
-            if depth == len(e):
-                reached_nodes.append(node)
-            else:
-                children_with_same_input = node.children[e[depth]]
-                for c in children_with_same_input:
-                    queue.append((c, depth + 1))
-
-        cell = [node.get_prefix()[-len(e):] for node in reached_nodes]
-        return cell
-
-    def get_table(self, s, e):
-        """
-        Generates a table from the tree
-
-        Args:
-          s: rows from S, S_dot_A, or both which should be presented in the table.
-          e: E
-
-        Returns:
-          a table in a format that can be used for printing.
-        """
-        result = {}
-        for prefix in s:
-            result[prefix] = {}
-
-            for inp in e:
-                result[prefix][inp] = self.get_all_traces(prefix, inp)
-
-        return result
-
-    def find_cex_in_cache(self, hypothesis):
-
-        queue = [(self.root_node, tuple())]
-        while queue:
-            curr_node, path = queue.pop(0)
-
-            if path:
-                hypothesis.reset_to_initial()
-                inputs, outputs = [], []
-                for i, o in zip(path[0::2], path[1::2]):
-                    inputs.append(i)
-                    outputs.append(o)
-                    out = hypothesis.step_to(i, o)
-                    if out is None:
-                        return inputs, outputs
-            for inp in curr_node.children.keys():
-                children = curr_node.children[inp]
-                for child in children:
-                    # if curr_node.frequency_counter[(inp, child_out)] >= threshold:
-                    queue.append((child, path + (inp, child.output)))
-
-        return None
-
-    def get_s_e_sampling_frequency(self, prefix, suffix):
-        sampling_frequency = 0
-        curr_node = self.root_node
-        for i, o in zip(prefix[0], prefix[1]):
-            curr_node = curr_node.get_child(i, o)
-            if curr_node is None:
-                return 0
-
-        queue = [(curr_node, 0)]
-        while queue:
-            node, depth = queue.pop(0)
-            children_with_same_input = node.children[suffix[depth]]
-            if depth == len(suffix) - 1:
-                for c in children_with_same_input:
-                    sampling_frequency += c.frequency_counter
-            else:
-                for c in children_with_same_input:
-                    queue.append((c, depth + 1))
-
-        return sampling_frequency
-
-    def get_sampling_distributions(self, prefix, input_from_alphabet):
-        sampling_distribution = {}
-        curr_node = self.root_node
-        for i, o in zip(prefix[0], prefix[1]):
-            curr_node = curr_node.get_child(i, o)
-
-        children = curr_node.children[input_from_alphabet]
-        sampling_sum = sum(c.frequency_counter for c in children)
-        for c in children:
-            sampling_distribution[c.output] = c.frequency_counter / sampling_sum
-
-        return sampling_distribution
+from collections import defaultdict
+
+
+class Node:
+    __slots__ = ['output', 'children', 'parent', 'frequency_counter']
+
+    def __init__(self, output):
+        self.output = output
+        self.children = defaultdict(list)
+        self.parent = None
+
+        # frq counter
+        self.frequency_counter = 0
+
+    def get_child(self, inp, out):
+        """
+        Args:
+          inp:
+          out:
+
+        Returns:
+
+        """
+        return next((child for child in self.children[inp] if child.output == out), None)
+
+    def get_prefix(self):
+        prefix = ()
+        curr_node = self
+        while curr_node.parent is not None:
+            prefix = (curr_node.output,) + prefix
+            curr_node = curr_node.parent
+        return prefix
+
+
+class TraceTree:
+    """
+    Tree used for keeping track of seen observations.
+    """
+
+    def __init__(self):
+        self.root_node = Node(None)
+        self.curr_node = None
+
+    def reset(self):
+        self.curr_node = self.root_node
+
+    def add_to_tree(self, inp, out):
+        """
+        Adds new element to tree and makes it the current node
+
+        Args:
+
+          inp: Input
+          out: Output
+
+        """
+        if inp not in self.curr_node.children.keys() or \
+                out not in {child.output for child in self.curr_node.children[inp]}:
+            node = Node(out)
+            self.curr_node.children[inp].append(node)
+            node.parent = self.curr_node
+
+        self.curr_node = self.curr_node.get_child(inp, out)
+        self.curr_node.frequency_counter += 1
+
+    def add_trace(self, inputs, outputs):
+        self.reset()
+        for i, o in zip(inputs, outputs):
+            self.add_to_tree(i, o)
+
+    def get_to_node(self, inputs, outputs):
+        """
+        Follows the path described by inp and out and returns the node which is reached
+
+        Args:
+          inputs: Inputs
+          outputs: Outputs
+
+        Returns:
+
+          Node that is reached when following the given input and output through the tree
+        """
+        curr_node = self.root_node
+        for i, o in zip(inputs, outputs):
+            node = curr_node.get_child(i, o)
+            if node is None:
+                return None
+            curr_node = node
+
+        return curr_node
+
+    def get_all_traces(self, prefix, e=None):
+        """
+
+        Args:
+
+          prefix: prefix
+          e: List of inputs
+
+        Returns:
+
+          Traces of outputs corresponding to the input-sequence given by e
+        """
+
+        if not prefix or not e:
+            return []
+
+        curr_node = self.root_node
+        for i, o in zip(prefix[0], prefix[1]):
+            curr_node = curr_node.get_child(i, o)
+            if curr_node is None:
+                return []
+
+        queue = [(curr_node, 0)]
+        reached_nodes = []
+        while queue:
+            node, depth = queue.pop(0)
+            if depth == len(e):
+                reached_nodes.append(node)
+            else:
+                children_with_same_input = node.children[e[depth]]
+                for c in children_with_same_input:
+                    queue.append((c, depth + 1))
+
+        cell = [node.get_prefix()[-len(e):] for node in reached_nodes]
+        return cell
+
+    def get_table(self, s, e):
+        """
+        Generates a table from the tree
+
+        Args:
+          s: rows from S, S_dot_A, or both which should be presented in the table.
+          e: E
+
+        Returns:
+          a table in a format that can be used for printing.
+        """
+        result = {}
+        for prefix in s:
+            result[prefix] = {}
+
+            for inp in e:
+                result[prefix][inp] = self.get_all_traces(prefix, inp)
+
+        return result
+
+    def find_cex_in_cache(self, hypothesis):
+
+        queue = [(self.root_node, tuple())]
+        while queue:
+            curr_node, path = queue.pop(0)
+
+            if path:
+                hypothesis.reset_to_initial()
+                inputs, outputs = [], []
+                for i, o in zip(path[0::2], path[1::2]):
+                    inputs.append(i)
+                    outputs.append(o)
+                    out = hypothesis.step_to(i, o)
+                    if out is None:
+                        return inputs, outputs
+            for inp in curr_node.children.keys():
+                children = curr_node.children[inp]
+                for child in children:
+                    # if curr_node.frequency_counter[(inp, child_out)] >= threshold:
+                    queue.append((child, path + (inp, child.output)))
+
+        return None
+
+    def get_s_e_sampling_frequency(self, prefix, suffix):
+        sampling_frequency = 0
+        curr_node = self.root_node
+        for i, o in zip(prefix[0], prefix[1]):
+            curr_node = curr_node.get_child(i, o)
+            if curr_node is None:
+                return 0
+
+        queue = [(curr_node, 0)]
+        while queue:
+            node, depth = queue.pop(0)
+            children_with_same_input = node.children[suffix[depth]]
+            if depth == len(suffix) - 1:
+                for c in children_with_same_input:
+                    sampling_frequency += c.frequency_counter
+            else:
+                for c in children_with_same_input:
+                    queue.append((c, depth + 1))
+
+        return sampling_frequency
+
+    def get_sampling_distributions(self, prefix, input_from_alphabet):
+        sampling_distribution = {}
+        curr_node = self.root_node
+        for i, o in zip(prefix[0], prefix[1]):
+            curr_node = curr_node.get_child(i, o)
+
+        children = curr_node.children[input_from_alphabet]
+        sampling_sum = sum(c.frequency_counter for c in children)
+        for c in children:
+            sampling_distribution[c.output] = c.frequency_counter / sampling_sum
+
+        return sampling_distribution
```

## aalpy/learning_algs/stochastic/DifferenceChecker.py

 * *Ordering differences only*

```diff
@@ -1,177 +1,177 @@
-from abc import ABC, abstractmethod
-from math import sqrt, log
-
-chi2_table = dict()
-
-chi2_table[0.95] = \
-    dict([(1, 3.841458820694124), (2, 5.991464547107979), (3, 7.814727903251179), (4, 9.487729036781154),
-          (5, 11.070497693516351), (6, 12.591587243743977), (7, 14.067140449340169), (8, 15.50731305586545),
-          (9, 16.918977604620448), (10, 18.307038053275146), (11, 19.67513757268249), (12, 21.02606981748307),
-          (13, 22.362032494826934), (14, 23.684791304840576), (15, 24.995790139728616), (16, 26.29622760486423),
-          (17, 27.58711163827534), (18, 28.869299430392623), (19, 30.14352720564616), (20, 31.410432844230918)])
-chi2_table[0.99] = \
-    dict([(1, 6.6348966010212145), (2, 9.21034037197618), (3, 11.344866730144373), (4, 13.276704135987622),
-          (5, 15.08627246938899), (6, 16.811893829770927), (7, 18.475306906582357), (8, 20.090235029663233),
-          (9, 21.665994333461924), (10, 23.209251158954356), (11, 24.724970311318277), (12, 26.216967305535853),
-          (13, 27.68824961045705), (14, 29.141237740672796), (15, 30.57791416689249), (16, 31.999926908815176),
-          (17, 33.40866360500461), (18, 34.805305734705065), (19, 36.19086912927004), (20, 37.56623478662507)])
-
-chi2_table[0.999] = \
-    dict([(1, 10.827566170662733), (2, 13.815510557964274), (3, 16.26623619623813), (4, 18.46682695290317),
-          (5, 20.515005652432873), (6, 22.457744484825323), (7, 24.321886347856854), (8, 26.12448155837614),
-          (9, 27.877164871256568), (10, 29.58829844507442), (11, 31.264133620239985), (12, 32.90949040736021),
-          (13, 34.52817897487089), (14, 36.12327368039813), (15, 37.69729821835383), (16, 39.252354790768464),
-          (17, 40.79021670690253), (18, 42.31239633167996), (19, 43.82019596451753), (20, 45.31474661812586)])
-
-
-class DifferenceChecker(ABC):
-
-    @abstractmethod
-    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
-        pass
-
-    def difference_value(self, c1: dict, c2: dict):
-        return None
-
-    def use_diff_value(self):
-        return False
-
-
-class HoeffdingChecker(DifferenceChecker):
-
-    def __init__(self, alpha=0.05):
-        self.alpha = alpha
-
-    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
-        if c1.keys() != c2.keys():
-            return True
-
-        n1 = sum(c1.values())
-        n2 = sum(c2.values())
-
-        if n1 > 0 and n2 > 0:
-            for o in c1.keys():
-                if abs(c1[o] / n1 - c2[o] / n2) > \
-                        ((sqrt(1 / n1) + sqrt(1 / n2)) * sqrt(0.5 * log(2 / self.alpha))):
-                    return True
-        return False
-
-
-def compute_epsilon(alpha1, n1):
-    epsilon1 = sqrt((1. / (2 * n1)) * log(2. / alpha1))
-    return epsilon1
-
-
-class AdvancedHoeffdingChecker(DifferenceChecker):
-    def __init__(self, alpha=0.05, use_diff=False):
-        self.alpha = alpha
-        self.use_diff = use_diff
-
-    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
-        n1 = sum(c1.values())
-        n2 = sum(c2.values())
-
-        if n1 > 0 and n2 > 0:
-            for o in set(c1.keys()).union(c2.keys()):
-                c1o = c1[o] if o in c1.keys() else 0
-                c2o = c2[o] if o in c2.keys() else 0
-                alpha1 = self.alpha
-                alpha2 = self.alpha
-                epsilon1 = compute_epsilon(alpha1, n1)
-                epsilon2 = compute_epsilon(alpha2, n2)
-
-                if abs(c1o / n1 - c2o / n2) > epsilon1 + epsilon2:
-                    return True
-        return False
-
-    def use_diff_value(self):
-        return self.use_diff
-
-    def difference_value(self, c1_out_freq: dict, c2_out_freq: dict):
-        n1 = 0 if not c1_out_freq else sum(c1_out_freq.values())
-        n2 = 0 if not c2_out_freq else sum(c2_out_freq.values())
-
-        if n1 > 0 and n2 > 0:
-            dist = 0
-            for o in set(c1_out_freq.keys()).union(c2_out_freq.keys()):
-                c1o = c1_out_freq[o] if o in c1_out_freq.keys() else 0
-                c2o = c2_out_freq[o] if o in c2_out_freq.keys() else 0
-                dist += abs(c1o / n1 - c2o / n2)
-            return dist
-        elif n1 > 0 or n2 > 0:
-            alpha1 = self.alpha
-            alpha2 = self.alpha
-            epsilon1 = compute_epsilon(alpha1, max(n1, n2))
-            epsilon2 = compute_epsilon(alpha2, max(n1, n2))
-            return epsilon1 + epsilon2
-        else:
-            return 0
-
-
-class ChiSquareChecker(DifferenceChecker):
-
-    def __init__(self, alpha=0.001, use_diff_value=False):
-        self.alpha = alpha
-        self.chi2_cache = dict()
-        if 1 - self.alpha not in chi2_table.keys():
-            raise ValueError("alpha must be in [0.01,0.001,0.05]")
-        self.chi2_values = chi2_table[1 - self.alpha]
-        self.use_diff = use_diff_value
-
-    def are_cells_different(self, c1_out_freq: dict, c2_out_freq: dict, **kwargs) -> bool:
-        # chi square test for homogeneity (see, for instance: https://online.stat.psu.edu/stat415/lesson/17/17.1)
-        if not c1_out_freq or not c2_out_freq:
-            return False
-        keys = list(set(c1_out_freq.keys()).union(c2_out_freq.keys()))
-        dof = len(keys) - 1
-        if dof == 0:
-            return False
-        shared_keys = set(c1_out_freq.keys()).intersection(c2_out_freq.keys())
-        if len(shared_keys) == 0:
-            # if the supports of the tested frequencies are completely then chi2 makes no sense, use the Hoeffding test
-            # to determine if there are enough observations for a difference
-            hoeffding_checker = AdvancedHoeffdingChecker()
-            return hoeffding_checker.are_cells_different(c1_out_freq, c2_out_freq)
-
-        Q = self.compute_Q(c1_out_freq, c2_out_freq, keys)
-        if dof not in self.chi2_values.keys():
-            raise ValueError("Too many possible outputs, chi2 table needs to be extended.")
-        else:
-            chi2_val = self.chi2_values[dof]
-
-        return Q >= chi2_val
-
-    def use_diff_value(self):
-        return self.use_diff
-
-    def difference_value(self, c1_out_freq: dict, c2_out_freq: dict):
-        if not c1_out_freq or not c2_out_freq:
-            # return a value on the threshold if we don't have information
-            c1_outs = set(c1_out_freq.keys()) if c1_out_freq else set()
-            c2_outs = set(c2_out_freq.keys()) if c2_out_freq else set()
-            nr_outs = len(c1_outs.union(c2_outs))
-            return self.chi2_values[max(1, nr_outs)]
-        keys = list(set(c1_out_freq.keys()).union(c2_out_freq.keys()))
-        shared_keys = set(c1_out_freq.keys()).intersection(c2_out_freq.keys())
-        dof = len(keys) - 1
-        if dof == 0:
-            return 0
-        Q = self.compute_Q(c1_out_freq, c2_out_freq, keys)
-        return Q
-
-    def compute_Q(self, c1_out_freq, c2_out_freq, keys):
-        n_1 = sum(c1_out_freq.values())
-        n_2 = sum(c2_out_freq.values())
-
-        Q = 0
-        default_val = 0
-        yates_correction = -0.5 if len(keys) == 2 and \
-                                   any(c1_out_freq.get(k, 0) < 5 or c2_out_freq.get(k, 0) < 5 for k in keys) else 0
-        for k in keys:
-            p_hat_k = float(c1_out_freq.get(k, default_val) + c2_out_freq.get(k, default_val)) / (n_1 + n_2)
-            q_1_k = float(((abs(c1_out_freq.get(k, default_val) - n_1 * p_hat_k)) + yates_correction) ** 2) / (
-                    n_1 * p_hat_k)
-            q_2_k = float(((abs(c2_out_freq.get(k, default_val) - n_2 * p_hat_k)) + yates_correction) ** 2) / (
-                    n_2 * p_hat_k)
-            Q = Q + q_1_k + q_2_k
-        return Q
+from abc import ABC, abstractmethod
+from math import sqrt, log
+
+chi2_table = dict()
+
+chi2_table[0.95] = \
+    dict([(1, 3.841458820694124), (2, 5.991464547107979), (3, 7.814727903251179), (4, 9.487729036781154),
+          (5, 11.070497693516351), (6, 12.591587243743977), (7, 14.067140449340169), (8, 15.50731305586545),
+          (9, 16.918977604620448), (10, 18.307038053275146), (11, 19.67513757268249), (12, 21.02606981748307),
+          (13, 22.362032494826934), (14, 23.684791304840576), (15, 24.995790139728616), (16, 26.29622760486423),
+          (17, 27.58711163827534), (18, 28.869299430392623), (19, 30.14352720564616), (20, 31.410432844230918)])
+chi2_table[0.99] = \
+    dict([(1, 6.6348966010212145), (2, 9.21034037197618), (3, 11.344866730144373), (4, 13.276704135987622),
+          (5, 15.08627246938899), (6, 16.811893829770927), (7, 18.475306906582357), (8, 20.090235029663233),
+          (9, 21.665994333461924), (10, 23.209251158954356), (11, 24.724970311318277), (12, 26.216967305535853),
+          (13, 27.68824961045705), (14, 29.141237740672796), (15, 30.57791416689249), (16, 31.999926908815176),
+          (17, 33.40866360500461), (18, 34.805305734705065), (19, 36.19086912927004), (20, 37.56623478662507)])
+
+chi2_table[0.999] = \
+    dict([(1, 10.827566170662733), (2, 13.815510557964274), (3, 16.26623619623813), (4, 18.46682695290317),
+          (5, 20.515005652432873), (6, 22.457744484825323), (7, 24.321886347856854), (8, 26.12448155837614),
+          (9, 27.877164871256568), (10, 29.58829844507442), (11, 31.264133620239985), (12, 32.90949040736021),
+          (13, 34.52817897487089), (14, 36.12327368039813), (15, 37.69729821835383), (16, 39.252354790768464),
+          (17, 40.79021670690253), (18, 42.31239633167996), (19, 43.82019596451753), (20, 45.31474661812586)])
+
+
+class DifferenceChecker(ABC):
+
+    @abstractmethod
+    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
+        pass
+
+    def difference_value(self, c1: dict, c2: dict):
+        return None
+
+    def use_diff_value(self):
+        return False
+
+
+class HoeffdingChecker(DifferenceChecker):
+
+    def __init__(self, alpha=0.05):
+        self.alpha = alpha
+
+    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
+        if c1.keys() != c2.keys():
+            return True
+
+        n1 = sum(c1.values())
+        n2 = sum(c2.values())
+
+        if n1 > 0 and n2 > 0:
+            for o in c1.keys():
+                if abs(c1[o] / n1 - c2[o] / n2) > \
+                        ((sqrt(1 / n1) + sqrt(1 / n2)) * sqrt(0.5 * log(2 / self.alpha))):
+                    return True
+        return False
+
+
+def compute_epsilon(alpha1, n1):
+    epsilon1 = sqrt((1. / (2 * n1)) * log(2. / alpha1))
+    return epsilon1
+
+
+class AdvancedHoeffdingChecker(DifferenceChecker):
+    def __init__(self, alpha=0.05, use_diff=False):
+        self.alpha = alpha
+        self.use_diff = use_diff
+
+    def are_cells_different(self, c1: dict, c2: dict, **kwargs) -> bool:
+        n1 = sum(c1.values())
+        n2 = sum(c2.values())
+
+        if n1 > 0 and n2 > 0:
+            for o in set(c1.keys()).union(c2.keys()):
+                c1o = c1[o] if o in c1.keys() else 0
+                c2o = c2[o] if o in c2.keys() else 0
+                alpha1 = self.alpha
+                alpha2 = self.alpha
+                epsilon1 = compute_epsilon(alpha1, n1)
+                epsilon2 = compute_epsilon(alpha2, n2)
+
+                if abs(c1o / n1 - c2o / n2) > epsilon1 + epsilon2:
+                    return True
+        return False
+
+    def use_diff_value(self):
+        return self.use_diff
+
+    def difference_value(self, c1_out_freq: dict, c2_out_freq: dict):
+        n1 = 0 if not c1_out_freq else sum(c1_out_freq.values())
+        n2 = 0 if not c2_out_freq else sum(c2_out_freq.values())
+
+        if n1 > 0 and n2 > 0:
+            dist = 0
+            for o in set(c1_out_freq.keys()).union(c2_out_freq.keys()):
+                c1o = c1_out_freq[o] if o in c1_out_freq.keys() else 0
+                c2o = c2_out_freq[o] if o in c2_out_freq.keys() else 0
+                dist += abs(c1o / n1 - c2o / n2)
+            return dist
+        elif n1 > 0 or n2 > 0:
+            alpha1 = self.alpha
+            alpha2 = self.alpha
+            epsilon1 = compute_epsilon(alpha1, max(n1, n2))
+            epsilon2 = compute_epsilon(alpha2, max(n1, n2))
+            return epsilon1 + epsilon2
+        else:
+            return 0
+
+
+class ChiSquareChecker(DifferenceChecker):
+
+    def __init__(self, alpha=0.001, use_diff_value=False):
+        self.alpha = alpha
+        self.chi2_cache = dict()
+        if 1 - self.alpha not in chi2_table.keys():
+            raise ValueError("alpha must be in [0.01,0.001,0.05]")
+        self.chi2_values = chi2_table[1 - self.alpha]
+        self.use_diff = use_diff_value
+
+    def are_cells_different(self, c1_out_freq: dict, c2_out_freq: dict, **kwargs) -> bool:
+        # chi square test for homogeneity (see, for instance: https://online.stat.psu.edu/stat415/lesson/17/17.1)
+        if not c1_out_freq or not c2_out_freq:
+            return False
+        keys = list(set(c1_out_freq.keys()).union(c2_out_freq.keys()))
+        dof = len(keys) - 1
+        if dof == 0:
+            return False
+        shared_keys = set(c1_out_freq.keys()).intersection(c2_out_freq.keys())
+        if len(shared_keys) == 0:
+            # if the supports of the tested frequencies are completely then chi2 makes no sense, use the Hoeffding test
+            # to determine if there are enough observations for a difference
+            hoeffding_checker = AdvancedHoeffdingChecker()
+            return hoeffding_checker.are_cells_different(c1_out_freq, c2_out_freq)
+
+        Q = self.compute_Q(c1_out_freq, c2_out_freq, keys)
+        if dof not in self.chi2_values.keys():
+            raise ValueError("Too many possible outputs, chi2 table needs to be extended.")
+        else:
+            chi2_val = self.chi2_values[dof]
+
+        return Q >= chi2_val
+
+    def use_diff_value(self):
+        return self.use_diff
+
+    def difference_value(self, c1_out_freq: dict, c2_out_freq: dict):
+        if not c1_out_freq or not c2_out_freq:
+            # return a value on the threshold if we don't have information
+            c1_outs = set(c1_out_freq.keys()) if c1_out_freq else set()
+            c2_outs = set(c2_out_freq.keys()) if c2_out_freq else set()
+            nr_outs = len(c1_outs.union(c2_outs))
+            return self.chi2_values[max(1, nr_outs)]
+        keys = list(set(c1_out_freq.keys()).union(c2_out_freq.keys()))
+        shared_keys = set(c1_out_freq.keys()).intersection(c2_out_freq.keys())
+        dof = len(keys) - 1
+        if dof == 0:
+            return 0
+        Q = self.compute_Q(c1_out_freq, c2_out_freq, keys)
+        return Q
+
+    def compute_Q(self, c1_out_freq, c2_out_freq, keys):
+        n_1 = sum(c1_out_freq.values())
+        n_2 = sum(c2_out_freq.values())
+
+        Q = 0
+        default_val = 0
+        yates_correction = -0.5 if len(keys) == 2 and \
+                                   any(c1_out_freq.get(k, 0) < 5 or c2_out_freq.get(k, 0) < 5 for k in keys) else 0
+        for k in keys:
+            p_hat_k = float(c1_out_freq.get(k, default_val) + c2_out_freq.get(k, default_val)) / (n_1 + n_2)
+            q_1_k = float(((abs(c1_out_freq.get(k, default_val) - n_1 * p_hat_k)) + yates_correction) ** 2) / (
+                    n_1 * p_hat_k)
+            q_2_k = float(((abs(c2_out_freq.get(k, default_val) - n_2 * p_hat_k)) + yates_correction) ** 2) / (
+                    n_2 * p_hat_k)
+            Q = Q + q_1_k + q_2_k
+        return Q
```

## aalpy/learning_algs/stochastic/SamplingBasedObservationTable.py

 * *Ordering differences only*

```diff
@@ -1,642 +1,642 @@
-from collections import defaultdict
-
-from aalpy.automata import Mdp, MdpState, StochasticMealyState, StochasticMealyMachine
-from .DifferenceChecker import DifferenceChecker
-from .StochasticTeacher import StochasticTeacher, Node
-from ...utils.HelperFunctions import is_suffix_of
-
-
-class SamplingBasedObservationTable:
-    def __init__(self, input_alphabet: list, automaton_type, teacher: StochasticTeacher,
-                 compatibility_checker: DifferenceChecker,
-                 alpha=0.05, strategy='normal',
-                 cex_processing=None):
-        """Constructor of the observation table. Initial queries are asked in the constructor.
-
-        Args:
-
-          input_alphabet: input alphabet
-          teacher: stochastic teacher
-          alpha: constant used in Hoeffding bound
-
-        """
-        self.compatibility_checker = compatibility_checker
-        assert input_alphabet is not None and teacher is not None
-        self.automaton_type = automaton_type
-
-        self.input_alphabet = [tuple([a]) for a in input_alphabet]
-
-        self.S = list()  # prefixes of S
-        self.E = [tuple([a]) for a in input_alphabet]
-        self.T = defaultdict(dict)
-
-        self.teacher = teacher
-        self.empty_word = tuple()
-        self.alpha = alpha
-        self.strategy = strategy
-        self.cex_processing = cex_processing
-
-        # initial output
-        if automaton_type == 'mdp':
-            self.initial_output = tuple(teacher.initial_value)
-            self.S.append(self.initial_output)
-        else:
-            self.S.append(tuple())
-
-        # Cache
-        self.compatibility_classes_representatives = None
-        self.compatibility_class = dict()
-        self.freq_query_cache = dict()
-
-        self.unambiguity_values = []
-
-    def refine_not_completed_cells(self, n_resample, uniform=False):
-        """
-        Firstly a prefix-tree acceptor is constructed for all non-completed cells and then that tree is used
-        for online testing/sampling.
-
-        Args:
-
-          uniform: if true, all cells will be uniformly sampled (Default value = False)
-          n_resample: Number of resamples
-
-        Returns:
-
-            False if no cells are to be refined, True if refining happened
-        """
-        if self.automaton_type == 'mdp':
-            pta_root = Node(self.initial_output[0])
-        else:
-            pta_root = Node(None)
-
-        dynamic = 0
-        if self.strategy == 'classic':
-            to_refine = []
-            for s in self.S + list(self.get_extended_s()):
-                for e in self.E:
-                    if not self.teacher.complete_query(s, e):
-                        to_refine.append(s + e)
-
-            if not to_refine:
-                return False
-
-            to_refine.sort(key=len, reverse=True)
-
-            for trace in to_refine:
-                self.add_to_PTA(pta_root, trace)
-
-        else:
-            for s in self.S + list(self.get_extended_s()):
-                if uniform:
-                    for e in self.E:
-                        self.add_to_PTA(pta_root, s + e, 1)
-                else:
-                    for e in self.E:
-                        longest_row_trace_prefix = (s + e)[:-1]
-                        while longest_row_trace_prefix not in self.T.keys():
-                            longest_row_trace_prefix = longest_row_trace_prefix[:-1]
-                        row_repr = 0
-                        for r in self.compatibility_classes_representatives:
-                            if self.are_rows_compatible(longest_row_trace_prefix, r):
-                                row_repr += 1
-                        # row_repr can be zero for non-closed
-                        # (int(row_repr - 1 * 2))
-                        uncertainty_value = max((row_repr - 1) * 2, 1)
-                        dynamic += uncertainty_value
-                        self.add_to_PTA(pta_root, s + e, uncertainty_value)
-
-        resample_value = n_resample if self.strategy == 'classic' else max(dynamic // 2, 500)
-
-        for i in range(resample_value):
-            self.teacher.tree_query(pta_root)
-        return True
-
-    def update_obs_table_with_freq_obs(self, element_of_s=None):
-        """
-        Updates cells in the observation table with frequency data. If the row in S has no extension yet, it is
-        generated and its cells populated.
-
-        Args:
-          element_of_s: if not None, selected row and its extensions will be updated (Default value = None)
-
-        Returns:
-
-        """
-        if element_of_s:
-            s_set = element_of_s + list(self.get_extended_s(element_of_s=element_of_s))
-        else:
-            s_set = self.S + list(self.get_extended_s())
-        # s_set = element_of_s if  else self.S + list(self.get_extended_s())
-
-        for s in s_set:
-            for e in self.E:
-                self.T[s][e] = self.teacher.frequency_query(s, e)
-                self.freq_query_cache[s + e] = self.T[s][e]
-
-    def get_extended_s(self, element_of_s=None):
-        """Generator returning all elements of the extended S set.
-
-        Args:
-          element_of_s:  (Default value = None)
-
-        Returns:
-
-        """
-        s_set = element_of_s if element_of_s else self.S
-        for s in s_set:
-            for i in self.input_alphabet:
-                if s + i in self.freq_query_cache.keys():
-                    freq_dict = self.freq_query_cache[s + i]
-                else:
-                    freq_dict = self.teacher.frequency_query(s, i)
-                for out, freq in freq_dict.items():
-                    new_pref = s + i + tuple([out])
-                    if freq > 0 and new_pref not in self.S:
-                        yield new_pref
-
-    def make_closed_and_consistent(self):
-        """
-        Observation table is updated until it is closed and consistent. Note that due the updated notion of row
-        equivalence no sampling is needed.
-        """
-        self.update_compatibility_classes()
-
-        while True:
-            closed, consistent = False, False
-            row_to_close = self.get_row_to_close()
-            if not row_to_close:
-                closed = True
-            if row_to_close:
-                self.S.append(row_to_close)
-                self.update_obs_table_with_freq_obs(element_of_s=[row_to_close])
-                self.update_compatibility_classes()
-
-            consistency_violation = self.get_consistency_violation()
-            if not consistency_violation:
-                consistent = True
-            if consistency_violation:
-                if consistency_violation not in self.E:
-                    self.E.append(consistency_violation)
-                self.update_obs_table_with_freq_obs()
-                self.update_compatibility_classes()
-
-            if closed and consistent:
-                break
-
-    def get_row_to_close(self):
-        """
-        Returns a row that is not closed.
-
-        Returns:
-
-            row that needs to be closed
-        """
-        for lt in self.get_extended_s():
-            row_is_closed = False
-            for r in self.compatibility_classes_representatives:
-                if self.are_rows_compatible(r, lt):
-                    row_is_closed = True
-                    break
-            if not row_is_closed:
-                return lt
-        return None
-
-    def get_consistency_violation(self, ignore=None):
-        """Find and return cause of consistency violation. Only computed on the compatibility class representatives.
-        :return: element of input + element of output + element of e that lead to the inconsistency
-
-        Args:
-          ignore:  (Default value = None)
-
-        Returns:
-
-            i + o + e that violate consistency
-        """
-        if self.cex_processing is not None:
-            return None
-
-        for ind, s1 in enumerate(self.S):
-            for s2 in self.S[ind + 1:]:
-                if self.are_rows_compatible(s1, s2, ignore):
-                    i_o_pairs = [(i, tuple([o])) for i in self.input_alphabet for o in self.T[s1][i].keys()]
-                    for i, o in i_o_pairs:
-                        s1_keys = self.T[s1 + i + o].keys()
-                        s2_keys = self.T[s2 + i + o].keys()
-                        if not s1_keys or not s2_keys:
-                            continue
-
-                        for e in self.E:
-                            if e == ignore:
-                                continue
-                            if self.are_cells_incompatible(s1 + i + o, s2 + i + o, e):
-                                return i + o + e
-        return None
-
-    def get_representative(self, target):
-        """
-
-        Args:
-          target: row in the observation table
-
-        Returns:
-          a representative compatible with the target
-
-        """
-        if self.compatibility_checker.use_diff_value():
-            smallest_diff_value = 2 ** 32
-            best_rep = None
-            if target in self.compatibility_classes_representatives:
-                return target
-            for r in self.compatibility_classes_representatives:
-                if self.automaton_type == "mdp" and r[-1] != target[-1]:
-                    continue
-                if not self.are_rows_compatible(r, target):
-                    continue
-                diff_value = 0
-                row_target = self.T[target]
-                row_r = self.T[r]
-                for e in self.E:
-                    diff_value += self.compatibility_checker.difference_value(row_r.get(e, None),
-                                                                              row_target.get(e, None))
-                if diff_value < smallest_diff_value:
-                    # if smallest_diff_value != 2**32:
-                    #    print("Found a better rep")
-                    smallest_diff_value = diff_value
-                    best_rep = r
-            return best_rep
-        else:
-            if target in self.S:
-                for r in self.compatibility_classes_representatives:
-                    if target == r or target in self.compatibility_class[r]:
-                        return r
-            else:
-                for r in self.compatibility_classes_representatives:
-                    if self.are_rows_compatible(r, target):
-                        return r
-        assert False
-
-    def trim_columns(self):
-        """ """
-        reverse_sorted_E = list(self.E)
-        reverse_sorted_E.sort(key=len, reverse=True)
-        to_remove = []
-        to_keep = []
-        self.update_obs_table_with_freq_obs()
-        self.make_closed_and_consistent()  # need a closed observation table
-
-        for e in reverse_sorted_E:
-            if e in self.input_alphabet:
-                continue
-            contains_dependent = False
-            for other_e in to_keep:
-                if is_suffix_of(e, other_e):
-                    contains_dependent = True
-            if contains_dependent:
-                to_keep.append(e)
-            elif self.get_consistency_violation(e):
-                to_keep.append(e)
-            else:
-                self.E.remove(e)  # need to remove here for get_consistency_violation to work
-                to_remove.append(e)
-
-        for e in to_remove:
-            for s in self.T.keys():
-                if e in self.T[s]:
-                    self.T[s].pop(e)
-
-    def trim(self, hypothesis):
-        """
-        Removes unnecessary rows from the observation table.
-
-        Args:
-          hypothesis: 
-
-        """
-
-        prefix_to_state_dict = {state.prefix: state for state in hypothesis.states}
-
-        to_remove = []
-        for s in self.S:
-            if s in self.compatibility_classes_representatives or s in to_remove:
-                continue
-
-            rep = self.get_representative(s)
-            if self.automaton_type == 'mdp':
-                if 'chaos' in {t[0].output for transitions in prefix_to_state_dict[rep].transitions.values()
-                               for t in transitions}:
-                    continue
-            else:
-                if 'chaos' in {t[1] for transitions in prefix_to_state_dict[rep].transitions.values()
-                               for t in transitions}:
-                    continue
-
-            num_compatible_repr = 0
-            row_is_prefix = False
-            for r in self.compatibility_classes_representatives:
-                if self.are_rows_compatible(r, s):
-                    num_compatible_repr += 1
-                if len(s) < len(r) and s == r[:len(s)]:
-                    row_is_prefix = True
-                    continue
-            if num_compatible_repr != 1 or row_is_prefix:
-                continue
-
-            to_remove.append(s)
-            for otherS in self.S:
-                if s == otherS[:len(s)] and otherS not in to_remove:
-                    to_remove.append(otherS)
-
-        for s in to_remove:
-            self.S.remove(s)
-            self.T.pop(s, None)
-            for i in self.input_alphabet:
-                for o in self.T[s + i]:
-                    self.T.pop(s + i + o, None)
-
-        if not self.cex_processing:
-            self.trim_columns()
-        else:
-            self.update_obs_table_with_freq_obs()
-
-    def stop(self, learning_round, chaos_cex_present, cex, stopping_range_dict, min_rounds=10, max_rounds=None,
-             target_unambiguity=0.99, print_unambiguity=False):
-        """
-        Decide if learning should terminate.
-
-        Args:
-
-          learning_round: current learning round
-          chaos_cex_present: is chaos counterexample present in the hypothesis
-          cex: counterexample found by the eq oracle
-          stopping_range_dict: dictionary where keys are number of last unambiguity values and value is
-          maximum differance allowed between them
-          min_rounds: minimum number of learning rounds (Default value = 5)
-          max_rounds: maximum number of learning rounds (Default value = None)
-          target_unambiguity: percentage of rows with unambiguous representatives (Default value = 0.99)
-          print_unambiguity: if true, current unambiguity rate will be printed (Default value = False)
-
-        Returns:
-
-          True if stopping condition satisfied, false otherwise
-        """
-        if max_rounds:
-            assert min_rounds <= max_rounds
-        if max_rounds and learning_round == max_rounds:
-            return True
-        if chaos_cex_present or cex is not None:
-            return False
-
-        extended_s = list(self.get_extended_s())
-        self.update_compatibility_classes()
-        numerator = 0
-        for row in self.S + extended_s:
-            row_repr = 0
-            for r in self.compatibility_classes_representatives:
-                if self.are_rows_compatible(row, r):
-                    row_repr += 1
-            numerator += 1 if row_repr == 1 else 0
-
-        unambiguous_rows_percentage = numerator / len(self.S + extended_s)
-
-        self.unambiguity_values.append(unambiguous_rows_percentage)
-        if self.strategy != 'classic' and learning_round >= min_rounds:
-            # keys are number of last unambiguity values and value is maximum differance allowed between them
-
-            for num_last, diff in stopping_range_dict.items():
-                if len(self.unambiguity_values) < num_last:
-                    continue
-                last_n_unamb = self.unambiguity_values[-num_last:]
-                if abs(max(last_n_unamb) - min(last_n_unamb) <= diff):
-                    return True
-
-        if print_unambiguity and learning_round % 5 == 0:
-            print(f'Unambiguous rows: {round(unambiguous_rows_percentage * 100, 2)}%;'
-                  f' {numerator} out of {len(self.S + extended_s)}')
-        if learning_round >= min_rounds and unambiguous_rows_percentage >= target_unambiguity:
-            return True
-
-        return False
-
-    def get_unamb_percentage(self):
-        extended_s = list(self.get_extended_s())
-        self.update_compatibility_classes()
-        numerator = 0
-        for row in self.S + extended_s:
-            row_repr = 0
-            for r in self.compatibility_classes_representatives:
-                if self.are_rows_compatible(row, r):
-                    row_repr += 1
-            numerator += 1 if row_repr == 1 else 0
-
-        unambiguous_rows_percentage = numerator / len(self.S + extended_s)
-        return round(unambiguous_rows_percentage * 100, 2)
-
-    def are_cells_incompatible(self, s1, s2, e):
-        """
-        Checks if 2 cells are considered different.
-
-        Args:
-
-          s1: prefix of row s1
-          s2: prefix of row s2
-          e: element of E
-
-        Returns:
-
-          True if cells are different, false otherwise
-
-        """
-        if self.strategy == 'classic':
-            if self.teacher.complete_query(s1, e) and self.teacher.complete_query(s2, e):
-                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e])
-        elif self.strategy == 'normal' or self.strategy == 'chi2':
-            if e in self.T[s1] and e in self.T[s2]:
-                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e])
-        else:
-            if e in self.T[s1] and e in self.T[s2]:
-                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e], s1=s1, s2=s2, e=e)
-        return False
-
-    def are_rows_compatible(self, s1, s2, e_ignore=None):
-        """
-        Check if the rows are compatible.
-        Rows are compatible if all cells are compatible(not different) and their prefixes
-        end in the same output element.
-
-        Args:
-          s1: prefix of row s1
-          s2: prefix of row s2
-          e_ignore: e not considered for the computation of row compatibility (Default value = None)
-
-        Returns:
-          True if rows are compatible, False otherwise
-
-        """
-        if self.automaton_type == 'mdp' and s1[-1] != s2[-1]:
-            return False
-
-        for e in self.E:
-            if e == e_ignore:
-                continue
-            if self.are_cells_incompatible(s1, s2, e):
-                return False
-        return True
-
-    def update_compatibility_classes(self):
-        """Updates the compatibility classes and stores their representatives."""
-        self.compatibility_class.clear()
-
-        class_rank_pair = []
-        for s in self.S:
-            rank = sum([sum(self.T[s][i].values()) for i in self.input_alphabet])
-            class_rank_pair.append((s, rank))
-
-        # sort according to frequency
-        class_rank_pair.sort(key=lambda x: x[1], reverse=True)
-
-        # # sort according to prefix length, and elements of same length sort by value
-        # class_rank_pair = [(s, -rank) for (s, rank) in class_rank_pair]
-        # class_rank_pair.sort(key=lambda x: (len(x[0]), x[1]))
-        # class_rank_pair = [(s, -rank) for (s, rank) in class_rank_pair]
-
-        compatibility_classes = [c[0] for c in class_rank_pair]
-
-        tmp_classes = list(compatibility_classes)
-        not_partitioned = list(self.S)
-
-        representatives = []
-        while not_partitioned:
-            r = tmp_classes.pop(0)
-            not_partitioned.remove(r)
-
-            cg_r = [s for s in not_partitioned if self.are_rows_compatible(r, s)]
-
-            self.compatibility_class[r] = cg_r
-
-            representatives.append(r)
-            for sp in cg_r:
-                not_partitioned.remove(sp)
-                tmp_classes.remove(sp)
-
-        self.compatibility_classes_representatives = representatives
-
-    def chaos_counterexample(self, hypothesis):
-        """ Check whether the chaos state is reachable.
-
-        Args:
-          hypothesis: current hypothesis
-
-        Returns:
-          True if chaos state is reachable, False otherwise
-
-        """
-        for state in hypothesis.states:
-            if self.automaton_type == "mdp" and state.output == "chaos" \
-                    or self.automaton_type == "smm" and state.state_id == "chaos":
-                # we are not interested in chaos state, but in prefix to chaos
-                continue
-            for i in self.input_alphabet:
-                output_states = state.transitions[i[0]]
-                if self.automaton_type == 'mdp':
-                    for (s, _) in output_states:
-                        if s.output == 'chaos':
-                            return True
-                            # return state.prefix + i
-                else:
-                    for (_, o, _) in output_states:
-                        if o == 'chaos':
-                            return True
-                            # return state.prefix
-        return False
-        # return None
-
-    def add_to_PTA(self, pta_root, trace, uncertainty_value=None):
-        """Adds a trace to the PTA. PTA is later used for online sampling. The uncertainty value is added to inputs as
-        frequencies, which specify how often a particular input should be sampled.
-
-        Args:
-          pta_root: root of the prefix tree acceptor
-          trace: trace to add to the PTA
-          uncertainty_value: uncertainty value (Default value = None)
-
-        Returns:
-
-        """
-        curr_node = pta_root
-        start = 1 if self.automaton_type == 'mdp' else 0
-        for index in range(start, len(trace), 2):
-            inp = trace[index]
-            if uncertainty_value:
-                # use frequencies for uncertainties
-                curr_node.input_frequencies[inp] += uncertainty_value
-            # need to add a dummy output in the leaves
-            output = trace[index + 1] if index + 1 < len(trace) else "dummy"
-            child = curr_node.get_child(inp, output)
-            if child:
-                curr_node = child
-            else:
-                new_node = Node(output)
-                curr_node.children[inp][output] = new_node
-                curr_node = new_node
-
-    def generate_hypothesis(self):
-        """Generates the hypothesis from the observation table.
-        :return: current hypothesis
-
-        Args:
-
-        Returns:
-
-        """
-        r_state_map = dict()
-        state_counter = 0
-        for r in self.compatibility_classes_representatives:
-            if self.automaton_type == 'mdp':
-                r_state_map[r] = MdpState(state_id=f's{state_counter}', output=r[-1])
-            else:
-                r_state_map[r] = StochasticMealyState(state_id=f's{state_counter}')
-            r_state_map[r].prefix = r
-
-            state_counter += 1
-        if self.automaton_type == 'mdp':
-            r_state_map['chaos'] = MdpState(state_id=f's{state_counter}', output='chaos')
-            for i in self.input_alphabet:
-                r_state_map['chaos'].transitions[i[0]].append((r_state_map['chaos'], 1.))
-        else:
-            r_state_map['chaos'] = StochasticMealyState(state_id=f'chaos')
-            for i in self.input_alphabet:
-                r_state_map['chaos'].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
-
-        for s in self.compatibility_classes_representatives:
-            for i in self.input_alphabet:
-                freq_dict = self.T[s][i]
-
-                total_sum = sum(freq_dict.values())
-
-                origin_state = s
-                if self.strategy == 'classic' and not self.teacher.complete_query(s, i) \
-                        or self.strategy != 'classic' and i not in self.T[s]:
-                    if self.automaton_type == 'mdp':
-                        r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 1.))
-                    else:
-                        r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
-                else:
-                    if len(freq_dict.items()) == 0:
-                        if self.automaton_type == 'mdp':
-                            r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 1.))
-                        else:
-                            r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
-                    else:
-                        for output, frequency in freq_dict.items():
-                            new_state = self.get_representative(s + i + tuple([output]))
-                            if self.automaton_type == 'mdp':
-                                r_state_map[origin_state].transitions[i[0]].append(
-                                    (r_state_map[new_state], frequency / total_sum))
-                            else:
-                                r_state_map[origin_state].transitions[i[0]].append(
-                                    (r_state_map[new_state], output, frequency / total_sum))
-
-        if self.automaton_type == 'mdp':
-            return Mdp(r_state_map[self.get_representative(self.initial_output)], list(r_state_map.values()))
-        else:
-            return StochasticMealyMachine(r_state_map[tuple()], list(r_state_map.values()))
+from collections import defaultdict
+
+from aalpy.automata import Mdp, MdpState, StochasticMealyState, StochasticMealyMachine
+from .DifferenceChecker import DifferenceChecker
+from .StochasticTeacher import StochasticTeacher, Node
+from ...utils.HelperFunctions import is_suffix_of
+
+
+class SamplingBasedObservationTable:
+    def __init__(self, input_alphabet: list, automaton_type, teacher: StochasticTeacher,
+                 compatibility_checker: DifferenceChecker,
+                 alpha=0.05, strategy='normal',
+                 cex_processing=None):
+        """Constructor of the observation table. Initial queries are asked in the constructor.
+
+        Args:
+
+          input_alphabet: input alphabet
+          teacher: stochastic teacher
+          alpha: constant used in Hoeffding bound
+
+        """
+        self.compatibility_checker = compatibility_checker
+        assert input_alphabet is not None and teacher is not None
+        self.automaton_type = automaton_type
+
+        self.input_alphabet = [tuple([a]) for a in input_alphabet]
+
+        self.S = list()  # prefixes of S
+        self.E = [tuple([a]) for a in input_alphabet]
+        self.T = defaultdict(dict)
+
+        self.teacher = teacher
+        self.empty_word = tuple()
+        self.alpha = alpha
+        self.strategy = strategy
+        self.cex_processing = cex_processing
+
+        # initial output
+        if automaton_type == 'mdp':
+            self.initial_output = tuple(teacher.initial_value)
+            self.S.append(self.initial_output)
+        else:
+            self.S.append(tuple())
+
+        # Cache
+        self.compatibility_classes_representatives = None
+        self.compatibility_class = dict()
+        self.freq_query_cache = dict()
+
+        self.unambiguity_values = []
+
+    def refine_not_completed_cells(self, n_resample, uniform=False):
+        """
+        Firstly a prefix-tree acceptor is constructed for all non-completed cells and then that tree is used
+        for online testing/sampling.
+
+        Args:
+
+          uniform: if true, all cells will be uniformly sampled (Default value = False)
+          n_resample: Number of resamples
+
+        Returns:
+
+            False if no cells are to be refined, True if refining happened
+        """
+        if self.automaton_type == 'mdp':
+            pta_root = Node(self.initial_output[0])
+        else:
+            pta_root = Node(None)
+
+        dynamic = 0
+        if self.strategy == 'classic':
+            to_refine = []
+            for s in self.S + list(self.get_extended_s()):
+                for e in self.E:
+                    if not self.teacher.complete_query(s, e):
+                        to_refine.append(s + e)
+
+            if not to_refine:
+                return False
+
+            to_refine.sort(key=len, reverse=True)
+
+            for trace in to_refine:
+                self.add_to_PTA(pta_root, trace)
+
+        else:
+            for s in self.S + list(self.get_extended_s()):
+                if uniform:
+                    for e in self.E:
+                        self.add_to_PTA(pta_root, s + e, 1)
+                else:
+                    for e in self.E:
+                        longest_row_trace_prefix = (s + e)[:-1]
+                        while longest_row_trace_prefix not in self.T.keys():
+                            longest_row_trace_prefix = longest_row_trace_prefix[:-1]
+                        row_repr = 0
+                        for r in self.compatibility_classes_representatives:
+                            if self.are_rows_compatible(longest_row_trace_prefix, r):
+                                row_repr += 1
+                        # row_repr can be zero for non-closed
+                        # (int(row_repr - 1 * 2))
+                        uncertainty_value = max((row_repr - 1) * 2, 1)
+                        dynamic += uncertainty_value
+                        self.add_to_PTA(pta_root, s + e, uncertainty_value)
+
+        resample_value = n_resample if self.strategy == 'classic' else max(dynamic // 2, 500)
+
+        for i in range(resample_value):
+            self.teacher.tree_query(pta_root)
+        return True
+
+    def update_obs_table_with_freq_obs(self, element_of_s=None):
+        """
+        Updates cells in the observation table with frequency data. If the row in S has no extension yet, it is
+        generated and its cells populated.
+
+        Args:
+          element_of_s: if not None, selected row and its extensions will be updated (Default value = None)
+
+        Returns:
+
+        """
+        if element_of_s:
+            s_set = element_of_s + list(self.get_extended_s(element_of_s=element_of_s))
+        else:
+            s_set = self.S + list(self.get_extended_s())
+        # s_set = element_of_s if  else self.S + list(self.get_extended_s())
+
+        for s in s_set:
+            for e in self.E:
+                self.T[s][e] = self.teacher.frequency_query(s, e)
+                self.freq_query_cache[s + e] = self.T[s][e]
+
+    def get_extended_s(self, element_of_s=None):
+        """Generator returning all elements of the extended S set.
+
+        Args:
+          element_of_s:  (Default value = None)
+
+        Returns:
+
+        """
+        s_set = element_of_s if element_of_s else self.S
+        for s in s_set:
+            for i in self.input_alphabet:
+                if s + i in self.freq_query_cache.keys():
+                    freq_dict = self.freq_query_cache[s + i]
+                else:
+                    freq_dict = self.teacher.frequency_query(s, i)
+                for out, freq in freq_dict.items():
+                    new_pref = s + i + tuple([out])
+                    if freq > 0 and new_pref not in self.S:
+                        yield new_pref
+
+    def make_closed_and_consistent(self):
+        """
+        Observation table is updated until it is closed and consistent. Note that due the updated notion of row
+        equivalence no sampling is needed.
+        """
+        self.update_compatibility_classes()
+
+        while True:
+            closed, consistent = False, False
+            row_to_close = self.get_row_to_close()
+            if not row_to_close:
+                closed = True
+            if row_to_close:
+                self.S.append(row_to_close)
+                self.update_obs_table_with_freq_obs(element_of_s=[row_to_close])
+                self.update_compatibility_classes()
+
+            consistency_violation = self.get_consistency_violation()
+            if not consistency_violation:
+                consistent = True
+            if consistency_violation:
+                if consistency_violation not in self.E:
+                    self.E.append(consistency_violation)
+                self.update_obs_table_with_freq_obs()
+                self.update_compatibility_classes()
+
+            if closed and consistent:
+                break
+
+    def get_row_to_close(self):
+        """
+        Returns a row that is not closed.
+
+        Returns:
+
+            row that needs to be closed
+        """
+        for lt in self.get_extended_s():
+            row_is_closed = False
+            for r in self.compatibility_classes_representatives:
+                if self.are_rows_compatible(r, lt):
+                    row_is_closed = True
+                    break
+            if not row_is_closed:
+                return lt
+        return None
+
+    def get_consistency_violation(self, ignore=None):
+        """Find and return cause of consistency violation. Only computed on the compatibility class representatives.
+        :return: element of input + element of output + element of e that lead to the inconsistency
+
+        Args:
+          ignore:  (Default value = None)
+
+        Returns:
+
+            i + o + e that violate consistency
+        """
+        if self.cex_processing is not None:
+            return None
+
+        for ind, s1 in enumerate(self.S):
+            for s2 in self.S[ind + 1:]:
+                if self.are_rows_compatible(s1, s2, ignore):
+                    i_o_pairs = [(i, tuple([o])) for i in self.input_alphabet for o in self.T[s1][i].keys()]
+                    for i, o in i_o_pairs:
+                        s1_keys = self.T[s1 + i + o].keys()
+                        s2_keys = self.T[s2 + i + o].keys()
+                        if not s1_keys or not s2_keys:
+                            continue
+
+                        for e in self.E:
+                            if e == ignore:
+                                continue
+                            if self.are_cells_incompatible(s1 + i + o, s2 + i + o, e):
+                                return i + o + e
+        return None
+
+    def get_representative(self, target):
+        """
+
+        Args:
+          target: row in the observation table
+
+        Returns:
+          a representative compatible with the target
+
+        """
+        if self.compatibility_checker.use_diff_value():
+            smallest_diff_value = 2 ** 32
+            best_rep = None
+            if target in self.compatibility_classes_representatives:
+                return target
+            for r in self.compatibility_classes_representatives:
+                if self.automaton_type == "mdp" and r[-1] != target[-1]:
+                    continue
+                if not self.are_rows_compatible(r, target):
+                    continue
+                diff_value = 0
+                row_target = self.T[target]
+                row_r = self.T[r]
+                for e in self.E:
+                    diff_value += self.compatibility_checker.difference_value(row_r.get(e, None),
+                                                                              row_target.get(e, None))
+                if diff_value < smallest_diff_value:
+                    # if smallest_diff_value != 2**32:
+                    #    print("Found a better rep")
+                    smallest_diff_value = diff_value
+                    best_rep = r
+            return best_rep
+        else:
+            if target in self.S:
+                for r in self.compatibility_classes_representatives:
+                    if target == r or target in self.compatibility_class[r]:
+                        return r
+            else:
+                for r in self.compatibility_classes_representatives:
+                    if self.are_rows_compatible(r, target):
+                        return r
+        assert False
+
+    def trim_columns(self):
+        """ """
+        reverse_sorted_E = list(self.E)
+        reverse_sorted_E.sort(key=len, reverse=True)
+        to_remove = []
+        to_keep = []
+        self.update_obs_table_with_freq_obs()
+        self.make_closed_and_consistent()  # need a closed observation table
+
+        for e in reverse_sorted_E:
+            if e in self.input_alphabet:
+                continue
+            contains_dependent = False
+            for other_e in to_keep:
+                if is_suffix_of(e, other_e):
+                    contains_dependent = True
+            if contains_dependent:
+                to_keep.append(e)
+            elif self.get_consistency_violation(e):
+                to_keep.append(e)
+            else:
+                self.E.remove(e)  # need to remove here for get_consistency_violation to work
+                to_remove.append(e)
+
+        for e in to_remove:
+            for s in self.T.keys():
+                if e in self.T[s]:
+                    self.T[s].pop(e)
+
+    def trim(self, hypothesis):
+        """
+        Removes unnecessary rows from the observation table.
+
+        Args:
+          hypothesis: 
+
+        """
+
+        prefix_to_state_dict = {state.prefix: state for state in hypothesis.states}
+
+        to_remove = []
+        for s in self.S:
+            if s in self.compatibility_classes_representatives or s in to_remove:
+                continue
+
+            rep = self.get_representative(s)
+            if self.automaton_type == 'mdp':
+                if 'chaos' in {t[0].output for transitions in prefix_to_state_dict[rep].transitions.values()
+                               for t in transitions}:
+                    continue
+            else:
+                if 'chaos' in {t[1] for transitions in prefix_to_state_dict[rep].transitions.values()
+                               for t in transitions}:
+                    continue
+
+            num_compatible_repr = 0
+            row_is_prefix = False
+            for r in self.compatibility_classes_representatives:
+                if self.are_rows_compatible(r, s):
+                    num_compatible_repr += 1
+                if len(s) < len(r) and s == r[:len(s)]:
+                    row_is_prefix = True
+                    continue
+            if num_compatible_repr != 1 or row_is_prefix:
+                continue
+
+            to_remove.append(s)
+            for otherS in self.S:
+                if s == otherS[:len(s)] and otherS not in to_remove:
+                    to_remove.append(otherS)
+
+        for s in to_remove:
+            self.S.remove(s)
+            self.T.pop(s, None)
+            for i in self.input_alphabet:
+                for o in self.T[s + i]:
+                    self.T.pop(s + i + o, None)
+
+        if not self.cex_processing:
+            self.trim_columns()
+        else:
+            self.update_obs_table_with_freq_obs()
+
+    def stop(self, learning_round, chaos_cex_present, cex, stopping_range_dict, min_rounds=10, max_rounds=None,
+             target_unambiguity=0.99, print_unambiguity=False):
+        """
+        Decide if learning should terminate.
+
+        Args:
+
+          learning_round: current learning round
+          chaos_cex_present: is chaos counterexample present in the hypothesis
+          cex: counterexample found by the eq oracle
+          stopping_range_dict: dictionary where keys are number of last unambiguity values and value is
+          maximum differance allowed between them
+          min_rounds: minimum number of learning rounds (Default value = 5)
+          max_rounds: maximum number of learning rounds (Default value = None)
+          target_unambiguity: percentage of rows with unambiguous representatives (Default value = 0.99)
+          print_unambiguity: if true, current unambiguity rate will be printed (Default value = False)
+
+        Returns:
+
+          True if stopping condition satisfied, false otherwise
+        """
+        if max_rounds:
+            assert min_rounds <= max_rounds
+        if max_rounds and learning_round == max_rounds:
+            return True
+        if chaos_cex_present or cex is not None:
+            return False
+
+        extended_s = list(self.get_extended_s())
+        self.update_compatibility_classes()
+        numerator = 0
+        for row in self.S + extended_s:
+            row_repr = 0
+            for r in self.compatibility_classes_representatives:
+                if self.are_rows_compatible(row, r):
+                    row_repr += 1
+            numerator += 1 if row_repr == 1 else 0
+
+        unambiguous_rows_percentage = numerator / len(self.S + extended_s)
+
+        self.unambiguity_values.append(unambiguous_rows_percentage)
+        if self.strategy != 'classic' and learning_round >= min_rounds:
+            # keys are number of last unambiguity values and value is maximum differance allowed between them
+
+            for num_last, diff in stopping_range_dict.items():
+                if len(self.unambiguity_values) < num_last:
+                    continue
+                last_n_unamb = self.unambiguity_values[-num_last:]
+                if abs(max(last_n_unamb) - min(last_n_unamb) <= diff):
+                    return True
+
+        if print_unambiguity and learning_round % 5 == 0:
+            print(f'Unambiguous rows: {round(unambiguous_rows_percentage * 100, 2)}%;'
+                  f' {numerator} out of {len(self.S + extended_s)}')
+        if learning_round >= min_rounds and unambiguous_rows_percentage >= target_unambiguity:
+            return True
+
+        return False
+
+    def get_unamb_percentage(self):
+        extended_s = list(self.get_extended_s())
+        self.update_compatibility_classes()
+        numerator = 0
+        for row in self.S + extended_s:
+            row_repr = 0
+            for r in self.compatibility_classes_representatives:
+                if self.are_rows_compatible(row, r):
+                    row_repr += 1
+            numerator += 1 if row_repr == 1 else 0
+
+        unambiguous_rows_percentage = numerator / len(self.S + extended_s)
+        return round(unambiguous_rows_percentage * 100, 2)
+
+    def are_cells_incompatible(self, s1, s2, e):
+        """
+        Checks if 2 cells are considered different.
+
+        Args:
+
+          s1: prefix of row s1
+          s2: prefix of row s2
+          e: element of E
+
+        Returns:
+
+          True if cells are different, false otherwise
+
+        """
+        if self.strategy == 'classic':
+            if self.teacher.complete_query(s1, e) and self.teacher.complete_query(s2, e):
+                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e])
+        elif self.strategy == 'normal' or self.strategy == 'chi2':
+            if e in self.T[s1] and e in self.T[s2]:
+                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e])
+        else:
+            if e in self.T[s1] and e in self.T[s2]:
+                return self.compatibility_checker.are_cells_different(self.T[s1][e], self.T[s2][e], s1=s1, s2=s2, e=e)
+        return False
+
+    def are_rows_compatible(self, s1, s2, e_ignore=None):
+        """
+        Check if the rows are compatible.
+        Rows are compatible if all cells are compatible(not different) and their prefixes
+        end in the same output element.
+
+        Args:
+          s1: prefix of row s1
+          s2: prefix of row s2
+          e_ignore: e not considered for the computation of row compatibility (Default value = None)
+
+        Returns:
+          True if rows are compatible, False otherwise
+
+        """
+        if self.automaton_type == 'mdp' and s1[-1] != s2[-1]:
+            return False
+
+        for e in self.E:
+            if e == e_ignore:
+                continue
+            if self.are_cells_incompatible(s1, s2, e):
+                return False
+        return True
+
+    def update_compatibility_classes(self):
+        """Updates the compatibility classes and stores their representatives."""
+        self.compatibility_class.clear()
+
+        class_rank_pair = []
+        for s in self.S:
+            rank = sum([sum(self.T[s][i].values()) for i in self.input_alphabet])
+            class_rank_pair.append((s, rank))
+
+        # sort according to frequency
+        class_rank_pair.sort(key=lambda x: x[1], reverse=True)
+
+        # # sort according to prefix length, and elements of same length sort by value
+        # class_rank_pair = [(s, -rank) for (s, rank) in class_rank_pair]
+        # class_rank_pair.sort(key=lambda x: (len(x[0]), x[1]))
+        # class_rank_pair = [(s, -rank) for (s, rank) in class_rank_pair]
+
+        compatibility_classes = [c[0] for c in class_rank_pair]
+
+        tmp_classes = list(compatibility_classes)
+        not_partitioned = list(self.S)
+
+        representatives = []
+        while not_partitioned:
+            r = tmp_classes.pop(0)
+            not_partitioned.remove(r)
+
+            cg_r = [s for s in not_partitioned if self.are_rows_compatible(r, s)]
+
+            self.compatibility_class[r] = cg_r
+
+            representatives.append(r)
+            for sp in cg_r:
+                not_partitioned.remove(sp)
+                tmp_classes.remove(sp)
+
+        self.compatibility_classes_representatives = representatives
+
+    def chaos_counterexample(self, hypothesis):
+        """ Check whether the chaos state is reachable.
+
+        Args:
+          hypothesis: current hypothesis
+
+        Returns:
+          True if chaos state is reachable, False otherwise
+
+        """
+        for state in hypothesis.states:
+            if self.automaton_type == "mdp" and state.output == "chaos" \
+                    or self.automaton_type == "smm" and state.state_id == "chaos":
+                # we are not interested in chaos state, but in prefix to chaos
+                continue
+            for i in self.input_alphabet:
+                output_states = state.transitions[i[0]]
+                if self.automaton_type == 'mdp':
+                    for (s, _) in output_states:
+                        if s.output == 'chaos':
+                            return True
+                            # return state.prefix + i
+                else:
+                    for (_, o, _) in output_states:
+                        if o == 'chaos':
+                            return True
+                            # return state.prefix
+        return False
+        # return None
+
+    def add_to_PTA(self, pta_root, trace, uncertainty_value=None):
+        """Adds a trace to the PTA. PTA is later used for online sampling. The uncertainty value is added to inputs as
+        frequencies, which specify how often a particular input should be sampled.
+
+        Args:
+          pta_root: root of the prefix tree acceptor
+          trace: trace to add to the PTA
+          uncertainty_value: uncertainty value (Default value = None)
+
+        Returns:
+
+        """
+        curr_node = pta_root
+        start = 1 if self.automaton_type == 'mdp' else 0
+        for index in range(start, len(trace), 2):
+            inp = trace[index]
+            if uncertainty_value:
+                # use frequencies for uncertainties
+                curr_node.input_frequencies[inp] += uncertainty_value
+            # need to add a dummy output in the leaves
+            output = trace[index + 1] if index + 1 < len(trace) else "dummy"
+            child = curr_node.get_child(inp, output)
+            if child:
+                curr_node = child
+            else:
+                new_node = Node(output)
+                curr_node.children[inp][output] = new_node
+                curr_node = new_node
+
+    def generate_hypothesis(self):
+        """Generates the hypothesis from the observation table.
+        :return: current hypothesis
+
+        Args:
+
+        Returns:
+
+        """
+        r_state_map = dict()
+        state_counter = 0
+        for r in self.compatibility_classes_representatives:
+            if self.automaton_type == 'mdp':
+                r_state_map[r] = MdpState(state_id=f's{state_counter}', output=r[-1])
+            else:
+                r_state_map[r] = StochasticMealyState(state_id=f's{state_counter}')
+            r_state_map[r].prefix = r
+
+            state_counter += 1
+        if self.automaton_type == 'mdp':
+            r_state_map['chaos'] = MdpState(state_id=f's{state_counter}', output='chaos')
+            for i in self.input_alphabet:
+                r_state_map['chaos'].transitions[i[0]].append((r_state_map['chaos'], 1.))
+        else:
+            r_state_map['chaos'] = StochasticMealyState(state_id=f'chaos')
+            for i in self.input_alphabet:
+                r_state_map['chaos'].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
+
+        for s in self.compatibility_classes_representatives:
+            for i in self.input_alphabet:
+                freq_dict = self.T[s][i]
+
+                total_sum = sum(freq_dict.values())
+
+                origin_state = s
+                if self.strategy == 'classic' and not self.teacher.complete_query(s, i) \
+                        or self.strategy != 'classic' and i not in self.T[s]:
+                    if self.automaton_type == 'mdp':
+                        r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 1.))
+                    else:
+                        r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
+                else:
+                    if len(freq_dict.items()) == 0:
+                        if self.automaton_type == 'mdp':
+                            r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 1.))
+                        else:
+                            r_state_map[origin_state].transitions[i[0]].append((r_state_map['chaos'], 'chaos', 1.))
+                    else:
+                        for output, frequency in freq_dict.items():
+                            new_state = self.get_representative(s + i + tuple([output]))
+                            if self.automaton_type == 'mdp':
+                                r_state_map[origin_state].transitions[i[0]].append(
+                                    (r_state_map[new_state], frequency / total_sum))
+                            else:
+                                r_state_map[origin_state].transitions[i[0]].append(
+                                    (r_state_map[new_state], output, frequency / total_sum))
+
+        if self.automaton_type == 'mdp':
+            return Mdp(r_state_map[self.get_representative(self.initial_output)], list(r_state_map.values()))
+        else:
+            return StochasticMealyMachine(r_state_map[tuple()], list(r_state_map.values()))
```

## aalpy/learning_algs/stochastic/StochasticCexProcessing.py

 * *Ordering differences only*

```diff
@@ -1,130 +1,130 @@
-from aalpy.automata import Mdp
-from aalpy.base import SUL
-
-
-def stochastic_longest_prefix(cex, prefixes):
-    """
-    Counterexample processing based on Shabaz-Groz cex processing.
-
-    Args:
-
-        cex: counterexample
-        prefixes: all prefixes in the observation table
-    Returns:
-
-        Single suffix.
-    """
-    prefixes = list(prefixes)
-    prefixes.sort(key=len, reverse=True)
-
-    trimmed_cex = None
-    trimmed = False
-    for p in prefixes:
-        if p[1::2] == cex[:len(p)][1::2]:
-            trimmed_cex = cex[len(p):]
-            trimmed = True
-            break
-
-    trimmed_cex = trimmed_cex if trimmed else cex
-    trimmed_cex = list(trimmed_cex)
-
-    if not trimmed_cex:
-        return ()
-
-    # get all suffixes and return
-    suffixes = [tuple(trimmed_cex[len(trimmed_cex) - i - 1:]) for i in range(0, len(trimmed_cex), 2)]
-
-    # prefixes
-    # need to pop 0 for MDP, for SMM remove the line
-    # trimmed_cex.pop(0)
-    # prefixes = [tuple(trimmed_cex[:i + 1]) for i in range(0, len(trimmed_cex), 2)]
-
-    return suffixes
-
-
-def stochastic_rs(sul: SUL, cex: tuple, hypothesis):
-    """Riverst-Schapire counter example processing.
-
-    Args:
-
-        sul: system under learning
-        cex: found counterexample
-        hypothesis: hypothesis on which counterexample was found
-    Returns:
-
-        suffixes to be added to the E set
-
-    """
-    # cex_out = self.sul.query(tuple(cex))
-
-    if isinstance(hypothesis, Mdp):
-        cex = cex[1:]
-
-    inputs = tuple(cex[::2])
-    outputs = tuple(cex[1::2])
-    # cex_out = self.teacher.sul.query(cex)
-
-    lower = 1
-    upper = len(inputs) - 2
-
-    while True:
-        hypothesis.reset_to_initial()
-        mid = (lower + upper) // 2
-
-        # arr[:n] -> first n values
-        # arr[n:] -> last n values
-
-        for i, o in zip(inputs[:mid], outputs[:mid]):
-            hypothesis.step_to(i, o)
-
-        s_bracket = hypothesis.current_state.prefix
-
-        # prefix in hyp is reached
-
-        prefix_inputs = s_bracket[1::2] if isinstance(hypothesis, Mdp) else s_bracket[::2]
-        # prefix_outputs = s_bracket[0::2] if isinstance(hypothesis, Mdp) else s_bracket[1::2]
-
-        not_same = False
-
-        prefix_reached = False
-        while not prefix_reached:
-            hypothesis.reset_to_initial()
-            sul.post()
-            sul.pre()
-
-            repeat = False
-            for inp in prefix_inputs:
-                o_sul = sul.step(inp)
-                o_hyp = hypothesis.step_to(inp, o_sul)
-
-                if o_hyp is None:
-                    repeat = True
-                    break
-
-            prefix_reached = not repeat
-
-        for inp in inputs[mid:]:
-
-            o_sul = sul.step(inp)
-            o_hyp = hypothesis.step_to(inp, o_sul)
-
-            if o_hyp is None:
-                not_same = True
-                break
-
-        if not not_same:
-            lower = mid + 1
-            if upper < lower:
-                suffix = cex[(mid + 1) * 2:]
-                break
-        else:
-            upper = mid - 1
-            if upper < lower:
-                suffix = cex[mid * 2:]
-                break
-
-    suffixes = [tuple(suffix[len(suffix) - i - 1:]) for i in range(0, len(suffix), 2)]
-
-    # suffixes = [suffixes[-1]]
-    # print(len(cex), len(suffixes[-1]))
-    return suffixes
+from aalpy.automata import Mdp
+from aalpy.base import SUL
+
+
+def stochastic_longest_prefix(cex, prefixes):
+    """
+    Counterexample processing based on Shabaz-Groz cex processing.
+
+    Args:
+
+        cex: counterexample
+        prefixes: all prefixes in the observation table
+    Returns:
+
+        Single suffix.
+    """
+    prefixes = list(prefixes)
+    prefixes.sort(key=len, reverse=True)
+
+    trimmed_cex = None
+    trimmed = False
+    for p in prefixes:
+        if p[1::2] == cex[:len(p)][1::2]:
+            trimmed_cex = cex[len(p):]
+            trimmed = True
+            break
+
+    trimmed_cex = trimmed_cex if trimmed else cex
+    trimmed_cex = list(trimmed_cex)
+
+    if not trimmed_cex:
+        return ()
+
+    # get all suffixes and return
+    suffixes = [tuple(trimmed_cex[len(trimmed_cex) - i - 1:]) for i in range(0, len(trimmed_cex), 2)]
+
+    # prefixes
+    # need to pop 0 for MDP, for SMM remove the line
+    # trimmed_cex.pop(0)
+    # prefixes = [tuple(trimmed_cex[:i + 1]) for i in range(0, len(trimmed_cex), 2)]
+
+    return suffixes
+
+
+def stochastic_rs(sul: SUL, cex: tuple, hypothesis):
+    """Riverst-Schapire counter example processing.
+
+    Args:
+
+        sul: system under learning
+        cex: found counterexample
+        hypothesis: hypothesis on which counterexample was found
+    Returns:
+
+        suffixes to be added to the E set
+
+    """
+    # cex_out = self.sul.query(tuple(cex))
+
+    if isinstance(hypothesis, Mdp):
+        cex = cex[1:]
+
+    inputs = tuple(cex[::2])
+    outputs = tuple(cex[1::2])
+    # cex_out = self.teacher.sul.query(cex)
+
+    lower = 1
+    upper = len(inputs) - 2
+
+    while True:
+        hypothesis.reset_to_initial()
+        mid = (lower + upper) // 2
+
+        # arr[:n] -> first n values
+        # arr[n:] -> last n values
+
+        for i, o in zip(inputs[:mid], outputs[:mid]):
+            hypothesis.step_to(i, o)
+
+        s_bracket = hypothesis.current_state.prefix
+
+        # prefix in hyp is reached
+
+        prefix_inputs = s_bracket[1::2] if isinstance(hypothesis, Mdp) else s_bracket[::2]
+        # prefix_outputs = s_bracket[0::2] if isinstance(hypothesis, Mdp) else s_bracket[1::2]
+
+        not_same = False
+
+        prefix_reached = False
+        while not prefix_reached:
+            hypothesis.reset_to_initial()
+            sul.post()
+            sul.pre()
+
+            repeat = False
+            for inp in prefix_inputs:
+                o_sul = sul.step(inp)
+                o_hyp = hypothesis.step_to(inp, o_sul)
+
+                if o_hyp is None:
+                    repeat = True
+                    break
+
+            prefix_reached = not repeat
+
+        for inp in inputs[mid:]:
+
+            o_sul = sul.step(inp)
+            o_hyp = hypothesis.step_to(inp, o_sul)
+
+            if o_hyp is None:
+                not_same = True
+                break
+
+        if not not_same:
+            lower = mid + 1
+            if upper < lower:
+                suffix = cex[(mid + 1) * 2:]
+                break
+        else:
+            upper = mid - 1
+            if upper < lower:
+                suffix = cex[mid * 2:]
+                break
+
+    suffixes = [tuple(suffix[len(suffix) - i - 1:]) for i in range(0, len(suffix), 2)]
+
+    # suffixes = [suffixes[-1]]
+    # print(len(cex), len(suffixes[-1]))
+    return suffixes
```

## aalpy/learning_algs/stochastic/StochasticLStar.py

 * *Ordering differences only*

```diff
@@ -1,220 +1,220 @@
-import time
-
-from aalpy.base import SUL, Oracle
-from aalpy.learning_algs.stochastic.DifferenceChecker import AdvancedHoeffdingChecker, HoeffdingChecker, \
-    ChiSquareChecker, DifferenceChecker
-from aalpy.learning_algs.stochastic.SamplingBasedObservationTable import SamplingBasedObservationTable
-from aalpy.learning_algs.stochastic.StochasticCexProcessing import stochastic_longest_prefix, stochastic_rs
-from aalpy.learning_algs.stochastic.StochasticTeacher import StochasticTeacher
-from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table, get_cex_prefixes, \
-    get_available_oracles_and_err_msg
-
-from aalpy.utils.ModelChecking import stop_based_on_confidence
-
-strategies = ['classic', 'normal', 'chi2']
-cex_sampling_options = [None, 'bfs']
-cex_processing_options = [None, 'longest_prefix', 'rs']
-print_options = [0, 1, 2, 3]
-diff_checker_options = {'classic': HoeffdingChecker(),
-                        'chi2': ChiSquareChecker(),
-                        'normal': AdvancedHoeffdingChecker()}
-available_oracles, available_oracles_error_msg = get_available_oracles_and_err_msg()
-
-
-def run_stochastic_Lstar(input_alphabet, sul: SUL, eq_oracle: Oracle, target_unambiguity=0.99,
-                         min_rounds=10, max_rounds=200, automaton_type='mdp', strategy='normal',
-                         cex_processing=None, samples_cex_strategy=None, stopping_range_dict='strict', custom_oracle=False,
-                         return_data=False, property_based_stopping=None, n_c=20, n_resample=100, print_level=2):
-    """
-    Learning of Markov Decision Processes and Stochastic Mealy machines based on 'L*-Based Learning of Markov Decision
-    Processes' and 'Active Model Learning of Stochastic Reactive Systems' by Tappler et al.
-
-    Args:
-
-        input_alphabet: input alphabet
-
-        sul: system under learning
-
-        eq_oracle: equivalence oracle
-
-        target_unambiguity: target unambiguity value (default 0.99)
-
-        min_rounds: minimum number of learning rounds (Default value = 10)
-
-        max_rounds: if learning_rounds >= max_rounds, learning will stop (Default value = 200)
-
-        automaton_type: either 'mdp' or 'smm' (Default value = 'mdp')
-
-        strategy: either one of ['classic', 'normal', 'chi2'] or a object implementing DifferenceChecker class,
-            default value is 'normal'. Classic strategy is the one presented
-            in the seed paper, 'normal' is the updated version and chi2 is based on chi squared.
-
-        cex_processing: cex processing strategy, None , 'longest_prefix' or 'rs' (rs is experimental)
-
-        samples_cex_strategy: strategy for finding counterexamples in the trace tree. None, 'bfs' or
-            "random:<#traces to check:int>:<stop probability for single trace in [0,1)>" eg. random:200:0.2
-
-        stopping_range_dict: Values in form of a dictionary, or 'strict', 'relaxed' to use predefined stopping
-        criteria. Custom values: Dictionary where keys encode the last n unambiguity values which need to be in range
-        of its value in order to perform early stopping. Eg. {5: 0.001, 10: 0.01} would stop if last 5 hypothesis had
-        unambiguity values when max(last_5_vals) - (last_5_vals) <= 0.001.
-
-        property_based_stopping: A tuple containing (path to the properties file, correct values of each property,
-            allowed error for each property. Recommended one is 0.02 (2%)).
-
-        custom_oracle: if True, warning about oracle type will be removed and custom oracle can be used
-
-        return_data: if True, map containing all information like number of queries... will be returned
-            (Default value = False)
-
-        n_c: cutoff for a cell to be considered complete (Default value = 20), only used with 'classic' strategy
-
-        n_resample: resampling size (Default value = 100), only used with 'classic' strategy
-
-        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
-            (Default value = 2)
-
-
-    Returns:
-
-      learned MDP/SMM
-    """
-
-    assert samples_cex_strategy in cex_sampling_options or samples_cex_strategy.startswith('random')
-    assert cex_processing in cex_processing_options
-    assert automaton_type in {'mdp', 'smm'}
-    if not isinstance(stopping_range_dict, dict):
-        assert stopping_range_dict in {'strict', 'relaxed'}
-    if property_based_stopping:
-        assert len(property_based_stopping) == 3
-
-    if strategy in diff_checker_options:
-        compatibility_checker = diff_checker_options[strategy]
-    else:
-        assert isinstance(strategy, DifferenceChecker)
-        compatibility_checker = strategy
-
-    if not custom_oracle and type(eq_oracle) not in available_oracles:
-        raise SystemExit(available_oracles_error_msg)
-
-    if stopping_range_dict == 'strict':
-        stopping_range_dict = {12: 0.001, 18: 0.002, 25: 0.005, 30: 0.01, 35: 0.02}
-    elif stopping_range_dict == 'relaxed':
-        stopping_range_dict = {7: 0.001, 12: 0.003, 17: 0.005, 22: 0.01, 28: 0.02}
-
-    stochastic_teacher = StochasticTeacher(sul, n_c, eq_oracle, automaton_type, compatibility_checker,
-                                           samples_cex_strategy=samples_cex_strategy)
-
-    # This way all steps from eq. oracle will be added to the tree
-    eq_oracle.sul = stochastic_teacher.sul
-
-    observation_table = SamplingBasedObservationTable(input_alphabet, automaton_type,
-                                                      stochastic_teacher, compatibility_checker=compatibility_checker,
-                                                      strategy=strategy,
-                                                      cex_processing=cex_processing)
-
-    start_time = time.time()
-    eq_query_time = 0
-
-    # Ask queries for non-completed cells and update the observation table
-    observation_table.refine_not_completed_cells(n_resample, uniform=True)
-    observation_table.update_obs_table_with_freq_obs()
-
-    learning_rounds = 0
-
-    while True:
-        learning_rounds += 1
-
-        observation_table.make_closed_and_consistent()
-
-        hypothesis = observation_table.generate_hypothesis()
-
-        observation_table.trim(hypothesis)
-
-        # If there is no chaos state is not reachable, remove it from state set
-        chaos_cex_present = observation_table.chaos_counterexample(hypothesis)
-
-        if not chaos_cex_present:
-            if automaton_type == 'mdp':
-                hypothesis.states.remove(next(state for state in hypothesis.states if state.output == 'chaos'))
-            else:
-                hypothesis.states.remove(next(state for state in hypothesis.states if state.state_id == 'chaos'))
-
-        if print_level > 1:
-            print(f'Hypothesis: {learning_rounds}: {len(hypothesis.states)} states.')
-
-        if print_level == 3:
-            print_observation_table(observation_table, 'stochastic')
-
-        cex = None
-
-        if not chaos_cex_present:
-            eq_query_start = time.time()
-            cex = stochastic_teacher.equivalence_query(hypothesis)
-            eq_query_time += time.time() - eq_query_start
-
-        if cex:
-            if print_level == 3:
-                print('Counterexample', cex)
-            # get all prefixes and add them to the S set
-            if cex_processing is None:
-                for pre in get_cex_prefixes(cex, automaton_type):
-                    if pre not in observation_table.S:
-                        observation_table.S.append(pre)
-            else:
-                suffixes = None
-                if cex_processing == 'longest_prefix':
-                    prefixes = observation_table.S + list(observation_table.get_extended_s())
-                    suffixes = [stochastic_longest_prefix(cex, prefixes)[-1]]
-                elif cex_processing == 'rs':
-                    suffixes = stochastic_rs(sul, cex, hypothesis)
-                for suf in suffixes:
-                    if suf not in observation_table.E:
-                        observation_table.E.append(suf)
-                        break
-
-        # Ask queries for non-completed cells and update the observation table
-        refined = observation_table.refine_not_completed_cells(n_resample)
-        observation_table.update_obs_table_with_freq_obs()
-
-        if property_based_stopping and learning_rounds >= min_rounds:
-            # stop based on maximum allowed error
-            if stop_based_on_confidence(hypothesis, property_based_stopping, print_level):
-                break
-        else:
-            # stop based on number of unambiguous rows
-            stop_based_on_unambiguity = observation_table.stop(learning_rounds, chaos_cex_present, cex,
-                                                               stopping_range_dict,
-                                                               target_unambiguity=target_unambiguity,
-                                                               min_rounds=min_rounds, max_rounds=max_rounds,
-                                                               print_unambiguity=print_level > 1)
-            if stop_based_on_unambiguity:
-                break
-
-        if not refined:
-            break
-
-    total_time = round(time.time() - start_time, 2)
-    eq_query_time = round(eq_query_time, 2)
-    learning_time = round(total_time - eq_query_time, 2)
-
-    info = {
-        'learning_rounds': learning_rounds,
-        'automaton_size': len(hypothesis.states),
-        'queries_learning': stochastic_teacher.sul.num_queries - eq_oracle.num_queries,
-        'steps_learning': stochastic_teacher.sul.num_steps - eq_oracle.num_queries,
-        'queries_eq_oracle': eq_oracle.num_queries,
-        'steps_eq_oracle': eq_oracle.num_steps,
-        'learning_time': learning_time,
-        'eq_oracle_time': eq_query_time,
-        'total_time': total_time
-    }
-
-    if print_level > 0:
-        print_learning_info(info)
-
-    if return_data:
-        return hypothesis, info
-
-    return hypothesis
-
+import time
+
+from aalpy.base import SUL, Oracle
+from aalpy.learning_algs.stochastic.DifferenceChecker import AdvancedHoeffdingChecker, HoeffdingChecker, \
+    ChiSquareChecker, DifferenceChecker
+from aalpy.learning_algs.stochastic.SamplingBasedObservationTable import SamplingBasedObservationTable
+from aalpy.learning_algs.stochastic.StochasticCexProcessing import stochastic_longest_prefix, stochastic_rs
+from aalpy.learning_algs.stochastic.StochasticTeacher import StochasticTeacher
+from aalpy.utils.HelperFunctions import print_learning_info, print_observation_table, get_cex_prefixes, \
+    get_available_oracles_and_err_msg
+
+from aalpy.utils.ModelChecking import stop_based_on_confidence
+
+strategies = ['classic', 'normal', 'chi2']
+cex_sampling_options = [None, 'bfs']
+cex_processing_options = [None, 'longest_prefix', 'rs']
+print_options = [0, 1, 2, 3]
+diff_checker_options = {'classic': HoeffdingChecker(),
+                        'chi2': ChiSquareChecker(),
+                        'normal': AdvancedHoeffdingChecker()}
+available_oracles, available_oracles_error_msg = get_available_oracles_and_err_msg()
+
+
+def run_stochastic_Lstar(input_alphabet, sul: SUL, eq_oracle: Oracle, target_unambiguity=0.99,
+                         min_rounds=10, max_rounds=200, automaton_type='mdp', strategy='normal',
+                         cex_processing=None, samples_cex_strategy=None, stopping_range_dict='strict', custom_oracle=False,
+                         return_data=False, property_based_stopping=None, n_c=20, n_resample=100, print_level=2):
+    """
+    Learning of Markov Decision Processes and Stochastic Mealy machines based on 'L*-Based Learning of Markov Decision
+    Processes' and 'Active Model Learning of Stochastic Reactive Systems' by Tappler et al.
+
+    Args:
+
+        input_alphabet: input alphabet
+
+        sul: system under learning
+
+        eq_oracle: equivalence oracle
+
+        target_unambiguity: target unambiguity value (default 0.99)
+
+        min_rounds: minimum number of learning rounds (Default value = 10)
+
+        max_rounds: if learning_rounds >= max_rounds, learning will stop (Default value = 200)
+
+        automaton_type: either 'mdp' or 'smm' (Default value = 'mdp')
+
+        strategy: either one of ['classic', 'normal', 'chi2'] or a object implementing DifferenceChecker class,
+            default value is 'normal'. Classic strategy is the one presented
+            in the seed paper, 'normal' is the updated version and chi2 is based on chi squared.
+
+        cex_processing: cex processing strategy, None , 'longest_prefix' or 'rs' (rs is experimental)
+
+        samples_cex_strategy: strategy for finding counterexamples in the trace tree. None, 'bfs' or
+            "random:<#traces to check:int>:<stop probability for single trace in [0,1)>" eg. random:200:0.2
+
+        stopping_range_dict: Values in form of a dictionary, or 'strict', 'relaxed' to use predefined stopping
+        criteria. Custom values: Dictionary where keys encode the last n unambiguity values which need to be in range
+        of its value in order to perform early stopping. Eg. {5: 0.001, 10: 0.01} would stop if last 5 hypothesis had
+        unambiguity values when max(last_5_vals) - (last_5_vals) <= 0.001.
+
+        property_based_stopping: A tuple containing (path to the properties file, correct values of each property,
+            allowed error for each property. Recommended one is 0.02 (2%)).
+
+        custom_oracle: if True, warning about oracle type will be removed and custom oracle can be used
+
+        return_data: if True, map containing all information like number of queries... will be returned
+            (Default value = False)
+
+        n_c: cutoff for a cell to be considered complete (Default value = 20), only used with 'classic' strategy
+
+        n_resample: resampling size (Default value = 100), only used with 'classic' strategy
+
+        print_level: 0 - None, 1 - just results, 2 - current round and hypothesis size, 3 - educational/debug
+            (Default value = 2)
+
+
+    Returns:
+
+      learned MDP/SMM
+    """
+
+    assert samples_cex_strategy in cex_sampling_options or samples_cex_strategy.startswith('random')
+    assert cex_processing in cex_processing_options
+    assert automaton_type in {'mdp', 'smm'}
+    if not isinstance(stopping_range_dict, dict):
+        assert stopping_range_dict in {'strict', 'relaxed'}
+    if property_based_stopping:
+        assert len(property_based_stopping) == 3
+
+    if strategy in diff_checker_options:
+        compatibility_checker = diff_checker_options[strategy]
+    else:
+        assert isinstance(strategy, DifferenceChecker)
+        compatibility_checker = strategy
+
+    if not custom_oracle and type(eq_oracle) not in available_oracles:
+        raise SystemExit(available_oracles_error_msg)
+
+    if stopping_range_dict == 'strict':
+        stopping_range_dict = {12: 0.001, 18: 0.002, 25: 0.005, 30: 0.01, 35: 0.02}
+    elif stopping_range_dict == 'relaxed':
+        stopping_range_dict = {7: 0.001, 12: 0.003, 17: 0.005, 22: 0.01, 28: 0.02}
+
+    stochastic_teacher = StochasticTeacher(sul, n_c, eq_oracle, automaton_type, compatibility_checker,
+                                           samples_cex_strategy=samples_cex_strategy)
+
+    # This way all steps from eq. oracle will be added to the tree
+    eq_oracle.sul = stochastic_teacher.sul
+
+    observation_table = SamplingBasedObservationTable(input_alphabet, automaton_type,
+                                                      stochastic_teacher, compatibility_checker=compatibility_checker,
+                                                      strategy=strategy,
+                                                      cex_processing=cex_processing)
+
+    start_time = time.time()
+    eq_query_time = 0
+
+    # Ask queries for non-completed cells and update the observation table
+    observation_table.refine_not_completed_cells(n_resample, uniform=True)
+    observation_table.update_obs_table_with_freq_obs()
+
+    learning_rounds = 0
+
+    while True:
+        learning_rounds += 1
+
+        observation_table.make_closed_and_consistent()
+
+        hypothesis = observation_table.generate_hypothesis()
+
+        observation_table.trim(hypothesis)
+
+        # If there is no chaos state is not reachable, remove it from state set
+        chaos_cex_present = observation_table.chaos_counterexample(hypothesis)
+
+        if not chaos_cex_present:
+            if automaton_type == 'mdp':
+                hypothesis.states.remove(next(state for state in hypothesis.states if state.output == 'chaos'))
+            else:
+                hypothesis.states.remove(next(state for state in hypothesis.states if state.state_id == 'chaos'))
+
+        if print_level > 1:
+            print(f'Hypothesis: {learning_rounds}: {len(hypothesis.states)} states.')
+
+        if print_level == 3:
+            print_observation_table(observation_table, 'stochastic')
+
+        cex = None
+
+        if not chaos_cex_present:
+            eq_query_start = time.time()
+            cex = stochastic_teacher.equivalence_query(hypothesis)
+            eq_query_time += time.time() - eq_query_start
+
+        if cex:
+            if print_level == 3:
+                print('Counterexample', cex)
+            # get all prefixes and add them to the S set
+            if cex_processing is None:
+                for pre in get_cex_prefixes(cex, automaton_type):
+                    if pre not in observation_table.S:
+                        observation_table.S.append(pre)
+            else:
+                suffixes = None
+                if cex_processing == 'longest_prefix':
+                    prefixes = observation_table.S + list(observation_table.get_extended_s())
+                    suffixes = [stochastic_longest_prefix(cex, prefixes)[-1]]
+                elif cex_processing == 'rs':
+                    suffixes = stochastic_rs(sul, cex, hypothesis)
+                for suf in suffixes:
+                    if suf not in observation_table.E:
+                        observation_table.E.append(suf)
+                        break
+
+        # Ask queries for non-completed cells and update the observation table
+        refined = observation_table.refine_not_completed_cells(n_resample)
+        observation_table.update_obs_table_with_freq_obs()
+
+        if property_based_stopping and learning_rounds >= min_rounds:
+            # stop based on maximum allowed error
+            if stop_based_on_confidence(hypothesis, property_based_stopping, print_level):
+                break
+        else:
+            # stop based on number of unambiguous rows
+            stop_based_on_unambiguity = observation_table.stop(learning_rounds, chaos_cex_present, cex,
+                                                               stopping_range_dict,
+                                                               target_unambiguity=target_unambiguity,
+                                                               min_rounds=min_rounds, max_rounds=max_rounds,
+                                                               print_unambiguity=print_level > 1)
+            if stop_based_on_unambiguity:
+                break
+
+        if not refined:
+            break
+
+    total_time = round(time.time() - start_time, 2)
+    eq_query_time = round(eq_query_time, 2)
+    learning_time = round(total_time - eq_query_time, 2)
+
+    info = {
+        'learning_rounds': learning_rounds,
+        'automaton_size': len(hypothesis.states),
+        'queries_learning': stochastic_teacher.sul.num_queries - eq_oracle.num_queries,
+        'steps_learning': stochastic_teacher.sul.num_steps - eq_oracle.num_queries,
+        'queries_eq_oracle': eq_oracle.num_queries,
+        'steps_eq_oracle': eq_oracle.num_steps,
+        'learning_time': learning_time,
+        'eq_oracle_time': eq_query_time,
+        'total_time': total_time
+    }
+
+    if print_level > 0:
+        print_learning_info(info)
+
+    if return_data:
+        return hypothesis, info
+
+    return hypothesis
+
```

## aalpy/learning_algs/stochastic/StochasticTeacher.py

 * *Ordering differences only*

```diff
@@ -1,393 +1,393 @@
-from collections import defaultdict
-from random import choice, random
-
-from aalpy.base import SUL
-from aalpy.learning_algs.stochastic.DifferenceChecker import DifferenceChecker
-
-
-class StochasticSUL(SUL):
-    def __init__(self, sul, teacher):
-        super().__init__()
-        self.sul = sul
-        self.teacher = teacher
-
-    def pre(self):
-        self.num_queries += 1
-        self.teacher.back_to_root()
-        return self.sul.pre()
-
-    def post(self):
-        self.sul.post()
-
-    def step(self, letter):
-        self.num_steps += 1
-        out = self.sul.step(letter)
-        self.teacher.add(letter, out)
-        return out
-
-
-class Node:
-    """
-    Node of the cache/multiset of all traces.
-    """
-
-    def __init__(self, output):
-        self.output = output
-        self.frequency = 0
-        self.children = defaultdict(dict)
-        self.input_frequencies = defaultdict(int)
-
-    def get_child(self, inp, out):
-        """
-
-        Args:
-
-            inp: input
-            out: output
-
-        Returns:
-
-            Child with output that equals to `out` reached when performing `inp`. If such child does not exist,
-            return None.
-        """
-        if inp not in self.children.keys() or out not in self.children[inp].keys():
-            return None
-        return self.children[inp][out]
-
-    def get_frequency_sum(self, input_letter):
-        """
-        Returns:
-
-            number of times input was observed in current state
-        """
-        return self.input_frequencies[input_letter]
-
-    def get_output_frequencies(self, input_letter):
-        """
-        Args:
-
-            input_letter: input
-
-        Returns:
-
-            observed outputs and their frequencies for given `input_letter` in the current state
-
-        """
-        if input_letter not in self.children.keys():
-            return dict()
-        return {child.output: child.frequency for child in self.children[input_letter].values()}
-
-
-class StochasticTeacher:
-    """
-    The sampling-based teacher maintains a multiset of traces S for the estimation of output distributions.
-    Whenever new traces are sampled in the course of learning, they are added to S.
-    """
-
-    def __init__(self, sul: SUL, n_c, eq_oracle, automaton_type, compatibility_checker: DifferenceChecker,
-                 samples_cex_strategy=None):
-        self.automaton_type = automaton_type
-        if automaton_type == 'mdp':
-            self.initial_value = sul.query(tuple())
-            self.root_node = Node(self.initial_value[-1])
-        else:
-            self.root_node = Node(None)
-
-        self.sul = StochasticSUL(sul=sul, teacher=self)
-
-        self.eq_oracle = eq_oracle
-        self.n_c = n_c
-
-        self.curr_node = None
-        # cache
-        self.complete_query_cache = set()
-        self.compatibility_checker = compatibility_checker
-        self.samples_cex_strategy = samples_cex_strategy
-
-        # eq query cache
-        self.last_cex = None
-        self.last_tree_cex = None
-
-    def back_to_root(self):
-        self.curr_node = self.root_node
-
-    def add(self, inp, out):
-        """
-        Adds a input/output to the tree.
-
-        Args:
-
-            inp: input
-            out: output
-
-
-        """
-        self.curr_node.input_frequencies[inp] += 1
-        if inp not in self.curr_node.children.keys() or out not in self.curr_node.children[inp].keys():
-            node = Node(out)
-            self.curr_node.children[inp][out] = node
-
-        self.curr_node = self.curr_node.children[inp][out]
-        self.curr_node.frequency += 1
-
-    def frequency_query(self, s: tuple, e: tuple):
-        """Output frequencies observed after trace s + e.
-
-        Args:
-
-            s: sequence from S set
-            e: sequence from E set
-
-
-        Returns:
-
-            sum of output frequencies
-
-        """
-        if self.automaton_type == 'mdp':
-            s = s[1:]
-
-        input_seq = list(s[0::2] + e[0::2])
-        output_seq = list(s[1::2] + e[1::2])
-
-        last_input = input_seq.pop()
-
-        curr_node = self.root_node
-        for i, o in zip(input_seq, output_seq):
-            curr_node = curr_node.get_child(i, o)
-            if not curr_node:
-                return dict()
-
-        output_freq = curr_node.get_output_frequencies(last_input)
-        if sum(output_freq.values()) >= self.n_c:
-            self.complete_query_cache.add(s + e)
-        return output_freq
-
-    def complete_query(self, s: tuple, e: tuple):
-        """
-        Given a test sequences returns true if sufficient information is available to estimate an output distribution
-        from frequency queries; returns false otherwise.
-
-        Args:
-
-            s: sequence from S set
-            e: sequence from E set
-
-        Returns:
-
-            True if cell is completed, false otherwise
-
-        """
-
-        # extract inputs and outputs
-        if s + e in self.complete_query_cache:
-            return True
-
-        if self.automaton_type == 'mdp':
-            s = s[1:]
-
-        input_seq = list(s[0::2] + e[0::2])
-        output_seq = list(s[1::2] + e[1::2])
-
-        # get last input
-        last_input = input_seq.pop()
-
-        curr_node = self.root_node
-        for i, o in zip(input_seq, output_seq):
-            new_node = curr_node.get_child(i, o)
-            if not new_node:
-                curr_node_complete = curr_node.get_frequency_sum(i) >= self.n_c
-                # if curr_node_complete:
-                #     self.complete_query_cache.add(s + e)
-                return curr_node_complete
-            else:
-                curr_node = new_node
-
-        sum_freq = curr_node.get_frequency_sum(last_input)
-        if sum_freq >= self.n_c:
-            self.complete_query_cache.add(s + e)
-        return sum_freq >= self.n_c
-
-    def tree_query(self, pta_root):
-        """
-        Execute a refine query based on input/output trace. If at some point real outputs differ from expected
-        outputs, trace to that point is added to the tree, otherwise whole trace is executed.
-
-        Args:
-
-            pta_root: root of the PTA
-
-        Returns:
-
-            number of steps taken
-
-        """
-        self.sul.pre()
-        curr_node = pta_root
-
-        inputs = []
-        outputs = []
-
-        while True:
-
-            if curr_node.children:
-                frequency_sum = sum(curr_node.input_frequencies.values())
-                if frequency_sum == 0:
-                    # uniform sampling in case we have no information
-                    inp = choice(list(curr_node.children.keys()))
-                else:
-                    # use float random rather than integers to be able to work with non-integer frequency information
-                    selection_value = random() * frequency_sum
-                    inp = None
-                    for i in curr_node.input_frequencies.keys():
-                        inp = i
-                        selection_value -= curr_node.input_frequencies[i]
-                        if selection_value <= 0:
-                            break
-                    # curr_node.input_frequencies[inp] -= 1
-
-                inputs.append(inp)
-                out = self.sul.step(inp)
-                new_node = curr_node.get_child(inp, out)
-
-                if new_node:
-                    outputs.append(out)
-                    curr_node = new_node
-                else:
-                    self.sul.post()
-                    return
-            else:
-                curr_node = pta_root
-                for i, o in zip(inputs, outputs):
-                    self.curr_node.input_frequencies[i] -= 1
-                    curr_node = curr_node.get_child(i, o)
-                self.sul.post()
-                return
-
-    def single_dfs_for_cex(self, stop_prob, hypothesis):
-        curr_node = self.root_node
-        curr_state = hypothesis.initial_state
-        if self.automaton_type == "mdp":
-            trace = tuple(self.initial_value)
-        else:
-            trace = ()
-
-        while True:
-            rep_trace = curr_state.prefix
-            if trace != rep_trace:
-                for i in curr_node.children.keys():
-                    freq_in_tree = self.frequency_query(trace, (i,))
-                    freq_in_hyp = self.frequency_query(rep_trace, (i,))
-                    if self.compatibility_checker.are_cells_different(freq_in_tree, freq_in_hyp):
-                        return trace + (i,)
-            # choose next node randomly and return None if there is no next node
-            if not curr_node.children:
-                return None
-            i = choice(list(curr_node.children.keys()))
-            if not curr_node.children[i]:
-                return None
-            c = choice(list(curr_node.children[i].values()))
-            o = c.output
-            if self.automaton_type == 'mdp':
-                next_state = next(
-                    (out_state[0] for out_state in curr_state.transitions[i] if out_state[0].output == o), None)
-            else:
-                next_state = next((out_state[0] for out_state in curr_state.transitions[i] if out_state[1] == o),
-                                  None)
-            if not next_state:
-                return trace + (i,)
-            if random() <= stop_prob:
-                return None
-            else:
-                curr_node = c
-                curr_state = next_state
-                trace = trace + (i,) + (o,)
-
-    def dfs_for_cex_in_tree(self, hypothesis, nr_traces, stop_prob):
-        for i in range(nr_traces):
-            cex = self.single_dfs_for_cex(stop_prob, hypothesis)
-            if cex:
-                return cex
-        return None
-
-    def bfs_for_cex_in_tree(self, hypothesis):
-        # BFS for cex
-        if self.automaton_type == "mdp":
-            to_check = [(self.root_node, hypothesis.initial_state, tuple(self.initial_value))]
-        else:
-            to_check = [(self.root_node, hypothesis.initial_state, ())]
-
-        while to_check:
-            (curr_node, curr_state, trace) = to_check.pop(0)
-            rep_trace = curr_state.prefix
-            if trace != rep_trace:
-                for i in curr_node.children.keys():
-                    freq_in_tree = self.frequency_query(trace, (i,))
-                    freq_in_hyp = self.frequency_query(rep_trace, (i,))
-                    if self.compatibility_checker.are_cells_different(freq_in_tree, freq_in_hyp):
-                        return trace + (i,)
-            for i in curr_node.children.keys():
-                for c in curr_node.children[i].values():
-                    o = c.output
-                    if self.automaton_type == 'mdp':
-                        next_state = next((out_state[0] for out_state in curr_state.transitions[i]
-                                           if out_state[0].output == o), None)
-                    else:
-                        next_state = next((out_state[0] for out_state in curr_state.transitions[i]
-                                           if out_state[1] == o), None)
-                    if not next_state:
-                        return trace + (i,)
-                    new_trace = trace + (i,) + (o,)
-                    to_check.append((c, next_state, new_trace))
-        return None
-
-    def equivalence_query(self, hypothesis):
-        """
-        Finds and returns a counterexample
-
-        Args:
-
-            hypothesis: current hypothesis
-
-        Returns:
-
-            counterexample
-
-        """
-        if self.last_cex and not self.is_cex_processed(hypothesis, self.last_cex):
-            return self.last_cex
-
-        if self.samples_cex_strategy:
-            cex = None
-            if self.samples_cex_strategy == 'bfs':
-                cex = self.bfs_for_cex_in_tree(hypothesis)
-            elif self.samples_cex_strategy.startswith('random'):
-                split_strategy = self.samples_cex_strategy.split(":")
-                try:
-                    nr_traces = int(split_strategy[1])
-                    stop_prob = float(split_strategy[2])
-                    cex = self.dfs_for_cex_in_tree(hypothesis, nr_traces, stop_prob)
-                except Exception as e:
-                    print("Problem in random DFS for cex in samples:", e)
-            if cex:
-                self.last_cex = cex
-                self.eq_oracle.reset_counter()
-                return cex
-
-        cex = self.eq_oracle.find_cex(hypothesis)
-        if cex:  # remove last output
-            cex = cex[:-1]
-        self.last_cex = cex
-        return cex
-
-    def is_cex_processed(self, hypothesis, cex):
-        if self.automaton_type == 'mdp':
-            cex = cex[1:]
-        last_inp = cex[-1]
-        hypothesis.reset_to_initial()
-        for i in range(0, len(cex) - 1, 2):
-            o = hypothesis.step_to(cex[i], cex[i + 1])
-            if o is None:
-                return False
-        o = hypothesis.step(last_inp)
-        return o is not None
+from collections import defaultdict
+from random import choice, random
+
+from aalpy.base import SUL
+from aalpy.learning_algs.stochastic.DifferenceChecker import DifferenceChecker
+
+
+class StochasticSUL(SUL):
+    def __init__(self, sul, teacher):
+        super().__init__()
+        self.sul = sul
+        self.teacher = teacher
+
+    def pre(self):
+        self.num_queries += 1
+        self.teacher.back_to_root()
+        return self.sul.pre()
+
+    def post(self):
+        self.sul.post()
+
+    def step(self, letter):
+        self.num_steps += 1
+        out = self.sul.step(letter)
+        self.teacher.add(letter, out)
+        return out
+
+
+class Node:
+    """
+    Node of the cache/multiset of all traces.
+    """
+
+    def __init__(self, output):
+        self.output = output
+        self.frequency = 0
+        self.children = defaultdict(dict)
+        self.input_frequencies = defaultdict(int)
+
+    def get_child(self, inp, out):
+        """
+
+        Args:
+
+            inp: input
+            out: output
+
+        Returns:
+
+            Child with output that equals to `out` reached when performing `inp`. If such child does not exist,
+            return None.
+        """
+        if inp not in self.children.keys() or out not in self.children[inp].keys():
+            return None
+        return self.children[inp][out]
+
+    def get_frequency_sum(self, input_letter):
+        """
+        Returns:
+
+            number of times input was observed in current state
+        """
+        return self.input_frequencies[input_letter]
+
+    def get_output_frequencies(self, input_letter):
+        """
+        Args:
+
+            input_letter: input
+
+        Returns:
+
+            observed outputs and their frequencies for given `input_letter` in the current state
+
+        """
+        if input_letter not in self.children.keys():
+            return dict()
+        return {child.output: child.frequency for child in self.children[input_letter].values()}
+
+
+class StochasticTeacher:
+    """
+    The sampling-based teacher maintains a multiset of traces S for the estimation of output distributions.
+    Whenever new traces are sampled in the course of learning, they are added to S.
+    """
+
+    def __init__(self, sul: SUL, n_c, eq_oracle, automaton_type, compatibility_checker: DifferenceChecker,
+                 samples_cex_strategy=None):
+        self.automaton_type = automaton_type
+        if automaton_type == 'mdp':
+            self.initial_value = sul.query(tuple())
+            self.root_node = Node(self.initial_value[-1])
+        else:
+            self.root_node = Node(None)
+
+        self.sul = StochasticSUL(sul=sul, teacher=self)
+
+        self.eq_oracle = eq_oracle
+        self.n_c = n_c
+
+        self.curr_node = None
+        # cache
+        self.complete_query_cache = set()
+        self.compatibility_checker = compatibility_checker
+        self.samples_cex_strategy = samples_cex_strategy
+
+        # eq query cache
+        self.last_cex = None
+        self.last_tree_cex = None
+
+    def back_to_root(self):
+        self.curr_node = self.root_node
+
+    def add(self, inp, out):
+        """
+        Adds a input/output to the tree.
+
+        Args:
+
+            inp: input
+            out: output
+
+
+        """
+        self.curr_node.input_frequencies[inp] += 1
+        if inp not in self.curr_node.children.keys() or out not in self.curr_node.children[inp].keys():
+            node = Node(out)
+            self.curr_node.children[inp][out] = node
+
+        self.curr_node = self.curr_node.children[inp][out]
+        self.curr_node.frequency += 1
+
+    def frequency_query(self, s: tuple, e: tuple):
+        """Output frequencies observed after trace s + e.
+
+        Args:
+
+            s: sequence from S set
+            e: sequence from E set
+
+
+        Returns:
+
+            sum of output frequencies
+
+        """
+        if self.automaton_type == 'mdp':
+            s = s[1:]
+
+        input_seq = list(s[0::2] + e[0::2])
+        output_seq = list(s[1::2] + e[1::2])
+
+        last_input = input_seq.pop()
+
+        curr_node = self.root_node
+        for i, o in zip(input_seq, output_seq):
+            curr_node = curr_node.get_child(i, o)
+            if not curr_node:
+                return dict()
+
+        output_freq = curr_node.get_output_frequencies(last_input)
+        if sum(output_freq.values()) >= self.n_c:
+            self.complete_query_cache.add(s + e)
+        return output_freq
+
+    def complete_query(self, s: tuple, e: tuple):
+        """
+        Given a test sequences returns true if sufficient information is available to estimate an output distribution
+        from frequency queries; returns false otherwise.
+
+        Args:
+
+            s: sequence from S set
+            e: sequence from E set
+
+        Returns:
+
+            True if cell is completed, false otherwise
+
+        """
+
+        # extract inputs and outputs
+        if s + e in self.complete_query_cache:
+            return True
+
+        if self.automaton_type == 'mdp':
+            s = s[1:]
+
+        input_seq = list(s[0::2] + e[0::2])
+        output_seq = list(s[1::2] + e[1::2])
+
+        # get last input
+        last_input = input_seq.pop()
+
+        curr_node = self.root_node
+        for i, o in zip(input_seq, output_seq):
+            new_node = curr_node.get_child(i, o)
+            if not new_node:
+                curr_node_complete = curr_node.get_frequency_sum(i) >= self.n_c
+                # if curr_node_complete:
+                #     self.complete_query_cache.add(s + e)
+                return curr_node_complete
+            else:
+                curr_node = new_node
+
+        sum_freq = curr_node.get_frequency_sum(last_input)
+        if sum_freq >= self.n_c:
+            self.complete_query_cache.add(s + e)
+        return sum_freq >= self.n_c
+
+    def tree_query(self, pta_root):
+        """
+        Execute a refine query based on input/output trace. If at some point real outputs differ from expected
+        outputs, trace to that point is added to the tree, otherwise whole trace is executed.
+
+        Args:
+
+            pta_root: root of the PTA
+
+        Returns:
+
+            number of steps taken
+
+        """
+        self.sul.pre()
+        curr_node = pta_root
+
+        inputs = []
+        outputs = []
+
+        while True:
+
+            if curr_node.children:
+                frequency_sum = sum(curr_node.input_frequencies.values())
+                if frequency_sum == 0:
+                    # uniform sampling in case we have no information
+                    inp = choice(list(curr_node.children.keys()))
+                else:
+                    # use float random rather than integers to be able to work with non-integer frequency information
+                    selection_value = random() * frequency_sum
+                    inp = None
+                    for i in curr_node.input_frequencies.keys():
+                        inp = i
+                        selection_value -= curr_node.input_frequencies[i]
+                        if selection_value <= 0:
+                            break
+                    # curr_node.input_frequencies[inp] -= 1
+
+                inputs.append(inp)
+                out = self.sul.step(inp)
+                new_node = curr_node.get_child(inp, out)
+
+                if new_node:
+                    outputs.append(out)
+                    curr_node = new_node
+                else:
+                    self.sul.post()
+                    return
+            else:
+                curr_node = pta_root
+                for i, o in zip(inputs, outputs):
+                    self.curr_node.input_frequencies[i] -= 1
+                    curr_node = curr_node.get_child(i, o)
+                self.sul.post()
+                return
+
+    def single_dfs_for_cex(self, stop_prob, hypothesis):
+        curr_node = self.root_node
+        curr_state = hypothesis.initial_state
+        if self.automaton_type == "mdp":
+            trace = tuple(self.initial_value)
+        else:
+            trace = ()
+
+        while True:
+            rep_trace = curr_state.prefix
+            if trace != rep_trace:
+                for i in curr_node.children.keys():
+                    freq_in_tree = self.frequency_query(trace, (i,))
+                    freq_in_hyp = self.frequency_query(rep_trace, (i,))
+                    if self.compatibility_checker.are_cells_different(freq_in_tree, freq_in_hyp):
+                        return trace + (i,)
+            # choose next node randomly and return None if there is no next node
+            if not curr_node.children:
+                return None
+            i = choice(list(curr_node.children.keys()))
+            if not curr_node.children[i]:
+                return None
+            c = choice(list(curr_node.children[i].values()))
+            o = c.output
+            if self.automaton_type == 'mdp':
+                next_state = next(
+                    (out_state[0] for out_state in curr_state.transitions[i] if out_state[0].output == o), None)
+            else:
+                next_state = next((out_state[0] for out_state in curr_state.transitions[i] if out_state[1] == o),
+                                  None)
+            if not next_state:
+                return trace + (i,)
+            if random() <= stop_prob:
+                return None
+            else:
+                curr_node = c
+                curr_state = next_state
+                trace = trace + (i,) + (o,)
+
+    def dfs_for_cex_in_tree(self, hypothesis, nr_traces, stop_prob):
+        for i in range(nr_traces):
+            cex = self.single_dfs_for_cex(stop_prob, hypothesis)
+            if cex:
+                return cex
+        return None
+
+    def bfs_for_cex_in_tree(self, hypothesis):
+        # BFS for cex
+        if self.automaton_type == "mdp":
+            to_check = [(self.root_node, hypothesis.initial_state, tuple(self.initial_value))]
+        else:
+            to_check = [(self.root_node, hypothesis.initial_state, ())]
+
+        while to_check:
+            (curr_node, curr_state, trace) = to_check.pop(0)
+            rep_trace = curr_state.prefix
+            if trace != rep_trace:
+                for i in curr_node.children.keys():
+                    freq_in_tree = self.frequency_query(trace, (i,))
+                    freq_in_hyp = self.frequency_query(rep_trace, (i,))
+                    if self.compatibility_checker.are_cells_different(freq_in_tree, freq_in_hyp):
+                        return trace + (i,)
+            for i in curr_node.children.keys():
+                for c in curr_node.children[i].values():
+                    o = c.output
+                    if self.automaton_type == 'mdp':
+                        next_state = next((out_state[0] for out_state in curr_state.transitions[i]
+                                           if out_state[0].output == o), None)
+                    else:
+                        next_state = next((out_state[0] for out_state in curr_state.transitions[i]
+                                           if out_state[1] == o), None)
+                    if not next_state:
+                        return trace + (i,)
+                    new_trace = trace + (i,) + (o,)
+                    to_check.append((c, next_state, new_trace))
+        return None
+
+    def equivalence_query(self, hypothesis):
+        """
+        Finds and returns a counterexample
+
+        Args:
+
+            hypothesis: current hypothesis
+
+        Returns:
+
+            counterexample
+
+        """
+        if self.last_cex and not self.is_cex_processed(hypothesis, self.last_cex):
+            return self.last_cex
+
+        if self.samples_cex_strategy:
+            cex = None
+            if self.samples_cex_strategy == 'bfs':
+                cex = self.bfs_for_cex_in_tree(hypothesis)
+            elif self.samples_cex_strategy.startswith('random'):
+                split_strategy = self.samples_cex_strategy.split(":")
+                try:
+                    nr_traces = int(split_strategy[1])
+                    stop_prob = float(split_strategy[2])
+                    cex = self.dfs_for_cex_in_tree(hypothesis, nr_traces, stop_prob)
+                except Exception as e:
+                    print("Problem in random DFS for cex in samples:", e)
+            if cex:
+                self.last_cex = cex
+                self.eq_oracle.reset_counter()
+                return cex
+
+        cex = self.eq_oracle.find_cex(hypothesis)
+        if cex:  # remove last output
+            cex = cex[:-1]
+        self.last_cex = cex
+        return cex
+
+    def is_cex_processed(self, hypothesis, cex):
+        if self.automaton_type == 'mdp':
+            cex = cex[1:]
+        last_inp = cex[-1]
+        hypothesis.reset_to_initial()
+        for i in range(0, len(cex) - 1, 2):
+            o = hypothesis.step_to(cex[i], cex[i + 1])
+            if o is None:
+                return False
+        o = hypothesis.step(last_inp)
+        return o is not None
```

## aalpy/learning_algs/stochastic_passive/ActiveAleriga.py

 * *Ordering differences only*

```diff
@@ -1,88 +1,88 @@
-from abc import ABC, abstractmethod
-from random import randint, choice
-
-from aalpy.learning_algs import run_Alergia
-
-
-class Sampler(ABC):
-    """
-    Abstract class whose implementations are used to provide samples for active passive learning.
-    """
-
-    @abstractmethod
-    def sample(self, sul, model):
-        """
-        Abstract method implementing sampling strategy.
-
-        Args:
-
-            sul: system under learning
-            model: current learned model
-
-        Returns:
-
-            Data to be added to the data set for the passive learnign.
-
-        """
-        pass
-
-
-class RandomWordSampler(Sampler):
-    def __init__(self, num_walks, min_walk_len, max_walk_len):
-        self.num_walks = num_walks
-        self.min_walk_len = min_walk_len
-        self.max_walk_len = max_walk_len
-
-    def sample(self, sul, model):
-        input_al = list({el for s in model.states for el in s.transitions.keys()})
-        samples = []
-
-        for _ in range(self.num_walks):
-            walk_len = randint(self.min_walk_len, self.max_walk_len)
-            random_walk = tuple(choice(input_al) for _ in range(walk_len))
-
-            outputs = sul.query(random_walk)
-
-            sample = [outputs.pop(0)]
-            for i in range(len(outputs)):
-                sample.append((random_walk[i], outputs[i]))
-
-            samples.append(sample)
-
-        return samples
-
-
-def run_active_Alergia(data, sul, sampler, n_iter, eps=0.05, compatibility_checker=None, automaton_type='mdp',
-                       print_info=True):
-    """
-    Active version of IOAlergia algorithm. Based on intermediate hypothesis sampling on the system is performed.
-    Sampled data is added to the learning data and more accurate model is learned.
-    Proposed in "Aichernig and Tappler, Probabilistic Black-Box Reachability Checking"
-
-    Args:
-
-        data: initial learning data, in form [[O, (I,O), (I,O)...] ,...] where O is outputs and I input.
-        sul: system under learning which is basis for sampling
-        sampler: instance of Sampler class
-        n_iter: number of iterations of active learning
-        eps: epsilon value if the default checker is used. Look in run_Alergia for description
-        compatibility_checker: passed to run_Alergia, check there for description
-        automaton_type: either 'mdp' or 'smm' (Markov decision process or Stochastic Mealy Machine)
-        print_info: print current learning iteration
-
-    Returns:
-
-        learned MDP
-
-    """
-    model = None
-    for i in range(n_iter):
-        if print_info:
-            print(f'Active Alergia Iteration: {i}')
-        model = run_Alergia(data, automaton_type='mdp', eps=eps, compatibility_checker=compatibility_checker)
-
-        new_samples = sampler.sample(sul, model)
-        data.extend(new_samples)
-
-    return model
-
+from abc import ABC, abstractmethod
+from random import randint, choice
+
+from aalpy.learning_algs import run_Alergia
+
+
+class Sampler(ABC):
+    """
+    Abstract class whose implementations are used to provide samples for active passive learning.
+    """
+
+    @abstractmethod
+    def sample(self, sul, model):
+        """
+        Abstract method implementing sampling strategy.
+
+        Args:
+
+            sul: system under learning
+            model: current learned model
+
+        Returns:
+
+            Data to be added to the data set for the passive learnign.
+
+        """
+        pass
+
+
+class RandomWordSampler(Sampler):
+    def __init__(self, num_walks, min_walk_len, max_walk_len):
+        self.num_walks = num_walks
+        self.min_walk_len = min_walk_len
+        self.max_walk_len = max_walk_len
+
+    def sample(self, sul, model):
+        input_al = list({el for s in model.states for el in s.transitions.keys()})
+        samples = []
+
+        for _ in range(self.num_walks):
+            walk_len = randint(self.min_walk_len, self.max_walk_len)
+            random_walk = tuple(choice(input_al) for _ in range(walk_len))
+
+            outputs = sul.query(random_walk)
+
+            sample = [outputs.pop(0)]
+            for i in range(len(outputs)):
+                sample.append((random_walk[i], outputs[i]))
+
+            samples.append(sample)
+
+        return samples
+
+
+def run_active_Alergia(data, sul, sampler, n_iter, eps=0.05, compatibility_checker=None, automaton_type='mdp',
+                       print_info=True):
+    """
+    Active version of IOAlergia algorithm. Based on intermediate hypothesis sampling on the system is performed.
+    Sampled data is added to the learning data and more accurate model is learned.
+    Proposed in "Aichernig and Tappler, Probabilistic Black-Box Reachability Checking"
+
+    Args:
+
+        data: initial learning data, in form [[O, (I,O), (I,O)...] ,...] where O is outputs and I input.
+        sul: system under learning which is basis for sampling
+        sampler: instance of Sampler class
+        n_iter: number of iterations of active learning
+        eps: epsilon value if the default checker is used. Look in run_Alergia for description
+        compatibility_checker: passed to run_Alergia, check there for description
+        automaton_type: either 'mdp' or 'smm' (Markov decision process or Stochastic Mealy Machine)
+        print_info: print current learning iteration
+
+    Returns:
+
+        learned MDP
+
+    """
+    model = None
+    for i in range(n_iter):
+        if print_info:
+            print(f'Active Alergia Iteration: {i}')
+        model = run_Alergia(data, automaton_type='mdp', eps=eps, compatibility_checker=compatibility_checker)
+
+        new_samples = sampler.sample(sul, model)
+        data.extend(new_samples)
+
+    return model
+
```

## aalpy/learning_algs/stochastic_passive/Alergia.py

 * *Ordering differences only*

```diff
@@ -1,268 +1,268 @@
-import time
-from bisect import insort
-
-from aalpy.automata import MarkovChain, MdpState, Mdp, McState, StochasticMealyState, \
-    StochasticMealyMachine
-from aalpy.learning_algs.stochastic_passive.CompatibilityChecker import HoeffdingCompatibility
-from aalpy.learning_algs.stochastic_passive.FPTA import create_fpta
-
-state_automaton_map = {'mc': (McState, MarkovChain), 'mdp': (MdpState, Mdp),
-                       'smm': (StochasticMealyState, StochasticMealyMachine)}
-
-
-class Alergia:
-    def __init__(self, data, automaton_type, eps=0.05, compatibility_checker=None, print_info=False):
-        assert eps == 'auto' or 0 < eps <= 2
-
-        self.automaton_type = automaton_type
-        self.print_info = print_info
-
-        if eps == 'auto':
-            eps = 10 / sum(len(d) - 1 for d in data)  # len - 1 to ignore initial output
-
-        self.diff_checker = HoeffdingCompatibility(eps) if not compatibility_checker else compatibility_checker
-
-        pta_start = time.time()
-
-        self.fpta = create_fpta(data, automaton_type)
-
-        pta_time = round(time.time() - pta_start, 2)
-        if self.print_info:
-            print(f'PTA Construction Time:  {pta_time}')
-
-    def compatibility_test(self, a, b):
-
-        # for MDPs and MC output of the state needs to be the same
-        if self.automaton_type != 'smm' and a.output != b.output:
-            return False
-
-        # leaf nodes are merged
-        if not a.original_children.keys() or not b.original_children.keys():
-            return True
-
-        # if states are statistically different, do not merge
-        if self.diff_checker.are_states_different(a, b):
-            return False
-
-        # check future for compatibility
-        for el in set(a.original_children.keys()).intersection(b.original_children.keys()):
-            if not self.compatibility_test(a.original_children[el], b.original_children[el]):
-                return False
-
-        return True
-
-    def merge(self, red_state, blue_state):
-        b_prefix = blue_state.prefix
-        to_update = self.fpta
-        for p in b_prefix[:-1]:
-            to_update = to_update.children[p]
-
-        to_update.children[b_prefix[-1]] = red_state
-
-        self.fold(red_state, blue_state)
-
-    def fold(self, red, blue):
-        for i, blue_child in blue.children.items():
-            if i in red.children:
-                red.input_frequency[i] += blue.input_frequency[i]
-                self.fold(red.children[i], blue_child)
-            else:
-                red.children[i] = blue.children[i]
-                red.input_frequency[i] = blue.input_frequency[i]
-
-    def run(self):
-        start_time = time.time()
-
-        # representative nodes that will be included in the final output model
-        red = [self.fpta]
-        # intermediate successors scheduled for testing
-        blue = self.fpta.successors()
-
-        while blue:
-            # get lexicographically minimal blue node (one with the shortest prefix)
-            lex_min_blue = min(list(blue))
-            merged = False
-
-            for red_state in red:
-                if self.compatibility_test(red_state, lex_min_blue):
-                    self.merge(red_state, lex_min_blue)
-                    merged = True
-                    break
-
-            if not merged:
-                insort(red, lex_min_blue)
-
-            blue.clear()
-
-            for r in red:
-                for s in r.successors():
-                    if s not in red:
-                        blue.append(s)
-
-        assert sorted(red, key=lambda x: len(x.prefix)) == red
-
-        self.normalize(red)
-
-        for i, r in enumerate(red):
-            r.state_id = f'q{i}'
-
-        if self.print_info:
-            print(f'Alergia Learning Time: {round(time.time() - start_time, 2)}')
-            print(f'Alergia Learned {len(red)} state automaton.')
-
-        return self.to_automaton(red)
-
-    def normalize(self, red):
-        red_sorted = sorted(list(red), key=lambda x: len(x.prefix))
-        for r in red_sorted:
-            # Initializing in here saves many unnecessary initializations
-            r.children_prob = dict()
-            if self.automaton_type == 'mc':
-                total_output = sum(r.input_frequency.values())
-                for i in r.input_frequency.keys():
-                    r.children_prob[i] = r.input_frequency[i] / total_output
-            else:
-                for i, o in r.input_frequency.keys():
-                    r.children_prob[(i, o)] = r.input_frequency[(i, o)] / r.get_input_frequency(i)
-
-    def to_automaton(self, red):
-        s_c = state_automaton_map[self.automaton_type][0]
-        a_c = state_automaton_map[self.automaton_type][1]
-
-        states = []
-        initial_state = None
-        red_mdp_map = dict()
-        for s in red:
-            if self.automaton_type != 'smm':
-                automaton_state = s_c(s.state_id, output=s.output)
-            else:
-                automaton_state = s_c(s.state_id)
-
-            automaton_state.prefix = s.prefix
-            states.append(automaton_state)
-            red_mdp_map[tuple(s.prefix)] = automaton_state
-            red_mdp_map[automaton_state.state_id] = s
-            if not s.prefix:
-                initial_state = automaton_state
-
-        for s in states:
-            red_eq = red_mdp_map[s.state_id]
-            for io, c in red_eq.children.items():
-                destination = red_mdp_map[tuple(c.prefix)]
-                i = io if self.automaton_type == 'mc' else io[0]
-                if self.automaton_type == 'mdp':
-                    s.transitions[i].append((destination, red_eq.children_prob[io]))
-                elif self.automaton_type == 'mc':
-                    s.transitions.append((destination, red_eq.children_prob[i]))
-                elif self.automaton_type == 'smm':
-                    s.transitions[i].append((destination, io[1], red_eq.children_prob[io]))
-                else:
-                    s.transitions[i] = destination
-
-        return a_c(initial_state, states)
-
-
-def run_Alergia(data, automaton_type, eps=0.05, compatibility_checker=None, print_info=False):
-    """
-    Run Alergia or IOAlergia on provided data.
-
-    Args:
-
-        data: data either in a form [[I,I,I],[I,I,I],...] if learning Markov Chains or [[O,(I,O),(I,O)...],
-        [O,(I,O), (I, O)_,...],..,] if learning MDPs, or [[I,O,I,O...], [I,O_,...],..,] if learning SMMs
-         (I represents input, O output).
-        Note that in whole data first symbol of each entry should be the same (Initial output of the MDP/MC).
-
-        eps: epsilon value if you are using default HoeffdingCompatibility. If it is set to 'auto' it will be computed
-        as 10/(all steps in the data)
-
-        automaton_type: either 'mdp' if you wish to learn an MDP, 'mc' if you want to learn Markov Chain, or 'smm' if
-        you want to learn stochastic Mealy machine
-
-        compatibility_checker: impl. of class CompatibilityChecker, HoeffdingCompatibility with eps value by default
-
-        (note: not interchangeable, depends on data)
-        print_info:
-
-    Returns:
-
-        mdp, smm, or markov chain
-    """
-    assert automaton_type in {'mdp', 'mc', 'smm'}
-    alergia = Alergia(data, eps=eps, automaton_type=automaton_type,
-                      compatibility_checker=compatibility_checker, print_info=print_info)
-    model = alergia.run()
-    del alergia.fpta, alergia
-    return model
-
-
-def run_JAlergia(path_to_data_file, automaton_type, path_to_jAlergia_jar, eps=0.05, heap_memory='-Xmx2048M'):
-    """
-    Run Alergia or IOAlergia on provided data.
-
-    Args:
-
-        path_to_data_file: either a data in a list of lists or a path to file containing data.
-        Form [[I,I,I],[I,I,I],...] if learning Markov Chains or
-        [[O,I,O,I,O...], [O,I,O_,...],..,] if learning MDPs (I represents input, O output), or
-        [[I,O,I,O...], [I,O_,...],..,] if learning SMMs.
-        Note that in whole data first symbol of each entry should be the same (Initial output of the MDP/MC).
-
-        eps: epsilon value
-
-        heap_memory: java heap memory flag, increase if heap is full
-
-        automaton_type: either 'mdp' if you wish to learn an MDP, 'mc' if you want to learn Markov Chain,
-         or 'smm' if you
-                        want to learn stochastic Mealy machine
-
-
-    Returns:
-
-        learnedModel
-    """
-    assert automaton_type in {'mdp', 'smm', 'mc'}
-
-    import os
-    import subprocess
-    from aalpy.utils.FileHandler import load_automaton_from_file
-
-    save_file = "jAlergiaModel.dot"
-    delete_tmp_file = False
-    if os.path.exists(save_file):
-        os.remove(save_file)
-
-    if os.path.exists(path_to_jAlergia_jar):
-        path_to_jAlergia_jar = os.path.abspath(path_to_jAlergia_jar)
-    else:
-        print(f'JAlergia jar not found at {path_to_jAlergia_jar}.')
-        return
-
-    if isinstance(path_to_data_file, str):
-        if os.path.exists(path_to_data_file):
-            abs_path = os.path.abspath(path_to_data_file)
-        else:
-            print('Input file not found.')
-            return
-    else:
-        if not isinstance(path_to_data_file, (list, tuple)):
-            print('Data should be either a list of sequences or a path to the data file.')
-        with open('jAlergiaInputs.txt', 'w') as f:
-            for seq in path_to_data_file:
-                f.write(','.join([str(s) for s in seq]) + '\n')
-        delete_tmp_file = True
-        abs_path = os.path.abspath('jAlergiaInputs.txt')
-
-    subprocess.call(['java', heap_memory, '-jar', path_to_jAlergia_jar, '-input', abs_path, '-eps', str(eps), '-type',
-                     automaton_type])
-
-    if not os.path.exists(save_file):
-        print("JAlergia error occurred.")
-        return
-
-    model = load_automaton_from_file(save_file, automaton_type=automaton_type)
-    os.remove(save_file)
-    if delete_tmp_file:
-        os.remove('jAlergiaInputs.txt')
-
-    return model
+import time
+from bisect import insort
+
+from aalpy.automata import MarkovChain, MdpState, Mdp, McState, StochasticMealyState, \
+    StochasticMealyMachine
+from aalpy.learning_algs.stochastic_passive.CompatibilityChecker import HoeffdingCompatibility
+from aalpy.learning_algs.stochastic_passive.FPTA import create_fpta
+
+state_automaton_map = {'mc': (McState, MarkovChain), 'mdp': (MdpState, Mdp),
+                       'smm': (StochasticMealyState, StochasticMealyMachine)}
+
+
+class Alergia:
+    def __init__(self, data, automaton_type, eps=0.05, compatibility_checker=None, print_info=False):
+        assert eps == 'auto' or 0 < eps <= 2
+
+        self.automaton_type = automaton_type
+        self.print_info = print_info
+
+        if eps == 'auto':
+            eps = 10 / sum(len(d) - 1 for d in data)  # len - 1 to ignore initial output
+
+        self.diff_checker = HoeffdingCompatibility(eps) if not compatibility_checker else compatibility_checker
+
+        pta_start = time.time()
+
+        self.fpta = create_fpta(data, automaton_type)
+
+        pta_time = round(time.time() - pta_start, 2)
+        if self.print_info:
+            print(f'PTA Construction Time:  {pta_time}')
+
+    def compatibility_test(self, a, b):
+
+        # for MDPs and MC output of the state needs to be the same
+        if self.automaton_type != 'smm' and a.output != b.output:
+            return False
+
+        # leaf nodes are merged
+        if not a.original_children.keys() or not b.original_children.keys():
+            return True
+
+        # if states are statistically different, do not merge
+        if self.diff_checker.are_states_different(a, b):
+            return False
+
+        # check future for compatibility
+        for el in set(a.original_children.keys()).intersection(b.original_children.keys()):
+            if not self.compatibility_test(a.original_children[el], b.original_children[el]):
+                return False
+
+        return True
+
+    def merge(self, red_state, blue_state):
+        b_prefix = blue_state.prefix
+        to_update = self.fpta
+        for p in b_prefix[:-1]:
+            to_update = to_update.children[p]
+
+        to_update.children[b_prefix[-1]] = red_state
+
+        self.fold(red_state, blue_state)
+
+    def fold(self, red, blue):
+        for i, blue_child in blue.children.items():
+            if i in red.children:
+                red.input_frequency[i] += blue.input_frequency[i]
+                self.fold(red.children[i], blue_child)
+            else:
+                red.children[i] = blue.children[i]
+                red.input_frequency[i] = blue.input_frequency[i]
+
+    def run(self):
+        start_time = time.time()
+
+        # representative nodes that will be included in the final output model
+        red = [self.fpta]
+        # intermediate successors scheduled for testing
+        blue = self.fpta.successors()
+
+        while blue:
+            # get lexicographically minimal blue node (one with the shortest prefix)
+            lex_min_blue = min(list(blue))
+            merged = False
+
+            for red_state in red:
+                if self.compatibility_test(red_state, lex_min_blue):
+                    self.merge(red_state, lex_min_blue)
+                    merged = True
+                    break
+
+            if not merged:
+                insort(red, lex_min_blue)
+
+            blue.clear()
+
+            for r in red:
+                for s in r.successors():
+                    if s not in red:
+                        blue.append(s)
+
+        assert sorted(red, key=lambda x: len(x.prefix)) == red
+
+        self.normalize(red)
+
+        for i, r in enumerate(red):
+            r.state_id = f'q{i}'
+
+        if self.print_info:
+            print(f'Alergia Learning Time: {round(time.time() - start_time, 2)}')
+            print(f'Alergia Learned {len(red)} state automaton.')
+
+        return self.to_automaton(red)
+
+    def normalize(self, red):
+        red_sorted = sorted(list(red), key=lambda x: len(x.prefix))
+        for r in red_sorted:
+            # Initializing in here saves many unnecessary initializations
+            r.children_prob = dict()
+            if self.automaton_type == 'mc':
+                total_output = sum(r.input_frequency.values())
+                for i in r.input_frequency.keys():
+                    r.children_prob[i] = r.input_frequency[i] / total_output
+            else:
+                for i, o in r.input_frequency.keys():
+                    r.children_prob[(i, o)] = r.input_frequency[(i, o)] / r.get_input_frequency(i)
+
+    def to_automaton(self, red):
+        s_c = state_automaton_map[self.automaton_type][0]
+        a_c = state_automaton_map[self.automaton_type][1]
+
+        states = []
+        initial_state = None
+        red_mdp_map = dict()
+        for s in red:
+            if self.automaton_type != 'smm':
+                automaton_state = s_c(s.state_id, output=s.output)
+            else:
+                automaton_state = s_c(s.state_id)
+
+            automaton_state.prefix = s.prefix
+            states.append(automaton_state)
+            red_mdp_map[tuple(s.prefix)] = automaton_state
+            red_mdp_map[automaton_state.state_id] = s
+            if not s.prefix:
+                initial_state = automaton_state
+
+        for s in states:
+            red_eq = red_mdp_map[s.state_id]
+            for io, c in red_eq.children.items():
+                destination = red_mdp_map[tuple(c.prefix)]
+                i = io if self.automaton_type == 'mc' else io[0]
+                if self.automaton_type == 'mdp':
+                    s.transitions[i].append((destination, red_eq.children_prob[io]))
+                elif self.automaton_type == 'mc':
+                    s.transitions.append((destination, red_eq.children_prob[i]))
+                elif self.automaton_type == 'smm':
+                    s.transitions[i].append((destination, io[1], red_eq.children_prob[io]))
+                else:
+                    s.transitions[i] = destination
+
+        return a_c(initial_state, states)
+
+
+def run_Alergia(data, automaton_type, eps=0.05, compatibility_checker=None, print_info=False):
+    """
+    Run Alergia or IOAlergia on provided data.
+
+    Args:
+
+        data: data either in a form [[I,I,I],[I,I,I],...] if learning Markov Chains or [[O,(I,O),(I,O)...],
+        [O,(I,O), (I, O)_,...],..,] if learning MDPs, or [[I,O,I,O...], [I,O_,...],..,] if learning SMMs
+         (I represents input, O output).
+        Note that in whole data first symbol of each entry should be the same (Initial output of the MDP/MC).
+
+        eps: epsilon value if you are using default HoeffdingCompatibility. If it is set to 'auto' it will be computed
+        as 10/(all steps in the data)
+
+        automaton_type: either 'mdp' if you wish to learn an MDP, 'mc' if you want to learn Markov Chain, or 'smm' if
+        you want to learn stochastic Mealy machine
+
+        compatibility_checker: impl. of class CompatibilityChecker, HoeffdingCompatibility with eps value by default
+
+        (note: not interchangeable, depends on data)
+        print_info:
+
+    Returns:
+
+        mdp, smm, or markov chain
+    """
+    assert automaton_type in {'mdp', 'mc', 'smm'}
+    alergia = Alergia(data, eps=eps, automaton_type=automaton_type,
+                      compatibility_checker=compatibility_checker, print_info=print_info)
+    model = alergia.run()
+    del alergia.fpta, alergia
+    return model
+
+
+def run_JAlergia(path_to_data_file, automaton_type, path_to_jAlergia_jar, eps=0.05, heap_memory='-Xmx2048M'):
+    """
+    Run Alergia or IOAlergia on provided data.
+
+    Args:
+
+        path_to_data_file: either a data in a list of lists or a path to file containing data.
+        Form [[I,I,I],[I,I,I],...] if learning Markov Chains or
+        [[O,I,O,I,O...], [O,I,O_,...],..,] if learning MDPs (I represents input, O output), or
+        [[I,O,I,O...], [I,O_,...],..,] if learning SMMs.
+        Note that in whole data first symbol of each entry should be the same (Initial output of the MDP/MC).
+
+        eps: epsilon value
+
+        heap_memory: java heap memory flag, increase if heap is full
+
+        automaton_type: either 'mdp' if you wish to learn an MDP, 'mc' if you want to learn Markov Chain,
+         or 'smm' if you
+                        want to learn stochastic Mealy machine
+
+
+    Returns:
+
+        learnedModel
+    """
+    assert automaton_type in {'mdp', 'smm', 'mc'}
+
+    import os
+    import subprocess
+    from aalpy.utils.FileHandler import load_automaton_from_file
+
+    save_file = "jAlergiaModel.dot"
+    delete_tmp_file = False
+    if os.path.exists(save_file):
+        os.remove(save_file)
+
+    if os.path.exists(path_to_jAlergia_jar):
+        path_to_jAlergia_jar = os.path.abspath(path_to_jAlergia_jar)
+    else:
+        print(f'JAlergia jar not found at {path_to_jAlergia_jar}.')
+        return
+
+    if isinstance(path_to_data_file, str):
+        if os.path.exists(path_to_data_file):
+            abs_path = os.path.abspath(path_to_data_file)
+        else:
+            print('Input file not found.')
+            return
+    else:
+        if not isinstance(path_to_data_file, (list, tuple)):
+            print('Data should be either a list of sequences or a path to the data file.')
+        with open('jAlergiaInputs.txt', 'w') as f:
+            for seq in path_to_data_file:
+                f.write(','.join([str(s) for s in seq]) + '\n')
+        delete_tmp_file = True
+        abs_path = os.path.abspath('jAlergiaInputs.txt')
+
+    subprocess.call(['java', heap_memory, '-jar', path_to_jAlergia_jar, '-input', abs_path, '-eps', str(eps), '-type',
+                     automaton_type])
+
+    if not os.path.exists(save_file):
+        print("JAlergia error occurred.")
+        return
+
+    model = load_automaton_from_file(save_file, automaton_type=automaton_type)
+    os.remove(save_file)
+    if delete_tmp_file:
+        os.remove('jAlergiaInputs.txt')
+
+    return model
```

## aalpy/learning_algs/stochastic_passive/CompatibilityChecker.py

 * *Ordering differences only*

```diff
@@ -1,50 +1,50 @@
-from abc import ABC, abstractmethod
-from math import sqrt, log
-
-from aalpy.learning_algs.stochastic_passive.FPTA import AlergiaPtaNode
-
-
-class CompatibilityChecker(ABC):
-
-    @abstractmethod
-    def are_states_different(self, a: AlergiaPtaNode, b: AlergiaPtaNode, **kwargs) -> bool:
-        pass
-
-
-class HoeffdingCompatibility(CompatibilityChecker):
-    def __init__(self, eps):
-        self.eps = eps
-        self.log_term = sqrt(0.5 * log(2 / self.eps))
-
-    def hoeffding_bound(self, a: dict, b: dict):
-        n1 = sum(a.values())
-        n2 = sum(b.values())
-
-        if n1 * n2 == 0:
-            return False
-
-        bound = (sqrt(1 / n1) + sqrt(1 / n2)) * self.log_term
-
-        for o in set(a.keys()).union(b.keys()):
-            a_freq = a[o] if o in a else 0
-            b_freq = b[o] if o in b else 0
-
-            if abs(a_freq / n1 - b_freq / n2) > bound:
-                return True
-        return False
-
-    def are_states_different(self, a: AlergiaPtaNode, b: AlergiaPtaNode, **kwargs):
-
-        # no data available for any node
-        if len(a.original_input_frequency) * len(b.original_children) == 0:
-            return False
-
-        # assuming tuples are used for IOAlergia and not as Alergia outputs
-        if not isinstance(list(a.original_input_frequency.keys())[0], tuple):
-            return self.hoeffding_bound(a.original_input_frequency, b.original_input_frequency)
-
-        # IOAlergia: check hoeffding bound conditioned on inputs
-        for i in a.get_immutable_inputs().intersection(b.get_immutable_inputs()):
-            if self.hoeffding_bound(a.get_original_output_frequencies(i), b.get_original_output_frequencies(i)):
-                return True
-        return False
+from abc import ABC, abstractmethod
+from math import sqrt, log
+
+from aalpy.learning_algs.stochastic_passive.FPTA import AlergiaPtaNode
+
+
+class CompatibilityChecker(ABC):
+
+    @abstractmethod
+    def are_states_different(self, a: AlergiaPtaNode, b: AlergiaPtaNode, **kwargs) -> bool:
+        pass
+
+
+class HoeffdingCompatibility(CompatibilityChecker):
+    def __init__(self, eps):
+        self.eps = eps
+        self.log_term = sqrt(0.5 * log(2 / self.eps))
+
+    def hoeffding_bound(self, a: dict, b: dict):
+        n1 = sum(a.values())
+        n2 = sum(b.values())
+
+        if n1 * n2 == 0:
+            return False
+
+        bound = (sqrt(1 / n1) + sqrt(1 / n2)) * self.log_term
+
+        for o in set(a.keys()).union(b.keys()):
+            a_freq = a[o] if o in a else 0
+            b_freq = b[o] if o in b else 0
+
+            if abs(a_freq / n1 - b_freq / n2) > bound:
+                return True
+        return False
+
+    def are_states_different(self, a: AlergiaPtaNode, b: AlergiaPtaNode, **kwargs):
+
+        # no data available for any node
+        if len(a.original_input_frequency) * len(b.original_children) == 0:
+            return False
+
+        # assuming tuples are used for IOAlergia and not as Alergia outputs
+        if not isinstance(list(a.original_input_frequency.keys())[0], tuple):
+            return self.hoeffding_bound(a.original_input_frequency, b.original_input_frequency)
+
+        # IOAlergia: check hoeffding bound conditioned on inputs
+        for i in a.get_immutable_inputs().intersection(b.get_immutable_inputs()):
+            if self.hoeffding_bound(a.get_original_output_frequencies(i), b.get_original_output_frequencies(i)):
+                return True
+        return False
```

## aalpy/learning_algs/stochastic_passive/FPTA.py

 * *Ordering differences only*

```diff
@@ -1,88 +1,88 @@
-from functools import total_ordering
-
-
-@total_ordering
-class AlergiaPtaNode:
-    __slots__ = ['prefix', 'output', 'input_frequency', 'children', 'original_input_frequency',
-                 'original_children', 'state_id', 'children_prob']
-
-    def __init__(self, output, prefix):
-        self.prefix = prefix
-        self.output = output
-        # mutable values
-        self.input_frequency = dict()
-        self.children = dict()
-        # immutable values used for statistical computability check
-        self.original_input_frequency = dict()
-        self.original_children = dict()
-        # # for visualization
-        self.state_id = None
-        self.children_prob = None
-
-    def successors(self):
-        return list(self.children.values())
-
-    def get_inputs(self):
-        return {i for i, _ in self.input_frequency.keys()}
-
-    def get_input_frequency(self, target_input):
-        return sum(freq for (i, _), freq in self.input_frequency.items() if i == target_input)
-
-    def get_output_frequencies(self, target_input):
-        return {o: freq for (i, o), freq in self.input_frequency.items() if i == target_input}
-
-    def get_immutable_inputs(self):
-        return {i for i, _ in self.original_children.keys()}
-
-    def get_immutable_input_frequency(self, target_input):
-        return sum(freq for (i, _), freq in self.original_input_frequency.items() if i == target_input)
-
-    def get_original_output_frequencies(self, target_input):
-        return {o: freq for (i, o), freq in self.original_input_frequency.items() if i == target_input}
-
-    def __lt__(self, other):
-        return (len(self.prefix), self.prefix) < (len(other.prefix), other.prefix)
-
-    def __le__(self, other):
-        return self < other or self == other
-
-    def __eq__(self, other):
-        return self.prefix == other.prefix
-
-
-def create_fpta(data, automaton_type):
-    # in case of SMM, there is no initial input
-    seq_iter_index = 0 if automaton_type == 'smm' else 1
-
-    initial_output = None if automaton_type == 'smm' else data[0][0]
-
-    root_node = AlergiaPtaNode(initial_output, ())
-
-    for seq in data:
-        if automaton_type != 'smm' and seq[0] != root_node.output:
-            print('All sequances passed to Alergia should have the same initial output!')
-            assert False
-
-        curr_node = root_node
-
-        for el in seq[seq_iter_index:]:
-            if el not in curr_node.children:
-                out = None
-                if automaton_type == 'mc':
-                    out = el
-                elif automaton_type == 'mdp':
-                    out = el[1]
-
-                reached_node = AlergiaPtaNode(out, curr_node.prefix + (el,))
-                curr_node.children[el] = reached_node
-                curr_node.original_children[el] = reached_node
-
-                curr_node.input_frequency[el] = 0
-                curr_node.original_input_frequency[el] = 0
-
-            curr_node.input_frequency[el] += 1
-            curr_node.original_input_frequency[el] += 1
-
-            curr_node = curr_node.children[el]
-
-    return root_node
+from functools import total_ordering
+
+
+@total_ordering
+class AlergiaPtaNode:
+    __slots__ = ['prefix', 'output', 'input_frequency', 'children', 'original_input_frequency',
+                 'original_children', 'state_id', 'children_prob']
+
+    def __init__(self, output, prefix):
+        self.prefix = prefix
+        self.output = output
+        # mutable values
+        self.input_frequency = dict()
+        self.children = dict()
+        # immutable values used for statistical computability check
+        self.original_input_frequency = dict()
+        self.original_children = dict()
+        # # for visualization
+        self.state_id = None
+        self.children_prob = None
+
+    def successors(self):
+        return list(self.children.values())
+
+    def get_inputs(self):
+        return {i for i, _ in self.input_frequency.keys()}
+
+    def get_input_frequency(self, target_input):
+        return sum(freq for (i, _), freq in self.input_frequency.items() if i == target_input)
+
+    def get_output_frequencies(self, target_input):
+        return {o: freq for (i, o), freq in self.input_frequency.items() if i == target_input}
+
+    def get_immutable_inputs(self):
+        return {i for i, _ in self.original_children.keys()}
+
+    def get_immutable_input_frequency(self, target_input):
+        return sum(freq for (i, _), freq in self.original_input_frequency.items() if i == target_input)
+
+    def get_original_output_frequencies(self, target_input):
+        return {o: freq for (i, o), freq in self.original_input_frequency.items() if i == target_input}
+
+    def __lt__(self, other):
+        return (len(self.prefix), self.prefix) < (len(other.prefix), other.prefix)
+
+    def __le__(self, other):
+        return self < other or self == other
+
+    def __eq__(self, other):
+        return self.prefix == other.prefix
+
+
+def create_fpta(data, automaton_type):
+    # in case of SMM, there is no initial input
+    seq_iter_index = 0 if automaton_type == 'smm' else 1
+
+    initial_output = None if automaton_type == 'smm' else data[0][0]
+
+    root_node = AlergiaPtaNode(initial_output, ())
+
+    for seq in data:
+        if automaton_type != 'smm' and seq[0] != root_node.output:
+            print('All sequances passed to Alergia should have the same initial output!')
+            assert False
+
+        curr_node = root_node
+
+        for el in seq[seq_iter_index:]:
+            if el not in curr_node.children:
+                out = None
+                if automaton_type == 'mc':
+                    out = el
+                elif automaton_type == 'mdp':
+                    out = el[1]
+
+                reached_node = AlergiaPtaNode(out, curr_node.prefix + (el,))
+                curr_node.children[el] = reached_node
+                curr_node.original_children[el] = reached_node
+
+                curr_node.input_frequency[el] = 0
+                curr_node.original_input_frequency[el] = 0
+
+            curr_node.input_frequency[el] += 1
+            curr_node.original_input_frequency[el] += 1
+
+            curr_node = curr_node.children[el]
+
+    return root_node
```

## aalpy/oracles/BreadthFirstExplorationEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,51 +1,51 @@
-from aalpy.base.Oracle import Oracle
-from aalpy.base.SUL import SUL
-
-from itertools import product
-from random import shuffle
-
-
-class BreadthFirstExplorationEqOracle(Oracle):
-    """
-    Breadth-First Exploration of all possible input combinations up to a certain depth.
-    Extremely inefficient equivalence oracle and should only be used for demonstrations.
-    """
-
-    def __init__(self, alphabet, sul: SUL, depth=5):
-        """
-        Args:
-
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            depth: depth of the tree
-        """
-
-        super().__init__(alphabet, sul)
-        self.depth = depth
-        self.queue = []
-
-        # generate all test-cases
-        for seq in product(self.alphabet, repeat=self.depth):
-            input_seq = tuple([i for sub in seq for i in sub])
-            self.queue.append(input_seq)
-
-        shuffle(self.queue)
-
-    def find_cex(self, hypothesis):
-
-        while self.queue:
-            test_case = self.queue.pop()
-            self.reset_hyp_and_sul(hypothesis)
-
-            for ind, letter in enumerate(test_case):
-                out_hyp = hypothesis.step(letter)
-                out_sul = self.sul.step(letter)
-                self.num_steps += 1
-
-                if out_hyp != out_sul:
-                    self.sul.post()
-                    return test_case[:ind + 1]
-
-        return None
+from aalpy.base.Oracle import Oracle
+from aalpy.base.SUL import SUL
+
+from itertools import product
+from random import shuffle
+
+
+class BreadthFirstExplorationEqOracle(Oracle):
+    """
+    Breadth-First Exploration of all possible input combinations up to a certain depth.
+    Extremely inefficient equivalence oracle and should only be used for demonstrations.
+    """
+
+    def __init__(self, alphabet, sul: SUL, depth=5):
+        """
+        Args:
+
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            depth: depth of the tree
+        """
+
+        super().__init__(alphabet, sul)
+        self.depth = depth
+        self.queue = []
+
+        # generate all test-cases
+        for seq in product(self.alphabet, repeat=self.depth):
+            input_seq = tuple([i for sub in seq for i in sub])
+            self.queue.append(input_seq)
+
+        shuffle(self.queue)
+
+    def find_cex(self, hypothesis):
+
+        while self.queue:
+            test_case = self.queue.pop()
+            self.reset_hyp_and_sul(hypothesis)
+
+            for ind, letter in enumerate(test_case):
+                out_hyp = hypothesis.step(letter)
+                out_sul = self.sul.step(letter)
+                self.num_steps += 1
+
+                if out_hyp != out_sul:
+                    self.sul.post()
+                    return test_case[:ind + 1]
+
+        return None
```

## aalpy/oracles/CacheBasedEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,97 +1,97 @@
-from aalpy.base import Oracle, SUL
-from aalpy.base.SUL import CacheSUL
-
-from random import choice
-
-
-class CacheBasedEqOracle(Oracle):
-    """
-    Equivalence oracle where test case selection is based on the multiset of all traces observed during learning and
-    conformance checking. Firstly all leaves of the tree are gathered and then random leaves are extended with a suffix
-    of length (max_tree_depth + 'depth_increase') - len(prefix), where prefix is a path to the leaf.
-    """
-
-    def __init__(self, alphabet: list, sul: SUL, num_walks=100, depth_increase=5, reset_after_cex=True):
-        """
-
-        Args:
-
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            num_walks: number of random walks to perform
-
-            depth_increase: length of random walk that exceeds the maximum depth of the tree
-
-            reset_after_cex: if False, total number of queries will equal num_walks, if True, in each execution of
-                find_cex method at most num_walks will be executed
-        """
-
-        super().__init__(alphabet, sul)
-        self.cache_tree = None
-        self.num_walks = num_walks
-        self.depth_increase = depth_increase
-        self.reset_after_cex = reset_after_cex
-        self.num_walks_done = 0
-
-    def find_cex(self, hypothesis):
-
-        assert isinstance(self.sul, CacheSUL)
-        self.cache_tree = self.sul.cache
-
-        paths_to_leaves = self.get_paths(self.cache_tree.root_node)
-        max_tree_depth = len(max(paths_to_leaves, key=len))
-
-        while self.num_walks_done < self.num_walks:
-            self.num_walks_done += 1
-            self.reset_hyp_and_sul(hypothesis)
-
-            prefix = choice(paths_to_leaves)
-            walk_len = (max_tree_depth + self.depth_increase) - len(prefix)
-            inputs = []
-            inputs.extend(prefix)
-
-            for p in prefix:
-                hypothesis.step(p)
-                self.sul.step(p)
-                self.num_steps += 1
-
-            for _ in range(walk_len):
-                inputs.append(choice(self.alphabet))
-
-                out_sul = self.sul.step(inputs[-1])
-                out_hyp = hypothesis.step(inputs[-1])
-                self.num_steps += 1
-
-                if out_sul != out_hyp:
-                    if self.reset_after_cex:
-                        self.num_walks_done = 0
-                    self.sul.post()
-                    return inputs
-
-        return None
-
-    def get_paths(self, t, paths=None, current_path=None):
-        """
-
-        Args:
-          t: 
-          paths:  (Default value = None)
-          current_path:  (Default value = None)
-
-        Returns:
-
-        """
-        if paths is None:
-            paths = []
-        if current_path is None:
-            current_path = []
-
-        if len(t.children) == 0:
-            paths.append(current_path)
-        else:
-            for inp, child in t.children.items():
-                current_path.append(inp)
-                self.get_paths(child, paths, list(current_path))
-        return paths
+from aalpy.base import Oracle, SUL
+from aalpy.base.SUL import CacheSUL
+
+from random import choice
+
+
+class CacheBasedEqOracle(Oracle):
+    """
+    Equivalence oracle where test case selection is based on the multiset of all traces observed during learning and
+    conformance checking. Firstly all leaves of the tree are gathered and then random leaves are extended with a suffix
+    of length (max_tree_depth + 'depth_increase') - len(prefix), where prefix is a path to the leaf.
+    """
+
+    def __init__(self, alphabet: list, sul: SUL, num_walks=100, depth_increase=5, reset_after_cex=True):
+        """
+
+        Args:
+
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            num_walks: number of random walks to perform
+
+            depth_increase: length of random walk that exceeds the maximum depth of the tree
+
+            reset_after_cex: if False, total number of queries will equal num_walks, if True, in each execution of
+                find_cex method at most num_walks will be executed
+        """
+
+        super().__init__(alphabet, sul)
+        self.cache_tree = None
+        self.num_walks = num_walks
+        self.depth_increase = depth_increase
+        self.reset_after_cex = reset_after_cex
+        self.num_walks_done = 0
+
+    def find_cex(self, hypothesis):
+
+        assert isinstance(self.sul, CacheSUL)
+        self.cache_tree = self.sul.cache
+
+        paths_to_leaves = self.get_paths(self.cache_tree.root_node)
+        max_tree_depth = len(max(paths_to_leaves, key=len))
+
+        while self.num_walks_done < self.num_walks:
+            self.num_walks_done += 1
+            self.reset_hyp_and_sul(hypothesis)
+
+            prefix = choice(paths_to_leaves)
+            walk_len = (max_tree_depth + self.depth_increase) - len(prefix)
+            inputs = []
+            inputs.extend(prefix)
+
+            for p in prefix:
+                hypothesis.step(p)
+                self.sul.step(p)
+                self.num_steps += 1
+
+            for _ in range(walk_len):
+                inputs.append(choice(self.alphabet))
+
+                out_sul = self.sul.step(inputs[-1])
+                out_hyp = hypothesis.step(inputs[-1])
+                self.num_steps += 1
+
+                if out_sul != out_hyp:
+                    if self.reset_after_cex:
+                        self.num_walks_done = 0
+                    self.sul.post()
+                    return inputs
+
+        return None
+
+    def get_paths(self, t, paths=None, current_path=None):
+        """
+
+        Args:
+          t: 
+          paths:  (Default value = None)
+          current_path:  (Default value = None)
+
+        Returns:
+
+        """
+        if paths is None:
+            paths = []
+        if current_path is None:
+            current_path = []
+
+        if len(t.children) == 0:
+            paths.append(current_path)
+        else:
+            for inp, child in t.children.items():
+                current_path.append(inp)
+                self.get_paths(child, paths, list(current_path))
+        return paths
```

## aalpy/oracles/PerfectKnowledgeEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,15 +1,15 @@
-from aalpy.base import Oracle, SUL, DeterministicAutomaton
-from aalpy.utils import bisimilar
-
-
-class PerfectKnowledgeEqOracle(Oracle):
-    """
-    Oracle that can be used when developing and testing deterministic learning algorithms,
-    so that the focus is put off equivalence query.
-    """
-    def __init__(self, alphabet: list, sul: SUL, model_under_learning: DeterministicAutomaton):
-        super().__init__(alphabet, sul, )
-        self.model_under_learning = model_under_learning
-
-    def find_cex(self, hypothesis):
-        return bisimilar(hypothesis, self.model_under_learning, return_cex=True)
+from aalpy.base import Oracle, SUL, DeterministicAutomaton
+from aalpy.utils import bisimilar
+
+
+class PerfectKnowledgeEqOracle(Oracle):
+    """
+    Oracle that can be used when developing and testing deterministic learning algorithms,
+    so that the focus is put off equivalence query.
+    """
+    def __init__(self, alphabet: list, sul: SUL, model_under_learning: DeterministicAutomaton):
+        super().__init__(alphabet, sul, )
+        self.model_under_learning = model_under_learning
+
+    def find_cex(self, hypothesis):
+        return bisimilar(hypothesis, self.model_under_learning, return_cex=True)
```

## aalpy/oracles/ProvidedSequencesOracleWrapper.py

 * *Ordering differences only*

```diff
@@ -1,46 +1,46 @@
-from aalpy.base import Oracle, SUL
-
-
-class ProvidedSequencesOracleWrapper(Oracle):
-    def __init__(self, alphabet: list, sul: SUL, oracle: Oracle, provided_counterexamples: list):
-        """
-        Oracle wrapper which first executes provided sequences (possible counterexamples) and then switches to another
-        oracle instance.
-
-        Args:
-            alphabet: input alphabet
-            sul: system under learning
-            oracle: oracle which will be used once all provided counterexamples are used
-            provided_counterexamples: list of input sequance lists. eg [[1,2,3], [2,3,1], ...] where 1,2,3 are elements
-            of input alphabet
-        """
-        super().__init__(alphabet, sul)
-        self.provided_counterexamples = provided_counterexamples
-        self.oracle = oracle
-
-    def find_cex(self, hypothesis):
-        for provided_cex in self.provided_counterexamples.copy():
-            inputs = []
-            self.reset_hyp_and_sul(hypothesis)
-
-            for i in provided_cex:
-                inputs.append(i)
-                out_sul = self.sul.step(i)
-                out_hyp = hypothesis.step(i)
-                self.num_steps += 1
-
-                if out_sul != out_hyp:
-                    self.sul.post()
-                    return tuple(inputs)
-
-            self.provided_counterexamples.remove(provided_cex)
-
-        cex = self.oracle.find_cex(hypothesis)
-
-        # to account for steps statistics from actual oracle
-        if cex is None:
-            self.num_queries += self.oracle.num_queries
-            self.num_steps += self.oracle.num_steps
-
-        return cex
-
+from aalpy.base import Oracle, SUL
+
+
+class ProvidedSequencesOracleWrapper(Oracle):
+    def __init__(self, alphabet: list, sul: SUL, oracle: Oracle, provided_counterexamples: list):
+        """
+        Oracle wrapper which first executes provided sequences (possible counterexamples) and then switches to another
+        oracle instance.
+
+        Args:
+            alphabet: input alphabet
+            sul: system under learning
+            oracle: oracle which will be used once all provided counterexamples are used
+            provided_counterexamples: list of input sequance lists. eg [[1,2,3], [2,3,1], ...] where 1,2,3 are elements
+            of input alphabet
+        """
+        super().__init__(alphabet, sul)
+        self.provided_counterexamples = provided_counterexamples
+        self.oracle = oracle
+
+    def find_cex(self, hypothesis):
+        for provided_cex in self.provided_counterexamples.copy():
+            inputs = []
+            self.reset_hyp_and_sul(hypothesis)
+
+            for i in provided_cex:
+                inputs.append(i)
+                out_sul = self.sul.step(i)
+                out_hyp = hypothesis.step(i)
+                self.num_steps += 1
+
+                if out_sul != out_hyp:
+                    self.sul.post()
+                    return tuple(inputs)
+
+            self.provided_counterexamples.remove(provided_cex)
+
+        cex = self.oracle.find_cex(hypothesis)
+
+        # to account for steps statistics from actual oracle
+        if cex is None:
+            self.num_queries += self.oracle.num_queries
+            self.num_steps += self.oracle.num_steps
+
+        return cex
+
```

## aalpy/oracles/RandomWalkEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,89 +1,89 @@
-import random
-
-from aalpy.automata import Onfsm, Mdp, StochasticMealyMachine
-from aalpy.base import Oracle, SUL
-
-automaton_dict = {Onfsm: 'onfsm', Mdp: 'mdp', StochasticMealyMachine: 'smm'}
-
-
-class RandomWalkEqOracle(Oracle):
-    """
-    Equivalence oracle where queries contain random inputs. After every step, 'reset_prob' determines the probability
-    that the system will reset and a new query asked.
-    """
-
-    def __init__(self, alphabet: list, sul: SUL, num_steps=5000, reset_after_cex=True, reset_prob=0.09):
-        """
-
-        Args:
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            num_steps: number of steps to be preformed
-
-            reset_after_cex: if true, num_steps will be preformed after every counter example, else the total number
-                or steps will equal to num_steps
-
-            reset_prob: probability that the new query will be asked
-        """
-
-        super().__init__(alphabet, sul)
-        self.step_limit = num_steps
-        self.reset_after_cex = reset_after_cex
-        self.reset_prob = reset_prob
-        self.random_steps_done = 0
-        self.automata_type = None
-
-    def find_cex(self, hypothesis):
-        if not self.automata_type:
-            self.automata_type = automaton_dict.get(type(hypothesis), 'det')
-
-        inputs = []
-        outputs = []
-        self.reset_hyp_and_sul(hypothesis)
-
-        while self.random_steps_done < self.step_limit:
-            self.num_steps += 1
-            self.random_steps_done += 1
-
-            if random.random() <= self.reset_prob:
-                self.reset_hyp_and_sul(hypothesis)
-                inputs.clear()
-                outputs.clear()
-
-            inputs.append(random.choice(self.alphabet))
-
-            out_sul = self.sul.step(inputs[-1])
-            outputs.append(out_sul)
-
-            if self.automata_type == 'det':
-                out_hyp = hypothesis.step(inputs[-1])
-            else:
-                out_hyp = hypothesis.step_to(inputs[-1], out_sul)
-
-            if self.automata_type == 'det' and out_sul != out_hyp:
-                if self.reset_after_cex:
-                    self.random_steps_done = 0
-
-                self.sul.post()
-                return inputs
-            elif out_hyp is None:
-                if self.reset_after_cex:
-                    self.random_steps_done = 0
-                self.sul.post()
-
-                if self.automata_type == 'onfsm':
-                    return inputs, outputs
-                else:
-                    # hypothesis is MDP or SMM
-                    cex = [hypothesis.initial_state.output] if self.automata_type == 'mdp' else []
-                    for i, o in zip(inputs, outputs):
-                        cex.extend([i, o])
-                    return cex
-
-        return None
-
-    def reset_counter(self):
-        if self.reset_after_cex:
+import random
+
+from aalpy.automata import Onfsm, Mdp, StochasticMealyMachine
+from aalpy.base import Oracle, SUL
+
+automaton_dict = {Onfsm: 'onfsm', Mdp: 'mdp', StochasticMealyMachine: 'smm'}
+
+
+class RandomWalkEqOracle(Oracle):
+    """
+    Equivalence oracle where queries contain random inputs. After every step, 'reset_prob' determines the probability
+    that the system will reset and a new query asked.
+    """
+
+    def __init__(self, alphabet: list, sul: SUL, num_steps=5000, reset_after_cex=True, reset_prob=0.09):
+        """
+
+        Args:
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            num_steps: number of steps to be preformed
+
+            reset_after_cex: if true, num_steps will be preformed after every counter example, else the total number
+                or steps will equal to num_steps
+
+            reset_prob: probability that the new query will be asked
+        """
+
+        super().__init__(alphabet, sul)
+        self.step_limit = num_steps
+        self.reset_after_cex = reset_after_cex
+        self.reset_prob = reset_prob
+        self.random_steps_done = 0
+        self.automata_type = None
+
+    def find_cex(self, hypothesis):
+        if not self.automata_type:
+            self.automata_type = automaton_dict.get(type(hypothesis), 'det')
+
+        inputs = []
+        outputs = []
+        self.reset_hyp_and_sul(hypothesis)
+
+        while self.random_steps_done < self.step_limit:
+            self.num_steps += 1
+            self.random_steps_done += 1
+
+            if random.random() <= self.reset_prob:
+                self.reset_hyp_and_sul(hypothesis)
+                inputs.clear()
+                outputs.clear()
+
+            inputs.append(random.choice(self.alphabet))
+
+            out_sul = self.sul.step(inputs[-1])
+            outputs.append(out_sul)
+
+            if self.automata_type == 'det':
+                out_hyp = hypothesis.step(inputs[-1])
+            else:
+                out_hyp = hypothesis.step_to(inputs[-1], out_sul)
+
+            if self.automata_type == 'det' and out_sul != out_hyp:
+                if self.reset_after_cex:
+                    self.random_steps_done = 0
+
+                self.sul.post()
+                return inputs
+            elif out_hyp is None:
+                if self.reset_after_cex:
+                    self.random_steps_done = 0
+                self.sul.post()
+
+                if self.automata_type == 'onfsm':
+                    return inputs, outputs
+                else:
+                    # hypothesis is MDP or SMM
+                    cex = [hypothesis.initial_state.output] if self.automata_type == 'mdp' else []
+                    for i, o in zip(inputs, outputs):
+                        cex.extend([i, o])
+                    return cex
+
+        return None
+
+    def reset_counter(self):
+        if self.reset_after_cex:
             self.random_steps_done = 0
```

## aalpy/oracles/RandomWordEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,95 +1,95 @@
-from statistics import mean
-
-from aalpy.automata import Onfsm, Mdp, StochasticMealyMachine
-from aalpy.base import Oracle, SUL
-from random import randint, choice
-
-automaton_dict = {Onfsm: 'onfsm', Mdp: 'mdp', StochasticMealyMachine: 'smm'}
-
-
-class RandomWordEqOracle(Oracle):
-    """
-    Equivalence oracle where queries are of random length in a predefined range.
-    """
-
-    def __init__(self, alphabet: list, sul: SUL, num_walks=500, min_walk_len=10, max_walk_len=30,
-                 reset_after_cex=True):
-        """
-        Args:
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            num_walks: number of walks to perform during search for cex
-
-            min_walk_len: minimum length of each walk
-
-            max_walk_len: maximum length of each walk
-
-            reset_after_cex: if True, num_walks will be preformed after every counter example, else the total number
-                or walks will equal to num_walks
-        """
-
-        super().__init__(alphabet, sul)
-        self.num_walks = num_walks
-        self.min_walk_len = min_walk_len
-        self.max_walk_len = max_walk_len
-        self.reset_after_cex = reset_after_cex
-        self.num_walks_done = 0
-        self.automata_type = None
-
-        self.walk_lengths = [randint(min_walk_len, max_walk_len) for _ in range(num_walks)]
-
-    def find_cex(self, hypothesis):
-        if not self.automata_type:
-            self.automata_type = automaton_dict.get(type(hypothesis), 'det')
-
-        while self.num_walks_done < self.num_walks:
-            inputs = []
-            outputs = []
-            self.reset_hyp_and_sul(hypothesis)
-            self.num_walks_done += 1
-
-            num_steps = self.walk_lengths.pop(0)
-
-            for _ in range(num_steps):
-                inputs.append(choice(self.alphabet))
-
-                out_sul = self.sul.step(inputs[-1])
-                if self.automata_type == 'det':
-                    out_hyp = hypothesis.step(inputs[-1])
-                else:
-                    out_hyp = hypothesis.step_to(inputs[-1], out_sul)
-                    outputs.append(out_sul)
-
-                self.num_steps += 1
-
-                if self.automata_type == 'det' and out_sul != out_hyp:
-                    if self.reset_after_cex:
-                        self.walk_lengths = [randint(self.min_walk_len, self.max_walk_len) for _ in range(self.num_walks)]
-                        self.num_walks_done = 0
-
-                    self.sul.post()
-                    return inputs
-
-                elif out_hyp is None:
-                    self.sul.post()
-
-                    if self.reset_after_cex:
-                        self.walk_lengths = [randint(self.min_walk_len, self.max_walk_len) for _ in range(self.num_walks)]
-                        self.num_walks_done = 0
-
-                    if self.automata_type == 'onfsm':
-                        return inputs, outputs
-                    else:
-                        # hypothesis is MDP or SMM
-                        cex = [hypothesis.initial_state.output] if self.automata_type == 'mdp' else []
-                        for i, o in zip(inputs, outputs):
-                            cex.extend([i, o])
-                        return cex
-
-        return None
-
-    def reset_counter(self):
-        if self.reset_after_cex:
-            self.num_walks_done = 0
+from statistics import mean
+
+from aalpy.automata import Onfsm, Mdp, StochasticMealyMachine
+from aalpy.base import Oracle, SUL
+from random import randint, choice
+
+automaton_dict = {Onfsm: 'onfsm', Mdp: 'mdp', StochasticMealyMachine: 'smm'}
+
+
+class RandomWordEqOracle(Oracle):
+    """
+    Equivalence oracle where queries are of random length in a predefined range.
+    """
+
+    def __init__(self, alphabet: list, sul: SUL, num_walks=500, min_walk_len=10, max_walk_len=30,
+                 reset_after_cex=True):
+        """
+        Args:
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            num_walks: number of walks to perform during search for cex
+
+            min_walk_len: minimum length of each walk
+
+            max_walk_len: maximum length of each walk
+
+            reset_after_cex: if True, num_walks will be preformed after every counter example, else the total number
+                or walks will equal to num_walks
+        """
+
+        super().__init__(alphabet, sul)
+        self.num_walks = num_walks
+        self.min_walk_len = min_walk_len
+        self.max_walk_len = max_walk_len
+        self.reset_after_cex = reset_after_cex
+        self.num_walks_done = 0
+        self.automata_type = None
+
+        self.walk_lengths = [randint(min_walk_len, max_walk_len) for _ in range(num_walks)]
+
+    def find_cex(self, hypothesis):
+        if not self.automata_type:
+            self.automata_type = automaton_dict.get(type(hypothesis), 'det')
+
+        while self.num_walks_done < self.num_walks:
+            inputs = []
+            outputs = []
+            self.reset_hyp_and_sul(hypothesis)
+            self.num_walks_done += 1
+
+            num_steps = self.walk_lengths.pop(0)
+
+            for _ in range(num_steps):
+                inputs.append(choice(self.alphabet))
+
+                out_sul = self.sul.step(inputs[-1])
+                if self.automata_type == 'det':
+                    out_hyp = hypothesis.step(inputs[-1])
+                else:
+                    out_hyp = hypothesis.step_to(inputs[-1], out_sul)
+                    outputs.append(out_sul)
+
+                self.num_steps += 1
+
+                if self.automata_type == 'det' and out_sul != out_hyp:
+                    if self.reset_after_cex:
+                        self.walk_lengths = [randint(self.min_walk_len, self.max_walk_len) for _ in range(self.num_walks)]
+                        self.num_walks_done = 0
+
+                    self.sul.post()
+                    return inputs
+
+                elif out_hyp is None:
+                    self.sul.post()
+
+                    if self.reset_after_cex:
+                        self.walk_lengths = [randint(self.min_walk_len, self.max_walk_len) for _ in range(self.num_walks)]
+                        self.num_walks_done = 0
+
+                    if self.automata_type == 'onfsm':
+                        return inputs, outputs
+                    else:
+                        # hypothesis is MDP or SMM
+                        cex = [hypothesis.initial_state.output] if self.automata_type == 'mdp' else []
+                        for i, o in zip(inputs, outputs):
+                            cex.extend([i, o])
+                        return cex
+
+        return None
+
+    def reset_counter(self):
+        if self.reset_after_cex:
+            self.num_walks_done = 0
```

## aalpy/oracles/StatePrefixEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,78 +1,78 @@
-import random
-
-from aalpy.base.Oracle import Oracle
-from aalpy.base.SUL import SUL
-
-
-class StatePrefixEqOracle(Oracle):
-    """
-    Equivalence oracle that achieves guided exploration by starting random walks from each state a walk_per_state
-    times. Starting the random walk ensures that all states are reached at least walk_per_state times and that their
-    surrounding is randomly explored. Note that each state serves as a root of random exploration of maximum length
-    rand_walk_len exactly walk_per_state times during learning. Therefore excessive testing of initial states is
-    avoided.
-    """
-    def __init__(self, alphabet: list, sul: SUL, walks_per_state=10, walk_len=12, depth_first=False):
-        """
-        Args:
-
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            walks_per_state:individual walks per state of the automaton over the whole learning process
-
-            walk_len:length of random walk
-
-            depth_first:first explore newest states
-        """
-
-        super().__init__(alphabet, sul)
-        self.walks_per_state = walks_per_state
-        self.steps_per_walk = walk_len
-        self.depth_first = depth_first
-
-        self.freq_dict = dict()
-
-    def find_cex(self, hypothesis):
-
-        states_to_cover = []
-        for state in hypothesis.states:
-            if state.prefix is None:
-                state.prefix = hypothesis.get_shortest_path(hypothesis.initial_state, state)
-            if state.prefix not in self.freq_dict.keys():
-                self.freq_dict[state.prefix] = 0
-
-            states_to_cover.extend([state] * (self.walks_per_state - self.freq_dict[state.prefix]))
-
-        if self.depth_first:
-            # reverse sort the states by length of their access sequences
-            # first do the random walk on the state with longest access sequence
-            states_to_cover.sort(key=lambda x: len(x.prefix), reverse=True)
-        else:
-            random.shuffle(states_to_cover)
-
-        for state in states_to_cover:
-            self.freq_dict[state.prefix] = self.freq_dict[state.prefix] + 1
-
-            self.reset_hyp_and_sul(hypothesis)
-
-            prefix = state.prefix
-            for p in prefix:
-                hypothesis.step(p)
-                self.sul.step(p)
-                self.num_steps += 1
-
-            suffix = ()
-            for _ in range(self.steps_per_walk):
-                suffix += (random.choice(self.alphabet),)
-
-                out_sul = self.sul.step(suffix[-1])
-                out_hyp = hypothesis.step(suffix[-1])
-                self.num_steps += 1
-
-                if out_sul != out_hyp:
-                    self.sul.post()
-                    return prefix + suffix
-
-        return None
+import random
+
+from aalpy.base.Oracle import Oracle
+from aalpy.base.SUL import SUL
+
+
+class StatePrefixEqOracle(Oracle):
+    """
+    Equivalence oracle that achieves guided exploration by starting random walks from each state a walk_per_state
+    times. Starting the random walk ensures that all states are reached at least walk_per_state times and that their
+    surrounding is randomly explored. Note that each state serves as a root of random exploration of maximum length
+    rand_walk_len exactly walk_per_state times during learning. Therefore excessive testing of initial states is
+    avoided.
+    """
+    def __init__(self, alphabet: list, sul: SUL, walks_per_state=10, walk_len=12, depth_first=False):
+        """
+        Args:
+
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            walks_per_state:individual walks per state of the automaton over the whole learning process
+
+            walk_len:length of random walk
+
+            depth_first:first explore newest states
+        """
+
+        super().__init__(alphabet, sul)
+        self.walks_per_state = walks_per_state
+        self.steps_per_walk = walk_len
+        self.depth_first = depth_first
+
+        self.freq_dict = dict()
+
+    def find_cex(self, hypothesis):
+
+        states_to_cover = []
+        for state in hypothesis.states:
+            if state.prefix is None:
+                state.prefix = hypothesis.get_shortest_path(hypothesis.initial_state, state)
+            if state.prefix not in self.freq_dict.keys():
+                self.freq_dict[state.prefix] = 0
+
+            states_to_cover.extend([state] * (self.walks_per_state - self.freq_dict[state.prefix]))
+
+        if self.depth_first:
+            # reverse sort the states by length of their access sequences
+            # first do the random walk on the state with longest access sequence
+            states_to_cover.sort(key=lambda x: len(x.prefix), reverse=True)
+        else:
+            random.shuffle(states_to_cover)
+
+        for state in states_to_cover:
+            self.freq_dict[state.prefix] = self.freq_dict[state.prefix] + 1
+
+            self.reset_hyp_and_sul(hypothesis)
+
+            prefix = state.prefix
+            for p in prefix:
+                hypothesis.step(p)
+                self.sul.step(p)
+                self.num_steps += 1
+
+            suffix = ()
+            for _ in range(self.steps_per_walk):
+                suffix += (random.choice(self.alphabet),)
+
+                out_sul = self.sul.step(suffix[-1])
+                out_hyp = hypothesis.step(suffix[-1])
+                self.num_steps += 1
+
+                if out_sul != out_hyp:
+                    self.sul.post()
+                    return prefix + suffix
+
+        return None
```

## aalpy/oracles/TransitionFocusOracle.py

 * *Ordering differences only*

```diff
@@ -1,53 +1,53 @@
-import random
-
-from aalpy.base.Oracle import Oracle
-from aalpy.base.SUL import SUL
-
-
-class TransitionFocusOracle(Oracle):
-    """
-    This equivalence oracle focuses either on the same state transitions or transitions that lead to the different
-    states. This equivalence oracle should be used on grammars like balanced parentheses. In such grammars,
-    all interesting behavior occurs on the transitions between states and potential bugs can be found only by
-    focusing on transitions.
-    """
-    def __init__(self, alphabet, sul: SUL, num_random_walks=500, walk_len=20, same_state_prob=0.2):
-        """
-        Args:
-            alphabet: input alphabet
-            sul: system under learning
-            num_random_walks: number of walks
-            walk_len: length of each walk
-            same_state_prob: probability that the next input will lead to same state transition
-        """
-
-        super().__init__(alphabet, sul)
-        self.num_walks = num_random_walks
-        self.steps_per_walk = walk_len
-        self.same_state_prob = same_state_prob
-
-    def find_cex(self, hypothesis):
-
-        for _ in range(self.num_walks):
-            self.reset_hyp_and_sul(hypothesis)
-
-            curr_state = hypothesis.initial_state
-            inputs = []
-            for _ in range(self.steps_per_walk):
-                if random.random() <= self.same_state_prob:
-                    possible_inputs = curr_state.get_same_state_transitions()
-                else:
-                    possible_inputs = curr_state.get_diff_state_transitions()
-
-                act = random.choice(possible_inputs) if possible_inputs else random.choice(self.alphabet)
-                inputs.append(act)
-
-                out_sul = self.sul.step(inputs[-1])
-                out_hyp = hypothesis.step(inputs[-1])
-                self.num_steps += 1
-
-                if out_sul != out_hyp:
-                    self.sul.post()
-                    return inputs
-
-        return None
+import random
+
+from aalpy.base.Oracle import Oracle
+from aalpy.base.SUL import SUL
+
+
+class TransitionFocusOracle(Oracle):
+    """
+    This equivalence oracle focuses either on the same state transitions or transitions that lead to the different
+    states. This equivalence oracle should be used on grammars like balanced parentheses. In such grammars,
+    all interesting behavior occurs on the transitions between states and potential bugs can be found only by
+    focusing on transitions.
+    """
+    def __init__(self, alphabet, sul: SUL, num_random_walks=500, walk_len=20, same_state_prob=0.2):
+        """
+        Args:
+            alphabet: input alphabet
+            sul: system under learning
+            num_random_walks: number of walks
+            walk_len: length of each walk
+            same_state_prob: probability that the next input will lead to same state transition
+        """
+
+        super().__init__(alphabet, sul)
+        self.num_walks = num_random_walks
+        self.steps_per_walk = walk_len
+        self.same_state_prob = same_state_prob
+
+    def find_cex(self, hypothesis):
+
+        for _ in range(self.num_walks):
+            self.reset_hyp_and_sul(hypothesis)
+
+            curr_state = hypothesis.initial_state
+            inputs = []
+            for _ in range(self.steps_per_walk):
+                if random.random() <= self.same_state_prob:
+                    possible_inputs = curr_state.get_same_state_transitions()
+                else:
+                    possible_inputs = curr_state.get_diff_state_transitions()
+
+                act = random.choice(possible_inputs) if possible_inputs else random.choice(self.alphabet)
+                inputs.append(act)
+
+                out_sul = self.sul.step(inputs[-1])
+                out_hyp = hypothesis.step(inputs[-1])
+                self.num_steps += 1
+
+                if out_sul != out_hyp:
+                    self.sul.post()
+                    return inputs
+
+        return None
```

## aalpy/oracles/UserInputEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,69 +1,69 @@
-from aalpy.base import Oracle, SUL
-from aalpy.utils.FileHandler import visualize_automaton
-
-
-class UserInputEqOracle(Oracle):
-    """
-    Interactive equivalence oracle. For every counterexample, the current hypothesis will be visualized and the user can
-    enter the counterexample step by step.
-    The user provides elements of the input alphabet or commands.
-    When the element of the input alphabet is entered, the step will be performed in the current hypothesis and output
-    will be printed.
-
-    Commands offered to the users are:
-
-        print alphabet - prints the input alphabet
-
-        current inputs - inputs entered so far
-
-        cex - returns inputs entered so far as the counterexample
-
-        end - no counterexample exists
-
-        reset - resets the current state of the hypothesis and clears inputs
-    """
-    def __init__(self, alphabet: list, sul: SUL):
-        super().__init__(alphabet, sul)
-        self.curr_hypothesis = 0
-
-    def find_cex(self, hypothesis):
-
-        self.reset_hyp_and_sul(hypothesis)
-
-        self.curr_hypothesis += 1
-        inputs = []
-        visualize_automaton(hypothesis, path=f'Hypothesis_{self.curr_hypothesis}')
-        while True:
-            inp = input('Please provide an input: ')
-            if inp == 'help':
-                print('Use one of following commands [print alphabet, current inputs, cex, end, reset] '
-                      'or provide an input')
-                continue
-            if inp == 'print alphabet':
-                print(self.alphabet)
-                continue
-            if inp == 'current inputs':
-                print(inputs)
-                continue
-            if inp == 'cex':
-                if inputs:
-                    self.sul.post()
-                    return inputs
-            if inp == 'end':
-                return None
-            if inp == 'reset':
-                inputs.clear()
-                self.reset_hyp_and_sul(hypothesis)
-                print('You are back in the initial state. Please provide an input: ')
-                continue
-            if inp not in self.alphabet:
-                print("Provided input is not in the input alphabet.")
-                continue
-            inputs.append(inp)
-            self.num_steps += 1
-            out_hyp = hypothesis.step(inp)
-            out_sul = self.sul.step(inp)
-            print('Hypothesis Output :', out_hyp)
-            print('SUL Output        :', out_sul)
-            if out_hyp != out_sul:
-                print('Counterexample found.\nIf you want to return it, type \'cex\'.')
+from aalpy.base import Oracle, SUL
+from aalpy.utils.FileHandler import visualize_automaton
+
+
+class UserInputEqOracle(Oracle):
+    """
+    Interactive equivalence oracle. For every counterexample, the current hypothesis will be visualized and the user can
+    enter the counterexample step by step.
+    The user provides elements of the input alphabet or commands.
+    When the element of the input alphabet is entered, the step will be performed in the current hypothesis and output
+    will be printed.
+
+    Commands offered to the users are:
+
+        print alphabet - prints the input alphabet
+
+        current inputs - inputs entered so far
+
+        cex - returns inputs entered so far as the counterexample
+
+        end - no counterexample exists
+
+        reset - resets the current state of the hypothesis and clears inputs
+    """
+    def __init__(self, alphabet: list, sul: SUL):
+        super().__init__(alphabet, sul)
+        self.curr_hypothesis = 0
+
+    def find_cex(self, hypothesis):
+
+        self.reset_hyp_and_sul(hypothesis)
+
+        self.curr_hypothesis += 1
+        inputs = []
+        visualize_automaton(hypothesis, path=f'Hypothesis_{self.curr_hypothesis}')
+        while True:
+            inp = input('Please provide an input: ')
+            if inp == 'help':
+                print('Use one of following commands [print alphabet, current inputs, cex, end, reset] '
+                      'or provide an input')
+                continue
+            if inp == 'print alphabet':
+                print(self.alphabet)
+                continue
+            if inp == 'current inputs':
+                print(inputs)
+                continue
+            if inp == 'cex':
+                if inputs:
+                    self.sul.post()
+                    return inputs
+            if inp == 'end':
+                return None
+            if inp == 'reset':
+                inputs.clear()
+                self.reset_hyp_and_sul(hypothesis)
+                print('You are back in the initial state. Please provide an input: ')
+                continue
+            if inp not in self.alphabet:
+                print("Provided input is not in the input alphabet.")
+                continue
+            inputs.append(inp)
+            self.num_steps += 1
+            out_hyp = hypothesis.step(inp)
+            out_sul = self.sul.step(inp)
+            print('Hypothesis Output :', out_hyp)
+            print('SUL Output        :', out_sul)
+            if out_hyp != out_sul:
+                print('Counterexample found.\nIf you want to return it, type \'cex\'.')
```

## aalpy/oracles/WMethodEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,123 +1,123 @@
-from itertools import product
-from random import shuffle, choice, randint
-
-from aalpy.base.Oracle import Oracle
-from aalpy.base.SUL import SUL
-
-
-class WMethodEqOracle(Oracle):
-    """
-    Equivalence oracle based on characterization set/ W-set. From 'Tsun S. Chow.   Testing software design modeled by
-    finite-state machines'.
-    """
-    def __init__(self, alphabet: list, sul: SUL, max_number_of_states, shuffle_test_set=True):
-        """
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-            max_number_of_states: maximum number of states in the automaton
-            shuffle_test_set: if True, test cases will be shuffled
-        """
-
-        super().__init__(alphabet, sul)
-        self.m = max_number_of_states
-        self.shuffle = shuffle_test_set
-        self.cache = set()
-
-    def find_cex(self, hypothesis):
-
-        if not hypothesis.characterization_set:
-            hypothesis.characterization_set = hypothesis.compute_characterization_set()
-
-        # covers every transition of the specification at least once.
-        transition_cover = [state.prefix + (letter,) for state in hypothesis.states for letter in self.alphabet]
-
-        middle = []
-        for i in range(self.m + 1 - len(hypothesis.states)):
-            middle.extend(list(product(self.alphabet, repeat=i)))
-
-        for seq in product(transition_cover, middle, hypothesis.characterization_set):
-            inp_seq = tuple([i for sub in seq for i in sub])
-            if inp_seq not in self.cache:
-                self.reset_hyp_and_sul(hypothesis)
-                outputs = []
-
-                for ind, letter in enumerate(inp_seq):
-                    out_hyp = hypothesis.step(letter)
-                    out_sul = self.sul.step(letter)
-                    self.num_steps += 1
-
-                    outputs.append(out_sul)
-                    if out_hyp != out_sul:
-                        self.sul.post()
-                        return inp_seq[:ind + 1]
-                self.cache.add(inp_seq)
-            
-
-        return None
-
-
-class RandomWMethodEqOracle(Oracle):
-    """
-    Randomized version of the W-Method equivalence oracle.
-    Random walks stem from fixed prefix (path to the state). At the end of the random
-    walk an element from the characterization set is added to the test case.
-    """
-    def __init__(self, alphabet: list, sul: SUL, walks_per_state=12, walk_len=12):
-        """
-        Args:
-
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            walks_per_state: number of random walks that should start from each state
-
-            walk_len: length of random walk
-        """
-
-        super().__init__(alphabet, sul)
-        self.walks_per_state = walks_per_state
-        self.random_walk_len = walk_len
-        self.freq_dict = dict()
-
-    def find_cex(self, hypothesis):
-
-        if not hypothesis.characterization_set:
-            hypothesis.characterization_set = hypothesis.compute_characterization_set()
-            # fix for non-minimal intermediate hypothesis that can occur in KV
-            if not hypothesis.characterization_set:
-                hypothesis.characterization_set = [(a,) for a in hypothesis.get_input_alphabet()]
-
-        states_to_cover = []
-        for state in hypothesis.states:
-            if state.prefix is None:
-                state.prefix = hypothesis.get_shortest_path(hypothesis.initial_state, state)
-            if state.prefix not in self.freq_dict.keys():
-                self.freq_dict[state.prefix] = 0
-
-            states_to_cover.extend([state] * (self.walks_per_state - self.freq_dict[state.prefix]))
-
-        shuffle(states_to_cover)
-
-        for state in states_to_cover:
-            self.freq_dict[state.prefix] = self.freq_dict[state.prefix] + 1
-
-            self.reset_hyp_and_sul(hypothesis)
-
-            prefix = state.prefix
-            random_walk = tuple(choice(self.alphabet) for _ in range(randint(1, self.random_walk_len)))
-
-            test_case = prefix + random_walk + choice(hypothesis.characterization_set)
-
-            for ind, i in enumerate(test_case):
-                output_hyp = hypothesis.step(i)
-                output_sul = self.sul.step(i)
-                self.num_steps += 1
-
-                if output_sul != output_hyp:
-                    self.sul.post()
-                    return test_case[:ind + 1]
-
-        return None
+from itertools import product
+from random import shuffle, choice, randint
+
+from aalpy.base.Oracle import Oracle
+from aalpy.base.SUL import SUL
+
+
+class WMethodEqOracle(Oracle):
+    """
+    Equivalence oracle based on characterization set/ W-set. From 'Tsun S. Chow.   Testing software design modeled by
+    finite-state machines'.
+    """
+    def __init__(self, alphabet: list, sul: SUL, max_number_of_states, shuffle_test_set=True):
+        """
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+            max_number_of_states: maximum number of states in the automaton
+            shuffle_test_set: if True, test cases will be shuffled
+        """
+
+        super().__init__(alphabet, sul)
+        self.m = max_number_of_states
+        self.shuffle = shuffle_test_set
+        self.cache = set()
+
+    def find_cex(self, hypothesis):
+
+        if not hypothesis.characterization_set:
+            hypothesis.characterization_set = hypothesis.compute_characterization_set()
+
+        # covers every transition of the specification at least once.
+        transition_cover = [state.prefix + (letter,) for state in hypothesis.states for letter in self.alphabet]
+
+        middle = []
+        for i in range(self.m + 1 - len(hypothesis.states)):
+            middle.extend(list(product(self.alphabet, repeat=i)))
+
+        for seq in product(transition_cover, middle, hypothesis.characterization_set):
+            inp_seq = tuple([i for sub in seq for i in sub])
+            if inp_seq not in self.cache:
+                self.reset_hyp_and_sul(hypothesis)
+                outputs = []
+
+                for ind, letter in enumerate(inp_seq):
+                    out_hyp = hypothesis.step(letter)
+                    out_sul = self.sul.step(letter)
+                    self.num_steps += 1
+
+                    outputs.append(out_sul)
+                    if out_hyp != out_sul:
+                        self.sul.post()
+                        return inp_seq[:ind + 1]
+                self.cache.add(inp_seq)
+            
+
+        return None
+
+
+class RandomWMethodEqOracle(Oracle):
+    """
+    Randomized version of the W-Method equivalence oracle.
+    Random walks stem from fixed prefix (path to the state). At the end of the random
+    walk an element from the characterization set is added to the test case.
+    """
+    def __init__(self, alphabet: list, sul: SUL, walks_per_state=12, walk_len=12):
+        """
+        Args:
+
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            walks_per_state: number of random walks that should start from each state
+
+            walk_len: length of random walk
+        """
+
+        super().__init__(alphabet, sul)
+        self.walks_per_state = walks_per_state
+        self.random_walk_len = walk_len
+        self.freq_dict = dict()
+
+    def find_cex(self, hypothesis):
+
+        if not hypothesis.characterization_set:
+            hypothesis.characterization_set = hypothesis.compute_characterization_set()
+            # fix for non-minimal intermediate hypothesis that can occur in KV
+            if not hypothesis.characterization_set:
+                hypothesis.characterization_set = [(a,) for a in hypothesis.get_input_alphabet()]
+
+        states_to_cover = []
+        for state in hypothesis.states:
+            if state.prefix is None:
+                state.prefix = hypothesis.get_shortest_path(hypothesis.initial_state, state)
+            if state.prefix not in self.freq_dict.keys():
+                self.freq_dict[state.prefix] = 0
+
+            states_to_cover.extend([state] * (self.walks_per_state - self.freq_dict[state.prefix]))
+
+        shuffle(states_to_cover)
+
+        for state in states_to_cover:
+            self.freq_dict[state.prefix] = self.freq_dict[state.prefix] + 1
+
+            self.reset_hyp_and_sul(hypothesis)
+
+            prefix = state.prefix
+            random_walk = tuple(choice(self.alphabet) for _ in range(randint(1, self.random_walk_len)))
+
+            test_case = prefix + random_walk + choice(hypothesis.characterization_set)
+
+            for ind, i in enumerate(test_case):
+                output_hyp = hypothesis.step(i)
+                output_sul = self.sul.step(i)
+                self.num_steps += 1
+
+                if output_sul != output_hyp:
+                    self.sul.post()
+                    return test_case[:ind + 1]
+
+        return None
```

## aalpy/oracles/__init__.py

 * *Ordering differences only*

```diff
@@ -1,13 +1,13 @@
-from .BreadthFirstExplorationEqOracle import BreadthFirstExplorationEqOracle
-from .CacheBasedEqOracle import CacheBasedEqOracle
-from .kWayStateCoverageEqOracle import KWayStateCoverageEqOracle
-from .kWayTransitionCoverageEqOracle import KWayTransitionCoverageEqOracle
-from .RandomWalkEqOracle import RandomWalkEqOracle
-from .RandomWordEqOracle import RandomWordEqOracle
-from .StatePrefixEqOracle import StatePrefixEqOracle
-from .TransitionFocusOracle import TransitionFocusOracle
-from .UserInputEqOracle import UserInputEqOracle
-from .WMethodEqOracle import RandomWMethodEqOracle, WMethodEqOracle
-from .PacOracle import PacOracle
-from .ProvidedSequencesOracleWrapper import ProvidedSequencesOracleWrapper
-from .PerfectKnowledgeEqOracle import PerfectKnowledgeEqOracle
+from .BreadthFirstExplorationEqOracle import BreadthFirstExplorationEqOracle
+from .CacheBasedEqOracle import CacheBasedEqOracle
+from .kWayStateCoverageEqOracle import KWayStateCoverageEqOracle
+from .kWayTransitionCoverageEqOracle import KWayTransitionCoverageEqOracle
+from .RandomWalkEqOracle import RandomWalkEqOracle
+from .RandomWordEqOracle import RandomWordEqOracle
+from .StatePrefixEqOracle import StatePrefixEqOracle
+from .TransitionFocusOracle import TransitionFocusOracle
+from .UserInputEqOracle import UserInputEqOracle
+from .WMethodEqOracle import RandomWMethodEqOracle, WMethodEqOracle
+from .PacOracle import PacOracle
+from .ProvidedSequencesOracleWrapper import ProvidedSequencesOracleWrapper
+from .PerfectKnowledgeEqOracle import PerfectKnowledgeEqOracle
```

## aalpy/oracles/kWayStateCoverageEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,81 +1,81 @@
-from random import choices, shuffle
-
-from aalpy.base import Oracle, SUL
-from itertools import combinations, permutations
-
-
-class KWayStateCoverageEqOracle(Oracle):
-    """
-    A test case will be computed for every k-combination or k-permutation of states with additional
-    random walk at the end.
-    """
-
-    def __init__(self, alphabet: list, sul: SUL, k=2, random_walk_len=20, method='combinations'):
-        """
-
-        Args:
-
-            alphabet: input alphabet
-
-            sul: system under learning
-
-            k: k value used for k-wise combinations/permutations of states
-
-            random_walk_len: length of random walk performed at the end of each combination/permutation
-
-            method: either 'combinations' or 'permutations'
-        """
-        super().__init__(alphabet, sul)
-        assert k > 1 and method in ['combinations', 'permutations']
-        self.k = k
-        self.cache = set()
-        self.fun = combinations if method == 'combinations' else permutations
-        self.random_walk_len = random_walk_len
-
-    def find_cex(self, hypothesis):
-
-        if len(hypothesis.states) == 1:
-            for _ in range(self.random_walk_len):
-                path = choices(self.alphabet, k=self.random_walk_len)
-                hypothesis.reset_to_initial()
-                self.sul.post()
-                self.sul.pre()
-                for i, p in enumerate(path):
-                    out_sul = self.sul.step(p)
-                    out_hyp = hypothesis.step(p)
-                    self.num_steps += 1
-
-                    if out_sul != out_hyp:
-                        self.sul.post()
-                        return path[:i + 1]
-
-        states = hypothesis.states
-        shuffle(states)
-
-        for comb in self.fun(hypothesis.states, self.k):
-            prefixes = frozenset([c.prefix for c in comb])
-            if prefixes in self.cache:
-                continue
-            else:
-                self.cache.add(prefixes)
-
-            index = 0
-            path = comb[0].prefix
-            while index < len(comb) - 1:
-                path += hypothesis.get_shortest_path(comb[index], comb[index + 1])
-                index += 1
-
-            path += tuple(choices(self.alphabet, k=self.random_walk_len))
-
-            self.reset_hyp_and_sul(hypothesis)
-
-            for i, p in enumerate(path):
-                out_sul = self.sul.step(p)
-                out_hyp = hypothesis.step(p)
-                self.num_steps += 1
-
-                if out_sul != out_hyp:
-                    self.sul.post()
-                    return path[:i + 1]
-
-        return None
+from random import choices, shuffle
+
+from aalpy.base import Oracle, SUL
+from itertools import combinations, permutations
+
+
+class KWayStateCoverageEqOracle(Oracle):
+    """
+    A test case will be computed for every k-combination or k-permutation of states with additional
+    random walk at the end.
+    """
+
+    def __init__(self, alphabet: list, sul: SUL, k=2, random_walk_len=20, method='combinations'):
+        """
+
+        Args:
+
+            alphabet: input alphabet
+
+            sul: system under learning
+
+            k: k value used for k-wise combinations/permutations of states
+
+            random_walk_len: length of random walk performed at the end of each combination/permutation
+
+            method: either 'combinations' or 'permutations'
+        """
+        super().__init__(alphabet, sul)
+        assert k > 1 and method in ['combinations', 'permutations']
+        self.k = k
+        self.cache = set()
+        self.fun = combinations if method == 'combinations' else permutations
+        self.random_walk_len = random_walk_len
+
+    def find_cex(self, hypothesis):
+
+        if len(hypothesis.states) == 1:
+            for _ in range(self.random_walk_len):
+                path = choices(self.alphabet, k=self.random_walk_len)
+                hypothesis.reset_to_initial()
+                self.sul.post()
+                self.sul.pre()
+                for i, p in enumerate(path):
+                    out_sul = self.sul.step(p)
+                    out_hyp = hypothesis.step(p)
+                    self.num_steps += 1
+
+                    if out_sul != out_hyp:
+                        self.sul.post()
+                        return path[:i + 1]
+
+        states = hypothesis.states
+        shuffle(states)
+
+        for comb in self.fun(hypothesis.states, self.k):
+            prefixes = frozenset([c.prefix for c in comb])
+            if prefixes in self.cache:
+                continue
+            else:
+                self.cache.add(prefixes)
+
+            index = 0
+            path = comb[0].prefix
+            while index < len(comb) - 1:
+                path += hypothesis.get_shortest_path(comb[index], comb[index + 1])
+                index += 1
+
+            path += tuple(choices(self.alphabet, k=self.random_walk_len))
+
+            self.reset_hyp_and_sul(hypothesis)
+
+            for i, p in enumerate(path):
+                out_sul = self.sul.step(p)
+                out_hyp = hypothesis.step(p)
+                self.num_steps += 1
+
+                if out_sul != out_hyp:
+                    self.sul.post()
+                    return path[:i + 1]
+
+        return None
```

## aalpy/oracles/kWayTransitionCoverageEqOracle.py

 * *Ordering differences only*

```diff
@@ -1,165 +1,165 @@
-from collections import namedtuple
-from itertools import product
-from random import choices, randint, random
-
-from aalpy.base import SUL, Automaton, Oracle
-
-KWayTransition = namedtuple("KWayTransition", "start_state end_state steps")
-Path = namedtuple("Path", "start_state end_state steps kWayTransitions, transitions_log")
-
-
-class KWayTransitionCoverageEqOracle(Oracle):
-    """
-    This Equivalence oracle selects test cases based on k-way transitions coverage. It does that
-    by generating random queries and finding the smallest subset with the highest coverage. In other words, this oracle
-    finds counter examples by running random paths that cover all pairwise / k-way transitions.
-    """
-
-    def __init__(self, alphabet: list, sul: SUL, k: int = 2, method='random',
-                 num_generate_paths: int = 1000,
-                 max_path_len: int = 50,
-                 max_number_of_steps: int = 0,
-                 optimize: str = 'steps',
-                 random_walk_len=10):
-        """
-        Args:
-
-            alphabet: input alphabet
-            sul: system under learning
-            k: k value used for K-Way transitions, i.e the number of steps between the start and the end of a transition
-            method: defines how the queries are generated 'random' or 'prefix'
-            num_generate_paths: number of random queries used to find the optimal subset
-            max_path_len: the maximum step size of a generated path
-            max_number_of_steps: maximum number of steps that will be executed on the SUL (0 = no limit)
-            optimize: minimize either the number of  'steps' or 'queries' that are executed
-            random_walk_len: the number of steps that are added by 'prefix' generated paths
-
-        """
-        super().__init__(alphabet, sul)
-        assert k >= 2
-        assert method in ['random', 'prefix']
-        assert optimize in ['steps', 'queries']
-
-        self.k = k
-        self.method = method
-        self.num_generate_paths = num_generate_paths
-        self.max_path_len = max_path_len
-        self.max_number_of_steps = max_number_of_steps
-        self.optimize = optimize
-        self.random_walk_len = random_walk_len
-
-        self.cached_paths = list()
-
-    def find_cex(self, hypothesis: Automaton):
-        if self.method == 'random':
-            paths = self.generate_random_paths(hypothesis) + self.cached_paths
-            self.cached_paths = self.greedy_set_cover(hypothesis, paths)
-
-            for path in self.cached_paths:
-                counter_example = self.check_path(hypothesis, path.steps)
-
-                if counter_example is not None:
-                    return counter_example
-
-        elif self.method == 'prefix':
-            for steps in self.generate_prefix_steps(hypothesis):
-                counter_example = self.check_path(hypothesis, steps)
-
-                if counter_example is not None:
-                    return counter_example
-        return None
-
-    def greedy_set_cover(self, hypothesis: Automaton, paths: list):
-        result = list()
-        covered = set()
-        step_count = 0
-
-        size_of_universe = len(hypothesis.states) * pow(len(self.alphabet), self.k)
-
-        while size_of_universe > len(covered):
-            path = self.select_optimal_path(covered, paths)
-
-            if path is not None:
-                covered = set.union(covered, path.kWayTransitions)
-                paths.remove(path)
-                result.append(path)
-                step_count += len(path.steps)
-
-            if path is None or not paths:
-                paths = [self.create_path(hypothesis, steps) for steps in self.generate_prefix_steps(hypothesis)]
-
-            if self.max_number_of_steps != 0 and step_count > self.max_number_of_steps:
-                print("stop")
-                break
-
-        return result
-
-    def select_optimal_path(self, covered: set, paths: list) -> Path:
-        result = None
-
-        if self.optimize == 'steps':
-            result = max(paths, key=lambda p: len(
-                p.kWayTransitions - covered) / len(p.steps))
-
-        if self.optimize == 'queries':
-            result = max(paths, key=lambda p: len(p.kWayTransitions - covered))
-
-        return result if len(result.kWayTransitions - covered) != 0 else None
-
-    def generate_random_paths(self, hypothesis: Automaton) -> list:
-        result = list()
-
-        for _ in range(self.num_generate_paths):
-            random_length = randint(self.k, self.max_path_len)
-            steps = tuple(choices(self.alphabet, k=random_length))
-            path = self.create_path(hypothesis, steps)
-            result.append(path)
-
-        return result
-
-    def generate_prefix_steps(self, hypothesis: Automaton) -> tuple:
-        for state in reversed(hypothesis.states):
-            prefix = state.prefix
-            for steps in sorted(product(self.alphabet, repeat=self.k), key=lambda k: random()):
-                yield prefix + steps + tuple(choices(self.alphabet, k=self.random_walk_len))
-
-    def create_path(self, hypothesis: Automaton, steps: tuple) -> Path:
-        transitions = set()
-        transitions_log = list()
-
-        prev_states = list()
-        end_states = list()
-
-        hypothesis.reset_to_initial()
-
-        for i, s in enumerate(steps):
-            prev_states.append(hypothesis.current_state)
-            hypothesis.step(s)
-            end_states.append(hypothesis.current_state)
-
-        for i in range(len(steps) - self.k + 1):
-            prev_state = prev_states[i]
-            end_state = end_states[i + self.k - 1]
-            chunk = tuple(steps[i:i + self.k])
-
-            transition = KWayTransition(prev_state.state_id, end_state.state_id, chunk)
-
-            transitions_log.append(transition)
-            transitions.add(transition)
-
-        return Path(hypothesis.initial_state, end_states[-1], steps, transitions, transitions_log)
-
-    def check_path(self, hypothesis: Automaton, steps: tuple):
-        self.reset_hyp_and_sul(hypothesis)
-
-        for i, s in enumerate(steps):
-            out_sul = self.sul.step(s)
-            out_hyp = hypothesis.step(s)
-
-            self.num_steps += 1
-
-            if out_sul != out_hyp:
-                self.sul.post()
-                return steps[:i + 1]
-
-        return None
+from collections import namedtuple
+from itertools import product
+from random import choices, randint, random
+
+from aalpy.base import SUL, Automaton, Oracle
+
+KWayTransition = namedtuple("KWayTransition", "start_state end_state steps")
+Path = namedtuple("Path", "start_state end_state steps kWayTransitions, transitions_log")
+
+
+class KWayTransitionCoverageEqOracle(Oracle):
+    """
+    This Equivalence oracle selects test cases based on k-way transitions coverage. It does that
+    by generating random queries and finding the smallest subset with the highest coverage. In other words, this oracle
+    finds counter examples by running random paths that cover all pairwise / k-way transitions.
+    """
+
+    def __init__(self, alphabet: list, sul: SUL, k: int = 2, method='random',
+                 num_generate_paths: int = 1000,
+                 max_path_len: int = 50,
+                 max_number_of_steps: int = 0,
+                 optimize: str = 'steps',
+                 random_walk_len=10):
+        """
+        Args:
+
+            alphabet: input alphabet
+            sul: system under learning
+            k: k value used for K-Way transitions, i.e the number of steps between the start and the end of a transition
+            method: defines how the queries are generated 'random' or 'prefix'
+            num_generate_paths: number of random queries used to find the optimal subset
+            max_path_len: the maximum step size of a generated path
+            max_number_of_steps: maximum number of steps that will be executed on the SUL (0 = no limit)
+            optimize: minimize either the number of  'steps' or 'queries' that are executed
+            random_walk_len: the number of steps that are added by 'prefix' generated paths
+
+        """
+        super().__init__(alphabet, sul)
+        assert k >= 2
+        assert method in ['random', 'prefix']
+        assert optimize in ['steps', 'queries']
+
+        self.k = k
+        self.method = method
+        self.num_generate_paths = num_generate_paths
+        self.max_path_len = max_path_len
+        self.max_number_of_steps = max_number_of_steps
+        self.optimize = optimize
+        self.random_walk_len = random_walk_len
+
+        self.cached_paths = list()
+
+    def find_cex(self, hypothesis: Automaton):
+        if self.method == 'random':
+            paths = self.generate_random_paths(hypothesis) + self.cached_paths
+            self.cached_paths = self.greedy_set_cover(hypothesis, paths)
+
+            for path in self.cached_paths:
+                counter_example = self.check_path(hypothesis, path.steps)
+
+                if counter_example is not None:
+                    return counter_example
+
+        elif self.method == 'prefix':
+            for steps in self.generate_prefix_steps(hypothesis):
+                counter_example = self.check_path(hypothesis, steps)
+
+                if counter_example is not None:
+                    return counter_example
+        return None
+
+    def greedy_set_cover(self, hypothesis: Automaton, paths: list):
+        result = list()
+        covered = set()
+        step_count = 0
+
+        size_of_universe = len(hypothesis.states) * pow(len(self.alphabet), self.k)
+
+        while size_of_universe > len(covered):
+            path = self.select_optimal_path(covered, paths)
+
+            if path is not None:
+                covered = set.union(covered, path.kWayTransitions)
+                paths.remove(path)
+                result.append(path)
+                step_count += len(path.steps)
+
+            if path is None or not paths:
+                paths = [self.create_path(hypothesis, steps) for steps in self.generate_prefix_steps(hypothesis)]
+
+            if self.max_number_of_steps != 0 and step_count > self.max_number_of_steps:
+                print("stop")
+                break
+
+        return result
+
+    def select_optimal_path(self, covered: set, paths: list) -> Path:
+        result = None
+
+        if self.optimize == 'steps':
+            result = max(paths, key=lambda p: len(
+                p.kWayTransitions - covered) / len(p.steps))
+
+        if self.optimize == 'queries':
+            result = max(paths, key=lambda p: len(p.kWayTransitions - covered))
+
+        return result if len(result.kWayTransitions - covered) != 0 else None
+
+    def generate_random_paths(self, hypothesis: Automaton) -> list:
+        result = list()
+
+        for _ in range(self.num_generate_paths):
+            random_length = randint(self.k, self.max_path_len)
+            steps = tuple(choices(self.alphabet, k=random_length))
+            path = self.create_path(hypothesis, steps)
+            result.append(path)
+
+        return result
+
+    def generate_prefix_steps(self, hypothesis: Automaton) -> tuple:
+        for state in reversed(hypothesis.states):
+            prefix = state.prefix
+            for steps in sorted(product(self.alphabet, repeat=self.k), key=lambda k: random()):
+                yield prefix + steps + tuple(choices(self.alphabet, k=self.random_walk_len))
+
+    def create_path(self, hypothesis: Automaton, steps: tuple) -> Path:
+        transitions = set()
+        transitions_log = list()
+
+        prev_states = list()
+        end_states = list()
+
+        hypothesis.reset_to_initial()
+
+        for i, s in enumerate(steps):
+            prev_states.append(hypothesis.current_state)
+            hypothesis.step(s)
+            end_states.append(hypothesis.current_state)
+
+        for i in range(len(steps) - self.k + 1):
+            prev_state = prev_states[i]
+            end_state = end_states[i + self.k - 1]
+            chunk = tuple(steps[i:i + self.k])
+
+            transition = KWayTransition(prev_state.state_id, end_state.state_id, chunk)
+
+            transitions_log.append(transition)
+            transitions.add(transition)
+
+        return Path(hypothesis.initial_state, end_states[-1], steps, transitions, transitions_log)
+
+    def check_path(self, hypothesis: Automaton, steps: tuple):
+        self.reset_hyp_and_sul(hypothesis)
+
+        for i, s in enumerate(steps):
+            out_sul = self.sul.step(s)
+            out_hyp = hypothesis.step(s)
+
+            self.num_steps += 1
+
+            if out_sul != out_hyp:
+                self.sul.post()
+                return steps[:i + 1]
+
+        return None
```

## aalpy/utils/AutomatonGenerators.py

```diff
@@ -1,528 +1,520 @@
-import random
-import warnings
-
-from aalpy.automata import Dfa, DfaState, MdpState, Mdp, MealyMachine, MealyState, \
-    MooreMachine, MooreState, OnfsmState, Onfsm, MarkovChain, McState, StochasticMealyState, StochasticMealyMachine, \
-    Sevpa, SevpaState, SevpaAlphabet, SevpaTransition
-
-
-def generate_random_deterministic_automata(automaton_type,
-                                           num_states,
-                                           input_alphabet_size,
-                                           output_alphabet_size=None,
-                                           ensure_minimality=True,
-                                           **kwargs
-                                           ):
-    """
-    Generates a random deterministic automata of 'automaton_type'.
-
-    Args:
-        automaton_type: type of automaton, either 'dfa', 'mealy', or 'moore'
-        num_states: number of states
-        input_alphabet_size: size of input alphabet
-        output_alphabet_size: size of output alphabet. (ignored for DFAs)
-        ensure_minimality: ensure that the automaton is minimal
-        **kwargs:
-            : 'num_accepting_states' number of accepting states for DFA generation. If not defined, half of states will
-            be accepting
-
-    Returns:
-
-        Random deterministic automaton of user defined type, size. If ensure_minimality is set to False returned
-        automaton is not necessarily minimal. If minimality is reacquired and random automaton cannot be produced in
-        multiple interactions, non-minimal automaton will be returned and a warning message printed.
-    """
-
-    assert automaton_type in {'dfa', 'mealy', 'moore'}
-    if output_alphabet_size and output_alphabet_size < 2 or output_alphabet_size is None:
-        output_alphabet_size = 2
-
-    state_class_map = {'dfa': DfaState, 'mealy': MealyState, 'moore': MooreState}
-    automaton_class_map = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
-
-    input_alphabet = [f'i{i + 1}' for i in range(input_alphabet_size)]
-    output_alphabet = [f'o{i + 1}' for i in range(output_alphabet_size)] if automaton_type != 'dfa' else [True, False]
-
-    # For backwards comparability or if uses passes custom input output functions
-    if 'custom_input_alphabet' in kwargs:
-        input_alphabet = kwargs.get('custom_input_alphabet')
-        if len(input_alphabet) != input_alphabet_size:
-            assert False, 'Lenght of input_alphabet_size and custom input alphabet should be equal.'
-    if 'custom_output_alphabet' in kwargs:
-        output_alphabet = kwargs.get('custom_output_alphabet')
-        if len(output_alphabet) != output_alphabet_size:
-            assert False, 'Lenght of output_alphabet_size and custom output alphabet should be equal.'
-
-    num_accepting_states = None
-    if 'num_accepting_states' in kwargs:
-        num_accepting_states = kwargs.get('num_accepting_states')
-    if num_accepting_states is None:
-        num_accepting_states = num_states // 2
-
-    num_random_outputs = num_states if automaton_type != 'mealy' else num_states * input_alphabet_size
-
-    output_list = []
-    output_al_copy = output_alphabet.copy()
-
-    if automaton_type != 'dfa':
-        for _ in range(num_random_outputs):
-            if output_al_copy:
-                o = random.choice(output_al_copy)
-                output_al_copy.remove(o)
-            else:
-                o = random.choice(output_alphabet)
-            output_list.append(o)
-    else:
-        output_list = [True] * num_accepting_states + [False] * (num_states - num_accepting_states)
-        random.shuffle(output_list)
-
-    states = [state_class_map[automaton_type](state_id=f's{i + 1}') for i in range(num_states)]
-
-    # define an output function
-    for state_index, state in enumerate(states):
-        if automaton_type == 'dfa':
-            state.is_accepting = output_list[state_index]
-        if automaton_type == 'moore':
-            state.output = output_list[state_index]
-        if automaton_type == 'mealy':
-            for i in input_alphabet:
-                state.output_fun[i] = output_list.pop(0)
-
-    state_buffer = []
-
-    state_buffer.extend(states)
-    while len(state_buffer) < num_states * input_alphabet_size:
-        state_buffer.append(random.choice(states))
-
-    random_automaton = None
-
-    # keep changing transitions until all states are reachable (update in future )
-    all_states_reachable = False
-    while not all_states_reachable:
-        random.shuffle(state_buffer)
-
-        transition_index = 0
-        for state in states:
-            for i in input_alphabet:
-                state.transitions[i] = state_buffer[transition_index]
-                transition_index += 1
-
-        random_automaton = automaton_class_map[automaton_type](states[0], states)
-
-        unreachable_state_exits = False
-        for state in random_automaton.states:
-            state.prefix = random_automaton.get_shortest_path(random_automaton.initial_state, state)
-            if state != random_automaton.initial_state and state.prefix is None:
-                unreachable_state_exits = True
-                break
-        all_states_reachable = not unreachable_state_exits
-
-    if ensure_minimality:
-        minimality_iterations = 1
-        while not random_automaton.is_minimal() or random_automaton.size != num_states:
-            # to avoid infinite loops
-            if minimality_iterations == 100:
-                warnings.warn(f'Non-minimal automaton ({automaton_type}, num_states : {num_states}) returned.')
-                break
-
-            custom_args = {}
-            if 'custom_input_alphabet' in kwargs:
-                custom_args['custom_input_alphabet'] = kwargs.get('custom_input_alphabet')
-            if 'custom_output_alphabet' in kwargs:
-                custom_args['custom_output_alphabet'] = kwargs.get('custom_output_alphabet')
-            if 'num_accepting_states' in kwargs:
-                custom_args['num_accepting_states'] = kwargs.get('num_accepting_states')
-
-            random_automaton = generate_random_deterministic_automata(automaton_type,
-                                                                      num_states,
-                                                                      input_alphabet_size,
-                                                                      output_alphabet_size,
-                                                                      False,  # ensure minimality
-                                                                      **custom_args)
-
-    return random_automaton
-
-
-def generate_random_mealy_machine(num_states, input_alphabet, output_alphabet,
-                                  compute_prefixes=False, ensure_minimality=True) -> MealyMachine:
-    """
-    Generates a random Mealy machine. Kept for backwards compatibility.
-
-    Args:
-
-        num_states: number of states
-        input_alphabet: input alphabet
-        output_alphabet: output alphabet
-        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
-        ensure_minimality: returned automaton will be minimal
-
-    Returns:
-
-        Mealy machine with num_states states
-    """
-
-    random_mealy_machine = generate_random_deterministic_automata('mealy', num_states,
-                                                                  input_alphabet_size=len(input_alphabet),
-                                                                  output_alphabet_size=len(output_alphabet),
-                                                                  ensure_minimality=ensure_minimality,
-                                                                  compute_prefixes=compute_prefixes,
-                                                                  custom_input_alphabet=input_alphabet,
-                                                                  custom_output_alphabet=output_alphabet)
-
-    return random_mealy_machine
-
-
-def generate_random_moore_machine(num_states, input_alphabet, output_alphabet,
-                                  compute_prefixes=False, ensure_minimality=True) -> MooreMachine:
-    """
-    Generates a random Moore machine.
-
-    Args:
-
-        num_states: number of states
-        input_alphabet: input alphabet
-        output_alphabet: output alphabet
-        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
-        ensure_minimality: returned automaton will be minimal
-
-    Returns:
-
-        Random Moore machine with num_states states
-
-    """
-    random_moore_machine = generate_random_deterministic_automata('moore', num_states,
-                                                                  input_alphabet_size=len(input_alphabet),
-                                                                  output_alphabet_size=len(output_alphabet),
-                                                                  ensure_minimality=ensure_minimality,
-                                                                  compute_prefixes=compute_prefixes,
-                                                                  custom_input_alphabet=input_alphabet,
-                                                                  custom_output_alphabet=output_alphabet)
-
-    return random_moore_machine
-
-
-def generate_random_dfa(num_states, alphabet, num_accepting_states=1,
-                        compute_prefixes=False, ensure_minimality=True) -> Dfa:
-    """
-    Generates a random DFA.
-
-    Args:
-
-        num_states: number of states
-        alphabet: input alphabet
-        num_accepting_states: number of accepting states (Default value = 1)
-        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
-        ensure_minimality: returned automaton will be minimal
-
-    Returns:
-
-        Randomly generated DFA
-
-    """
-    if num_states <= num_accepting_states:
-        num_accepting_states = num_states // 2
-
-    random_dfa = generate_random_deterministic_automata('dfa', num_states,
-                                                        input_alphabet_size=len(alphabet),
-                                                        output_alphabet_size=2,
-                                                        ensure_minimality=ensure_minimality,
-                                                        compute_prefixes=compute_prefixes,
-                                                        custom_input_alphabet=alphabet,
-                                                        num_accepting_states=num_accepting_states)
-
-    return random_dfa
-
-
-def generate_random_mdp(num_states, input_size, output_size, possible_probabilities=None):
-    """
-    Generates random MDP.
-
-    Args:
-
-        num_states: number of states
-        input_size: number of inputs
-        output_size: user predefined outputs
-        possible_probabilities: list of possible probability pairs to choose from
-
-    Returns:
-
-        random MDP
-
-    """
-
-    deterministic_model = generate_random_deterministic_automata('moore', num_states, input_size, output_size)
-
-    if input_size > output_size:
-        assert False, 'Cannot create deterministic MDP (in all states, all input-output pairs leads to a single state)' \
-                      ', if number of inputs is smaller than number of outputs)'
-
-    if not possible_probabilities:
-        possible_probabilities = [(1.,), (1.,), (1.,), (0.9, 0.1),
-                                  (0.8, 0.2), (0.7, 0.3), (0.8, 0.1, 0.1), (0.7, 0.2, 0.1), (0.6, 0.2, 0.1, 0.1)]
-        # ensure that there are no infinite loops
-        max_prob_num = min(num_states, input_size)
-        possible_probabilities = [p for p in possible_probabilities if len(p) <= max_prob_num]
-
-    mdp_states = []
-    state_id_state_map = {}
-    for state in deterministic_model.states:
-        mdp_state = MdpState(state.state_id, state.output)
-        state_id_state_map[state.state_id] = mdp_state
-        mdp_states.append(mdp_state)
-
-    input_al = deterministic_model.get_input_alphabet()
-    for deterministic_state in deterministic_model.states:
-        for i in input_al:
-            state_from_det_model = state_id_state_map[deterministic_state.transitions[i].state_id]
-            prob = random.choice(possible_probabilities)
-
-            reached_states = [state_from_det_model]
-            for _ in range(len(prob) - 1):
-                while True:
-                    new_state = random.choice(mdp_states)
-
-                    # ensure determinism
-                    if new_state.output not in {s.output for s in reached_states}:
-                        break
-
-                reached_states.append(new_state)
-
-            for prob, reached_state in zip(prob, reached_states):
-                mdp_origin_state = state_id_state_map[deterministic_state.state_id]
-                mdp_origin_state.transitions[i].append((reached_state, prob))
-
-    # deterministically labeled check
-    for state in mdp_states:
-        for _, transition_values in state.transitions.items():
-            reached_outputs = [s.output for s, _ in transition_values]
-            assert len(reached_outputs) == len(set(reached_outputs))
-
-    return Mdp(mdp_states[0], mdp_states)
-
-
-def generate_random_smm(num_states, input_size, output_size, possible_probabilities=None):
-    """
-    Generates random SMM.
-
-    Args:
-
-        num_states: number of states
-        input_size: number of inputs
-        output_size: number of outputs
-        possible_probabilities: list of possible probability pairs to choose from
-
-    Returns:
-
-        random SMM
-
-    """
-
-    deterministic_model = generate_random_deterministic_automata('mealy', num_states, input_size, output_size)
-    input_al = deterministic_model.get_input_alphabet()
-    output_al = list(set([o for state in deterministic_model.states for o in state.output_fun.values()]))
-    output_al.sort()
-
-    if input_size > output_size:
-        assert False, 'Cannot create deterministic SMM (in all states, all input-output pairs leads to a single state)' \
-                      ', if number of inputs is smaller than number of outputs)'
-
-    if not possible_probabilities:
-        possible_probabilities = [(1.,), (1.,), (1.,), (0.9, 0.1),
-                                  (0.8, 0.2), (0.7, 0.3), (0.8, 0.1, 0.1), (0.7, 0.2, 0.1), (0.6, 0.2, 0.1, 0.1)]
-        # ensure that there are no infinite loops
-        max_prob_num = min(num_states, input_size)
-        possible_probabilities = [p for p in possible_probabilities if len(p) <= max_prob_num]
-
-    smm_states = []
-    state_id_state_map = {}
-    for state in deterministic_model.states:
-        smm_state = StochasticMealyState(state.state_id)
-        state_id_state_map[state.state_id] = smm_state
-        smm_states.append(smm_state)
-
-    for deterministic_state in deterministic_model.states:
-        for i in input_al:
-            state_from_det_model = state_id_state_map[deterministic_state.transitions[i].state_id]
-            output_from_det_model = deterministic_state.output_fun[i]
-
-            prob = random.choice(possible_probabilities)
-
-            state_id_state_map[deterministic_state.state_id].transitions[i].append(
-                (state_from_det_model, output_from_det_model, prob[0]))
-
-            observed_outputs = [output_from_det_model]
-            for prob_index in range(1, len(prob)):
-                while True:
-                    new_state = random.choice(smm_states)
-                    new_output = random.choice(output_al)
-
-                    # ensure determinism
-                    if new_output not in observed_outputs:
-                        state_id_state_map[deterministic_state.state_id].transitions[i].append(
-                            (new_state, new_output, prob[prob_index]))
-                        break
-
-    return StochasticMealyMachine(smm_states[0], smm_states)
-
-
-def generate_random_ONFSM(num_states, num_inputs, num_outputs, multiple_out_prob=0.33):
-    """
-    Randomly generate an observable non-deterministic finite-state machine.
-
-    Args:
-
-      num_states: number of states
-      num_inputs: number of inputs
-      num_outputs: number of outputs
-      multiple_out_prob: probability that state will have multiple outputs (Default value = 0.5)
-
-    Returns:
-
-        randomly generated ONFSM
-
-    """
-    inputs = [f'i{i + 1}' for i in range(num_inputs)]
-    outputs = [f'o{i + 1}' for i in range(num_outputs)]
-
-    states = []
-    for i in range(num_states):
-        state = OnfsmState(f's{i}')
-        states.append(state)
-
-    state_buffer = states.copy()
-
-    for state in states:
-        for i in inputs:
-            state_outputs = 1
-            if random.random() <= multiple_out_prob and num_outputs >= 2:
-                state_outputs = random.randint(2, num_outputs)
-
-            random_out = random.sample(outputs, state_outputs)
-            for index in range(state_outputs):
-                if state_buffer:
-                    new_state = random.choice(state_buffer)
-                    state_buffer.remove(new_state)
-                else:
-                    new_state = random.choice(states)
-                state.transitions[i].append((random_out[index], new_state))
-
-    return Onfsm(states[0], states)
-
-
-def generate_random_markov_chain(num_states):
-    assert num_states >= 3
-    possible_probabilities = [1.0, 1.0, 0.8, 0.5, 0.9]
-    states = []
-
-    for i in range(num_states):
-        states.append(McState(f'q{i}', i))
-
-    for index, state in enumerate(states[:-1]):
-        prob = random.choice(possible_probabilities)
-        if prob == 1.:
-            new_state = states[index + 1]
-            state.transitions.append((new_state, prob))
-        else:
-            next_state = states[index + 1]
-            up_states = list(states)
-            up_states.remove(next_state)
-            rand_state = random.choice(up_states)
-
-            state.transitions.append((next_state, prob))
-            state.transitions.append((rand_state, round(1 - prob, 2)))
-
-    return MarkovChain(states[0], states)
-
-
-def _has_transition(state: SevpaState, transition_letter, stack_guard) -> bool:
-    transitions = state.transitions[transition_letter]
-    if transitions is not None:
-        if stack_guard is None:  # internal transition
-            for transition in transitions:
-                if transition.letter == transition_letter:
-                    return True
-        else:  # return transition
-            for transition in transitions:
-                if transition.stack_guard == stack_guard and transition.letter == transition_letter:
-                    return True
-
-    return False
-
-
-def generate_random_sevpa(num_states, internal_alphabet_size, call_alphabet_size, return_alphabet_size
-                          , acceptance_prob, return_transition_prob):
-    """
-    Generate a random Single Entry Visibly Pushdown Automaton (SEVPA).
-
-    Args:
-        num_states (int): The number of states in the SEVPA.
-        internal_alphabet_size (int): The size of the internal alphabet.
-        call_alphabet_size (int): The size of the call alphabet.
-        return_alphabet_size (int): The size of the return alphabet.
-        acceptance_prob (float): The probability of a state being an accepting state.
-        return_transition_prob (float): The probability of generating a return transition.
-
-    Returns:
-        Sevpa: A randomly generated SEVPA.
-    """
-
-    internal_alphabet = [f'i{i}' for i in range(internal_alphabet_size)]
-    call_alphabet = [f'c{i}' for i in range(call_alphabet_size)]
-    return_alphabet = [f'r{i}' for i in range(return_alphabet_size)]
-
-    sevpa_alphabet = SevpaAlphabet(internal_alphabet, call_alphabet, return_alphabet)
-
-    states = [SevpaState(f'q{i}', random.random() < acceptance_prob) for i in range(num_states)]
-    state_buffer = states.copy()
-
-    for state in states:
-        if not internal_alphabet or random.uniform(0.0, 1.0) < return_transition_prob:
-            # add return transition
-            while True:
-                return_letter = random.choice(return_alphabet)
-                stack_state = random.choice(states) if not state_buffer else random.choice(state_buffer)
-                if stack_state in state_buffer:
-                    state_buffer.remove(stack_state)
-
-                call_letter = random.choice(call_alphabet)
-                stack_guard = (stack_state.state_id, call_letter)
-
-                if not _has_transition(state, return_letter, stack_guard):
-                    break
-
-            target_state = random.choice(states)
-            state.transitions[return_letter].append(
-                SevpaTransition(target_state, return_letter, 'pop', stack_guard))
-        else:
-            # add an internal transition
-            while True:
-                internal_letter = random.choice(internal_alphabet)
-                if not _has_transition(state, internal_letter, None):
-                    break
-
-            target_state = random.choice(states) if not state_buffer else random.choice(state_buffer)
-            if target_state in state_buffer:
-                state_buffer.remove(target_state)
-            state.transitions[internal_letter].append(
-                SevpaTransition(target_state, internal_letter, None, None))
-
-    assert len(states) == num_states
-    initial_state = random.choice(states)
-
-    for state in states:
-        for internal_letter in internal_alphabet:
-            if state.transitions[internal_letter] is None:
-                target_state = random.choice(states)
-                state.transitions[internal_letter].append(
-                    SevpaTransition(target_state, internal_letter, None, None))
-
-        for call_letter in call_alphabet:
-            for stack_state in states:
-                stack_guard = (stack_state.state_id, call_letter)
-                for return_letter in return_alphabet:
-                    if not _has_transition(state, return_letter, stack_guard):
-                        target_state = states[random.randint(0, len(states) - 1)]
-                        state.transitions[return_letter].append(
-                            SevpaTransition(target_state, return_letter, 'pop', stack_guard))
-
-    return Sevpa(initial_state, states)
+import random
+import warnings
+
+from aalpy.automata import Dfa, DfaState, MdpState, Mdp, MealyMachine, MealyState, \
+    MooreMachine, MooreState, OnfsmState, Onfsm, MarkovChain, McState, StochasticMealyState, StochasticMealyMachine, \
+    Sevpa, SevpaState, SevpaAlphabet, SevpaTransition
+
+
+def generate_random_deterministic_automata(automaton_type,
+                                           num_states,
+                                           input_alphabet_size,
+                                           output_alphabet_size=None,
+                                           ensure_minimality=True,
+                                           **kwargs
+                                           ):
+    """
+    Generates a random deterministic automata of 'automaton_type'.
+
+    Args:
+        automaton_type: type of automaton, either 'dfa', 'mealy', or 'moore'
+        num_states: number of states
+        input_alphabet_size: size of input alphabet
+        output_alphabet_size: size of output alphabet. (ignored for DFAs)
+        ensure_minimality: ensure that the automaton is minimal
+        **kwargs:
+            : 'num_accepting_states' number of accepting states for DFA generation. If not defined, half of states will
+            be accepting
+
+    Returns:
+
+        Random deterministic automaton of user defined type, size. If ensure_minimality is set to False returned
+        automaton is not necessarily minimal. If minimality is reacquired and random automaton cannot be produced in
+        multiple interactions, non-minimal automaton will be returned and a warning message printed.
+    """
+
+    assert automaton_type in {'dfa', 'mealy', 'moore'}
+    if output_alphabet_size and output_alphabet_size < 2 or output_alphabet_size is None:
+        output_alphabet_size = 2
+
+    state_class_map = {'dfa': DfaState, 'mealy': MealyState, 'moore': MooreState}
+    automaton_class_map = {'dfa': Dfa, 'mealy': MealyMachine, 'moore': MooreMachine}
+
+    input_alphabet = [f'i{i + 1}' for i in range(input_alphabet_size)]
+    output_alphabet = [f'o{i + 1}' for i in range(output_alphabet_size)] if automaton_type != 'dfa' else [True, False]
+
+    # For backwards comparability or if uses passes custom input output functions
+    if 'custom_input_alphabet' in kwargs:
+        input_alphabet = kwargs.get('custom_input_alphabet')
+        if len(input_alphabet) != input_alphabet_size:
+            assert False, 'Lenght of input_alphabet_size and custom input alphabet should be equal.'
+    if 'custom_output_alphabet' in kwargs:
+        output_alphabet = kwargs.get('custom_output_alphabet')
+        if len(output_alphabet) != output_alphabet_size:
+            assert False, 'Lenght of output_alphabet_size and custom output alphabet should be equal.'
+
+    num_accepting_states = None
+    if 'num_accepting_states' in kwargs:
+        num_accepting_states = kwargs.get('num_accepting_states')
+    if num_accepting_states is None:
+        num_accepting_states = num_states // 2
+
+    num_random_outputs = num_states if automaton_type != 'mealy' else num_states * input_alphabet_size
+
+    output_list = []
+    output_al_copy = output_alphabet.copy()
+
+    if automaton_type != 'dfa':
+        for _ in range(num_random_outputs):
+            if output_al_copy:
+                o = random.choice(output_al_copy)
+                output_al_copy.remove(o)
+            else:
+                o = random.choice(output_alphabet)
+            output_list.append(o)
+    else:
+        output_list = [True] * num_accepting_states + [False] * (num_states - num_accepting_states)
+        random.shuffle(output_list)
+
+    states = [state_class_map[automaton_type](state_id=f's{i + 1}') for i in range(num_states)]
+
+    # define an output function
+    for state_index, state in enumerate(states):
+        if automaton_type == 'dfa':
+            state.is_accepting = output_list[state_index]
+        if automaton_type == 'moore':
+            state.output = output_list[state_index]
+        if automaton_type == 'mealy':
+            for i in input_alphabet:
+                state.output_fun[i] = output_list.pop(0)
+
+    state_buffer = []
+
+    state_buffer.extend(states)
+    while len(state_buffer) < num_states * input_alphabet_size:
+        state_buffer.append(random.choice(states))
+
+    random_automaton = None
+
+    # keep changing transitions until all states are reachable (update in future )
+    all_states_reachable = False
+    while not all_states_reachable:
+        random.shuffle(state_buffer)
+
+        transition_index = 0
+        for state in states:
+            for i in input_alphabet:
+                state.transitions[i] = state_buffer[transition_index]
+                transition_index += 1
+
+        random_automaton = automaton_class_map[automaton_type](states[0], states)
+
+        unreachable_state_exits = False
+        for state in random_automaton.states:
+            state.prefix = random_automaton.get_shortest_path(random_automaton.initial_state, state)
+            if state != random_automaton.initial_state and state.prefix is None:
+                unreachable_state_exits = True
+                break
+        all_states_reachable = not unreachable_state_exits
+
+    if ensure_minimality:
+        minimality_iterations = 1
+        while not random_automaton.is_minimal() or random_automaton.size != num_states:
+            # to avoid infinite loops
+            if minimality_iterations == 100:
+                warnings.warn(f'Non-minimal automaton ({automaton_type}, num_states : {num_states}) returned.')
+                break
+
+            custom_args = {}
+            if 'custom_input_alphabet' in kwargs:
+                custom_args['custom_input_alphabet'] = kwargs.get('custom_input_alphabet')
+            if 'custom_output_alphabet' in kwargs:
+                custom_args['custom_output_alphabet'] = kwargs.get('custom_output_alphabet')
+            if 'num_accepting_states' in kwargs:
+                custom_args['num_accepting_states'] = kwargs.get('num_accepting_states')
+
+            random_automaton = generate_random_deterministic_automata(automaton_type,
+                                                                      num_states,
+                                                                      input_alphabet_size,
+                                                                      output_alphabet_size,
+                                                                      False,  # ensure minimality
+                                                                      **custom_args)
+
+    return random_automaton
+
+
+def generate_random_mealy_machine(num_states, input_alphabet, output_alphabet,
+                                  compute_prefixes=False, ensure_minimality=True) -> MealyMachine:
+    """
+    Generates a random Mealy machine. Kept for backwards compatibility.
+
+    Args:
+
+        num_states: number of states
+        input_alphabet: input alphabet
+        output_alphabet: output alphabet
+        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
+        ensure_minimality: returned automaton will be minimal
+
+    Returns:
+
+        Mealy machine with num_states states
+    """
+
+    random_mealy_machine = generate_random_deterministic_automata('mealy', num_states,
+                                                                  input_alphabet_size=len(input_alphabet),
+                                                                  output_alphabet_size=len(output_alphabet),
+                                                                  ensure_minimality=ensure_minimality,
+                                                                  compute_prefixes=compute_prefixes,
+                                                                  custom_input_alphabet=input_alphabet,
+                                                                  custom_output_alphabet=output_alphabet)
+
+    return random_mealy_machine
+
+
+def generate_random_moore_machine(num_states, input_alphabet, output_alphabet,
+                                  compute_prefixes=False, ensure_minimality=True) -> MooreMachine:
+    """
+    Generates a random Moore machine.
+
+    Args:
+
+        num_states: number of states
+        input_alphabet: input alphabet
+        output_alphabet: output alphabet
+        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
+        ensure_minimality: returned automaton will be minimal
+
+    Returns:
+
+        Random Moore machine with num_states states
+
+    """
+    random_moore_machine = generate_random_deterministic_automata('moore', num_states,
+                                                                  input_alphabet_size=len(input_alphabet),
+                                                                  output_alphabet_size=len(output_alphabet),
+                                                                  ensure_minimality=ensure_minimality,
+                                                                  compute_prefixes=compute_prefixes,
+                                                                  custom_input_alphabet=input_alphabet,
+                                                                  custom_output_alphabet=output_alphabet)
+
+    return random_moore_machine
+
+
+def generate_random_dfa(num_states, alphabet, num_accepting_states=1,
+                        compute_prefixes=False, ensure_minimality=True) -> Dfa:
+    """
+    Generates a random DFA.
+
+    Args:
+
+        num_states: number of states
+        alphabet: input alphabet
+        num_accepting_states: number of accepting states (Default value = 1)
+        compute_prefixes: if true, shortest path to reach each state will be computed (Default value = False)
+        ensure_minimality: returned automaton will be minimal
+
+    Returns:
+
+        Randomly generated DFA
+
+    """
+    if num_states <= num_accepting_states:
+        num_accepting_states = num_states // 2
+
+    random_dfa = generate_random_deterministic_automata('dfa', num_states,
+                                                        input_alphabet_size=len(alphabet),
+                                                        output_alphabet_size=2,
+                                                        ensure_minimality=ensure_minimality,
+                                                        compute_prefixes=compute_prefixes,
+                                                        custom_input_alphabet=alphabet,
+                                                        num_accepting_states=num_accepting_states)
+
+    return random_dfa
+
+
+def generate_random_mdp(num_states, input_size, output_size, possible_probabilities=None):
+    """
+    Generates random MDP.
+
+    Args:
+
+        num_states: number of states
+        input_size: number of inputs
+        output_size: user predefined outputs
+        possible_probabilities: list of possible probability pairs to choose from
+
+    Returns:
+
+        random MDP
+
+    """
+
+    deterministic_model = generate_random_deterministic_automata('moore', num_states, input_size, output_size)
+
+    if not possible_probabilities:
+        possible_probabilities = [(1.,), (1.,), (1.,), (0.9, 0.1),
+                                  (0.8, 0.2), (0.7, 0.3), (0.8, 0.1, 0.1), (0.7, 0.2, 0.1), (0.6, 0.2, 0.1, 0.1)]
+        # ensure that there are no infinite loops
+        max_prob_num = min(num_states, output_size)
+        possible_probabilities = [p for p in possible_probabilities if len(p) <= max_prob_num]
+
+    mdp_states = []
+    state_id_state_map = {}
+    for state in deterministic_model.states:
+        mdp_state = MdpState(state.state_id, state.output)
+        state_id_state_map[state.state_id] = mdp_state
+        mdp_states.append(mdp_state)
+
+    input_al = deterministic_model.get_input_alphabet()
+    for deterministic_state in deterministic_model.states:
+        for i in input_al:
+            state_from_det_model = state_id_state_map[deterministic_state.transitions[i].state_id]
+            prob = random.choice(possible_probabilities)
+
+            reached_states = [state_from_det_model]
+            for _ in range(len(prob) - 1):
+                while True:
+                    new_state = random.choice(mdp_states)
+
+                    # ensure determinism
+                    if new_state.output not in {s.output for s in reached_states}:
+                        break
+
+                reached_states.append(new_state)
+
+            for prob, reached_state in zip(prob, reached_states):
+                mdp_origin_state = state_id_state_map[deterministic_state.state_id]
+                mdp_origin_state.transitions[i].append((reached_state, prob))
+
+    # deterministically labeled check
+    for state in mdp_states:
+        for _, transition_values in state.transitions.items():
+            reached_outputs = [s.output for s, _ in transition_values]
+            assert len(reached_outputs) == len(set(reached_outputs))
+
+    return Mdp(mdp_states[0], mdp_states)
+
+
+def generate_random_smm(num_states, input_size, output_size, possible_probabilities=None):
+    """
+    Generates random SMM.
+
+    Args:
+
+        num_states: number of states
+        input_size: number of inputs
+        output_size: number of outputs
+        possible_probabilities: list of possible probability pairs to choose from
+
+    Returns:
+
+        random SMM
+
+    """
+
+    deterministic_model = generate_random_deterministic_automata('mealy', num_states, input_size, output_size)
+    input_al = deterministic_model.get_input_alphabet()
+    output_al = list(set([o for state in deterministic_model.states for o in state.output_fun.values()]))
+    output_al.sort()
+
+    if not possible_probabilities:
+        possible_probabilities = [(1.,), (1.,), (1.,), (0.9, 0.1),
+                                  (0.8, 0.2), (0.7, 0.3), (0.8, 0.1, 0.1), (0.7, 0.2, 0.1), (0.6, 0.2, 0.1, 0.1)]
+        # ensure that there are no infinite loops
+        max_prob_num = min(num_states, output_size)
+        possible_probabilities = [p for p in possible_probabilities if len(p) <= max_prob_num]
+
+    smm_states = []
+    state_id_state_map = {}
+    for state in deterministic_model.states:
+        smm_state = StochasticMealyState(state.state_id)
+        state_id_state_map[state.state_id] = smm_state
+        smm_states.append(smm_state)
+
+    for deterministic_state in deterministic_model.states:
+        for i in input_al:
+            state_from_det_model = state_id_state_map[deterministic_state.transitions[i].state_id]
+            output_from_det_model = deterministic_state.output_fun[i]
+
+            prob = random.choice(possible_probabilities)
+
+            state_id_state_map[deterministic_state.state_id].transitions[i].append(
+                (state_from_det_model, output_from_det_model, prob[0]))
+
+            observed_outputs = [output_from_det_model]
+            for prob_index in range(1, len(prob)):
+                while True:
+                    new_state = random.choice(smm_states)
+                    new_output = random.choice(output_al)
+
+                    # ensure determinism
+                    if new_output not in observed_outputs:
+                        state_id_state_map[deterministic_state.state_id].transitions[i].append(
+                            (new_state, new_output, prob[prob_index]))
+                        break
+
+    return StochasticMealyMachine(smm_states[0], smm_states)
+
+
+def generate_random_ONFSM(num_states, num_inputs, num_outputs, multiple_out_prob=0.33):
+    """
+    Randomly generate an observable non-deterministic finite-state machine.
+
+    Args:
+
+      num_states: number of states
+      num_inputs: number of inputs
+      num_outputs: number of outputs
+      multiple_out_prob: probability that state will have multiple outputs (Default value = 0.5)
+
+    Returns:
+
+        randomly generated ONFSM
+
+    """
+    inputs = [f'i{i + 1}' for i in range(num_inputs)]
+    outputs = [f'o{i + 1}' for i in range(num_outputs)]
+
+    states = []
+    for i in range(num_states):
+        state = OnfsmState(f's{i}')
+        states.append(state)
+
+    state_buffer = states.copy()
+
+    for state in states:
+        for i in inputs:
+            state_outputs = 1
+            if random.random() <= multiple_out_prob and num_outputs >= 2:
+                state_outputs = random.randint(2, num_outputs)
+
+            random_out = random.sample(outputs, state_outputs)
+            for index in range(state_outputs):
+                if state_buffer:
+                    new_state = random.choice(state_buffer)
+                    state_buffer.remove(new_state)
+                else:
+                    new_state = random.choice(states)
+                state.transitions[i].append((random_out[index], new_state))
+
+    return Onfsm(states[0], states)
+
+
+def generate_random_markov_chain(num_states):
+    assert num_states >= 3
+    possible_probabilities = [1.0, 1.0, 0.8, 0.5, 0.9]
+    states = []
+
+    for i in range(num_states):
+        states.append(McState(f'q{i}', i))
+
+    for index, state in enumerate(states[:-1]):
+        prob = random.choice(possible_probabilities)
+        if prob == 1.:
+            new_state = states[index + 1]
+            state.transitions.append((new_state, prob))
+        else:
+            next_state = states[index + 1]
+            up_states = list(states)
+            up_states.remove(next_state)
+            rand_state = random.choice(up_states)
+
+            state.transitions.append((next_state, prob))
+            state.transitions.append((rand_state, round(1 - prob, 2)))
+
+    return MarkovChain(states[0], states)
+
+
+def _has_transition(state: SevpaState, transition_letter, stack_guard) -> bool:
+    transitions = state.transitions[transition_letter]
+    if transitions is not None:
+        if stack_guard is None:  # internal transition
+            for transition in transitions:
+                if transition.letter == transition_letter:
+                    return True
+        else:  # return transition
+            for transition in transitions:
+                if transition.stack_guard == stack_guard and transition.letter == transition_letter:
+                    return True
+
+    return False
+
+
+def generate_random_sevpa(num_states, internal_alphabet_size, call_alphabet_size, return_alphabet_size
+                          , acceptance_prob, return_transition_prob):
+    """
+    Generate a random Single Entry Visibly Pushdown Automaton (SEVPA).
+
+    Args:
+        num_states (int): The number of states in the SEVPA.
+        internal_alphabet_size (int): The size of the internal alphabet.
+        call_alphabet_size (int): The size of the call alphabet.
+        return_alphabet_size (int): The size of the return alphabet.
+        acceptance_prob (float): The probability of a state being an accepting state.
+        return_transition_prob (float): The probability of generating a return transition.
+
+    Returns:
+        Sevpa: A randomly generated SEVPA.
+    """
+
+    internal_alphabet = [f'i{i}' for i in range(internal_alphabet_size)]
+    call_alphabet = [f'c{i}' for i in range(call_alphabet_size)]
+    return_alphabet = [f'r{i}' for i in range(return_alphabet_size)]
+
+    sevpa_alphabet = SevpaAlphabet(internal_alphabet, call_alphabet, return_alphabet)
+
+    states = [SevpaState(f'q{i}', random.random() < acceptance_prob) for i in range(num_states)]
+    state_buffer = states.copy()
+
+    for state in states:
+        if not internal_alphabet or random.uniform(0.0, 1.0) < return_transition_prob:
+            # add return transition
+            while True:
+                return_letter = random.choice(return_alphabet)
+                stack_state = random.choice(states) if not state_buffer else random.choice(state_buffer)
+                if stack_state in state_buffer:
+                    state_buffer.remove(stack_state)
+
+                call_letter = random.choice(call_alphabet)
+                stack_guard = (stack_state.state_id, call_letter)
+
+                if not _has_transition(state, return_letter, stack_guard):
+                    break
+
+            target_state = random.choice(states)
+            state.transitions[return_letter].append(
+                SevpaTransition(target_state, return_letter, 'pop', stack_guard))
+        else:
+            # add an internal transition
+            while True:
+                internal_letter = random.choice(internal_alphabet)
+                if not _has_transition(state, internal_letter, None):
+                    break
+
+            target_state = random.choice(states) if not state_buffer else random.choice(state_buffer)
+            if target_state in state_buffer:
+                state_buffer.remove(target_state)
+            state.transitions[internal_letter].append(
+                SevpaTransition(target_state, internal_letter, None, None))
+
+    assert len(states) == num_states
+    initial_state = random.choice(states)
+
+    for state in states:
+        for internal_letter in internal_alphabet:
+            if state.transitions[internal_letter] is None:
+                target_state = random.choice(states)
+                state.transitions[internal_letter].append(
+                    SevpaTransition(target_state, internal_letter, None, None))
+
+        for call_letter in call_alphabet:
+            for stack_state in states:
+                stack_guard = (stack_state.state_id, call_letter)
+                for return_letter in return_alphabet:
+                    if not _has_transition(state, return_letter, stack_guard):
+                        target_state = states[random.randint(0, len(states) - 1)]
+                        state.transitions[return_letter].append(
+                            SevpaTransition(target_state, return_letter, 'pop', stack_guard))
+
+    return Sevpa(initial_state, states)
```

## aalpy/utils/BenchmarkSULs.py

 * *Ordering differences only*

```diff
@@ -1,432 +1,432 @@
-def get_Angluin_dfa():
-    from aalpy.automata import Dfa
-
-    anguin_dfa = {
-        'q0': (True, {'a': 'q1', 'b': 'q2'}),
-        'q1': (False, {'a': 'q0', 'b': 'q3'}),
-        'q2': (False, {'a': 'q3', 'b': 'q0'}),
-        'q3': (False, {'a': 'q2', 'b': 'q1'})
-    }
-
-    return Dfa.from_state_setup(anguin_dfa)
-
-
-def get_benchmark_ONFSM():
-    """
-    Returns ONFSM presented in 'Learning Finite State Models of Observable Nondeterministic Systems in a Testing
-    Context'.
-    """
-    from aalpy.automata import Onfsm, OnfsmState
-
-    a = OnfsmState('q0')
-    b = OnfsmState('q1')
-    c = OnfsmState('g2')
-    d = OnfsmState('q3')
-
-    a.transitions['a'].append((0, b))
-    a.transitions['b'].append((2, a))
-    a.transitions['b'].append((0, c))
-
-    b.transitions['a'].append((2, a))
-    b.transitions['b'].append((3, b))
-
-    c.transitions['a'].append((2, d))
-    c.transitions['b'].append((0, c))
-    c.transitions['b'].append((3, c))
-
-    d.transitions['a'].append((2, b))
-    d.transitions['b'].append((3, d))
-
-    return Onfsm(a, [a, b, c, d])
-
-
-def get_ONFSM():
-    """
-    Returns example of an ONFSM.
-    """
-    from aalpy.automata import Onfsm, OnfsmState
-
-    q0 = OnfsmState('q0')
-    q1 = OnfsmState('q1')
-    q2 = OnfsmState('q2')
-    q3 = OnfsmState('q3')
-    q4 = OnfsmState('q4')
-    q5 = OnfsmState('q5')
-    q6 = OnfsmState('q6')
-    q7 = OnfsmState('q7')
-    q8 = OnfsmState('q8')
-
-    q0.transitions['a'].append((2, q1))
-    q0.transitions['b'].append((0, q0))
-
-    q1.transitions['a'].append((2, q0))
-    q1.transitions['b'].append((0, q2))
-
-    q2.transitions['a'].append((1, q2))
-    q2.transitions['b'].append((0, q3))
-
-    q3.transitions['a'].append((2, q8))
-    q3.transitions['b'].append((0, q4))
-
-    q4.transitions['a'].append((1, q4))
-    q4.transitions['b'].append((0, q5))
-
-    q5.transitions['a'].append((2, q6))
-    q5.transitions['b'].append((0, q7))
-
-    q6.transitions['a'].append((2, q5))
-    q6.transitions['b'].append((0, q6))
-
-    q7.transitions['a'].append((1, q7))
-    q7.transitions['b'].append(('O', q0))
-
-    q8.transitions['a'].append((2, q3))
-    q8.transitions['b'].append((0, q8))
-
-    return Onfsm(q0, [q0, q1, q2, q3, q4, q5, q6, q7, q8])
-
-
-def get_faulty_coffee_machine_MDP():
-    from aalpy.automata import Mdp, MdpState
-
-    q0 = MdpState("q0", "init")
-    q1 = MdpState("q1", "beep")
-    q2 = MdpState("q2", "coffee")
-
-    q0.transitions['but'].append((q0, 1))
-    q0.transitions['coin'].append((q1, 1))
-    q1.transitions['but'].append((q0, 0.1))
-    q1.transitions['but'].append((q2, 0.9))
-    q1.transitions['coin'].append((q1, 1))
-    q2.transitions['but'].append((q0, 1))
-    q2.transitions['coin'].append((q1, 1))
-
-    mdp = Mdp(q0, [q0, q1, q2])
-
-    return mdp
-
-
-def get_weird_coffee_machine_MDP():
-    from aalpy.automata import Mdp, MdpState
-
-    q0 = MdpState("q0", "init")
-    q1 = MdpState("q1", "beep")
-    q2 = MdpState("q2", "coffee")
-    q3 = MdpState("q3", "beep")
-    q4 = MdpState("q4", "coffee")
-    q5 = MdpState("q5", "init")
-    q6 = MdpState("q6", "crash")
-
-    q0.transitions['but'].append((q0, 1))
-    q0.transitions['coin'].append((q1, 1))
-    q0.transitions['koin'].append((q3, 1))
-
-    q1.transitions['but'].append((q0, 0.1))
-    q1.transitions['but'].append((q2, 0.9))
-
-    q3.transitions['but'].append((q0, 0.1))
-    q3.transitions['but'].append((q4, 0.9))
-
-    q1.transitions['coin'].append((q1, 1))
-    q3.transitions['koin'].append((q3, 1))
-    q1.transitions['koin'].append((q3, 1))
-    q3.transitions['coin'].append((q1, 1))
-
-    q2.transitions['but'].append((q0, 1))
-    q2.transitions['coin'].append((q1, 1))
-    q2.transitions['koin'].append((q3, 1))
-
-    q4.transitions['coin'].append((q1, 1))
-    q4.transitions['koin'].append((q3, 1))
-
-    q4.transitions['but'].append((q5, 1))
-
-    q5.transitions['but'].append((q6, 1))
-    q5.transitions['coin'].append((q6, 1))
-    q5.transitions['koin'].append((q6, 1))
-
-    q6.transitions['but'].append((q6, 1))
-    q6.transitions['coin'].append((q6, 1))
-    q6.transitions['koin'].append((q6, 1))
-
-    mdp = Mdp(q0, [q0, q1, q2, q3, q4, q5, q6])
-
-    return mdp
-
-
-def get_faulty_coffee_machine_SMM():
-    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
-
-    s0 = StochasticMealyState('q0')
-    s1 = StochasticMealyState('q1')
-    s2 = StochasticMealyState('q2')
-
-    s0.transitions['but'].append((s0, 'init', 1.))
-    s0.transitions['coin'].append((s1, 'beep', 1.))
-    s1.transitions['but'].append((s0, 'init', 0.1))
-    s1.transitions['but'].append((s2, 'coffee', 0.9))
-    s1.transitions['coin'].append((s1, 'beep', 1.))
-    s2.transitions['but'].append((s0, 'init', 1.))
-    s2.transitions['coin'].append((s1, 'beep', 1.))
-
-    smm = StochasticMealyMachine(s0, [s0, s1, s2])
-
-    return smm
-
-
-def get_minimal_faulty_coffee_machine_SMM():
-    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
-
-    s0 = StochasticMealyState('q0')
-    s1 = StochasticMealyState('q1')
-
-    s0.transitions['but'].append((s0, 'init', 1.))
-    s0.transitions['coin'].append((s1, 'beep', 1.))
-    s1.transitions['but'].append((s0, 'init', 0.1))
-    s1.transitions['but'].append((s0, 'coffee', 0.9))
-    s1.transitions['coin'].append((s1, 'beep', 1.))
-
-    smm = StochasticMealyMachine(s0, [s0, s1])
-
-    return smm
-
-
-def get_faulty_mqtt_SMM():
-    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
-
-    s0 = StochasticMealyState('q0')
-    s1 = StochasticMealyState('q1')
-    s2 = StochasticMealyState('q2')
-
-    s0.transitions['connect'].append((s1, 'CONNACK', 1.))
-    s0.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
-    s0.transitions['publish'].append((s0, 'CONCLOSED', 1.))
-    s0.transitions['subscribe'].append((s0, 'CONCLOSED', 1.))
-    s0.transitions['unsubscribe'].append((s0, 'CONCLOSED', 1.))
-
-    s1.transitions['connect'].append((s0, 'CONCLOSED', 1.))
-    s1.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
-    s1.transitions['publish'].append((s1, 'PUBACK', 0.9))
-    s1.transitions['publish'].append((s0, 'CONCLOSED', 0.1))
-    s1.transitions['subscribe'].append((s2, 'SUBACK', 1.))
-    s1.transitions['unsubscribe'].append((s1, 'UNSUBACK', 1.))
-
-    s2.transitions['connect'].append((s0, 'CONCLOSED', 1.))
-    s2.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
-    s2.transitions['publish'].append((s2, 'PUBLISH_PUBACK', 1.))
-    s2.transitions['subscribe'].append((s2, 'SUBACK', 1.))
-    s2.transitions['unsubscribe'].append((s1, 'UNSUBACK', 0.8))
-    s2.transitions['unsubscribe'].append((s2, 'SUBACK', 0.2))
-
-    smm = StochasticMealyMachine(s0, [s0, s1, s2])
-
-    return smm
-
-
-def get_small_gridworld():
-    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
-
-    s0 = StochasticMealyState('q0')
-    s1 = StochasticMealyState('q1')
-    s2 = StochasticMealyState('q2')
-    s3 = StochasticMealyState('q3')
-
-    p_g = 0.8
-    p_m = 0.6
-
-    # gridworld of the form
-    # W W W W with a start in the top left
-    # W G M W states like s0 s1
-    # W M G W             s2 s3
-    # W W W W
-
-    s0.transitions['north'].append((s0, 'wall', 1.))
-    s0.transitions['west'].append((s0, 'wall', 1.))
-    s0.transitions['east'].append((s1, 'mud', p_m))
-    s0.transitions['east'].append((s3, 'grass', 1 - p_m))
-    s0.transitions['south'].append((s2, 'mud', p_m))
-    s0.transitions['south'].append((s3, 'grass', 1 - p_m))
-
-    s1.transitions['north'].append((s1, 'wall', 1.))
-    s1.transitions['east'].append((s1, 'wall', 1.))
-    s1.transitions['west'].append((s0, 'grass', p_g))
-    s1.transitions['west'].append((s2, 'mud', 1 - p_g))
-    s1.transitions['south'].append((s3, 'grass', p_g))
-    s1.transitions['south'].append((s2, 'mud', 1 - p_g))
-
-    s2.transitions['south'].append((s2, 'wall', 1.))
-    s2.transitions['west'].append((s2, 'wall', 1.))
-    s2.transitions['east'].append((s3, 'grass', p_g))
-    s2.transitions['east'].append((s1, 'mud', 1 - p_g))
-    s2.transitions['north'].append((s0, 'grass', p_g))
-    s2.transitions['south'].append((s1, 'mud', 1 - p_g))
-
-    s3.transitions['south'].append((s3, 'wall', 1.))
-    s3.transitions['east'].append((s3, 'wall', 1.))
-    s3.transitions['west'].append((s2, 'mud', p_m))
-    s3.transitions['west'].append((s0, 'grass', 1 - p_m))
-    s3.transitions['north'].append((s1, 'mud', p_m))
-    s3.transitions['north'].append((s0, 'grass', 1 - p_m))
-
-    smm = StochasticMealyMachine(s0, [s0, s1, s2, s3])
-
-    return smm
-
-
-class MockMqttExample:
-
-    def __init__(self):
-        self.state = 'CONCLOSED'
-        self.topics = set()
-
-    def subscribe(self, topic: str):
-        if '\n' in topic or '\u0000' in topic:
-            self.state = 'CONCLOSED'
-            self.topics.clear()
-        elif self.state != 'CONCLOSED':
-            self.topics.add(topic)
-            self.state = 'SUBACK'
-
-        return self.state
-
-    def unsubscribe(self, topic):
-        if '\n' in topic or '\u0000' in topic:
-            self.state = 'CONCLOSED'
-            self.topics.clear()
-        elif self.state != 'CONCLOSED':
-            if topic in self.topics:
-                self.topics.remove(topic)
-            self.state = 'UNSUBACK'
-
-        return self.state
-
-    def connect(self):
-        if self.state == 'CONCLOSED':
-            self.state = 'CONNACK'
-        else:
-            self.topics.clear()
-            self.state = 'CONCLOSED'
-        return self.state
-
-    def disconnect(self):
-        self.state = 'CONCLOSED'
-        self.topics.clear()
-        return self.state
-
-    def publish(self, topic):
-        if '\n' in topic or '\u0000' in topic:
-            self.state = 'CONCLOSED'
-            self.topics.clear()
-        if self.state != 'CONCLOSED':
-            if topic not in self.topics:
-                self.state = 'PUBACK'
-            else:
-                self.state = 'PUBACK_PUBACK'
-        return self.state
-
-
-class DateValidator:
-    """
-    Class mimicking Date Validator API.
-    It does not account for the leap years.
-    The format of the dates is %d/%m/%Y'
-    """
-
-    def is_date_accepted(self, date_string: str):
-        values = date_string.split('/')
-        if len(values) != 3:
-            return False
-        try:
-            day = int(values[0])
-            month = int(values[1])
-            year = int(values[2])
-        except ValueError:
-            return False
-
-        if not (0 <= year <= 9999):
-            return False
-
-        if month == 2 and not (1 <= day <= 28):
-            return False
-
-        if month in [1, 3, 5, 7, 8, 10, 12] and not (1 <= day <= 31):
-            return False
-
-        elif not (1 <= day <= 31):
-            return False
-
-        return True
-
-
-def get_small_pomdp():
-    from aalpy.automata import Mdp, MdpState
-
-    q0 = MdpState("q0", "init")
-    q1 = MdpState("q1", "beep")
-    q2 = MdpState("q2", "beep")
-    q3 = MdpState("q3", "coffee")
-    q4 = MdpState("q4", "tea")
-
-    q0.transitions['but'].append((q0, 1))
-    q0.transitions['coin'].append((q1, 0.8))
-    q0.transitions['coin'].append((q2, 0.2))
-
-    q1.transitions['coin'].append((q1, 1))
-    q1.transitions['but'].append((q3, 1))
-
-    q2.transitions['coin'].append((q2, 0.3))
-    q2.transitions['coin'].append((q1, 0.7))
-    q2.transitions['but'].append((q4, 1))
-
-    q3.transitions['coin'].append((q3, 1))
-    q3.transitions['but'].append((q3, 1))
-
-    q4.transitions['coin'].append((q4, 1))
-    q4.transitions['but'].append((q4, 1))
-
-    return Mdp(q0, [q0, q1, q2, q3, q4])
-
-
-def is_balanced(test_string, call_return_map, allow_empty_string):
-    stack = []
-    # Create a set of open and close characters for faster lookup
-    open_chars = set(call_return_map.keys())
-    close_chars = set(call_return_map.values())
-
-    for char in test_string:
-        if char in open_chars:
-            stack.append(char)
-        elif char in close_chars:
-            # Stack should exist
-            if not stack:
-                return False
-            last_open = stack.pop()
-            # Mismatched open and close character
-            if call_return_map[last_open] != char:
-                return False
-
-    return not stack if allow_empty_string else not stack and len(test_string) > 0
-
-
-def get_balanced_string_sul(call_return_map, allow_empty_string):
-    from aalpy.base import SUL
-
-    class BalancedStringSUL(SUL):
-        def __init__(self, call_return_map, allow_empty_string):
-            super(BalancedStringSUL, self).__init__()
-            self.call_return_map = call_return_map
-            self.allow_empty_string = allow_empty_string
-            self.sting_under_test = []
-
-        def pre(self):
-            self.sting_under_test = []
-
-        def post(self):
-            pass
-
-        def step(self, letter):
-            if letter:
-                self.sting_under_test += letter
-            return is_balanced(self.sting_under_test, self.call_return_map, self.allow_empty_string)
-
-    return BalancedStringSUL(call_return_map, allow_empty_string)
+def get_Angluin_dfa():
+    from aalpy.automata import Dfa
+
+    anguin_dfa = {
+        'q0': (True, {'a': 'q1', 'b': 'q2'}),
+        'q1': (False, {'a': 'q0', 'b': 'q3'}),
+        'q2': (False, {'a': 'q3', 'b': 'q0'}),
+        'q3': (False, {'a': 'q2', 'b': 'q1'})
+    }
+
+    return Dfa.from_state_setup(anguin_dfa)
+
+
+def get_benchmark_ONFSM():
+    """
+    Returns ONFSM presented in 'Learning Finite State Models of Observable Nondeterministic Systems in a Testing
+    Context'.
+    """
+    from aalpy.automata import Onfsm, OnfsmState
+
+    a = OnfsmState('q0')
+    b = OnfsmState('q1')
+    c = OnfsmState('g2')
+    d = OnfsmState('q3')
+
+    a.transitions['a'].append((0, b))
+    a.transitions['b'].append((2, a))
+    a.transitions['b'].append((0, c))
+
+    b.transitions['a'].append((2, a))
+    b.transitions['b'].append((3, b))
+
+    c.transitions['a'].append((2, d))
+    c.transitions['b'].append((0, c))
+    c.transitions['b'].append((3, c))
+
+    d.transitions['a'].append((2, b))
+    d.transitions['b'].append((3, d))
+
+    return Onfsm(a, [a, b, c, d])
+
+
+def get_ONFSM():
+    """
+    Returns example of an ONFSM.
+    """
+    from aalpy.automata import Onfsm, OnfsmState
+
+    q0 = OnfsmState('q0')
+    q1 = OnfsmState('q1')
+    q2 = OnfsmState('q2')
+    q3 = OnfsmState('q3')
+    q4 = OnfsmState('q4')
+    q5 = OnfsmState('q5')
+    q6 = OnfsmState('q6')
+    q7 = OnfsmState('q7')
+    q8 = OnfsmState('q8')
+
+    q0.transitions['a'].append((2, q1))
+    q0.transitions['b'].append((0, q0))
+
+    q1.transitions['a'].append((2, q0))
+    q1.transitions['b'].append((0, q2))
+
+    q2.transitions['a'].append((1, q2))
+    q2.transitions['b'].append((0, q3))
+
+    q3.transitions['a'].append((2, q8))
+    q3.transitions['b'].append((0, q4))
+
+    q4.transitions['a'].append((1, q4))
+    q4.transitions['b'].append((0, q5))
+
+    q5.transitions['a'].append((2, q6))
+    q5.transitions['b'].append((0, q7))
+
+    q6.transitions['a'].append((2, q5))
+    q6.transitions['b'].append((0, q6))
+
+    q7.transitions['a'].append((1, q7))
+    q7.transitions['b'].append(('O', q0))
+
+    q8.transitions['a'].append((2, q3))
+    q8.transitions['b'].append((0, q8))
+
+    return Onfsm(q0, [q0, q1, q2, q3, q4, q5, q6, q7, q8])
+
+
+def get_faulty_coffee_machine_MDP():
+    from aalpy.automata import Mdp, MdpState
+
+    q0 = MdpState("q0", "init")
+    q1 = MdpState("q1", "beep")
+    q2 = MdpState("q2", "coffee")
+
+    q0.transitions['but'].append((q0, 1))
+    q0.transitions['coin'].append((q1, 1))
+    q1.transitions['but'].append((q0, 0.1))
+    q1.transitions['but'].append((q2, 0.9))
+    q1.transitions['coin'].append((q1, 1))
+    q2.transitions['but'].append((q0, 1))
+    q2.transitions['coin'].append((q1, 1))
+
+    mdp = Mdp(q0, [q0, q1, q2])
+
+    return mdp
+
+
+def get_weird_coffee_machine_MDP():
+    from aalpy.automata import Mdp, MdpState
+
+    q0 = MdpState("q0", "init")
+    q1 = MdpState("q1", "beep")
+    q2 = MdpState("q2", "coffee")
+    q3 = MdpState("q3", "beep")
+    q4 = MdpState("q4", "coffee")
+    q5 = MdpState("q5", "init")
+    q6 = MdpState("q6", "crash")
+
+    q0.transitions['but'].append((q0, 1))
+    q0.transitions['coin'].append((q1, 1))
+    q0.transitions['koin'].append((q3, 1))
+
+    q1.transitions['but'].append((q0, 0.1))
+    q1.transitions['but'].append((q2, 0.9))
+
+    q3.transitions['but'].append((q0, 0.1))
+    q3.transitions['but'].append((q4, 0.9))
+
+    q1.transitions['coin'].append((q1, 1))
+    q3.transitions['koin'].append((q3, 1))
+    q1.transitions['koin'].append((q3, 1))
+    q3.transitions['coin'].append((q1, 1))
+
+    q2.transitions['but'].append((q0, 1))
+    q2.transitions['coin'].append((q1, 1))
+    q2.transitions['koin'].append((q3, 1))
+
+    q4.transitions['coin'].append((q1, 1))
+    q4.transitions['koin'].append((q3, 1))
+
+    q4.transitions['but'].append((q5, 1))
+
+    q5.transitions['but'].append((q6, 1))
+    q5.transitions['coin'].append((q6, 1))
+    q5.transitions['koin'].append((q6, 1))
+
+    q6.transitions['but'].append((q6, 1))
+    q6.transitions['coin'].append((q6, 1))
+    q6.transitions['koin'].append((q6, 1))
+
+    mdp = Mdp(q0, [q0, q1, q2, q3, q4, q5, q6])
+
+    return mdp
+
+
+def get_faulty_coffee_machine_SMM():
+    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
+
+    s0 = StochasticMealyState('q0')
+    s1 = StochasticMealyState('q1')
+    s2 = StochasticMealyState('q2')
+
+    s0.transitions['but'].append((s0, 'init', 1.))
+    s0.transitions['coin'].append((s1, 'beep', 1.))
+    s1.transitions['but'].append((s0, 'init', 0.1))
+    s1.transitions['but'].append((s2, 'coffee', 0.9))
+    s1.transitions['coin'].append((s1, 'beep', 1.))
+    s2.transitions['but'].append((s0, 'init', 1.))
+    s2.transitions['coin'].append((s1, 'beep', 1.))
+
+    smm = StochasticMealyMachine(s0, [s0, s1, s2])
+
+    return smm
+
+
+def get_minimal_faulty_coffee_machine_SMM():
+    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
+
+    s0 = StochasticMealyState('q0')
+    s1 = StochasticMealyState('q1')
+
+    s0.transitions['but'].append((s0, 'init', 1.))
+    s0.transitions['coin'].append((s1, 'beep', 1.))
+    s1.transitions['but'].append((s0, 'init', 0.1))
+    s1.transitions['but'].append((s0, 'coffee', 0.9))
+    s1.transitions['coin'].append((s1, 'beep', 1.))
+
+    smm = StochasticMealyMachine(s0, [s0, s1])
+
+    return smm
+
+
+def get_faulty_mqtt_SMM():
+    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
+
+    s0 = StochasticMealyState('q0')
+    s1 = StochasticMealyState('q1')
+    s2 = StochasticMealyState('q2')
+
+    s0.transitions['connect'].append((s1, 'CONNACK', 1.))
+    s0.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
+    s0.transitions['publish'].append((s0, 'CONCLOSED', 1.))
+    s0.transitions['subscribe'].append((s0, 'CONCLOSED', 1.))
+    s0.transitions['unsubscribe'].append((s0, 'CONCLOSED', 1.))
+
+    s1.transitions['connect'].append((s0, 'CONCLOSED', 1.))
+    s1.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
+    s1.transitions['publish'].append((s1, 'PUBACK', 0.9))
+    s1.transitions['publish'].append((s0, 'CONCLOSED', 0.1))
+    s1.transitions['subscribe'].append((s2, 'SUBACK', 1.))
+    s1.transitions['unsubscribe'].append((s1, 'UNSUBACK', 1.))
+
+    s2.transitions['connect'].append((s0, 'CONCLOSED', 1.))
+    s2.transitions['disconnect'].append((s0, 'CONCLOSED', 1.))
+    s2.transitions['publish'].append((s2, 'PUBLISH_PUBACK', 1.))
+    s2.transitions['subscribe'].append((s2, 'SUBACK', 1.))
+    s2.transitions['unsubscribe'].append((s1, 'UNSUBACK', 0.8))
+    s2.transitions['unsubscribe'].append((s2, 'SUBACK', 0.2))
+
+    smm = StochasticMealyMachine(s0, [s0, s1, s2])
+
+    return smm
+
+
+def get_small_gridworld():
+    from aalpy.automata import StochasticMealyMachine, StochasticMealyState
+
+    s0 = StochasticMealyState('q0')
+    s1 = StochasticMealyState('q1')
+    s2 = StochasticMealyState('q2')
+    s3 = StochasticMealyState('q3')
+
+    p_g = 0.8
+    p_m = 0.6
+
+    # gridworld of the form
+    # W W W W with a start in the top left
+    # W G M W states like s0 s1
+    # W M G W             s2 s3
+    # W W W W
+
+    s0.transitions['north'].append((s0, 'wall', 1.))
+    s0.transitions['west'].append((s0, 'wall', 1.))
+    s0.transitions['east'].append((s1, 'mud', p_m))
+    s0.transitions['east'].append((s3, 'grass', 1 - p_m))
+    s0.transitions['south'].append((s2, 'mud', p_m))
+    s0.transitions['south'].append((s3, 'grass', 1 - p_m))
+
+    s1.transitions['north'].append((s1, 'wall', 1.))
+    s1.transitions['east'].append((s1, 'wall', 1.))
+    s1.transitions['west'].append((s0, 'grass', p_g))
+    s1.transitions['west'].append((s2, 'mud', 1 - p_g))
+    s1.transitions['south'].append((s3, 'grass', p_g))
+    s1.transitions['south'].append((s2, 'mud', 1 - p_g))
+
+    s2.transitions['south'].append((s2, 'wall', 1.))
+    s2.transitions['west'].append((s2, 'wall', 1.))
+    s2.transitions['east'].append((s3, 'grass', p_g))
+    s2.transitions['east'].append((s1, 'mud', 1 - p_g))
+    s2.transitions['north'].append((s0, 'grass', p_g))
+    s2.transitions['south'].append((s1, 'mud', 1 - p_g))
+
+    s3.transitions['south'].append((s3, 'wall', 1.))
+    s3.transitions['east'].append((s3, 'wall', 1.))
+    s3.transitions['west'].append((s2, 'mud', p_m))
+    s3.transitions['west'].append((s0, 'grass', 1 - p_m))
+    s3.transitions['north'].append((s1, 'mud', p_m))
+    s3.transitions['north'].append((s0, 'grass', 1 - p_m))
+
+    smm = StochasticMealyMachine(s0, [s0, s1, s2, s3])
+
+    return smm
+
+
+class MockMqttExample:
+
+    def __init__(self):
+        self.state = 'CONCLOSED'
+        self.topics = set()
+
+    def subscribe(self, topic: str):
+        if '\n' in topic or '\u0000' in topic:
+            self.state = 'CONCLOSED'
+            self.topics.clear()
+        elif self.state != 'CONCLOSED':
+            self.topics.add(topic)
+            self.state = 'SUBACK'
+
+        return self.state
+
+    def unsubscribe(self, topic):
+        if '\n' in topic or '\u0000' in topic:
+            self.state = 'CONCLOSED'
+            self.topics.clear()
+        elif self.state != 'CONCLOSED':
+            if topic in self.topics:
+                self.topics.remove(topic)
+            self.state = 'UNSUBACK'
+
+        return self.state
+
+    def connect(self):
+        if self.state == 'CONCLOSED':
+            self.state = 'CONNACK'
+        else:
+            self.topics.clear()
+            self.state = 'CONCLOSED'
+        return self.state
+
+    def disconnect(self):
+        self.state = 'CONCLOSED'
+        self.topics.clear()
+        return self.state
+
+    def publish(self, topic):
+        if '\n' in topic or '\u0000' in topic:
+            self.state = 'CONCLOSED'
+            self.topics.clear()
+        if self.state != 'CONCLOSED':
+            if topic not in self.topics:
+                self.state = 'PUBACK'
+            else:
+                self.state = 'PUBACK_PUBACK'
+        return self.state
+
+
+class DateValidator:
+    """
+    Class mimicking Date Validator API.
+    It does not account for the leap years.
+    The format of the dates is %d/%m/%Y'
+    """
+
+    def is_date_accepted(self, date_string: str):
+        values = date_string.split('/')
+        if len(values) != 3:
+            return False
+        try:
+            day = int(values[0])
+            month = int(values[1])
+            year = int(values[2])
+        except ValueError:
+            return False
+
+        if not (0 <= year <= 9999):
+            return False
+
+        if month == 2 and not (1 <= day <= 28):
+            return False
+
+        if month in [1, 3, 5, 7, 8, 10, 12] and not (1 <= day <= 31):
+            return False
+
+        elif not (1 <= day <= 31):
+            return False
+
+        return True
+
+
+def get_small_pomdp():
+    from aalpy.automata import Mdp, MdpState
+
+    q0 = MdpState("q0", "init")
+    q1 = MdpState("q1", "beep")
+    q2 = MdpState("q2", "beep")
+    q3 = MdpState("q3", "coffee")
+    q4 = MdpState("q4", "tea")
+
+    q0.transitions['but'].append((q0, 1))
+    q0.transitions['coin'].append((q1, 0.8))
+    q0.transitions['coin'].append((q2, 0.2))
+
+    q1.transitions['coin'].append((q1, 1))
+    q1.transitions['but'].append((q3, 1))
+
+    q2.transitions['coin'].append((q2, 0.3))
+    q2.transitions['coin'].append((q1, 0.7))
+    q2.transitions['but'].append((q4, 1))
+
+    q3.transitions['coin'].append((q3, 1))
+    q3.transitions['but'].append((q3, 1))
+
+    q4.transitions['coin'].append((q4, 1))
+    q4.transitions['but'].append((q4, 1))
+
+    return Mdp(q0, [q0, q1, q2, q3, q4])
+
+
+def is_balanced(test_string, call_return_map, allow_empty_string):
+    stack = []
+    # Create a set of open and close characters for faster lookup
+    open_chars = set(call_return_map.keys())
+    close_chars = set(call_return_map.values())
+
+    for char in test_string:
+        if char in open_chars:
+            stack.append(char)
+        elif char in close_chars:
+            # Stack should exist
+            if not stack:
+                return False
+            last_open = stack.pop()
+            # Mismatched open and close character
+            if call_return_map[last_open] != char:
+                return False
+
+    return not stack if allow_empty_string else not stack and len(test_string) > 0
+
+
+def get_balanced_string_sul(call_return_map, allow_empty_string):
+    from aalpy.base import SUL
+
+    class BalancedStringSUL(SUL):
+        def __init__(self, call_return_map, allow_empty_string):
+            super(BalancedStringSUL, self).__init__()
+            self.call_return_map = call_return_map
+            self.allow_empty_string = allow_empty_string
+            self.sting_under_test = []
+
+        def pre(self):
+            self.sting_under_test = []
+
+        def post(self):
+            pass
+
+        def step(self, letter):
+            if letter:
+                self.sting_under_test += letter
+            return is_balanced(self.sting_under_test, self.call_return_map, self.allow_empty_string)
+
+    return BalancedStringSUL(call_return_map, allow_empty_string)
```

## aalpy/utils/BenchmarkSevpaModels.py

 * *Ordering differences only*

```diff
@@ -1,293 +1,293 @@
-from aalpy.automata.Sevpa import Sevpa
-from aalpy.utils import load_automaton_from_file
-
-
-def sevpa_for_L1():
-    state_setup = {
-        'q0': (False, {'b': [('q1', 'pop', ('q0', 'a'))]
-                       }),
-        'q1': (True, {'b': [('q1', 'pop', ('q0', 'a'))]
-                      })
-    }
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L2():
-    state_setup = {
-        'q0': (False, {'d': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))],
-                       'c': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))]
-                       }),
-        'q1': (True, {'d': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))],
-                      'c': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L3():
-    state_setup = {
-        'q0': (False, {'g': [('q6', 'pop', ('q0', 'd')),
-                             ('q4', 'pop', ('q0', 'b'))],
-                       'e': [('q5', 'pop', ('q0', 'd')),
-                             ('q2', 'pop', ('q0', 'b'))]
-                       }),
-        'q1': (True, {'g': [('q6', 'pop', ('q0', 'd')),
-                            ('q4', 'pop', ('q0', 'b'))],
-                      'e': [('q5', 'pop', ('q0', 'd')),
-                            ('q2', 'pop', ('q0', 'b'))]
-                      }),
-        'q2': (False, {'f': [('q1', 'pop', ('q0', 'a'))]
-                       }),
-        'q4': (False, {'h': [('q1', 'pop', ('q0', 'a'))]
-                       }),
-        'q5': (False, {'f': [('q1', 'pop', ('q0', 'c'))]
-                       }),
-        'q6': (False, {'h': [('q1', 'pop', ('q0', 'c'))]
-                       })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L4():
-    state_setup = {
-        'q0': (False, {'c': [('q2', 'pop', ('q0', 'b'))]
-                       }),
-        'q1': (True, {'c': [('q2', 'pop', ('q0', 'b'))]
-                      }),
-        'q2': (False, {'d': [('q1', 'pop', ('q0', 'a'))]
-                       })
-    }
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L5():
-    state_setup = {
-        'q0': (False, {'d': [('q2', 'pop', ('q0', 'c'))]
-                       }),
-        'q1': (True, {'d': [('q2', 'pop', ('q0', 'c'))]
-                      }),
-        'q2': (False, {'e': [('q3', 'pop', ('q0', 'b'))]
-                       }),
-        'q3': (False, {'f': [('q1', 'pop', ('q0', 'a'))]
-                       })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L7():
-    state_setup = {
-        'q0': (False, {')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))],
-                       ']': [('q1', 'pop', ('q0', '[')),
-                             ('q1', 'pop', ('q1', '['))]
-                       }),
-        'q1': (True, {')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))],
-                      ']': [('q1', 'pop', ('q0', '[')),
-                            ('q1', 'pop', ('q1', '['))]
-                      })
-
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L8():
-    state_setup = {
-        'q0': (False, {')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))],
-                       '}': [('q1', 'pop', ('q0', '{')),
-                             ('q1', 'pop', ('q1', '{'))],
-                       ']': [('q1', 'pop', ('q0', '[')),
-                             ('q1', 'pop', ('q1', '['))]
-                       }),
-        'q1': (True, {')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))],
-                      '}': [('q1', 'pop', ('q0', '{')),
-                            ('q1', 'pop', ('q1', '{'))],
-                      ']': [('q1', 'pop', ('q0', '[')),
-                            ('q1', 'pop', ('q1', '['))]
-                      })
-    }
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L9():
-    state_setup = {
-        'q0': (False, {']': [('q1', 'pop', ('q0', '[')),
-                             ('q1', 'pop', ('q1', '['))],
-                       '}': [('q1', 'pop', ('q0', '{')),
-                             ('q1', 'pop', ('q1', '{'))],
-                       ')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))],
-                       '>': [('q1', 'pop', ('q0', '<')),
-                             ('q1', 'pop', ('q1', '<'))]
-                       }),
-        'q1': (True, {']': [('q1', 'pop', ('q0', '[')),
-                            ('q1', 'pop', ('q1', '['))],
-                      '}': [('q1', 'pop', ('q0', '{')),
-                            ('q1', 'pop', ('q1', '{'))],
-                      ')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))],
-                      '>': [('q1', 'pop', ('q0', '<')),
-                            ('q1', 'pop', ('q1', '<'))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L10():
-    state_setup = {
-        "q0": (False, {"b": [("qb", None, None)],
-                       }),
-        "qb": (False, {"c": [("qc", None, None)],
-                       }),
-        "qc": (False, {"d": [("qd", None, None)],
-                       }),
-        "qd": (False, {"e": [("q1", None, None)],
-                       }),
-        "q1": (False, {"v": [("qv", 'pop', ('q0', 'a')),
-                             ("qv", 'pop', ('q1', 'a')),
-                             ("qv", 'pop', ('q2', 'a'))]
-                       }),
-        "qv": (False, {"w": [("qw", None, None)]
-                       }),
-        "qw": (False, {"x": [("qx", None, None)]
-                       }),
-        "qx": (False, {"y": [("qy", None, None)]
-                       }),
-        "qy": (False, {"z": [("q2", None, None)]
-                       }),
-        "q2": (True, {"v": [("qv", 'pop', ('q0', 'a')),
-                            ("qv", 'pop', ('q1', 'a')),
-                            ("qv", 'pop', ('q2', 'a'))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L11():
-    state_setup = {
-        'q0': (False, {'i1': [('q2', None, None)],
-                       'r1': [('q3', 'pop', ('q0', 'c2')),
-                              ('q3', 'pop', ('q1', 'c2')),
-                              ('q5', 'pop', ('q2', 'c2'))],
-                       'r2': [('q1', 'pop', ('q0', 'c2')),
-                              ('q1', 'pop', ('q1', 'c2')),
-                              ('q2', 'pop', ('q2', 'c2'))]
-                       }),
-        'q1': (True, {'r1': [('q3', 'pop', ('q0', 'c2')),
-                             ('q3', 'pop', ('q1', 'c2')),
-                             ('q5', 'pop', ('q2', 'c2'))],
-                      'r2': [('q1', 'pop', ('q0', 'c2')),
-                             ('q1', 'pop', ('q1', 'c2')),
-                             ('q2', 'pop', ('q2', 'c2'))]
-                      }),
-        'q2': (False, {'r1': [('q3', 'pop', ('q0', 'c1')),
-                              ('q3', 'pop', ('q1', 'c1')),
-                              ('q5', 'pop', ('q2', 'c1'))],
-                       'r2': [('q1', 'pop', ('q0', 'c1')),
-                              ('q1', 'pop', ('q1', 'c1')),
-                              ('q2', 'pop', ('q2', 'c1'))]
-                       }),
-        'q3': (False, {'i2': [('q1', None, None)]
-                       }),
-        'q5': (False, {'i2': [('q2', None, None)]
-                       })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L12():
-    state_setup = {
-        'q0': (False, {']': [('q1', 'pop', ('q0', '['))],
-                       ')': [('q1', 'pop', ('q0', '('))]
-                       }),
-        'q1': (True, {']': [('q1', 'pop', ('q0', '['))],
-                      ')': [('q1', 'pop', ('q0', '('))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0", )
-
-
-def sevpa_for_L13():
-    state_setup = {
-        'q0': (False, {'c': [('q1', None, None)],
-                       'b': [('q1', None, None)],
-                       'a': [('q1', None, None)],
-                       ')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))]
-                       }),
-        'q1': (True, {'c': [('q1', None, None)],
-                      'b': [('q1', None, None)],
-                      'a': [('q1', None, None)],
-                      ')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L14():
-    state_setup = {
-        'q0': (False, {'a': [('q1', None, None)],
-                       'b': [('q1', None, None)],
-                       'c': [('q1', None, None)],
-                       ']': [('q1', 'pop', ('q0', '[')),
-                             ('q1', 'pop', ('q1', '['))],
-                       ')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))]
-                       }),
-        'q1': (True, {'a': [('q1', None, None)],
-                      'b': [('q1', None, None)],
-                      'c': [('q1', None, None)],
-                      ']': [('q1', 'pop', ('q0', '[')),
-                            ('q1', 'pop', ('q1', '['))],
-                      ')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))]
-                      })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-def sevpa_for_L15():
-    # Dyck order 1
-
-    state_setup = {
-        'q0': (False, {'d': [('q1', None, None)],
-                       'a': [('q2', None, None)],
-                       ')': [('q1', 'pop', ('q0', '(')),
-                             ('q1', 'pop', ('q1', '('))]
-                       }),
-        'q1': (True, {'d': [('q1', None, None)],
-                      'a': [('q2', None, None)],
-                      ')': [('q1', 'pop', ('q0', '(')),
-                            ('q1', 'pop', ('q1', '('))]
-                      }),
-        'q2': (False, {'b': [('q3', None, None)]
-                       }),
-        'q3': (False, {'c': [('q1', None, None)]
-                       })
-    }
-
-    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
-
-
-if __name__ == '__main__':
-    e = sevpa_for_L13()
-    print(e)
-    print(e.get_input_alphabet())
-    e.save('test')
-    m = load_automaton_from_file('test.dot', automaton_type='vpa')
-    print('Loaded')
-    print(m)
-
+from aalpy.automata.Sevpa import Sevpa
+from aalpy.utils import load_automaton_from_file
+
+
+def sevpa_for_L1():
+    state_setup = {
+        'q0': (False, {'b': [('q1', 'pop', ('q0', 'a'))]
+                       }),
+        'q1': (True, {'b': [('q1', 'pop', ('q0', 'a'))]
+                      })
+    }
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L2():
+    state_setup = {
+        'q0': (False, {'d': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))],
+                       'c': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))]
+                       }),
+        'q1': (True, {'d': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))],
+                      'c': [('q1', 'pop', ('q0', 'a')), ('q1', 'pop', ('q0', 'b'))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L3():
+    state_setup = {
+        'q0': (False, {'g': [('q6', 'pop', ('q0', 'd')),
+                             ('q4', 'pop', ('q0', 'b'))],
+                       'e': [('q5', 'pop', ('q0', 'd')),
+                             ('q2', 'pop', ('q0', 'b'))]
+                       }),
+        'q1': (True, {'g': [('q6', 'pop', ('q0', 'd')),
+                            ('q4', 'pop', ('q0', 'b'))],
+                      'e': [('q5', 'pop', ('q0', 'd')),
+                            ('q2', 'pop', ('q0', 'b'))]
+                      }),
+        'q2': (False, {'f': [('q1', 'pop', ('q0', 'a'))]
+                       }),
+        'q4': (False, {'h': [('q1', 'pop', ('q0', 'a'))]
+                       }),
+        'q5': (False, {'f': [('q1', 'pop', ('q0', 'c'))]
+                       }),
+        'q6': (False, {'h': [('q1', 'pop', ('q0', 'c'))]
+                       })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L4():
+    state_setup = {
+        'q0': (False, {'c': [('q2', 'pop', ('q0', 'b'))]
+                       }),
+        'q1': (True, {'c': [('q2', 'pop', ('q0', 'b'))]
+                      }),
+        'q2': (False, {'d': [('q1', 'pop', ('q0', 'a'))]
+                       })
+    }
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L5():
+    state_setup = {
+        'q0': (False, {'d': [('q2', 'pop', ('q0', 'c'))]
+                       }),
+        'q1': (True, {'d': [('q2', 'pop', ('q0', 'c'))]
+                      }),
+        'q2': (False, {'e': [('q3', 'pop', ('q0', 'b'))]
+                       }),
+        'q3': (False, {'f': [('q1', 'pop', ('q0', 'a'))]
+                       })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L7():
+    state_setup = {
+        'q0': (False, {')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))],
+                       ']': [('q1', 'pop', ('q0', '[')),
+                             ('q1', 'pop', ('q1', '['))]
+                       }),
+        'q1': (True, {')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))],
+                      ']': [('q1', 'pop', ('q0', '[')),
+                            ('q1', 'pop', ('q1', '['))]
+                      })
+
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L8():
+    state_setup = {
+        'q0': (False, {')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))],
+                       '}': [('q1', 'pop', ('q0', '{')),
+                             ('q1', 'pop', ('q1', '{'))],
+                       ']': [('q1', 'pop', ('q0', '[')),
+                             ('q1', 'pop', ('q1', '['))]
+                       }),
+        'q1': (True, {')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))],
+                      '}': [('q1', 'pop', ('q0', '{')),
+                            ('q1', 'pop', ('q1', '{'))],
+                      ']': [('q1', 'pop', ('q0', '[')),
+                            ('q1', 'pop', ('q1', '['))]
+                      })
+    }
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L9():
+    state_setup = {
+        'q0': (False, {']': [('q1', 'pop', ('q0', '[')),
+                             ('q1', 'pop', ('q1', '['))],
+                       '}': [('q1', 'pop', ('q0', '{')),
+                             ('q1', 'pop', ('q1', '{'))],
+                       ')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))],
+                       '>': [('q1', 'pop', ('q0', '<')),
+                             ('q1', 'pop', ('q1', '<'))]
+                       }),
+        'q1': (True, {']': [('q1', 'pop', ('q0', '[')),
+                            ('q1', 'pop', ('q1', '['))],
+                      '}': [('q1', 'pop', ('q0', '{')),
+                            ('q1', 'pop', ('q1', '{'))],
+                      ')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))],
+                      '>': [('q1', 'pop', ('q0', '<')),
+                            ('q1', 'pop', ('q1', '<'))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L10():
+    state_setup = {
+        "q0": (False, {"b": [("qb", None, None)],
+                       }),
+        "qb": (False, {"c": [("qc", None, None)],
+                       }),
+        "qc": (False, {"d": [("qd", None, None)],
+                       }),
+        "qd": (False, {"e": [("q1", None, None)],
+                       }),
+        "q1": (False, {"v": [("qv", 'pop', ('q0', 'a')),
+                             ("qv", 'pop', ('q1', 'a')),
+                             ("qv", 'pop', ('q2', 'a'))]
+                       }),
+        "qv": (False, {"w": [("qw", None, None)]
+                       }),
+        "qw": (False, {"x": [("qx", None, None)]
+                       }),
+        "qx": (False, {"y": [("qy", None, None)]
+                       }),
+        "qy": (False, {"z": [("q2", None, None)]
+                       }),
+        "q2": (True, {"v": [("qv", 'pop', ('q0', 'a')),
+                            ("qv", 'pop', ('q1', 'a')),
+                            ("qv", 'pop', ('q2', 'a'))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L11():
+    state_setup = {
+        'q0': (False, {'i1': [('q2', None, None)],
+                       'r1': [('q3', 'pop', ('q0', 'c2')),
+                              ('q3', 'pop', ('q1', 'c2')),
+                              ('q5', 'pop', ('q2', 'c2'))],
+                       'r2': [('q1', 'pop', ('q0', 'c2')),
+                              ('q1', 'pop', ('q1', 'c2')),
+                              ('q2', 'pop', ('q2', 'c2'))]
+                       }),
+        'q1': (True, {'r1': [('q3', 'pop', ('q0', 'c2')),
+                             ('q3', 'pop', ('q1', 'c2')),
+                             ('q5', 'pop', ('q2', 'c2'))],
+                      'r2': [('q1', 'pop', ('q0', 'c2')),
+                             ('q1', 'pop', ('q1', 'c2')),
+                             ('q2', 'pop', ('q2', 'c2'))]
+                      }),
+        'q2': (False, {'r1': [('q3', 'pop', ('q0', 'c1')),
+                              ('q3', 'pop', ('q1', 'c1')),
+                              ('q5', 'pop', ('q2', 'c1'))],
+                       'r2': [('q1', 'pop', ('q0', 'c1')),
+                              ('q1', 'pop', ('q1', 'c1')),
+                              ('q2', 'pop', ('q2', 'c1'))]
+                       }),
+        'q3': (False, {'i2': [('q1', None, None)]
+                       }),
+        'q5': (False, {'i2': [('q2', None, None)]
+                       })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L12():
+    state_setup = {
+        'q0': (False, {']': [('q1', 'pop', ('q0', '['))],
+                       ')': [('q1', 'pop', ('q0', '('))]
+                       }),
+        'q1': (True, {']': [('q1', 'pop', ('q0', '['))],
+                      ')': [('q1', 'pop', ('q0', '('))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0", )
+
+
+def sevpa_for_L13():
+    state_setup = {
+        'q0': (False, {'c': [('q1', None, None)],
+                       'b': [('q1', None, None)],
+                       'a': [('q1', None, None)],
+                       ')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))]
+                       }),
+        'q1': (True, {'c': [('q1', None, None)],
+                      'b': [('q1', None, None)],
+                      'a': [('q1', None, None)],
+                      ')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L14():
+    state_setup = {
+        'q0': (False, {'a': [('q1', None, None)],
+                       'b': [('q1', None, None)],
+                       'c': [('q1', None, None)],
+                       ']': [('q1', 'pop', ('q0', '[')),
+                             ('q1', 'pop', ('q1', '['))],
+                       ')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))]
+                       }),
+        'q1': (True, {'a': [('q1', None, None)],
+                      'b': [('q1', None, None)],
+                      'c': [('q1', None, None)],
+                      ']': [('q1', 'pop', ('q0', '[')),
+                            ('q1', 'pop', ('q1', '['))],
+                      ')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))]
+                      })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+def sevpa_for_L15():
+    # Dyck order 1
+
+    state_setup = {
+        'q0': (False, {'d': [('q1', None, None)],
+                       'a': [('q2', None, None)],
+                       ')': [('q1', 'pop', ('q0', '(')),
+                             ('q1', 'pop', ('q1', '('))]
+                       }),
+        'q1': (True, {'d': [('q1', None, None)],
+                      'a': [('q2', None, None)],
+                      ')': [('q1', 'pop', ('q0', '(')),
+                            ('q1', 'pop', ('q1', '('))]
+                      }),
+        'q2': (False, {'b': [('q3', None, None)]
+                       }),
+        'q3': (False, {'c': [('q1', None, None)]
+                       })
+    }
+
+    return Sevpa.from_state_setup(state_setup, init_state_id="q0")
+
+
+if __name__ == '__main__':
+    e = sevpa_for_L13()
+    print(e)
+    print(e.get_input_alphabet())
+    e.save('test')
+    m = load_automaton_from_file('test.dot', automaton_type='vpa')
+    print('Loaded')
+    print(m)
+
```

## aalpy/utils/DataHandler.py

 * *Ordering differences only*

```diff
@@ -1,73 +1,73 @@
-from abc import ABC, abstractmethod
-
-
-class DataHandler(ABC):
-    """
-    Abstract class used for data loading for Alergia algorithm. Usage of class is not needed, but recommended for
-    consistency.
-    """
-
-    @abstractmethod
-    def tokenize_data(self, path):
-        pass
-
-
-class CharacterTokenizer(DataHandler):
-    """
-    Used for Markov Chain data parsing.
-    Processes data where each input is a single character.
-    Each input sequence is in the separate line.
-    """
-
-    def tokenize_data(self, path):
-        data = []
-        lines = open(path).read().splitlines()
-        for l in lines:
-            data.append(list(l))
-        return data
-
-
-class DelimiterTokenizer(DataHandler):
-    """
-    Used for Markov Chain data parsing.
-    Processes data where each input is separated by the delimiter.
-    Each input sequence is in the separate line.
-    """
-
-    def tokenize_data(self, path, delimiter=','):
-        data = []
-        lines = open(path).read().splitlines()
-        for l in lines:
-            data.append(l.split(delimiter))
-        return data
-
-
-class IODelimiterTokenizer(DataHandler):
-    """
-    Used for Markov Decision Process data parsing.
-    Processes data where each input/output is separated by the io_delimiter, and i/o pairs are separated
-    by word delimiter.
-    Each [output, tuple(input,output)*] sequence is in the separate line.
-    """
-
-    def tokenize_data(self, path, io_delimiter='/', word_delimiter=','):
-        data = []
-        lines = open(path).read().splitlines()
-        for l in lines:
-            words = l.split(word_delimiter)
-            seq = [words[0]]
-            for w in words[1:]:
-                i_o = w.split(io_delimiter)
-                if len(i_o) != 2:
-                    print('Data formatting error. io_delimiter should split words into <input> <delim> <output>'
-                          'where <delim> is values of param \"io_delimiter\'"')
-                    exit(-1)
-                seq.append(tuple([try_int(i_o[0]), try_int(i_o[1])]))
-            data.append(seq)
-        return data
-
-
-def try_int(x):
-    if str.isdigit(x):
-        return int(x)
-    return x
+from abc import ABC, abstractmethod
+
+
+class DataHandler(ABC):
+    """
+    Abstract class used for data loading for Alergia algorithm. Usage of class is not needed, but recommended for
+    consistency.
+    """
+
+    @abstractmethod
+    def tokenize_data(self, path):
+        pass
+
+
+class CharacterTokenizer(DataHandler):
+    """
+    Used for Markov Chain data parsing.
+    Processes data where each input is a single character.
+    Each input sequence is in the separate line.
+    """
+
+    def tokenize_data(self, path):
+        data = []
+        lines = open(path).read().splitlines()
+        for l in lines:
+            data.append(list(l))
+        return data
+
+
+class DelimiterTokenizer(DataHandler):
+    """
+    Used for Markov Chain data parsing.
+    Processes data where each input is separated by the delimiter.
+    Each input sequence is in the separate line.
+    """
+
+    def tokenize_data(self, path, delimiter=','):
+        data = []
+        lines = open(path).read().splitlines()
+        for l in lines:
+            data.append(l.split(delimiter))
+        return data
+
+
+class IODelimiterTokenizer(DataHandler):
+    """
+    Used for Markov Decision Process data parsing.
+    Processes data where each input/output is separated by the io_delimiter, and i/o pairs are separated
+    by word delimiter.
+    Each [output, tuple(input,output)*] sequence is in the separate line.
+    """
+
+    def tokenize_data(self, path, io_delimiter='/', word_delimiter=','):
+        data = []
+        lines = open(path).read().splitlines()
+        for l in lines:
+            words = l.split(word_delimiter)
+            seq = [words[0]]
+            for w in words[1:]:
+                i_o = w.split(io_delimiter)
+                if len(i_o) != 2:
+                    print('Data formatting error. io_delimiter should split words into <input> <delim> <output>'
+                          'where <delim> is values of param \"io_delimiter\'"')
+                    exit(-1)
+                seq.append(tuple([try_int(i_o[0]), try_int(i_o[1])]))
+            data.append(seq)
+        return data
+
+
+def try_int(x):
+    if str.isdigit(x):
+        return int(x)
+    return x
```

## aalpy/utils/FileHandler.py

```diff
@@ -1,336 +1,427 @@
-import re
-import sys
-import sys
-import traceback
-from pathlib import Path
-
-from pydot import Dot, Node, Edge, graph_from_dot_file
-
-from aalpy.automata import Dfa, MooreMachine, Mdp, Onfsm, MealyState, DfaState, MooreState, MealyMachine, \
-    MdpState, StochasticMealyMachine, StochasticMealyState, OnfsmState, MarkovChain, McState, Sevpa, SevpaState, \
-    SevpaTransition
-
-file_types = ['dot', 'png', 'svg', 'pdf', 'string']
-automaton_types = {Dfa: 'dfa', MealyMachine: 'mealy', MooreMachine: 'moore', Mdp: 'mdp',
-                   StochasticMealyMachine: 'smm', Onfsm: 'onfsm', MarkovChain: 'mc', Sevpa: 'vpa'}
-
-sevpa_transition_regex = r"(\S+)\s*/\s*\(\s*'(\S+)'\s*,\s*'(\S+)'\s*\)"
-
-def _wrap_label(label):
-    """
-    Adds a " " around a label if not already present on both ends.
-    """
-    if label[0] == '\"' and label[-1] == '\"':
-        return label
-    return f'\"{label}\"'
-
-
-def _get_node(state, automaton_type):
-    if automaton_type == 'dfa':
-        if state.is_accepting:
-            return Node(state.state_id, label=_wrap_label(state.state_id), shape='doublecircle')
-        return Node(state.state_id, label=_wrap_label(state.state_id))
-    if automaton_type == 'mealy':
-        return Node(state.state_id, label=_wrap_label(state.state_id))
-    if automaton_type == 'moore':
-        return Node(state.state_id, label=_wrap_label(f'{state.state_id}|{state.output}'), shape='record',
-                    style='rounded')
-    if automaton_type == 'onfsm':
-        return Node(state.state_id, label=_wrap_label(state.state_id))
-    if automaton_type == 'mc':
-        return Node(state.state_id, label=_wrap_label(f'{state.output}'))
-    if automaton_type == 'mdp':
-        return Node(state.state_id, label=_wrap_label(f'{state.output}'))
-    if automaton_type == 'smm':
-        return Node(state.state_id, label=_wrap_label(state.state_id))
-    if automaton_type == 'vpa':
-        if state.is_accepting:
-            return Node(state.state_id, label=_wrap_label(state.state_id), shape='doublecircle')
-        return Node(state.state_id, label=_wrap_label(state.state_id))
-
-
-def _add_transition_to_graph(graph, state, automaton_type, display_same_state_trans, round_floats):
-    if automaton_type == 'dfa' or automaton_type == 'moore':
-        for i in state.transitions.keys():
-            new_state = state.transitions[i]
-            if not display_same_state_trans and new_state.state_id == state.state_id:
-                continue
-            graph.add_edge(Edge(state.state_id, new_state.state_id, label=_wrap_label(f'{i}')))
-    if automaton_type == 'mealy':
-        for i in state.transitions.keys():
-            new_state = state.transitions[i]
-            if not display_same_state_trans and new_state.state_id == state.state_id:
-                continue
-            graph.add_edge(Edge(state.state_id, new_state.state_id, label=_wrap_label(f'{i}/{state.output_fun[i]}')))
-    if automaton_type == 'onfsm':
-        for i in state.transitions.keys():
-            new_state = state.transitions[i]
-            for s in new_state:
-                if not display_same_state_trans and state.state_id == s[1].state_id:
-                    continue
-                graph.add_edge(Edge(state.state_id, s[1].state_id, label=_wrap_label(f'{i}/{s[0]}')))
-    if automaton_type == 'mc':
-        for new_state, prob in state.transitions:
-            prob = round(prob, round_floats) if round_floats else prob
-            graph.add_edge(Edge(state.state_id, new_state.state_id, label=f'{prob}'))
-    if automaton_type == 'mdp':
-        for i in state.transitions.keys():
-            new_state = state.transitions[i]
-            for s in new_state:
-                if not display_same_state_trans and s[0].state_id == state.state_id:
-                    continue
-                prob = round(s[1], round_floats) if round_floats else s[1]
-                graph.add_edge(Edge(state.state_id, s[0].state_id, label=_wrap_label(f'{i}:{prob}')))
-    if automaton_type == 'smm':
-        for i in state.transitions.keys():
-            new_state = state.transitions[i]
-            for s in new_state:
-                if not display_same_state_trans and s[0].state_id == state.state_id:
-                    continue
-                prob = round(s[2], round_floats) if round_floats else s[2]
-                graph.add_edge(Edge(state.state_id, s[0].state_id, label=_wrap_label(f'{i}/{s[1]}:{prob}')))
-    if automaton_type == 'vpa':
-        for i in state.transitions.keys():
-            transitions_list = state.transitions[i]
-            for transition in transitions_list:
-                if transition.action == 'pop':
-                    edge = Edge(state.state_id, transition.target_state.state_id,
-                                label=_wrap_label(f'{transition.letter} / {transition.stack_guard}'))
-                elif transition.action is None:
-                    edge = Edge(state.state_id, transition.target_state.state_id,
-                                label=_wrap_label(f'{transition.letter}'))
-                else:
-                    assert False
-                graph.add_edge(edge)
-
-
-def visualize_automaton(automaton, path="LearnedModel", file_type="pdf", display_same_state_trans=True):
-    """
-    Create a graphical representation of the automaton.
-    Function is round in the separate thread in the background.
-    If possible, it will be opened by systems default program.
-
-    Args:
-
-        automaton: automaton to be visualized
-
-        path: pathlike or str, file in which visualization will be saved (Default value = "LearnedModel.pdf")
-
-        file_type: type of file/visualization. Can be ['png', 'svg', 'pdf'] (Default value = "pdf")
-
-        display_same_state_trans: if True, same state transitions will be displayed (Default value = True)
-
-    """
-    print('Visualization started in the background thread.')
-
-    if len(automaton.states) >= 25:
-        print(f'Visualizing {len(automaton.states)} state automaton could take some time.')
-
-    import threading
-    visualization_thread = threading.Thread(target=save_automaton_to_file, name="Visualization",
-                                            args=(automaton, path, file_type, display_same_state_trans, True, 2))
-    visualization_thread.start()
-
-
-def save_automaton_to_file(automaton, path="LearnedModel", file_type="dot",
-                           display_same_state_trans=True, visualize=False, round_floats=None):
-    """
-    The Standard of the automata strictly follows the syntax found at: https://automata.cs.ru.nl/Syntax/Overview.
-    For non-deterministic and stochastic systems syntax can be found on AALpy's Wiki.
-
-    Args:
-
-        automaton: automaton to be saved to file
-
-        path: pathlike or str, file in which visualization will be saved (Default value = "LearnedModel")
-
-        file_type: type of file/visualization. Can be ['dot', 'png', 'svg', 'pdf'] (Default value = "dot)
-
-        display_same_state_trans: True, should not be set to false except from the visualization method
-            (Default value = True)
-
-        visualize: visualize the automaton
-
-        round_floats: for stochastic automata, round the floating point numbers to defined number of decimal places
-
-    Returns:
-
-    """
-    path = Path(path)
-    file_type = file_type.lower()
-    assert file_type in file_types, f"Filetype {file_type} not in allowed filetypes"
-    path = path.with_suffix(f".{file_type}")
-    if file_type == 'dot' and not display_same_state_trans:
-        print("When saving to file all transitions will be saved")
-        display_same_state_trans = True
-    automaton_type = automaton_types[automaton.__class__]
-
-    graph = Dot(path.stem, graph_type='digraph')
-    for state in automaton.states:
-        if automaton_type == 'pda' and state.state_id == 'ErrorSinkState':
-            continue
-        graph.add_node(_get_node(state, automaton_type))
-
-    for state in automaton.states:
-        _add_transition_to_graph(graph, state, automaton_type, display_same_state_trans, round_floats)
-
-    # add initial node
-    graph.add_node(Node('__start0', shape='none', label=''))
-    graph.add_edge(Edge('__start0', automaton.initial_state.state_id, label=''))
-
-    if file_type == 'string':
-        return graph.to_string()
-    else:
-        try:
-            graph.write(path=path, format=file_type if file_type != 'dot' else 'raw')
-            print(f'Model saved to {path.as_posix()}.')
-
-            if visualize and file_type in {'pdf', 'png', 'svg'}:
-                try:
-                    import webbrowser
-                    webbrowser.open(path.resolve().as_uri())
-                except OSError:
-                    traceback.print_exc()
-                    print(f'Could not open the file {path.as_posix()}.', file=sys.stderr)
-        except OSError:
-            traceback.print_exc()
-            print(f'Could not write to the file {path.as_posix()}.', file=sys.stderr)
-
-
-def _process_label(label, source, destination, automaton_type):
-    if automaton_type == 'dfa' or automaton_type == 'moore':
-        source.transitions[int(label) if label.isdigit() else label] = destination
-    if automaton_type == 'mealy':
-        inp, out = label.split('/', maxsplit=1)
-        inp = int(inp) if inp.isdigit() else inp
-        out = int(out) if out.isdigit() else out
-        source.transitions[inp] = destination
-        source.output_fun[inp] = out
-    if automaton_type == 'onfsm':
-        inp, out = label.split('/', maxsplit=1)
-        inp = int(inp) if inp.isdigit() else inp
-        out = int(out) if out.isdigit() else out
-        source.transitions[inp].append((out, destination))
-    if automaton_type == 'mc':
-        prob = label
-        source.transitions.append((destination, float(prob)))
-    if automaton_type == 'mdp':
-        inp, prob = label.split(':', maxsplit=1)
-        inp = int(inp) if inp.isdigit() else inp
-        prob = float(prob)
-        source.transitions[inp].append((destination, prob))
-    if automaton_type == 'smm':
-        inp, out_prob = label.split('/', maxsplit=1)
-        out, prob = out_prob.split(':', maxsplit=1)
-        inp = int(inp) if inp.isdigit() else inp
-        out = int(out) if out.isdigit() else out
-        source.transitions[inp].append((destination, out, float(prob)))
-    if automaton_type == 'vpa':
-        match = re.match(sevpa_transition_regex, label)
-        # cast to integer
-        label = int(label) if label.isdigit() else label
-        if match:
-            ret, stack_guard, top_of_stack = match.groups()
-            return_transition = SevpaTransition(destination, ret, 'pop', (stack_guard, top_of_stack))
-            source.transitions[label].append(return_transition)
-        else:
-            internal_transition = SevpaTransition(destination, label, None, None)
-            source.transitions[label].append(internal_transition)
-        pass
-
-
-def _process_node_label(node, label, node_label_dict, node_type, automaton_type):
-    node_name = node.get_name()
-    if automaton_type == 'mdp' or automaton_type == 'mc':
-        node_label_dict[node_name] = node_type(node_name, label)
-    else:
-        if automaton_type == 'moore' and label != "":
-            label_output = _strip_label(label)
-            label, output = label_output.split("|", maxsplit=1)
-            output = output if not output.isdigit() else int(output)
-            node_label_dict[node_name] = node_type(label, output)
-        else:
-            node_label_dict[node_name] = node_type(label)
-        if automaton_type == 'dfa' or automaton_type == 'vpa':
-            if 'shape' in node.get_attributes().keys() and 'doublecircle' in node.get_attributes()['shape']:
-                node_label_dict[node_name].is_accepting = True
-
-
-def _strip_label(label: str) -> str:
-    label = label.strip()
-    if label[0] == '\"' and label[-1] == label[0]:
-        label = label[1:-1]
-    if label[0] == '{' and label[-1] == '}':
-        label = label[1:-1]
-    # label = label.replace(" ", "")
-    return label
-
-
-def load_automaton_from_file(path, automaton_type, compute_prefixes=False):
-    """
-    Loads the automaton from the file.
-    Standard of the automatas strictly follows syntax found at: https://automata.cs.ru.nl/Syntax/Overview.
-    For non-deterministic and stochastic systems syntax can be found on AALpy's Wiki.
-
-    Args:
-
-        path: pathlike or str to the file
-
-        automaton_type: type of the automaton, if not specified it will be automatically determined according,
-            one of ['dfa', 'mealy', 'moore', 'mdp', 'smm', 'onfsm', 'mc']
-
-        compute_prefixes: it True, shortest path to reach every state will be computed and saved in the prefix of
-            the state. Useful when loading the model to use them as a equivalence oracle. (Default value = False)
-
-    Returns:
-      automaton
-
-    """
-    path = Path(path)
-    graph = graph_from_dot_file(path)[0]
-
-    assert automaton_type in automaton_types.values()
-
-    id_node_aut_map = {'dfa': (DfaState, Dfa), 'mealy': (MealyState, MealyMachine), 'moore': (MooreState, MooreMachine),
-                       'onfsm': (OnfsmState, Onfsm), 'mdp': (MdpState, Mdp), 'mc': (McState, MarkovChain),
-                       'smm': (StochasticMealyState, StochasticMealyMachine), 'vpa': (SevpaState, Sevpa)}
-
-    nodeType, aut_type = id_node_aut_map[automaton_type]
-
-    node_label_dict = dict()
-    for n in graph.get_node_list():
-        if n.get_name() == '__start0' or n.get_name() == '' or n.get_name() == '"\\n"':
-            continue
-        label = None
-        if 'label' in n.get_attributes().keys():
-            label = n.get_attributes()['label']
-            label = _strip_label(label)
-
-        _process_node_label(n, label, node_label_dict, nodeType, automaton_type)
-
-    initial_node = None
-    for edge in graph.get_edge_list():
-        if edge.get_source() == '__start0':
-            initial_node = node_label_dict[edge.get_destination()]
-            continue
-
-        source = node_label_dict[edge.get_source()]
-        destination = node_label_dict[edge.get_destination()]
-
-        label = edge.get_attributes()['label']
-        label = _strip_label(label)
-        _process_label(label, source, destination, automaton_type)
-
-    if initial_node is None:
-        print("No initial state found. \n"
-              "Please follow syntax found at: https://github.com/DES-Lab/AALpy/wiki/"
-              "Loading,Saving,-Syntax-and-Visualization-of-Automata ")
-        assert False
-
-    automaton = aut_type(initial_node, list(node_label_dict.values()))
-    if automaton_type not in {'mc', 'vpa'} and not automaton.is_input_complete():
-        print('Warning: Loaded automaton is not input complete.')
-    if compute_prefixes and not automaton_type not in {'mc', 'vpa'}:
-        for state in automaton.states:
-            state.prefix = automaton.get_shortest_path(automaton.initial_state, state)
-    return automaton
+import re
+import sys
+import sys
+import traceback
+from pathlib import Path
+
+from pydot import Dot, Node, Edge, graph_from_dot_file
+
+from aalpy.automata import Dfa, MooreMachine, Mdp, Onfsm, MealyState, DfaState, MooreState, MealyMachine, \
+    MdpState, StochasticMealyMachine, StochasticMealyState, OnfsmState, MarkovChain, McState, Sevpa, SevpaState, \
+    SevpaTransition
+
+file_types = ['dot', 'png', 'svg', 'pdf', 'string']
+automaton_types = {Dfa: 'dfa', MealyMachine: 'mealy', MooreMachine: 'moore', Mdp: 'mdp',
+                   StochasticMealyMachine: 'smm', Onfsm: 'onfsm', MarkovChain: 'mc', Sevpa: 'vpa'}
+
+sevpa_transition_regex = r"(\S+)\s*/\s*\(\s*'(\S+)'\s*,\s*'(\S+)'\s*\)"
+
+
+def _wrap_label(label):
+    """
+    Adds a " " around a label if not already present on both ends.
+    """
+    if label[0] == '\"' and label[-1] == '\"':
+        return label
+    return f'\"{label}\"'
+
+
+def _get_node(state, automaton_type):
+    if automaton_type == 'dfa':
+        if state.is_accepting:
+            return Node(state.state_id, label=_wrap_label(state.state_id), shape='doublecircle')
+        return Node(state.state_id, label=_wrap_label(state.state_id))
+    if automaton_type == 'mealy':
+        return Node(state.state_id, label=_wrap_label(state.state_id))
+    if automaton_type == 'moore':
+        return Node(state.state_id, label=_wrap_label(f'{state.state_id}|{state.output}'), shape='record',
+                    style='rounded')
+    if automaton_type == 'onfsm':
+        return Node(state.state_id, label=_wrap_label(state.state_id))
+    if automaton_type == 'mc':
+        return Node(state.state_id, label=_wrap_label(f'{state.output}'))
+    if automaton_type == 'mdp':
+        return Node(state.state_id, label=_wrap_label(f'{state.output}'))
+    if automaton_type == 'smm':
+        return Node(state.state_id, label=_wrap_label(state.state_id))
+    if automaton_type == 'vpa':
+        if state.is_accepting:
+            return Node(state.state_id, label=_wrap_label(state.state_id), shape='doublecircle')
+        return Node(state.state_id, label=_wrap_label(state.state_id))
+
+
+def _add_transition_to_graph(graph, state, automaton_type, display_same_state_trans, round_floats):
+    if automaton_type == 'dfa' or automaton_type == 'moore':
+        for i in state.transitions.keys():
+            new_state = state.transitions[i]
+            if not display_same_state_trans and new_state.state_id == state.state_id:
+                continue
+            graph.add_edge(Edge(state.state_id, new_state.state_id, label=_wrap_label(f'{i}')))
+    if automaton_type == 'mealy':
+        for i in state.transitions.keys():
+            new_state = state.transitions[i]
+            if not display_same_state_trans and new_state.state_id == state.state_id:
+                continue
+            graph.add_edge(Edge(state.state_id, new_state.state_id, label=_wrap_label(f'{i}/{state.output_fun[i]}')))
+    if automaton_type == 'onfsm':
+        for i in state.transitions.keys():
+            new_state = state.transitions[i]
+            for s in new_state:
+                if not display_same_state_trans and state.state_id == s[1].state_id:
+                    continue
+                graph.add_edge(Edge(state.state_id, s[1].state_id, label=_wrap_label(f'{i}/{s[0]}')))
+    if automaton_type == 'mc':
+        for new_state, prob in state.transitions:
+            prob = round(prob, round_floats) if round_floats else prob
+            graph.add_edge(Edge(state.state_id, new_state.state_id, label=f'{prob}'))
+    if automaton_type == 'mdp':
+        for i in state.transitions.keys():
+            new_state = state.transitions[i]
+            for s in new_state:
+                if not display_same_state_trans and s[0].state_id == state.state_id:
+                    continue
+                prob = round(s[1], round_floats) if round_floats else s[1]
+                graph.add_edge(Edge(state.state_id, s[0].state_id, label=_wrap_label(f'{i}:{prob}')))
+    if automaton_type == 'smm':
+        for i in state.transitions.keys():
+            new_state = state.transitions[i]
+            for s in new_state:
+                if not display_same_state_trans and s[0].state_id == state.state_id:
+                    continue
+                prob = round(s[2], round_floats) if round_floats else s[2]
+                graph.add_edge(Edge(state.state_id, s[0].state_id, label=_wrap_label(f'{i}/{s[1]}:{prob}')))
+    if automaton_type == 'vpa':
+        for i in state.transitions.keys():
+            transitions_list = state.transitions[i]
+            for transition in transitions_list:
+                if transition.action == 'pop':
+                    edge = Edge(state.state_id, transition.target_state.state_id,
+                                label=_wrap_label(f'{transition.letter} / {transition.stack_guard}'))
+                elif transition.action is None:
+                    edge = Edge(state.state_id, transition.target_state.state_id,
+                                label=_wrap_label(f'{transition.letter}'))
+                else:
+                    assert False
+                graph.add_edge(edge)
+
+
+def visualize_automaton(automaton, path="LearnedModel", file_type="pdf", display_same_state_trans=True):
+    """
+    Create a graphical representation of the automaton.
+    Function is round in the separate thread in the background.
+    If possible, it will be opened by systems default program.
+
+    Args:
+
+        automaton: automaton to be visualized
+
+        path: pathlike or str, file in which visualization will be saved (Default value = "LearnedModel.pdf")
+
+        file_type: type of file/visualization. Can be ['png', 'svg', 'pdf'] (Default value = "pdf")
+
+        display_same_state_trans: if True, same state transitions will be displayed (Default value = True)
+
+    """
+    print('Visualization started in the background thread.')
+
+    if len(automaton.states) >= 25:
+        print(f'Visualizing {len(automaton.states)} state automaton could take some time.')
+
+    import threading
+    visualization_thread = threading.Thread(target=save_automaton_to_file, name="Visualization",
+                                            args=(automaton, path, file_type, display_same_state_trans, True, 2))
+    visualization_thread.start()
+
+
+def save_automaton_to_file(automaton, path="LearnedModel", file_type="dot",
+                           display_same_state_trans=True, visualize=False, round_floats=None):
+    """
+    The Standard of the automata strictly follows the syntax found at: https://automata.cs.ru.nl/Syntax/Overview.
+    For non-deterministic and stochastic systems syntax can be found on AALpy's Wiki.
+
+    Args:
+
+        automaton: automaton to be saved to file
+
+        path: pathlike or str, file in which visualization will be saved (Default value = "LearnedModel")
+
+        file_type: type of file/visualization. Can be ['dot', 'png', 'svg', 'pdf'] (Default value = "dot)
+
+        display_same_state_trans: True, should not be set to false except from the visualization method
+            (Default value = True)
+
+        visualize: visualize the automaton
+
+        round_floats: for stochastic automata, round the floating point numbers to defined number of decimal places
+
+    Returns:
+
+    """
+    path = Path(path)
+    file_type = file_type.lower()
+    assert file_type in file_types, f"Filetype {file_type} not in allowed filetypes"
+    path = path.with_suffix(f".{file_type}")
+    if file_type == 'dot' and not display_same_state_trans:
+        print("When saving to file all transitions will be saved")
+        display_same_state_trans = True
+    automaton_type = automaton_types[automaton.__class__]
+
+    graph = Dot(path.stem, graph_type='digraph')
+    for state in automaton.states:
+        if automaton_type == 'pda' and state.state_id == 'ErrorSinkState':
+            continue
+        graph.add_node(_get_node(state, automaton_type))
+
+    for state in automaton.states:
+        _add_transition_to_graph(graph, state, automaton_type, display_same_state_trans, round_floats)
+
+    # add initial node
+    graph.add_node(Node('__start0', shape='none', label=''))
+    graph.add_edge(Edge('__start0', automaton.initial_state.state_id, label=''))
+
+    if file_type == 'string':
+        return graph.to_string()
+    else:
+        try:
+            graph.write(path=path, format=file_type if file_type != 'dot' else 'raw')
+            print(f'Model saved to {path.as_posix()}.')
+
+            if visualize and file_type in {'pdf', 'png', 'svg'}:
+                try:
+                    import webbrowser
+                    webbrowser.open(path.resolve().as_uri())
+                except OSError:
+                    traceback.print_exc()
+                    print(f'Could not open the file {path.as_posix()}.', file=sys.stderr)
+        except OSError:
+            traceback.print_exc()
+            print(f'Could not write to the file {path.as_posix()}.', file=sys.stderr)
+
+
+def _process_label(label, source, destination, automaton_type):
+    if automaton_type == 'dfa' or automaton_type == 'moore':
+        source.transitions[int(label) if label.isdigit() else label] = destination
+    if automaton_type == 'mealy':
+        inp, out = label.split('/', maxsplit=1)
+        inp = int(inp) if inp.isdigit() else inp
+        out = int(out) if out.isdigit() else out
+        source.transitions[inp] = destination
+        source.output_fun[inp] = out
+    if automaton_type == 'onfsm':
+        inp, out = label.split('/', maxsplit=1)
+        inp = int(inp) if inp.isdigit() else inp
+        out = int(out) if out.isdigit() else out
+        source.transitions[inp].append((out, destination))
+    if automaton_type == 'mc':
+        prob = label
+        source.transitions.append((destination, float(prob)))
+    if automaton_type == 'mdp':
+        inp, prob = label.split(':', maxsplit=1)
+        inp = int(inp) if inp.isdigit() else inp
+        prob = float(prob)
+        source.transitions[inp].append((destination, prob))
+    if automaton_type == 'smm':
+        inp, out_prob = label.split('/', maxsplit=1)
+        out, prob = out_prob.split(':', maxsplit=1)
+        inp = int(inp) if inp.isdigit() else inp
+        out = int(out) if out.isdigit() else out
+        source.transitions[inp].append((destination, out, float(prob)))
+    if automaton_type == 'vpa':
+        match = re.match(sevpa_transition_regex, label)
+        # cast to integer
+        label = int(label) if label.isdigit() else label
+        if match:
+            ret, stack_guard, top_of_stack = match.groups()
+            return_transition = SevpaTransition(destination, ret, 'pop', (stack_guard, top_of_stack))
+            source.transitions[label].append(return_transition)
+        else:
+            internal_transition = SevpaTransition(destination, label, None, None)
+            source.transitions[label].append(internal_transition)
+        pass
+
+
+def _process_node_label(node, label, node_label_dict, node_type, automaton_type):
+    node_name = node.get_name()
+    if automaton_type == 'mdp' or automaton_type == 'mc':
+        node_label_dict[node_name] = node_type(node_name, label)
+    else:
+        if automaton_type == 'moore' and label != "":
+            label_output = _strip_label(label)
+            label, output = label_output.split("|", maxsplit=1)
+            output = output.strip() if not output.isdigit() else int(output)
+            node_label_dict[node_name] = node_type(label, output)
+        else:
+            node_label_dict[node_name] = node_type(label)
+        if automaton_type == 'dfa' or automaton_type == 'vpa':
+            if 'shape' in node.get_attributes().keys() and 'doublecircle' in node.get_attributes()['shape']:
+                node_label_dict[node_name].is_accepting = True
+
+
+def _strip_label(label: str) -> str:
+    label = label.strip()
+    if label[0] == '\"' and label[-1] == label[0]:
+        label = label[1:-1]
+    if label[0] == '{' and label[-1] == '}':
+        label = label[1:-1]
+    # label = label.replace(" ", "")
+    return label
+
+
+def load_automaton_from_file_pydot_version(path, automaton_type, compute_prefixes=False):
+    """
+    Loads the automaton from the file.
+    Standard of the automatas strictly follows syntax found at: https://automata.cs.ru.nl/Syntax/Overview.
+    For non-deterministic and stochastic systems syntax can be found on AALpy's Wiki.
+
+    Args:
+
+        path: pathlike or str to the file
+
+        automaton_type: type of the automaton, if not specified it will be automatically determined according,
+            one of ['dfa', 'mealy', 'moore', 'mdp', 'smm', 'onfsm', 'mc']
+
+        compute_prefixes: it True, shortest path to reach every state will be computed and saved in the prefix of
+            the state. Useful when loading the model to use them as a equivalence oracle. (Default value = False)
+
+    Returns:
+      automaton
+
+    """
+    path = Path(path)
+    graph = graph_from_dot_file(path)[0]
+
+    assert automaton_type in automaton_types.values()
+
+    id_node_aut_map = {'dfa': (DfaState, Dfa), 'mealy': (MealyState, MealyMachine), 'moore': (MooreState, MooreMachine),
+                       'onfsm': (OnfsmState, Onfsm), 'mdp': (MdpState, Mdp), 'mc': (McState, MarkovChain),
+                       'smm': (StochasticMealyState, StochasticMealyMachine), 'vpa': (SevpaState, Sevpa)}
+
+    nodeType, aut_type = id_node_aut_map[automaton_type]
+
+    node_label_dict = dict()
+    for n in graph.get_node_list():
+        if n.get_name() == '__start0' or n.get_name() == '' or n.get_name() == '"\\n"':
+            continue
+        label = None
+        if 'label' in n.get_attributes().keys():
+            label = n.get_attributes()['label']
+            label = _strip_label(label)
+
+        _process_node_label(n, label, node_label_dict, nodeType, automaton_type)
+
+    initial_node = None
+    for edge in graph.get_edge_list():
+        if edge.get_source() == '__start0':
+            initial_node = node_label_dict[edge.get_destination()]
+            continue
+
+        source = node_label_dict[edge.get_source()]
+        destination = node_label_dict[edge.get_destination()]
+
+        label = edge.get_attributes()['label']
+        label = _strip_label(label)
+        _process_label(label, source, destination, automaton_type)
+
+    if initial_node is None:
+        print("No initial state found. \n"
+              "Please follow syntax found at: https://github.com/DES-Lab/AALpy/wiki/"
+              "Loading,Saving,-Syntax-and-Visualization-of-Automata ")
+        assert False
+
+    automaton = aut_type(initial_node, list(node_label_dict.values()))
+    if automaton_type not in {'mc', 'vpa'} and not automaton.is_input_complete():
+        print('Warning: Loaded automaton is not input complete.')
+    if compute_prefixes and not automaton_type not in {'mc', 'vpa'}:
+        for state in automaton.states:
+            state.prefix = automaton.get_shortest_path(automaton.initial_state, state)
+    return automaton
+
+
+def _process_node_label_prime(node_name, label, line, node_label_dict, node_type, automaton_type):
+    if automaton_type == 'mdp' or automaton_type == 'mc':
+        node_label_dict[node_name] = node_type(node_name, label)
+    else:
+        if automaton_type == 'moore' and label != "":
+            label_output = _strip_label(label)
+            label, output = label_output.split("|", maxsplit=1)
+            output = output.strip() if not output.isdigit() else int(output)
+            node_label_dict[node_name] = node_type(label, output)
+        else:
+            node_label_dict[node_name] = node_type(label)
+        if automaton_type == 'dfa' or automaton_type == 'vpa':
+            if 'doublecircle' in line:
+                node_label_dict[node_name].is_accepting = True
+
+
+label_pattern = r'label=("[^"]*"|[^\s\],]*)'
+starting_state_pattern = r'__start0\s*->\s*(\w+)\s*(?:\[label=""\])?;?'
+transition_pattern = r'(\w+)\s*->\s*(\w+)\s*(.*);'
+
+
+def load_automaton_from_file(path, automaton_type, compute_prefixes=False):
+    """
+    Loads the automaton from the file.
+    Standard of the automatas strictly follows syntax found at: https://automata.cs.ru.nl/Syntax/Overview.
+    For non-deterministic and stochastic systems syntax can be found on AALpy's Wiki.
+
+    Args:
+
+        path: pathlike or str to the file
+
+        automaton_type: type of the automaton, one of ['dfa', 'mealy', 'moore', 'mdp', 'smm', 'onfsm', 'mc', 'vpa']
+
+        compute_prefixes: it True, shortest path to reach every state will be computed and saved in the prefix of
+            the state. Useful when loading the model to use them as a equivalence oracle. (Default value = False)
+
+    Returns:
+
+      loaded automaton
+
+    """
+    assert automaton_type in automaton_types.values()
+
+    id_node_aut_map = {'dfa': (DfaState, Dfa), 'mealy': (MealyState, MealyMachine), 'moore': (MooreState, MooreMachine),
+                       'onfsm': (OnfsmState, Onfsm), 'mdp': (MdpState, Mdp), 'mc': (McState, MarkovChain),
+                       'smm': (StochasticMealyState, StochasticMealyMachine), 'vpa': (SevpaState, Sevpa)}
+
+    nodeType, aut_type = id_node_aut_map[automaton_type]
+
+    initial_state = None
+    transition_data = []
+
+    node_label_dict = dict()
+
+    with open(Path(path)) as f:
+        for line in f.readlines():
+            line = line.strip()
+            if '__start0 ->' in line:
+                match = re.search(starting_state_pattern, line)
+                initial_state = match.group(1).strip()
+            # State definitions
+            elif '__start0' not in line and 'label' in line and '->' not in line:
+                state_id = line.split('[')[0].strip()
+                match = re.search(label_pattern, line)
+                label = _strip_label(match.group(1))
+                _process_node_label_prime(state_id, label, line, node_label_dict, nodeType, automaton_type)
+            # transitions
+            elif '->' in line:
+                match = re.match(transition_pattern, line)
+                # source, destination, label
+                label = re.search(label_pattern, match.group(3)).group(1)
+                transition_data.append((match.group(1).strip(), match.group(2).strip(), label))
+
+    # ensure initial state is defined and it is defined states
+    assert initial_state is not None and initial_state in node_label_dict.keys()
+    initial_state = node_label_dict[initial_state]
+
+    for source, destination, transition_label in transition_data:
+        label = _strip_label(transition_label)
+        _process_label(label, node_label_dict[source], node_label_dict[destination], automaton_type)
+
+    automaton = aut_type(initial_state, list(node_label_dict.values()))
+    if automaton_type not in {'mc', 'vpa'} and not automaton.is_input_complete():
+        print('Warning: Loaded automaton is not input complete.')
+    if compute_prefixes and not automaton_type not in {'mc', 'vpa'}:
+        for state in automaton.states:
+            state.prefix = automaton.get_shortest_path(automaton.initial_state, state)
+    return automaton
```

## aalpy/utils/HelperFunctions.py

 * *Ordering differences only*

```diff
@@ -1,325 +1,325 @@
-import string
-from collections import defaultdict
-
-
-def extend_set(list_to_extend: list, new_elements: list) -> list:
-    """
-    Helper function to extend a list while maintaining set property.
-    They are stored as lists, so with this function set property is maintained.
-    :return
-
-    Returns:
-
-        list of elements that were added to the set
-
-    """
-    set_repr = set(list_to_extend)
-    added_elements = [s for s in new_elements if s not in set_repr]
-    list_to_extend.extend(added_elements)
-    return added_elements
-
-
-def all_prefixes(li):
-    """
-    Returns all prefixes of a list.
-
-    Args:
-      li: list from which to compute all prefixes
-
-    Returns:
-      list of all prefixes
-
-    """
-    return [tuple(li[:i + 1]) for i in range(len(li))]
-
-
-def all_suffixes(li):
-    """
-    Returns all suffixes of a list.
-
-    Args:
-      li: list from which to compute all suffixes
-
-    Returns:
-      list of all suffixes
-
-    """
-    return [tuple(li[len(li) - i - 1:]) for i in range(len(li))]
-
-
-def profile_function(function: callable, sort_key='cumtime'):
-    """
-
-    Args:
-      function: callable: 
-      sort_key:  (Default value = 'cumtime')
-
-    Returns:
-        prints the profiling results
-    """
-    import cProfile
-    pr = cProfile.Profile()
-    pr.enable()
-    function()
-    pr.disable()
-    pr.print_stats(sort=sort_key)
-
-
-def random_string_generator(size=10, chars=string.ascii_lowercase + string.digits):
-    """
-
-    Args:
-
-      size:  (Default value = 10)
-      chars:  (Default value = string.ascii_lowercase + string.digits)
-
-    Returns:
-
-        a random string of length size
-    """
-    import random
-    return ''.join(random.choice(chars) for _ in range(size))
-
-
-def print_learning_info(info: dict):
-    """
-    Print learning statistics.
-    """
-    print('-----------------------------------')
-    print('Learning Finished.')
-    print('Learning Rounds:  {}'.format(info['learning_rounds']))
-    print('Number of states: {}'.format(info['automaton_size']))
-    print('Time (in seconds)')
-    print('  Total                : {}'.format(info['total_time']))
-    print('  Learning algorithm   : {}'.format(info['learning_time']))
-    print('  Conformance checking : {}'.format(info['eq_oracle_time']))
-    print('Learning Algorithm')
-    print(' # Membership Queries  : {}'.format(info['queries_learning']))
-    if 'cache_saved' in info.keys():
-        print(' # MQ Saved by Caching : {}'.format(info['cache_saved']))
-    print(' # Steps               : {}'.format(info['steps_learning']))
-    print('Equivalence Query')
-    print(' # Membership Queries  : {}'.format(info['queries_eq_oracle']))
-    print(' # Steps               : {}'.format(info['steps_eq_oracle']))
-    print('-----------------------------------')
-
-
-def print_observation_table(ot, table_type):
-    """
-    Prints the whole observation table.
-
-    Args:
-
-        ot: observation table
-        table_type: 'det', 'non-det', or 'stoc'
-
-    """
-    if table_type == 'det':
-        s_set, extended_s, e_set, table = ot.S, ot.s_dot_a(), ot.E, ot.T
-    elif table_type == 'non-det':
-        s_set, extended_s, e_set = ot.S, ot.get_extended_S(), ot.E
-        table = ot.sul.cache.get_table(s_set + extended_s, e_set)
-    elif table_type == 'abstracted-non-det':
-        s_set, extended_s, e_set, table = ot.S, ot.S_dot_A, ot.E, ot.T
-    else:
-        s_set, extended_s, e_set, table = ot.S, ot.get_extended_s(), ot.E, ot.T
-
-    headers = [str(e) for e in e_set]
-    s_rows = []
-    extended_rows = []
-    headers.insert(0, 'Prefixes / E set')
-    for s in s_set:
-        row = [str(s)]
-        if table_type == 'det':
-            row.extend(str(e) for e in table[s])
-        else:
-            row.extend(str(table[s][e]) for e in e_set)
-        s_rows.append(row)
-    for s in extended_s:
-        row = [str(s)]
-        if table_type == 'det':
-            row.extend(str(e) for e in table[s])
-        else:
-            row.extend(str(table[s][e]) for e in e_set)
-        extended_rows.append(row)
-
-    table = [headers] + s_rows
-    columns = defaultdict(int)
-    for i in table + extended_rows:
-        for index, el in enumerate(i):
-            columns[index] = max(columns[index], len(el))
-
-    row_len = 0
-    for row in table:
-        row = "|".join(element.ljust(columns[ind] + 1) for ind, element in enumerate(row))
-        print("-" * len(row))
-        row_len = len(row)
-        print(row)
-    print('=' * row_len)
-    for row in extended_rows:
-        row = "|".join(element.ljust(columns[ind] + 1) for ind, element in enumerate(row))
-        print("-" * len(row))
-        print(row)
-    print('-' * row_len)
-
-
-def is_suffix_of(suffix, trace) -> bool:
-    """
-
-    Args:
-      suffix: target suffix
-      trace: trace in question
-
-    Returns:
-
-        True if suffix is the suffix of trace.
-    """
-    if len(trace) < len(suffix):
-        return False
-    else:
-        return trace[-len(suffix):] == suffix
-
-
-def get_cex_prefixes(cex, automaton_type):
-    """
-    Returns all prefixes of the stochastic automaton.
-
-    Args:
-        cex: counterexample
-        automaton_type: `mdp` or `smm`
-
-    Returns:
-
-        all prefixes of the counterexample based on the `automaton_type`
-    """
-    if automaton_type == 'mdp':
-        return [tuple(cex[:i + 1]) for i in range(0, len(cex), 2)]
-    return [tuple(cex[:i]) for i in range(0, len(cex) + 1, 2)]
-
-
-def get_available_oracles_and_err_msg():
-    from aalpy.oracles import RandomWalkEqOracle
-    from aalpy.oracles import RandomWordEqOracle
-    available_oracles = {RandomWalkEqOracle, RandomWordEqOracle}
-
-    available_oracles_msg = 'Warning! Only Random Walk and Random Word oracles are supported for non-deterministic and ' \
-                            'stochastic learning. If you have implemented the custom oracle, set the custom_oracle ' \
-                            'flag to True. '
-
-    return available_oracles, available_oracles_msg
-
-
-def make_input_complete(automaton, missing_transition_go_to='self_loop'):
-    """
-    Makes the automaton input complete/enabled. If a input is not defined in a state, it will lead to the self loop.
-    In case of Mealy Machines, Stochastic Mealy machines and ONFSM 'epsilon' is used as output.
-    Self loop simply loops the transition back to state which was not input complete,
-    whereas 'sink_state' leads all transitions to a newly added sink state. If transitions have output
-    (Mealy machines and their derivatives), 'epsilon' is used as an output value. If a state has an output value,
-    it is either False (in case of DFA) or 'sink_state' in case of Moore machines and its derivatives.
-
-    Args:
-
-        automaton: automaton that is potentially not input complete
-        missing_transition_go_to: either 'self_loop' or 'sink_state'.
-
-    Returns:
-
-        an input complete automaton
-    """
-    from aalpy.base import DeterministicAutomaton
-    from aalpy.automata import Dfa, MooreState, MealyMachine, Mdp, StochasticMealyMachine, Onfsm, \
-        DfaState, MealyState, MooreMachine, OnfsmState, MdpState, StochasticMealyState
-
-    assert missing_transition_go_to in {'self_loop', 'sink_state'}
-
-    input_al = automaton.get_input_alphabet()
-
-    if automaton.is_input_complete():
-        return automaton
-
-    sink_state = None
-    sink_state_type_dict = {Dfa: DfaState(state_id='sink', is_accepting=False),
-                            MooreMachine: MooreState(state_id='sink', output='sink_state'),
-                            MealyMachine: MealyState(state_id='sink'),
-                            Onfsm: OnfsmState(state_id='sink'),
-                            Mdp: MdpState(state_id='sink', output='sink_state'),
-                            StochasticMealyMachine: StochasticMealyState(state_id='sink')}
-
-    if missing_transition_go_to == 'sink_state':
-        sink_state = sink_state_type_dict[automaton.__class__]
-        automaton.states.append(sink_state)
-
-    for state in automaton.states:
-        for i in input_al:
-            if i not in state.transitions.keys():
-                if missing_transition_go_to == 'self_loop':
-                    if isinstance(automaton, DeterministicAutomaton):
-                        state.transitions[i] = state
-                        if isinstance(automaton, MealyMachine):
-                            state.output_fun[i] = 'epsilon'
-                    if isinstance(automaton, Onfsm):
-                        state.transitions[i].append(('epsilon', state))
-                    if isinstance(automaton, Mdp):
-                        state.transitions[i].append((state, 1.))
-                    if isinstance(automaton, StochasticMealyMachine):
-                        state.transitions[i].append((state, 'epsilon', 1.))
-                else:
-                    if isinstance(automaton, Dfa):
-                        state.transitions[i] = sink_state
-                    if isinstance(automaton, MooreMachine):
-                        state.transitions[i] = sink_state
-                    if isinstance(automaton, MealyMachine):
-                        state.transitions[i] = sink_state
-                        state.output_fun[i] = 'epsilon'
-                    if isinstance(automaton, Onfsm):
-                        state.transitions[i].append(('epsilon', sink_state))
-                    if isinstance(automaton, Mdp):
-                        state.transitions[i].append((sink_state, 1.))
-                    if isinstance(automaton, StochasticMealyMachine):
-                        state.transitions[i].append((sink_state, 'epsilon', 1.))
-
-    return automaton
-
-
-def convert_i_o_traces_for_RPNI(sequences):
-    """
-    Converts a list of input-output sequences to RPNI format.
-    Eg. [[(1,'a'), (2,'b'), (3,'c')], [(6,'7'), (4,'e'), (3,'c')]] to
-    [((1,), 'a'), ((1, 2), 'b'), ((1, 2, 3), 'c'), ((6,), '7'), ((6, 4), 'e'), ((6, 4, 3), 'c')]
-    """
-    rpni_sequences = set()
-
-    for s in sequences:
-        for i in range(len(s)):
-            inputs = tuple([io[0] for io in s[:i + 1]])
-            rpni_sequences.add((inputs, s[i][1]))
-
-    return list(rpni_sequences)
-
-
-def visualize_classification_tree(root_node):
-    from pydot import Dot, Node, Edge
-
-    graph = Dot('classification_tree', graph_type='digraph')
-    root_node_dot = Node(id(root_node), shape='box',
-                         label=f'Distinguishing String:\n{root_node.distinguishing_string}')
-    graph.add_node(root_node_dot)
-
-    queue = [(root_node, root_node_dot)]
-
-    while queue:
-        origin_node, origin_node_dot = queue.pop(0)
-
-        for key, child in origin_node.children.items():
-            if child.is_leaf():
-                destination_dot = Node(id(child), label=f'Access String:\n{child.access_string}')
-            else:
-                destination_dot = Node(id(child), shape='box',
-                                       label=f'Distinguishing String:\n{child.distinguishing_string}')
-                queue.append((child, destination_dot))
-            graph.add_node(destination_dot)
-            graph.add_edge(Edge(origin_node_dot, destination_dot, label=key))
-
-    # print(graph.to_string())
-    graph.write(path='classification_tree.pdf', format='pdf')
+import string
+from collections import defaultdict
+
+
+def extend_set(list_to_extend: list, new_elements: list) -> list:
+    """
+    Helper function to extend a list while maintaining set property.
+    They are stored as lists, so with this function set property is maintained.
+    :return
+
+    Returns:
+
+        list of elements that were added to the set
+
+    """
+    set_repr = set(list_to_extend)
+    added_elements = [s for s in new_elements if s not in set_repr]
+    list_to_extend.extend(added_elements)
+    return added_elements
+
+
+def all_prefixes(li):
+    """
+    Returns all prefixes of a list.
+
+    Args:
+      li: list from which to compute all prefixes
+
+    Returns:
+      list of all prefixes
+
+    """
+    return [tuple(li[:i + 1]) for i in range(len(li))]
+
+
+def all_suffixes(li):
+    """
+    Returns all suffixes of a list.
+
+    Args:
+      li: list from which to compute all suffixes
+
+    Returns:
+      list of all suffixes
+
+    """
+    return [tuple(li[len(li) - i - 1:]) for i in range(len(li))]
+
+
+def profile_function(function: callable, sort_key='cumtime'):
+    """
+
+    Args:
+      function: callable: 
+      sort_key:  (Default value = 'cumtime')
+
+    Returns:
+        prints the profiling results
+    """
+    import cProfile
+    pr = cProfile.Profile()
+    pr.enable()
+    function()
+    pr.disable()
+    pr.print_stats(sort=sort_key)
+
+
+def random_string_generator(size=10, chars=string.ascii_lowercase + string.digits):
+    """
+
+    Args:
+
+      size:  (Default value = 10)
+      chars:  (Default value = string.ascii_lowercase + string.digits)
+
+    Returns:
+
+        a random string of length size
+    """
+    import random
+    return ''.join(random.choice(chars) for _ in range(size))
+
+
+def print_learning_info(info: dict):
+    """
+    Print learning statistics.
+    """
+    print('-----------------------------------')
+    print('Learning Finished.')
+    print('Learning Rounds:  {}'.format(info['learning_rounds']))
+    print('Number of states: {}'.format(info['automaton_size']))
+    print('Time (in seconds)')
+    print('  Total                : {}'.format(info['total_time']))
+    print('  Learning algorithm   : {}'.format(info['learning_time']))
+    print('  Conformance checking : {}'.format(info['eq_oracle_time']))
+    print('Learning Algorithm')
+    print(' # Membership Queries  : {}'.format(info['queries_learning']))
+    if 'cache_saved' in info.keys():
+        print(' # MQ Saved by Caching : {}'.format(info['cache_saved']))
+    print(' # Steps               : {}'.format(info['steps_learning']))
+    print('Equivalence Query')
+    print(' # Membership Queries  : {}'.format(info['queries_eq_oracle']))
+    print(' # Steps               : {}'.format(info['steps_eq_oracle']))
+    print('-----------------------------------')
+
+
+def print_observation_table(ot, table_type):
+    """
+    Prints the whole observation table.
+
+    Args:
+
+        ot: observation table
+        table_type: 'det', 'non-det', or 'stoc'
+
+    """
+    if table_type == 'det':
+        s_set, extended_s, e_set, table = ot.S, ot.s_dot_a(), ot.E, ot.T
+    elif table_type == 'non-det':
+        s_set, extended_s, e_set = ot.S, ot.get_extended_S(), ot.E
+        table = ot.sul.cache.get_table(s_set + extended_s, e_set)
+    elif table_type == 'abstracted-non-det':
+        s_set, extended_s, e_set, table = ot.S, ot.S_dot_A, ot.E, ot.T
+    else:
+        s_set, extended_s, e_set, table = ot.S, ot.get_extended_s(), ot.E, ot.T
+
+    headers = [str(e) for e in e_set]
+    s_rows = []
+    extended_rows = []
+    headers.insert(0, 'Prefixes / E set')
+    for s in s_set:
+        row = [str(s)]
+        if table_type == 'det':
+            row.extend(str(e) for e in table[s])
+        else:
+            row.extend(str(table[s][e]) for e in e_set)
+        s_rows.append(row)
+    for s in extended_s:
+        row = [str(s)]
+        if table_type == 'det':
+            row.extend(str(e) for e in table[s])
+        else:
+            row.extend(str(table[s][e]) for e in e_set)
+        extended_rows.append(row)
+
+    table = [headers] + s_rows
+    columns = defaultdict(int)
+    for i in table + extended_rows:
+        for index, el in enumerate(i):
+            columns[index] = max(columns[index], len(el))
+
+    row_len = 0
+    for row in table:
+        row = "|".join(element.ljust(columns[ind] + 1) for ind, element in enumerate(row))
+        print("-" * len(row))
+        row_len = len(row)
+        print(row)
+    print('=' * row_len)
+    for row in extended_rows:
+        row = "|".join(element.ljust(columns[ind] + 1) for ind, element in enumerate(row))
+        print("-" * len(row))
+        print(row)
+    print('-' * row_len)
+
+
+def is_suffix_of(suffix, trace) -> bool:
+    """
+
+    Args:
+      suffix: target suffix
+      trace: trace in question
+
+    Returns:
+
+        True if suffix is the suffix of trace.
+    """
+    if len(trace) < len(suffix):
+        return False
+    else:
+        return trace[-len(suffix):] == suffix
+
+
+def get_cex_prefixes(cex, automaton_type):
+    """
+    Returns all prefixes of the stochastic automaton.
+
+    Args:
+        cex: counterexample
+        automaton_type: `mdp` or `smm`
+
+    Returns:
+
+        all prefixes of the counterexample based on the `automaton_type`
+    """
+    if automaton_type == 'mdp':
+        return [tuple(cex[:i + 1]) for i in range(0, len(cex), 2)]
+    return [tuple(cex[:i]) for i in range(0, len(cex) + 1, 2)]
+
+
+def get_available_oracles_and_err_msg():
+    from aalpy.oracles import RandomWalkEqOracle
+    from aalpy.oracles import RandomWordEqOracle
+    available_oracles = {RandomWalkEqOracle, RandomWordEqOracle}
+
+    available_oracles_msg = 'Warning! Only Random Walk and Random Word oracles are supported for non-deterministic and ' \
+                            'stochastic learning. If you have implemented the custom oracle, set the custom_oracle ' \
+                            'flag to True. '
+
+    return available_oracles, available_oracles_msg
+
+
+def make_input_complete(automaton, missing_transition_go_to='self_loop'):
+    """
+    Makes the automaton input complete/enabled. If a input is not defined in a state, it will lead to the self loop.
+    In case of Mealy Machines, Stochastic Mealy machines and ONFSM 'epsilon' is used as output.
+    Self loop simply loops the transition back to state which was not input complete,
+    whereas 'sink_state' leads all transitions to a newly added sink state. If transitions have output
+    (Mealy machines and their derivatives), 'epsilon' is used as an output value. If a state has an output value,
+    it is either False (in case of DFA) or 'sink_state' in case of Moore machines and its derivatives.
+
+    Args:
+
+        automaton: automaton that is potentially not input complete
+        missing_transition_go_to: either 'self_loop' or 'sink_state'.
+
+    Returns:
+
+        an input complete automaton
+    """
+    from aalpy.base import DeterministicAutomaton
+    from aalpy.automata import Dfa, MooreState, MealyMachine, Mdp, StochasticMealyMachine, Onfsm, \
+        DfaState, MealyState, MooreMachine, OnfsmState, MdpState, StochasticMealyState
+
+    assert missing_transition_go_to in {'self_loop', 'sink_state'}
+
+    input_al = automaton.get_input_alphabet()
+
+    if automaton.is_input_complete():
+        return automaton
+
+    sink_state = None
+    sink_state_type_dict = {Dfa: DfaState(state_id='sink', is_accepting=False),
+                            MooreMachine: MooreState(state_id='sink', output='sink_state'),
+                            MealyMachine: MealyState(state_id='sink'),
+                            Onfsm: OnfsmState(state_id='sink'),
+                            Mdp: MdpState(state_id='sink', output='sink_state'),
+                            StochasticMealyMachine: StochasticMealyState(state_id='sink')}
+
+    if missing_transition_go_to == 'sink_state':
+        sink_state = sink_state_type_dict[automaton.__class__]
+        automaton.states.append(sink_state)
+
+    for state in automaton.states:
+        for i in input_al:
+            if i not in state.transitions.keys():
+                if missing_transition_go_to == 'self_loop':
+                    if isinstance(automaton, DeterministicAutomaton):
+                        state.transitions[i] = state
+                        if isinstance(automaton, MealyMachine):
+                            state.output_fun[i] = 'epsilon'
+                    if isinstance(automaton, Onfsm):
+                        state.transitions[i].append(('epsilon', state))
+                    if isinstance(automaton, Mdp):
+                        state.transitions[i].append((state, 1.))
+                    if isinstance(automaton, StochasticMealyMachine):
+                        state.transitions[i].append((state, 'epsilon', 1.))
+                else:
+                    if isinstance(automaton, Dfa):
+                        state.transitions[i] = sink_state
+                    if isinstance(automaton, MooreMachine):
+                        state.transitions[i] = sink_state
+                    if isinstance(automaton, MealyMachine):
+                        state.transitions[i] = sink_state
+                        state.output_fun[i] = 'epsilon'
+                    if isinstance(automaton, Onfsm):
+                        state.transitions[i].append(('epsilon', sink_state))
+                    if isinstance(automaton, Mdp):
+                        state.transitions[i].append((sink_state, 1.))
+                    if isinstance(automaton, StochasticMealyMachine):
+                        state.transitions[i].append((sink_state, 'epsilon', 1.))
+
+    return automaton
+
+
+def convert_i_o_traces_for_RPNI(sequences):
+    """
+    Converts a list of input-output sequences to RPNI format.
+    Eg. [[(1,'a'), (2,'b'), (3,'c')], [(6,'7'), (4,'e'), (3,'c')]] to
+    [((1,), 'a'), ((1, 2), 'b'), ((1, 2, 3), 'c'), ((6,), '7'), ((6, 4), 'e'), ((6, 4, 3), 'c')]
+    """
+    rpni_sequences = set()
+
+    for s in sequences:
+        for i in range(len(s)):
+            inputs = tuple([io[0] for io in s[:i + 1]])
+            rpni_sequences.add((inputs, s[i][1]))
+
+    return list(rpni_sequences)
+
+
+def visualize_classification_tree(root_node):
+    from pydot import Dot, Node, Edge
+
+    graph = Dot('classification_tree', graph_type='digraph')
+    root_node_dot = Node(id(root_node), shape='box',
+                         label=f'Distinguishing String:\n{root_node.distinguishing_string}')
+    graph.add_node(root_node_dot)
+
+    queue = [(root_node, root_node_dot)]
+
+    while queue:
+        origin_node, origin_node_dot = queue.pop(0)
+
+        for key, child in origin_node.children.items():
+            if child.is_leaf():
+                destination_dot = Node(id(child), label=f'Access String:\n{child.access_string}')
+            else:
+                destination_dot = Node(id(child), shape='box',
+                                       label=f'Distinguishing String:\n{child.distinguishing_string}')
+                queue.append((child, destination_dot))
+            graph.add_node(destination_dot)
+            graph.add_edge(Edge(origin_node_dot, destination_dot, label=key))
+
+    # print(graph.to_string())
+    graph.write(path='classification_tree.pdf', format='pdf')
```

## aalpy/utils/ModelChecking.py

 * *Ordering differences only*

```diff
@@ -1,422 +1,422 @@
-import itertools as it
-import os
-import re
-from collections import defaultdict
-from queue import Queue
-from random import choices
-from typing import Tuple, Union
-
-import aalpy.paths
-from aalpy.SULs import AutomatonSUL
-from aalpy.automata import Mdp, StochasticMealyMachine, MealyMachine, Dfa, MooreMachine, MooreState, MealyState, \
-    DfaState
-from aalpy.base import DeterministicAutomaton, SUL, AutomatonState
-
-prism_prob_output_regex = re.compile("Result: (\d+\.\d+)")
-
-
-def get_properties_file(exp_name):
-    property_files = {
-        'first_grid': aalpy.paths.path_to_properties + 'first_eval.props',
-        'second_grid': aalpy.paths.path_to_properties + 'second_eval.props',
-        'shared_coin': aalpy.paths.path_to_properties + 'shared_coin_eval.props',
-        'slot_machine': aalpy.paths.path_to_properties + 'slot_machine_eval.props',
-        'mqtt': aalpy.paths.path_to_properties + 'emqtt_two_client.props',
-        'tcp': aalpy.paths.path_to_properties + 'tcp_eval.props',
-        'bluetooth': aalpy.paths.path_to_properties + 'bluetooth.props',
-    }
-    return property_files[exp_name]
-
-
-def get_correct_prop_values(exp_name):
-    correct_model_properties = {
-        'first_grid': {'prob1': 0.96217534, 'prob2': 0.6499274956800001, 'prob3': 0.6911765746880001},
-        'second_grid': {'prob1': 0.93480795088125, 'prob2': 0.6711947700000002, 'prob3': 0.9742903305241055,
-                        'prob4': 0.14244219329051103},
-        'shared_coin': {'prob1': 0.10694382182657244, 'prob2': 0.5555528623795738, 'prob3': 0.3333324384052837,
-                        'prob4': 0.42857002816478273, 'prob5': 0.001708984375, 'prob6': 0.266845703125,
-                        'prob7': 0.244384765625, 'prob8': 0.263427734375},
-        'slot_machine': {'prob1': 0.36380049887344645, 'prob2': 0.6445910164135946, 'prob3': 1.0, 'prob4': 0.159,
-                         'prob5': 0.28567, 'prob6': 0.2500000000000001, 'prob7': 0.025445087448668406},
-        'mqtt': {'prob1': 0.9612, 'prob2': 0.34390000000000004, 'prob3': 0.6513215599000001, 'prob4': 0.814697981114816,
-                 'prob5': 0.7290000000000001},
-        'tcp': {'prob1': 0.19, 'prob2': 0.5695327900000001, 'prob3': 0.7712320754503901, 'prob4': 0.8784233454094308},
-        'bluetooth': {'prop1': 0.16800000000000004, 'prop2': 0.3926480000000001, 'prop3': 0.5572338000000001,
-                      'prop4': 0.6772233874640001, 'prop5': 0.7646958490393682, 'prop6': 0.8284632739463244,
-                      'prop7': 0.36000000000000004, 'prop8': 0.5904, 'prop9': 0.7902848,
-                      'prop10': 0.8926258176000001, 'prop11': 0.9450244186112, 'prop12': 0.9718525023289344,
-                      'prop13': 0.9855884811924145}
-    }
-    return list(correct_model_properties[exp_name].values())
-
-
-def _target_string(target, orig_id_to_int_id):
-    target_state = target[0]
-    target_prob = target[1]
-    target_id = orig_id_to_int_id[target_state.state_id]
-    return f"{target_prob} : (loc'={target_id})"
-
-
-def _sanitize_for_prism(symbol):
-    if symbol in ["mdp", "init", "module", "endmodule", "label"]:
-        return "___" + symbol + "___"
-    else:
-        return symbol
-
-
-def mdp_2_prism_format(mdp: Mdp, name: str, output_path=None):
-    """
-    Translates MDP to Prims modelling language.
-
-    Args:
-
-        mdp: markov decision process
-
-        name: name of the mdp/experiment
-
-        output_path: output file (Default value = None)
-
-    """
-    module_string = "mdp"
-    module_string += os.linesep
-    module_string += f"module {name}"
-    module_string += os.linesep
-
-    nr_states = len(mdp.states)
-    orig_id_to_int_id = dict()
-    for i, s in enumerate(mdp.states):
-        orig_id_to_int_id[s.state_id] = i
-    module_string += "loc : [0..{}] init {};".format(nr_states, orig_id_to_int_id[mdp.initial_state.state_id])
-    module_string += os.linesep
-
-    # print transitions
-    for source in mdp.states:
-        source_id = orig_id_to_int_id[source.state_id]
-        for inp in source.transitions.keys():
-            if source.transitions[inp]:
-                target_strings = \
-                    map(lambda target: _target_string(target, orig_id_to_int_id), source.transitions[inp])
-                target_joined = " + ".join(target_strings)
-                module_string += f"[{_sanitize_for_prism(inp)}] loc={source_id} -> {os.linesep} {target_joined};"
-                module_string += os.linesep
-    module_string += "endmodule"
-    module_string += os.linesep
-    # labelling function
-    output_to_state_id = defaultdict(list)
-    for s in mdp.states:
-        joined_output = s.output
-        outputs = joined_output.split("__")
-        for o in outputs:
-            if o:
-                output_to_state_id[o].append(orig_id_to_int_id[s.state_id])
-
-    for output, states in output_to_state_id.items():
-        state_propositions = map(lambda s_id: "loc={}".format(s_id), states)
-        state_disjunction = "|".join(state_propositions)
-        output_string = _sanitize_for_prism(output)
-        module_string += f"label \"{output_string}\" = {state_disjunction};"
-        module_string += os.linesep
-
-    if output_path:
-        with open(output_path, "w") as text_file:
-            text_file.write(module_string)
-    return module_string
-
-
-def evaluate_all_properties(prism_file_name, properties_file_name):
-    import subprocess
-    import io
-    from os import path
-
-    prism_file = aalpy.paths.path_to_prism.split('/')[-1]
-    path_to_prism_file = aalpy.paths.path_to_prism[:-len(prism_file)]
-
-    file_abs_path = path.abspath(prism_file_name)
-    properties_als_path = path.abspath(properties_file_name)
-    results = {}
-    proc = subprocess.Popen(
-        [aalpy.paths.path_to_prism, file_abs_path, properties_als_path],
-        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=path_to_prism_file)
-    for line in io.TextIOWrapper(proc.stdout, encoding="utf-8"):
-        if not line:
-            break
-        else:
-            match = prism_prob_output_regex.match(line)
-            if match:
-                results[f'prop{len(results) + 1}'] = float(match.group(1))
-    proc.kill()
-    return results
-
-
-def model_check_properties(model: Mdp, properties: str):
-    """
-
-    Args:
-        model: Markov Decision Process that serves as a basis for model checking.
-        properties: Properties file. It should point to a file under the path_to_properties folder.
-
-    Returns:
-
-        results of model checking
-    """
-    from os import remove
-    from aalpy.utils import mdp_2_prism_format
-    mdp_2_prism_format(mdp=model, name='mc_exp', output_path=f'mc_exp.prism')
-
-    prism_model_path = f'mc_exp.prism'
-
-    data = evaluate_all_properties(prism_model_path, properties)
-
-    remove(prism_model_path)
-
-    return data
-
-
-def model_check_experiment(path_to_properties, correct_prop_values, mdp, precision=4):
-    """
-    For our stochastic experiments you can use this function.
-    For example, check learn_stochastic_system_and_do_model_checking in Examples.py
-
-    Args:
-        path_to_properties: path to the properties file
-        correct_prop_values: correct values of all properties. In list, where property at index i corresponds to the
-            i-th element of the list.
-        mdp: MDP
-        precision: precision to which round up results
-
-    Returns:
-
-        results of model checking and absolute differance to the correct results
-    """
-    model_checking_results = model_check_properties(mdp, path_to_properties)
-
-    diff_2_correct = dict()
-    for ind, val in enumerate(model_checking_results.values()):
-        diff_2_correct[f'prop{ind + 1}'] = round(abs(correct_prop_values[ind] - val), precision)
-
-    results = {key: round(val, precision) for key, val in model_checking_results.items()}
-    return results, diff_2_correct
-
-
-def stop_based_on_confidence(hypothesis, property_based_stopping, print_level=2):
-    """
-
-    Args:
-
-        hypothesis: Markov decision process
-        property_based_stopping: a tuple (path to properties file, list of correct property values, max allowed error)
-        print_level: 2 or 3 if output of model checking is to be printed during learning
-
-    Returns:
-
-        True if absolute error for all properties is smaller then property_based_stopping[2]
-    """
-    from aalpy.automata.StochasticMealyMachine import smm_to_mdp_conversion
-
-    path_2_prop = property_based_stopping[0]
-    correct_values = property_based_stopping[1]
-    error_bound = property_based_stopping[2]
-
-    model = hypothesis
-    if isinstance(hypothesis, StochasticMealyMachine):
-        model = smm_to_mdp_conversion(hypothesis)
-
-    res, diff = model_check_experiment(path_2_prop, correct_values, model)
-
-    if print_level >= 2:
-        print('Error for each property:', [round(d * 100, 2) for d in diff.values()])
-    if not diff:
-        return False
-
-    for d in diff.values():
-        if d > error_bound:
-            return False
-
-    return True
-
-
-def bisimilar(a1: DeterministicAutomaton, a2: DeterministicAutomaton, return_cex=False) -> Union[bool, None, list]:
-    """
-    Checks whether the provided automata are bisimilar.
-    If return_cex the function returns a counter example or None, otherwise a Boolean is returned.
-
-    Returns:
-        object:
-    """
-
-    # TODO allow states as inputs instead of automata
-    if a1.__class__ != a2.__class__:
-        raise ValueError("tried to check bisimilarity of different automaton types")
-    supported_automaton_types = (Dfa, MooreMachine, MealyMachine)
-    if not isinstance(a1, supported_automaton_types):
-        raise NotImplementedError(
-            f"bisimilarity is not implemented for {a1.__class__.__name__}. Supported: {', '.join(t.__name__ for t in supported_automaton_types)}")
-
-    to_check: Queue[Tuple[AutomatonState, AutomatonState]] = Queue()
-    to_check.put((a1.initial_state, a2.initial_state))
-    requirements = dict()
-    requirements[(a1.initial_state, a2.initial_state)] = []
-
-    while not to_check.empty():
-        s1, s2 = to_check.get()
-
-        # check output equivalence for Dfa / Moore
-        if (isinstance(s1, DfaState)) and s1.is_accepting != s2.is_accepting:
-            return requirements[(s1, s2)] if return_cex else False
-        if (isinstance(s1, MooreState) and s1.output != s2.output):
-            return requirements[(s1, s2)] if return_cex else False
-
-        # check whether the same inputs are enabled + output equivalence for Mealy
-        t1, t2 = s1.transitions, s2.transitions
-        for t in it.chain(t1.keys(), filter(lambda x : x not in t1.keys(), t2.keys())):
-            common = t in t1.keys() and t in t2.keys()
-            if (not common) or (isinstance(s1, MealyState) and s1.output_fun[t] != s2.output_fun[t]) :
-                return requirements[(s1, s2)] + [t] if return_cex else False
-
-        for t in t1.keys():
-            c1, c2 = t1[t], t2[t]
-            if (c1, c2) not in requirements:
-                requirements[(c1, c2)] = requirements[(s1, s2)] + [t]
-                to_check.put((c1, c2))
-
-    return None if return_cex else True
-
-
-def compare_automata(aut_1: DeterministicAutomaton, aut_2: DeterministicAutomaton, num_cex=10):
-    """
-    Finds cases of non-conformance between first and second automaton. This is done by performing RandomW equivalence
-    check. It is possible that number of found counterexamples is smaller than num_cex, as no counterexample will be a
-    suffix of a previously found counterexample.
-
-    Args:
-
-        aut_1: first automaton
-
-        aut_2: second automaton
-
-        num_cex: max. number of searches for counterexamples
-
-    Returns:
-
-        A list of input sequences that revel different behaviour on both automata. Counterexamples are sorted by length.
-    """
-    #
-    from aalpy.oracles import RandomWMethodEqOracle
-
-    assert set(aut_1.get_input_alphabet()) == set(aut_2.get_input_alphabet())
-
-    input_al = aut_1.get_input_alphabet()
-    # larger automaton is used as hypothesis, as then test-cases will contain prefixes leading to states
-    # not in smaller automaton
-    base_automaton, test_automaton = (aut_1, aut_2) if aut_1.size < aut_2.size else (aut_2, aut_1)
-    base_sul = AutomatonSUL(base_automaton)
-
-    # compute prefixes for all states of the test automaton (needed for advanced eq. oracle)
-    for state in test_automaton.states:
-        if not state.prefix:
-            state.prefix = test_automaton.get_shortest_path(test_automaton.initial_state, state)
-
-    # setup  the eq oracle
-    eq_oracle = RandomWMethodEqOracle(input_al, base_sul, walks_per_state=min(100, len(input_al) * 10), walk_len=10)
-
-    found_cex = []
-    # to avoid near "infinite" loops due to while loop and set requirement
-    # that is, if you can only find 1 cex and all other cexs are suffixes of that cex, first while condition will never
-    # be reached
-    failsafe_counter = 0
-    failsafe_stopping = num_cex * 100
-    while len(found_cex) < num_cex or failsafe_counter == failsafe_stopping:
-        cex = eq_oracle.find_cex(test_automaton)
-        # if no counterexample can be found terminate the loop
-        if cex is None:
-            break
-        if cex not in found_cex:
-            found_cex.append(cex)
-        failsafe_counter += 1
-
-    found_cex.sort(key=len)
-
-    return found_cex
-
-
-class TestCaseWrapperSUL(SUL):
-    def __init__(self, sul):
-        super().__init__()
-        self.sul = sul
-        self.test_cases = []
-        self.test_case_inputs = None
-        self.test_case_outputs = None
-
-    def pre(self):
-        self.test_case_inputs = []
-        self.test_case_outputs = []
-        return self.sul.pre()
-
-    def post(self):
-        if self.test_case_inputs and self.test_case_outputs:
-            self.test_cases.append((tuple(self.test_case_inputs), tuple(self.test_case_outputs)))
-        return self.sul.post()
-
-    def step(self, letter):
-        output = self.sul.step(letter)
-        self.test_case_inputs.append(letter)
-        self.test_case_outputs.append(output)
-        return output
-
-
-def generate_test_cases(automaton: DeterministicAutomaton, oracle):
-    """
-    Uses parametrized eq. oracle to construct test cases on the automaton.
-    If automaton are big (200+ states), increase recursion depth if necessary (eg. sys.setrecursionlimit(10000)).
-
-    Args:
-
-        automaton: deterministic automaton that serves as a basis for test case generation
-        oracle: oracle that will construct test-cases and record inputs and outputs
-
-    Returns:
-
-        List of test cases, where each testcase is a tuple containing two elements, and input and an output sequance.
-    """
-    from copy import deepcopy
-
-    automaton_copy = deepcopy(automaton)
-    base_sul = AutomatonSUL(automaton_copy)
-
-    wrapped_sul = TestCaseWrapperSUL(base_sul)
-    oracle.sul = wrapped_sul
-    # no counterexamples can be found
-    cex = oracle.find_cex(automaton)
-    assert cex is None
-    return wrapped_sul.test_cases
-
-
-def statistical_model_checking(model, goals, max_num_steps, num_tests=105967):
-    """
-
-
-    Args:
-        model: model on which model checking is performed
-        goals: set of goal outputs
-        max_num_steps: bounded length of tests
-        num_tests: num of tests that will be performed
-
-    Returns:
-
-        num of tests containing element of goals set / num_tests
-    """
-
-    def compute_output_sequence(model, seq):
-        model.reset_to_initial()
-        observed_outputs = {model.step(i) for i in seq}
-        return observed_outputs
-
-    goal_reached = 0
-    inputs = model.get_input_alphabet()
-    for _ in range(num_tests):
-        test_sequence = choices(inputs, k=max_num_steps)
-        outputs = compute_output_sequence(model, test_sequence)
-        if goals & outputs:
-            goal_reached += 1
-
-    return goal_reached / num_tests
+import itertools as it
+import os
+import re
+from collections import defaultdict
+from queue import Queue
+from random import choices
+from typing import Tuple, Union
+
+import aalpy.paths
+from aalpy.SULs import AutomatonSUL
+from aalpy.automata import Mdp, StochasticMealyMachine, MealyMachine, Dfa, MooreMachine, MooreState, MealyState, \
+    DfaState
+from aalpy.base import DeterministicAutomaton, SUL, AutomatonState
+
+prism_prob_output_regex = re.compile("Result: (\d+\.\d+)")
+
+
+def get_properties_file(exp_name):
+    property_files = {
+        'first_grid': aalpy.paths.path_to_properties + 'first_eval.props',
+        'second_grid': aalpy.paths.path_to_properties + 'second_eval.props',
+        'shared_coin': aalpy.paths.path_to_properties + 'shared_coin_eval.props',
+        'slot_machine': aalpy.paths.path_to_properties + 'slot_machine_eval.props',
+        'mqtt': aalpy.paths.path_to_properties + 'emqtt_two_client.props',
+        'tcp': aalpy.paths.path_to_properties + 'tcp_eval.props',
+        'bluetooth': aalpy.paths.path_to_properties + 'bluetooth.props',
+    }
+    return property_files[exp_name]
+
+
+def get_correct_prop_values(exp_name):
+    correct_model_properties = {
+        'first_grid': {'prob1': 0.96217534, 'prob2': 0.6499274956800001, 'prob3': 0.6911765746880001},
+        'second_grid': {'prob1': 0.93480795088125, 'prob2': 0.6711947700000002, 'prob3': 0.9742903305241055,
+                        'prob4': 0.14244219329051103},
+        'shared_coin': {'prob1': 0.10694382182657244, 'prob2': 0.5555528623795738, 'prob3': 0.3333324384052837,
+                        'prob4': 0.42857002816478273, 'prob5': 0.001708984375, 'prob6': 0.266845703125,
+                        'prob7': 0.244384765625, 'prob8': 0.263427734375},
+        'slot_machine': {'prob1': 0.36380049887344645, 'prob2': 0.6445910164135946, 'prob3': 1.0, 'prob4': 0.159,
+                         'prob5': 0.28567, 'prob6': 0.2500000000000001, 'prob7': 0.025445087448668406},
+        'mqtt': {'prob1': 0.9612, 'prob2': 0.34390000000000004, 'prob3': 0.6513215599000001, 'prob4': 0.814697981114816,
+                 'prob5': 0.7290000000000001},
+        'tcp': {'prob1': 0.19, 'prob2': 0.5695327900000001, 'prob3': 0.7712320754503901, 'prob4': 0.8784233454094308},
+        'bluetooth': {'prop1': 0.16800000000000004, 'prop2': 0.3926480000000001, 'prop3': 0.5572338000000001,
+                      'prop4': 0.6772233874640001, 'prop5': 0.7646958490393682, 'prop6': 0.8284632739463244,
+                      'prop7': 0.36000000000000004, 'prop8': 0.5904, 'prop9': 0.7902848,
+                      'prop10': 0.8926258176000001, 'prop11': 0.9450244186112, 'prop12': 0.9718525023289344,
+                      'prop13': 0.9855884811924145}
+    }
+    return list(correct_model_properties[exp_name].values())
+
+
+def _target_string(target, orig_id_to_int_id):
+    target_state = target[0]
+    target_prob = target[1]
+    target_id = orig_id_to_int_id[target_state.state_id]
+    return f"{target_prob} : (loc'={target_id})"
+
+
+def _sanitize_for_prism(symbol):
+    if symbol in ["mdp", "init", "module", "endmodule", "label"]:
+        return "___" + symbol + "___"
+    else:
+        return symbol
+
+
+def mdp_2_prism_format(mdp: Mdp, name: str, output_path=None):
+    """
+    Translates MDP to Prims modelling language.
+
+    Args:
+
+        mdp: markov decision process
+
+        name: name of the mdp/experiment
+
+        output_path: output file (Default value = None)
+
+    """
+    module_string = "mdp"
+    module_string += os.linesep
+    module_string += f"module {name}"
+    module_string += os.linesep
+
+    nr_states = len(mdp.states)
+    orig_id_to_int_id = dict()
+    for i, s in enumerate(mdp.states):
+        orig_id_to_int_id[s.state_id] = i
+    module_string += "loc : [0..{}] init {};".format(nr_states, orig_id_to_int_id[mdp.initial_state.state_id])
+    module_string += os.linesep
+
+    # print transitions
+    for source in mdp.states:
+        source_id = orig_id_to_int_id[source.state_id]
+        for inp in source.transitions.keys():
+            if source.transitions[inp]:
+                target_strings = \
+                    map(lambda target: _target_string(target, orig_id_to_int_id), source.transitions[inp])
+                target_joined = " + ".join(target_strings)
+                module_string += f"[{_sanitize_for_prism(inp)}] loc={source_id} -> {os.linesep} {target_joined};"
+                module_string += os.linesep
+    module_string += "endmodule"
+    module_string += os.linesep
+    # labelling function
+    output_to_state_id = defaultdict(list)
+    for s in mdp.states:
+        joined_output = s.output
+        outputs = joined_output.split("__")
+        for o in outputs:
+            if o:
+                output_to_state_id[o].append(orig_id_to_int_id[s.state_id])
+
+    for output, states in output_to_state_id.items():
+        state_propositions = map(lambda s_id: "loc={}".format(s_id), states)
+        state_disjunction = "|".join(state_propositions)
+        output_string = _sanitize_for_prism(output)
+        module_string += f"label \"{output_string}\" = {state_disjunction};"
+        module_string += os.linesep
+
+    if output_path:
+        with open(output_path, "w") as text_file:
+            text_file.write(module_string)
+    return module_string
+
+
+def evaluate_all_properties(prism_file_name, properties_file_name):
+    import subprocess
+    import io
+    from os import path
+
+    prism_file = aalpy.paths.path_to_prism.split('/')[-1]
+    path_to_prism_file = aalpy.paths.path_to_prism[:-len(prism_file)]
+
+    file_abs_path = path.abspath(prism_file_name)
+    properties_als_path = path.abspath(properties_file_name)
+    results = {}
+    proc = subprocess.Popen(
+        [aalpy.paths.path_to_prism, file_abs_path, properties_als_path],
+        stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=path_to_prism_file)
+    for line in io.TextIOWrapper(proc.stdout, encoding="utf-8"):
+        if not line:
+            break
+        else:
+            match = prism_prob_output_regex.match(line)
+            if match:
+                results[f'prop{len(results) + 1}'] = float(match.group(1))
+    proc.kill()
+    return results
+
+
+def model_check_properties(model: Mdp, properties: str):
+    """
+
+    Args:
+        model: Markov Decision Process that serves as a basis for model checking.
+        properties: Properties file. It should point to a file under the path_to_properties folder.
+
+    Returns:
+
+        results of model checking
+    """
+    from os import remove
+    from aalpy.utils import mdp_2_prism_format
+    mdp_2_prism_format(mdp=model, name='mc_exp', output_path=f'mc_exp.prism')
+
+    prism_model_path = f'mc_exp.prism'
+
+    data = evaluate_all_properties(prism_model_path, properties)
+
+    remove(prism_model_path)
+
+    return data
+
+
+def model_check_experiment(path_to_properties, correct_prop_values, mdp, precision=4):
+    """
+    For our stochastic experiments you can use this function.
+    For example, check learn_stochastic_system_and_do_model_checking in Examples.py
+
+    Args:
+        path_to_properties: path to the properties file
+        correct_prop_values: correct values of all properties. In list, where property at index i corresponds to the
+            i-th element of the list.
+        mdp: MDP
+        precision: precision to which round up results
+
+    Returns:
+
+        results of model checking and absolute differance to the correct results
+    """
+    model_checking_results = model_check_properties(mdp, path_to_properties)
+
+    diff_2_correct = dict()
+    for ind, val in enumerate(model_checking_results.values()):
+        diff_2_correct[f'prop{ind + 1}'] = round(abs(correct_prop_values[ind] - val), precision)
+
+    results = {key: round(val, precision) for key, val in model_checking_results.items()}
+    return results, diff_2_correct
+
+
+def stop_based_on_confidence(hypothesis, property_based_stopping, print_level=2):
+    """
+
+    Args:
+
+        hypothesis: Markov decision process
+        property_based_stopping: a tuple (path to properties file, list of correct property values, max allowed error)
+        print_level: 2 or 3 if output of model checking is to be printed during learning
+
+    Returns:
+
+        True if absolute error for all properties is smaller then property_based_stopping[2]
+    """
+    from aalpy.automata.StochasticMealyMachine import smm_to_mdp_conversion
+
+    path_2_prop = property_based_stopping[0]
+    correct_values = property_based_stopping[1]
+    error_bound = property_based_stopping[2]
+
+    model = hypothesis
+    if isinstance(hypothesis, StochasticMealyMachine):
+        model = smm_to_mdp_conversion(hypothesis)
+
+    res, diff = model_check_experiment(path_2_prop, correct_values, model)
+
+    if print_level >= 2:
+        print('Error for each property:', [round(d * 100, 2) for d in diff.values()])
+    if not diff:
+        return False
+
+    for d in diff.values():
+        if d > error_bound:
+            return False
+
+    return True
+
+
+def bisimilar(a1: DeterministicAutomaton, a2: DeterministicAutomaton, return_cex=False) -> Union[bool, None, list]:
+    """
+    Checks whether the provided automata are bisimilar.
+    If return_cex the function returns a counter example or None, otherwise a Boolean is returned.
+
+    Returns:
+        object:
+    """
+
+    # TODO allow states as inputs instead of automata
+    if a1.__class__ != a2.__class__:
+        raise ValueError("tried to check bisimilarity of different automaton types")
+    supported_automaton_types = (Dfa, MooreMachine, MealyMachine)
+    if not isinstance(a1, supported_automaton_types):
+        raise NotImplementedError(
+            f"bisimilarity is not implemented for {a1.__class__.__name__}. Supported: {', '.join(t.__name__ for t in supported_automaton_types)}")
+
+    to_check: Queue[Tuple[AutomatonState, AutomatonState]] = Queue()
+    to_check.put((a1.initial_state, a2.initial_state))
+    requirements = dict()
+    requirements[(a1.initial_state, a2.initial_state)] = []
+
+    while not to_check.empty():
+        s1, s2 = to_check.get()
+
+        # check output equivalence for Dfa / Moore
+        if (isinstance(s1, DfaState)) and s1.is_accepting != s2.is_accepting:
+            return requirements[(s1, s2)] if return_cex else False
+        if (isinstance(s1, MooreState) and s1.output != s2.output):
+            return requirements[(s1, s2)] if return_cex else False
+
+        # check whether the same inputs are enabled + output equivalence for Mealy
+        t1, t2 = s1.transitions, s2.transitions
+        for t in it.chain(t1.keys(), filter(lambda x : x not in t1.keys(), t2.keys())):
+            common = t in t1.keys() and t in t2.keys()
+            if (not common) or (isinstance(s1, MealyState) and s1.output_fun[t] != s2.output_fun[t]) :
+                return requirements[(s1, s2)] + [t] if return_cex else False
+
+        for t in t1.keys():
+            c1, c2 = t1[t], t2[t]
+            if (c1, c2) not in requirements:
+                requirements[(c1, c2)] = requirements[(s1, s2)] + [t]
+                to_check.put((c1, c2))
+
+    return None if return_cex else True
+
+
+def compare_automata(aut_1: DeterministicAutomaton, aut_2: DeterministicAutomaton, num_cex=10):
+    """
+    Finds cases of non-conformance between first and second automaton. This is done by performing RandomW equivalence
+    check. It is possible that number of found counterexamples is smaller than num_cex, as no counterexample will be a
+    suffix of a previously found counterexample.
+
+    Args:
+
+        aut_1: first automaton
+
+        aut_2: second automaton
+
+        num_cex: max. number of searches for counterexamples
+
+    Returns:
+
+        A list of input sequences that revel different behaviour on both automata. Counterexamples are sorted by length.
+    """
+    #
+    from aalpy.oracles import RandomWMethodEqOracle
+
+    assert set(aut_1.get_input_alphabet()) == set(aut_2.get_input_alphabet())
+
+    input_al = aut_1.get_input_alphabet()
+    # larger automaton is used as hypothesis, as then test-cases will contain prefixes leading to states
+    # not in smaller automaton
+    base_automaton, test_automaton = (aut_1, aut_2) if aut_1.size < aut_2.size else (aut_2, aut_1)
+    base_sul = AutomatonSUL(base_automaton)
+
+    # compute prefixes for all states of the test automaton (needed for advanced eq. oracle)
+    for state in test_automaton.states:
+        if not state.prefix:
+            state.prefix = test_automaton.get_shortest_path(test_automaton.initial_state, state)
+
+    # setup  the eq oracle
+    eq_oracle = RandomWMethodEqOracle(input_al, base_sul, walks_per_state=min(100, len(input_al) * 10), walk_len=10)
+
+    found_cex = []
+    # to avoid near "infinite" loops due to while loop and set requirement
+    # that is, if you can only find 1 cex and all other cexs are suffixes of that cex, first while condition will never
+    # be reached
+    failsafe_counter = 0
+    failsafe_stopping = num_cex * 100
+    while len(found_cex) < num_cex or failsafe_counter == failsafe_stopping:
+        cex = eq_oracle.find_cex(test_automaton)
+        # if no counterexample can be found terminate the loop
+        if cex is None:
+            break
+        if cex not in found_cex:
+            found_cex.append(cex)
+        failsafe_counter += 1
+
+    found_cex.sort(key=len)
+
+    return found_cex
+
+
+class TestCaseWrapperSUL(SUL):
+    def __init__(self, sul):
+        super().__init__()
+        self.sul = sul
+        self.test_cases = []
+        self.test_case_inputs = None
+        self.test_case_outputs = None
+
+    def pre(self):
+        self.test_case_inputs = []
+        self.test_case_outputs = []
+        return self.sul.pre()
+
+    def post(self):
+        if self.test_case_inputs and self.test_case_outputs:
+            self.test_cases.append((tuple(self.test_case_inputs), tuple(self.test_case_outputs)))
+        return self.sul.post()
+
+    def step(self, letter):
+        output = self.sul.step(letter)
+        self.test_case_inputs.append(letter)
+        self.test_case_outputs.append(output)
+        return output
+
+
+def generate_test_cases(automaton: DeterministicAutomaton, oracle):
+    """
+    Uses parametrized eq. oracle to construct test cases on the automaton.
+    If automaton are big (200+ states), increase recursion depth if necessary (eg. sys.setrecursionlimit(10000)).
+
+    Args:
+
+        automaton: deterministic automaton that serves as a basis for test case generation
+        oracle: oracle that will construct test-cases and record inputs and outputs
+
+    Returns:
+
+        List of test cases, where each testcase is a tuple containing two elements, and input and an output sequance.
+    """
+    from copy import deepcopy
+
+    automaton_copy = deepcopy(automaton)
+    base_sul = AutomatonSUL(automaton_copy)
+
+    wrapped_sul = TestCaseWrapperSUL(base_sul)
+    oracle.sul = wrapped_sul
+    # no counterexamples can be found
+    cex = oracle.find_cex(automaton)
+    assert cex is None
+    return wrapped_sul.test_cases
+
+
+def statistical_model_checking(model, goals, max_num_steps, num_tests=105967):
+    """
+
+
+    Args:
+        model: model on which model checking is performed
+        goals: set of goal outputs
+        max_num_steps: bounded length of tests
+        num_tests: num of tests that will be performed
+
+    Returns:
+
+        num of tests containing element of goals set / num_tests
+    """
+
+    def compute_output_sequence(model, seq):
+        model.reset_to_initial()
+        observed_outputs = {model.step(i) for i in seq}
+        return observed_outputs
+
+    goal_reached = 0
+    inputs = model.get_input_alphabet()
+    for _ in range(num_tests):
+        test_sequence = choices(inputs, k=max_num_steps)
+        outputs = compute_output_sequence(model, test_sequence)
+        if goals & outputs:
+            goal_reached += 1
+
+    return goal_reached / num_tests
```

## aalpy/utils/__init__.py

 * *Ordering differences only*

```diff
@@ -1,10 +1,10 @@
-from .AutomatonGenerators import generate_random_dfa, generate_random_mealy_machine, generate_random_smm, \
-    generate_random_moore_machine, generate_random_markov_chain, generate_random_deterministic_automata
-from .AutomatonGenerators import generate_random_mdp, generate_random_ONFSM, generate_random_sevpa
-from .BenchmarkSULs import *
-from .DataHandler import DataHandler, CharacterTokenizer, DelimiterTokenizer, IODelimiterTokenizer
-from .FileHandler import save_automaton_to_file, load_automaton_from_file, visualize_automaton
-from .ModelChecking import model_check_experiment, mdp_2_prism_format, model_check_properties, get_properties_file, \
-    get_correct_prop_values, compare_automata, generate_test_cases, statistical_model_checking, \
-    bisimilar
+from .AutomatonGenerators import generate_random_dfa, generate_random_mealy_machine, generate_random_smm, \
+    generate_random_moore_machine, generate_random_markov_chain, generate_random_deterministic_automata
+from .AutomatonGenerators import generate_random_mdp, generate_random_ONFSM, generate_random_sevpa
+from .BenchmarkSULs import *
+from .DataHandler import DataHandler, CharacterTokenizer, DelimiterTokenizer, IODelimiterTokenizer
+from .FileHandler import save_automaton_to_file, load_automaton_from_file, visualize_automaton
+from .ModelChecking import model_check_experiment, mdp_2_prism_format, model_check_properties, get_properties_file, \
+    get_correct_prop_values, compare_automata, generate_test_cases, statistical_model_checking, \
+    bisimilar
 from .HelperFunctions import make_input_complete, convert_i_o_traces_for_RPNI
```

## Comparing `aalpy-1.4.0.dist-info/LICENCE.txt` & `aalpy-1.4.1.dist-info/LICENCE.txt`

 * *Files 15% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-MIT License
-
-Copyright (c) 2023 TU Graz - SAL Dependable Embedded Systems Lab (DES Lab),
-                   Edi Muskardin <edi.muskardin@silicon-austria.com>
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+MIT License
+
+Copyright (c) 2024 TU Graz - SAL Dependable Embedded Systems Lab (DES Lab),
+                   Edi Muskardin <edi.muskardin@silicon-austria.com>
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.
```

## Comparing `aalpy-1.4.0.dist-info/METADATA` & `aalpy-1.4.1.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: aalpy
-Version: 1.4.0
+Version: 1.4.1
 Summary: An active automata learning library
 Home-page: https://github.com/DES-Lab/AALpy
 Author: Edi Muskardin
 Author-email: edi.muskardin@silicon-austria.com
 License: MIT
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
@@ -36,15 +36,15 @@
 
 Whether you work with regular languages or you would like to learn models of 
 (black-box) reactive systems, AALpy supports a wide range of modeling formalisms, including 
 **deterministic**, **non-deterministic**, and **stochastic automata**, 
 as well as **deterministic context-free grammars/pushdown automata**. 
 
 <div align="center">
-   
+
 | **Automata Type** |                      **Supported Formalisms**                     | **Algorithms**        |                                                       **Features** |
 |-------------------|:-----------------------------------------------------------------:|-----------------------|-------------------------------------------------------------------:|
 | Deterministic     |                 DFAs <br /> Mealy Machines <br /> Moore Machines                 |      L* <br /> KV <br /> RPNI      | Seamless Caching <br /> Counterexample Processing <br /> 13 Equivalence Oracles  |
 | Non-Deterministic |                      ONFSM <br /> Abstracted ONFSM                      |        L*<sub>ONFSM</sub>       |                                 Size Reduction  Trough Abstraction |
 | Stochastic        | Markov Decision Processes <br /> Stochastic Mealy Machines <br /> Markov Chains | L*<sub>MDP</sub> <br /> L*<sub>SMM</sub> <br /> ALERGIA |               Counterexample Processing <br /> Exportable to PRISM format  <br /> Bindings to jALERGIA|
 | Pushdown          |          VPDA/SEVPA                                                            | KV<sub>VPA</sub> | Specification of exclusive <br/> call-return pairs
 </div>
@@ -52,15 +52,15 @@
 AALpy enables efficient learning by providing a large set of equivalence oracles, implementing various conformance testing strategies. Active learning 
 is mostly based on Angluin's [L* algorithm](https://people.eecs.berkeley.edu/~dawnsong/teaching/s10/papers/angluin87.pdf), for which AALpy supports a 
 selection of optimizations, including efficient counterexample processing caching. However, the recent addition of efficiently implemented 
 [KV](https://mitpress.mit.edu/9780262111935/an-introduction-to-computational-learning-theory/) algorithm
 requires (on average) much less interaction with the system under learning than L*. In addition, KV can be used to learn Visibly Deterministic Pushdown Automata (VPDA).
 
 AALpy also includes **passive automata learning algorithms**, namely RPNI for deterministic and ALERGIA for stochastic models. Unlike active algorithms which learn by interaction with the system, passive learning algorithms construct a model based on provided data.
- 
+
 ## Installation
 
 Use the package manager [pip](https://pip.pypa.io/en/stable/) to install the latest release of AALpy:
 ```bash
 pip install aalpy
 ```
 To install current version of the master branch (it might contain bugfixes and added functionalities between releases):
```

## Comparing `aalpy-1.4.0.dist-info/RECORD` & `aalpy-1.4.1.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,78 +1,78 @@
-aalpy/__init__.py,sha256=E4PtSezsnUgEKPIG4deY7ofPcj7CxIey4dYNxfBovoA,2109
-aalpy/paths.py,sha256=HuWZtzw_pfWFqSVwBffMn6z3NnFUlrm3b35kNpI05TE,460
-aalpy/SULs/AutomataSUL.py,sha256=KZRi5hoGXQDhwOtgL1jMuGiORPxxH0-Ti7sCR_uKD6k,505
-aalpy/SULs/PyMethodSUL.py,sha256=zjXzx8EPjN-hcx628P3zOO1jXqLjLXmjpEeDEYm2s3Q,1745
-aalpy/SULs/RegexSUL.py,sha256=gDP4AAATUfs-LSgbJtR9vfND-TBjnAZ6RjOC7gCoIGc,943
-aalpy/SULs/TomitaSUL.py,sha256=jiqlx_pBj3XkPVlo3FkNTQoVcmi0IA7iXjg73LP3CaI,1546
-aalpy/SULs/__init__.py,sha256=R46KJe-wGQZRCqIEthfXi3Hsq2s9pXg5T2PUybw1sds,150
-aalpy/automata/Dfa.py,sha256=5MTlGBljQJHYN05jaOhY9NC7-j5CbogzUdPSdchFvV0,3742
-aalpy/automata/MarkovChain.py,sha256=fBssfRTT0OsDNb9OV8QNAKsUL89M1jneMdmOAgOIdtM,2089
-aalpy/automata/Mdp.py,sha256=3N0dUv-uZgp7ggAAPPe8jS1fKY0JRaF1YiJwktW40TY,3203
-aalpy/automata/MealyMachine.py,sha256=_B1ibSN_DGfXoaisXhT7tlKU258J2eX9bgD6oUfb0-s,3287
-aalpy/automata/MooreMachine.py,sha256=Fj01SI4nDF493TjutzQ9BjwfhAU1xuOI7fMjA6D24Ec,3677
-aalpy/automata/Onfsm.py,sha256=S59yTDPguQrKlzvcoULnDbeQch5tKr2yQwghM20h9Y8,3037
-aalpy/automata/Sevpa.py,sha256=Z5F5LB9DHFFiiE0aLbrbgxktPbm89WEK17OhS8zrfJU,24177
-aalpy/automata/StochasticMealyMachine.py,sha256=1aPafwfbjxzy6cKpxGwpF7hT0ufvWvj3nRrDgDQSc7c,5044
-aalpy/automata/__init__.py,sha256=lT6q5vQfdVbWbQ7Sr0vNALk915rIYWeNy3Ub4Th8G4E,405
-aalpy/base/Automaton.py,sha256=GHy5c9CyGPmNfxBzlOzKNz6XUVj3jiBe0OIOf6_pWDE,17238
-aalpy/base/CacheTree.py,sha256=3z0yZ_Ce2SGoXDpeNDzjZnZU1sExNybABj1yvMas62Q,5736
-aalpy/base/Oracle.py,sha256=57eNkzlrWE6ETKZxjZfGuFI-kzjqXkMYAjgoKcHglrg,1229
-aalpy/base/SUL.py,sha256=ywlHPQSh5CcnXzkxUrxIMxJr03dou8u2RIBjkJaaJfk,4120
-aalpy/base/__init__.py,sha256=YnCibXYW2b_bz5HbIqeMUWo0ujX8gUoYQF2YpCXHVFc,124
-aalpy/learning_algs/__init__.py,sha256=q5LU5XI5VXHpahlw69zGfAAijTawDqWCDqNjm7TNTME,587
-aalpy/learning_algs/deterministic/ClassificationTree.py,sha256=OkBRebUKiWyMZEXNMYJDIKj-o6tuGuC340RWqQpkyZU,21155
-aalpy/learning_algs/deterministic/CounterExampleProcessing.py,sha256=jSk8Cat3VMXgAO54pzGh52VK5nD7ASiQcZh3PDiaEuA,7034
-aalpy/learning_algs/deterministic/KV.py,sha256=4e_msCmnl3SHPXZT4NBJAiYh4iJnno2i4ncpHACpJp4,6767
-aalpy/learning_algs/deterministic/LStar.py,sha256=3wMkEpoE8NUwDDZGs3kumdK-qGg7zB5Bz6zjDq5FUZc,8335
-aalpy/learning_algs/deterministic/ObservationTable.py,sha256=zfhs7NW_rFZPY24iIdwScWtsPp09zYRtDKkrjzbOh9Y,8318
+aalpy/__init__.py,sha256=mdXJfcvfyvqHsC54HCpzLTvJDnv8L1H3I6dvpcfC1_k,2015
+aalpy/paths.py,sha256=6aIoWlVEEsMnWCbBxQVKkkEKbUvC4GnH1wkBrQIJZzQ,448
+aalpy/SULs/AutomataSUL.py,sha256=TuujyipQ4Ra4cAaZz7W7oGtyOO-UlKeYU6hb487obQM,485
+aalpy/SULs/PyMethodSUL.py,sha256=Bp-ReQnT9K40yZdvwGXl3iiQbRbKUvB-ChvpB5Sd0JM,1677
+aalpy/SULs/RegexSUL.py,sha256=b4QfyzcnE2M92CN95cEozLj8sWokWZdia-K6ajCiFrk,906
+aalpy/SULs/TomitaSUL.py,sha256=O3xaGdkXaFjazTM9GsHovxROfaZ5dwGuCzSdg1gxRgU,1478
+aalpy/SULs/__init__.py,sha256=GThdmHkQDnSafZH7tEHNbeJq-t7LC9kjb_DZyXWkq6U,146
+aalpy/automata/Dfa.py,sha256=bASH8gyflrY5uIrjv89AjowpwXvbpn3bXLYxSdWJo-8,3639
+aalpy/automata/MarkovChain.py,sha256=6xLEx_z7VBQPw9F9OGkElYmsBltSUMsfDS0ACEKZQkg,2019
+aalpy/automata/Mdp.py,sha256=hRy3DBn-K4nyDsyIyM86wKfNl1ju_8zTcRth5gahGpI,3109
+aalpy/automata/MealyMachine.py,sha256=O1ttIG6ocTVTmMQ6CkhThh3a-A9FZLS7vlzzunub6Go,3193
+aalpy/automata/MooreMachine.py,sha256=94Z-agjKxdO5d65GsDYZCmyGHuP9pW-pYDw0v5-XIac,3575
+aalpy/automata/Onfsm.py,sha256=9oKWHKqKt2IotRlh8bxQ4JZIRBhPHegOIsvnwG_bZSw,2929
+aalpy/automata/Sevpa.py,sha256=1OR8jXI-Zt271lq2rzVuPvTa7hSemkQZZVflnM2e-jY,23609
+aalpy/automata/StochasticMealyMachine.py,sha256=-fXMrZAIYAiQZKCljG4lteg3HV36GiUVYFlEbIadMjM,4899
+aalpy/automata/__init__.py,sha256=tukasJ1KAwEKo_AOvgmWnwc66V1nb2IETEFogP0OKZM,397
+aalpy/base/Automaton.py,sha256=P4tjmMNvjqO-sazCI5ooeoqTFr3gxNA6p61x2i4mZq0,16904
+aalpy/base/CacheTree.py,sha256=VMOjXlhHZZn1n-je8nBUcAidEDzNwLtlJsuEmiFZ4lM,5567
+aalpy/base/Oracle.py,sha256=NQH6EqMAATISHaegIkiXEfRA8EesaM1mFwK3dFcfGlU,1178
+aalpy/base/SUL.py,sha256=IcYrtS4yDumzE9PQf0Yyc-LhVlLr0bOd72VKJJL2PQU,4066
+aalpy/base/__init__.py,sha256=n9-0MEorB3OczbK-p90_NVa4DUgy7QlYsiODZeOsc-s,121
+aalpy/learning_algs/__init__.py,sha256=sgYCpJV620towe11uslQnnZGkGzH8K6N8sLyXcPgpZ4,577
+aalpy/learning_algs/deterministic/ClassificationTree.py,sha256=aAFWhKtP7_jDxwaTBtjdYZNKFywpaTzCFwvF5WKxdwI,20713
+aalpy/learning_algs/deterministic/CounterExampleProcessing.py,sha256=tcXNk8S36CzS5p6vw1xqFEHrm3U4QCm7baZTzIr_VOU,6815
+aalpy/learning_algs/deterministic/KV.py,sha256=ZZgPfn5bnziFHlVLWvu461mT0TBPgpm3NhBkjJNz3Ns,6597
+aalpy/learning_algs/deterministic/LStar.py,sha256=KuvaGmmE_Up8uUZNmdu1NesCmQbkR7pXEiAPxoxxJ0g,8145
+aalpy/learning_algs/deterministic/ObservationTable.py,sha256=FlpdmWITCMRCc_qGLS8W_oES2dejOur7tdgsgiqjCPg,8099
 aalpy/learning_algs/deterministic/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-aalpy/learning_algs/deterministic_passive/GeneralizedStateMerging.py,sha256=hZ6IOA0PGbD1iXsMuMe9RoeR5EgqAaop8XvgYAbnekg,4060
-aalpy/learning_algs/deterministic_passive/RPNI.py,sha256=gfPJT1o1EFIZcLAE0AwPx5vaQ5tNOJR7NOygKCcdkfE,7807
+aalpy/learning_algs/deterministic_passive/GeneralizedStateMerging.py,sha256=722NaCDO8Z-PkomCdepKkHMpXEA54rgPhXk33efXzOI,3954
+aalpy/learning_algs/deterministic_passive/RPNI.py,sha256=28_Yeh0EYLZxvmYtlZffsCbvg5a00ROgrMNpizNa3_c,7619
 aalpy/learning_algs/deterministic_passive/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-aalpy/learning_algs/deterministic_passive/active_RPNI.py,sha256=6pN-SyGQG2GO0c8L7sVfK1qXqs-QzkaBbIC4CVdPAXE,1880
-aalpy/learning_algs/deterministic_passive/rpni_helper_functions.py,sha256=MT4vxObNXxremY-_Zi1Z4F4AxrAJAF1fCfZWzcEQypc,9298
-aalpy/learning_algs/non_deterministic/AbstractedOnfsmLstar.py,sha256=AMUGrQ7OCXnaX5LjnDjQJybaK8WVtG4EI4rTU2N0V0Q,6426
-aalpy/learning_algs/non_deterministic/AbstractedOnfsmObservationTable.py,sha256=8RQA2st0UsxOKkKuscKQg8S6wzgE1yvo4tfkKE37Gys,15947
-aalpy/learning_algs/non_deterministic/NonDeterministicSULWrapper.py,sha256=LnpY_uL7d-fIt2FEEy_prOGsYUGJrLf-E4gqxe83JV0,659
-aalpy/learning_algs/non_deterministic/OnfsmLstar.py,sha256=jBWVMaSYLv-rlKv2MnVhzgHVTPRsPmDlYm4RKn1nCFk,5020
-aalpy/learning_algs/non_deterministic/OnfsmObservationTable.py,sha256=87kyd4YvFQJc7AV86fAKDSTmrxb8dWYtr7Gkh_ht5r0,7032
-aalpy/learning_algs/non_deterministic/TraceTree.py,sha256=6aSS1344Wa3Aq_tQZLVIB3OL7M_rWGJye_1hx6qEdsA,6011
+aalpy/learning_algs/deterministic_passive/active_RPNI.py,sha256=f7WakEOC34mQn6bqPzwdC78g1h9zW-snSdpoFCp9rCE,1818
+aalpy/learning_algs/deterministic_passive/rpni_helper_functions.py,sha256=B4rMmozRUUGexTUIQM9s7pj0pJ3Slbcj4oZ8nO6EzFY,9033
+aalpy/learning_algs/non_deterministic/AbstractedOnfsmLstar.py,sha256=17z73iXQrYwMwDhRprqnJs9AdMg_BVWUmgGeGKYsaN8,6280
+aalpy/learning_algs/non_deterministic/AbstractedOnfsmObservationTable.py,sha256=IFNwi9wALmS4So6PUpz8WVaFi7JUBDytnMijME-Wg2w,15505
+aalpy/learning_algs/non_deterministic/NonDeterministicSULWrapper.py,sha256=uUzaFJQ8K6GwsWyj6PaunMaL08JVOkYNhHoR1jiUnVQ,634
+aalpy/learning_algs/non_deterministic/OnfsmLstar.py,sha256=G_nvZBrNAO-W5GoDBRRzUj8Cm9myct-0n1W5j76Wuz4,4870
+aalpy/learning_algs/non_deterministic/OnfsmObservationTable.py,sha256=I64eN2XQ0i7vdJABSyekzUkeZL0zM7kFbTpma285zp4,6828
+aalpy/learning_algs/non_deterministic/TraceTree.py,sha256=N_DpH2NTFk57wtSATAEbq_7mHNJ6zjPzkXMtsIo9EOE,5808
 aalpy/learning_algs/non_deterministic/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-aalpy/learning_algs/stochastic/DifferenceChecker.py,sha256=PXwzjCfGJhx4iXoeCbYSOIZ6OHwWyqV-fC0BI1x1Yw0,7764
-aalpy/learning_algs/stochastic/SamplingBasedObservationTable.py,sha256=piQNN4NmfEfeBG-zymlO-rtePvW0P6CX5cm0MwdyRws,25536
-aalpy/learning_algs/stochastic/StochasticCexProcessing.py,sha256=BlVwtzCfkd3fuRsPbqjEWw_SBQP2URjX7GjDuT3BAxY,3426
-aalpy/learning_algs/stochastic/StochasticLStar.py,sha256=5T1o5EqEnT1VOAuZxcLo3zb5X7jVtiLCtlcllf3XR6c,10173
-aalpy/learning_algs/stochastic/StochasticTeacher.py,sha256=9lSGe4ABHlJkhj4QY7xEuIDnw2VSx9dHyO-_jTJCAuk,13239
+aalpy/learning_algs/stochastic/DifferenceChecker.py,sha256=A6XBlZYbqv2omOMoGdaFS9q1E9LvHfxl6-jnjiX7t4U,7587
+aalpy/learning_algs/stochastic/SamplingBasedObservationTable.py,sha256=Ur-MD9DlbsIISMzeuAPmNmW-ExB4KJZb_2epOHJasak,24894
+aalpy/learning_algs/stochastic/StochasticCexProcessing.py,sha256=CERL0cmypQ6PuS2LwgQfBBoYeA-OHaPTtm2bedRdf-c,3296
+aalpy/learning_algs/stochastic/StochasticLStar.py,sha256=KImK-9pM9aztqf2GYbuuNxcBB5aJw_sIMuOePZ66ef0,9953
+aalpy/learning_algs/stochastic/StochasticTeacher.py,sha256=eyEA3M6lA5vEGJ4UGZViG3bsBm4Ts-nNs61t12ZM6xc,12846
 aalpy/learning_algs/stochastic/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-aalpy/learning_algs/stochastic_passive/ActiveAleriga.py,sha256=WC7vkQFUiFNVr5JcRUmiimCKrgOz_xEHLnaQ_vh2WiU,2892
-aalpy/learning_algs/stochastic_passive/Alergia.py,sha256=gkpf-UcrVTLMkwWa_C1E3UiIRXlqeV7SG9vmvuK9S0U,10137
-aalpy/learning_algs/stochastic_passive/CompatibilityChecker.py,sha256=mobapi4bBeO6wIxK9O83ZQVN965aYH0EwLalFMWqakc,1757
-aalpy/learning_algs/stochastic_passive/FPTA.py,sha256=Yc0gL5lpXw86ULvoBneMSjfJMBkltMOFDuVdndW2i84,3153
+aalpy/learning_algs/stochastic_passive/ActiveAleriga.py,sha256=4SOTAn5sBGcq7Px8SysPku4Flnd3cxB1L4FR-LHWyrM,2804
+aalpy/learning_algs/stochastic_passive/Alergia.py,sha256=LIBF4WcHc4RAaghjrmCBi6To8R4F3wmM-DpSYfS0bjA,9869
+aalpy/learning_algs/stochastic_passive/CompatibilityChecker.py,sha256=yr95hXqoGZPlWZ8rxJiQqK-heCJ3_1pziXAtkfVNt28,1707
+aalpy/learning_algs/stochastic_passive/FPTA.py,sha256=3u7xZBkfEB8kD9sBx3chTI0flLyqm75LKvbtEYCxSVY,3065
 aalpy/learning_algs/stochastic_passive/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-aalpy/oracles/BreadthFirstExplorationEqOracle.py,sha256=yI3ITVkuZ2Hzs65mStBmVf4HxvcLS7fy7sTqYqbJCJ0,1433
-aalpy/oracles/CacheBasedEqOracle.py,sha256=dNwoi4Lzxvuh1GwGe9Q9YFdFWdIxwL-cLRkUvBeiPcg,3135
+aalpy/oracles/BreadthFirstExplorationEqOracle.py,sha256=k2RWXIFFbBgeL1G2aCCR-FyTR7EnRr9qhICl8nVSF9A,1382
+aalpy/oracles/CacheBasedEqOracle.py,sha256=hi5eQiOf93NbyUdsB7oCaqkiDycQ4gNGpqJqKquX3I0,3038
 aalpy/oracles/PacOracle.py,sha256=7Wg4_WeFis2qw-JKlgv2WrFcbCcCdCSUZIVPWsi55LI,1670
-aalpy/oracles/PerfectKnowledgeEqOracle.py,sha256=T-ENWskF-pibox93FT9AZIFpn17ZNDVn4UatVP3mWZc,622
-aalpy/oracles/ProvidedSequencesOracleWrapper.py,sha256=fxaZ8zgqlODJEZTgG62efHx9iSkZmsMO2BEIhsEcE9Q,1670
-aalpy/oracles/RandomWalkEqOracle.py,sha256=G60D_tPQjFI_FM3BbSuMBODkd00DjLGNG0LWJAEY0Pg,2986
-aalpy/oracles/RandomWordEqOracle.py,sha256=evhAt6i5aCQnzzR2SRX82idXQs9W8o8WbY-PxmhT7J0,3438
-aalpy/oracles/StatePrefixEqOracle.py,sha256=6dq60ZRLoHQD_OXX3UN3ym2h2jSV4jhCXWvh8DYmbs4,2816
-aalpy/oracles/TransitionFocusOracle.py,sha256=xuZKrHAkE_lMuaH-RVABanewuhqZANbusGof5o8gXfU,2023
-aalpy/oracles/UserInputEqOracle.py,sha256=kwpFdX3CcyQuQTWWHpwoGcZXr8-C5AsFNOr__qvDsr0,2636
-aalpy/oracles/WMethodEqOracle.py,sha256=6HiCRKSsM9pcqzIMz7B2322HCtPlXpW2xQcGoyJ0NmM,4522
-aalpy/oracles/__init__.py,sha256=Q5L4RYVW7cABJig5E9jNSn652K8wLaJNbNiy18BJmOg,781
-aalpy/oracles/kWayStateCoverageEqOracle.py,sha256=tXgTEXDpkUFibPeBSo_m8EMqQgNe-4wvSbs8k4q4Z0k,2676
-aalpy/oracles/kWayTransitionCoverageEqOracle.py,sha256=5OrwPikjFc_KnQGTTQVpSYNah1XDWpsBAJ2sN5dYZ6g,6429
-aalpy/utils/AutomatonGenerators.py,sha256=TP67rk5PiZn9eTxYfHIu03pbX8Vp4feRvbB6lY-8kf0,22736
-aalpy/utils/BenchmarkSULs.py,sha256=-MaQJcT6vFl4yL0AOlWEXr70mvTkgo39T8OA3IRxdF8,13340
-aalpy/utils/BenchmarkSevpaModels.py,sha256=dNnUlk8cJU55TMyQvsZEJiMWWf9PAIjKmY8kK1afM8U,11066
-aalpy/utils/DataHandler.py,sha256=qmvn7RGKeiMkufrF-ccCYWsRrhO5dX9ZfdTuSTMSNZ0,2226
-aalpy/utils/FileHandler.py,sha256=bCXU-7_Vf7ckxS9IMuAsPOz46_AXuUGotwUctnycda4,15209
-aalpy/utils/HelperFunctions.py,sha256=9qTIGSv3d-zSB5DrjlBi-jy3oOzsjs_ULRa3-q1yjLc,11482
-aalpy/utils/ModelChecking.py,sha256=V2wmT6eZMoekwvhsXPda24b2gdM4cy7y3DhTBuUp7oQ,16196
-aalpy/utils/__init__.py,sha256=sn_XK_1Bs4zayvciERwtCXxcLhMSfI_4pqGCO978p8I,850
-aalpy-1.4.0.dist-info/LICENCE.txt,sha256=xqBBzioane_kvCV7bgAuNpC2jA88D_XU8-Fh2DX7lAs,1202
-aalpy-1.4.0.dist-info/METADATA,sha256=NiODD-e5Byadop_mzFbIa5MvPtatxObKqXzBMEHBTp8,10329
-aalpy-1.4.0.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-aalpy-1.4.0.dist-info/top_level.txt,sha256=Y20GlNzDowGtNjqyE09gUKkpPEoWwOzqrC_RzAAX0Hg,6
-aalpy-1.4.0.dist-info/RECORD,,
+aalpy/oracles/PerfectKnowledgeEqOracle.py,sha256=fnG_78t51oBwi4tDMjCqV5w-WL67hbOzo18LNkbsQL8,607
+aalpy/oracles/ProvidedSequencesOracleWrapper.py,sha256=Z24Ind2g1XE81_V3p-xdxmW9RqLJHfbvkaWUcXEjJPg,1624
+aalpy/oracles/RandomWalkEqOracle.py,sha256=DgPnuYYEmnp-3BeyKiifv44AyMS65leKxf1-vYyY32I,2898
+aalpy/oracles/RandomWordEqOracle.py,sha256=KQHxwpet4LpL3d1p7fFAi-aeYkl_CYpW1bZs9tgwDuo,3343
+aalpy/oracles/StatePrefixEqOracle.py,sha256=NfgZ_8sTIaLf7nqMf814GS-xbHC9YTsVKMBuBnP4m7Q,2738
+aalpy/oracles/TransitionFocusOracle.py,sha256=DwMSyqKCAD5dqYGEH-WbGe4IVtS_fIm7xa-gAACexvw,1970
+aalpy/oracles/UserInputEqOracle.py,sha256=1Evzm_98E4J0i-U8TJQRHLQI6vaBquvSIcyWYx3Ponc,2567
+aalpy/oracles/WMethodEqOracle.py,sha256=jXUoCHbSxSPCjSgNbMpX6BuTqsmjSf5-dkcNtq0FsFY,4399
+aalpy/oracles/__init__.py,sha256=sRc5ZP8vXkqGGmnFsEcypEF1jTOEOVn_gcf-j2q9WAA,768
+aalpy/oracles/kWayStateCoverageEqOracle.py,sha256=89e3ghLi1SFXSyKqRZLHTQ99Tjh55p0IfvjZxRjYIcM,2595
+aalpy/oracles/kWayTransitionCoverageEqOracle.py,sha256=k1WkyNN_0EjYII8tEicCmXfNcgXMuT1V1B0MRdoL8WA,6264
+aalpy/utils/AutomatonGenerators.py,sha256=U_tsMtOebnKAbYwigdXVw2ytFJ4Uu-bGDKz-EN0dPj8,21736
+aalpy/utils/BenchmarkSULs.py,sha256=o6bbM1QlJ3qK1AQeN_83m2yxL8ApvDJBTGIFWnJUzX8,12908
+aalpy/utils/BenchmarkSevpaModels.py,sha256=bwlHVg0Z6CtL7ge0YV0LA2HwSyDF_Bczh6aq0Jnkfd4,10773
+aalpy/utils/DataHandler.py,sha256=jscODbOQRuWMKtoR7ou6RKy8hNe0aWCI3lor_M8Viq4,2153
+aalpy/utils/FileHandler.py,sha256=UEdJ1teH5j1BKchw62o04tPzMoGRzKwu9ghmG0XFkkA,18958
+aalpy/utils/HelperFunctions.py,sha256=b7pBGB967kku-7lThIxAm2oP5hoWk37gccEDe6zAYL0,11157
+aalpy/utils/ModelChecking.py,sha256=YAmGf0BOJSeFgg-mvNKdf-e1fjrdSQu-hVxcIvrickI,15774
+aalpy/utils/__init__.py,sha256=ksx2gyt0S-XppoY2H1mtCpEp2gAWXawcZ8xFZcG6n0M,841
+aalpy-1.4.1.dist-info/LICENCE.txt,sha256=6PhOo_OnpkgcIlwLIVzqTEBv-a9-gYw-BAV4HIdO-Y0,1181
+aalpy-1.4.1.dist-info/METADATA,sha256=cm2c767uRz9Hgmo14RqlYr1OzPC0f45qUKwI0KLC4JI,10325
+aalpy-1.4.1.dist-info/WHEEL,sha256=D1Wh14kWDxPnrM-5t_6UCB-UuQNrEODtRa3vF4OsvQY,97
+aalpy-1.4.1.dist-info/top_level.txt,sha256=Y20GlNzDowGtNjqyE09gUKkpPEoWwOzqrC_RzAAX0Hg,6
+aalpy-1.4.1.dist-info/RECORD,,
```

